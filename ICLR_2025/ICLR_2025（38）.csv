type,name,virtualsite_url,speakers/authors,abstract
Poster,Beyond Sequence: Impact of Geometric Context for RNA Property Prediction,https://iclr.cc//virtual/2025/poster/30672,"Junjie Xu, Artem Moskalev, Tommaso Mansi, Mangal Prakash, Rui Liao","Accurate prediction of RNA properties, such as stability and interactions, is crucial for advancing our understanding of biological processes and developing RNA-based therapeutics. RNA structures can be represented as 1D sequences, 2D topological graphs, or 3D all-atom models, each offering different insights into its function. Existing works predominantly focus on 1D sequence-based models, which overlook the geometric context provided by 2D and 3D geometries. This study presents the first systematic evaluation of incorporating explicit 2D and 3D geometric information into RNA property prediction, considering not only performance but also real-world challenges such as limited data availability, partial labeling, sequencing noise, and computational efficiency. To this end, we introduce a newly curated set of RNA datasets with enhanced 2D and 3D structural annotations, providing a resource for model evaluation on RNA data. Our findings reveal that models with explicit geometry encoding generally outperform sequence-based models, with an average prediction RMSE reduction of around 12% across all various RNA tasks and excelling in low-data and partial labeling regimes, underscoring the value of explicitly incorporating geometric context. On the other hand, geometry-unaware sequence-based models are more robust under sequencing noise but often require around 2-5x training data to match the performance of geometry-aware models. Our study offers further insights into the trade-offs between different RNA representations in practical applications and addresses a significant gap in evaluating deep learning models for RNA tasks."
Poster,Beyond Single Concept Vector: Modeling Concept Subspace in LLMs with Gaussian Distribution,https://iclr.cc//virtual/2025/poster/30487,"Haiyan Zhao, Heng Zhao, Bo Shen, Ali Payani, Fan Yang, Mengnan Du","Probing learned concepts in large language models (LLMs) is crucial for understanding how semantic knowledge is encoded internally. Training linear classifiers on probing tasks is a principle approach to denote the vector of a certain concept in the representation space. However, the single vector identified for a concept varies with both data and training, making it less robust and weakening its effectiveness in real-world applications. To address this challenge, we propose an approach to approximate the subspace representing a specific concept. Built on linear probing classifiers, we extend the concept vectors into Gaussian Concept Subspace (GCS). We demonstrate GCS's effectiveness through measuring its faithfulness and plausibility across multiple LLMs with different sizes and architectures. Additionally, we use representation intervention tasks to showcase its efficacy in real-world applications such as emotion steering. Experimental results indicate that GCS concept vectors have the potential to balance steering performance and maintaining the fluency in natural language generation tasks."
Poster,Beyond single neurons: population response geometry in digital twins of mouse visual cortex,https://iclr.cc//virtual/2025/poster/28582,"Dario Liscai, Emanuele Luconi, Alessandro Marin Vargas, Alessandro Sanzeni","Hierarchical visual processing  is essential for cognitive functions like object recognition and spatial localization. Traditional studies of the neural basis of these computations have focused on single-neuron activity, but recent advances in large-scale neural recordings emphasize the growing need to understand computations at the population level. Digital twins-computational models trained on neural data-have successfully replicated single-neuron behavior, but their effectiveness in capturing the joint activity of neurons remains unclear. In this study, we investigate how well digital twins describe population responses in  mouse visual cortex. We show that these models fail to accurately represent the geometry of  population activity, particularly its differentiability and how this geometry evolves across the visual hierarchy. To address this, we explore how dataset, network architecture, loss function, and training method affect the ability of digital twins to recapitulate population properties. We demonstrate that improving model alignment with experiments requires training strategies that enhance robustness and generalization, reflecting principles observed in biological systems. These findings underscore the need to evaluate digital twins from multiple perspectives, identify key areas for refinement, and establish a foundation for using these models to explore neural computations at the population level."
Poster,Beyond Squared Error: Exploring Loss Design for Enhanced Training of Generative Flow Networks,https://iclr.cc//virtual/2025/poster/31016,"Rui Hu, Yifan Zhang, Zhuoran Li, Longbo Huang","Generative Flow Networks (GFlowNets) are a novel class of generative models designed to sample from unnormalized distributions and have found applications in various important tasks, attracting great research interest in their training algorithms. In general, GFlowNets are trained by fitting the forward flow to the backward flow on sampled training objects. Prior work focused on the choice of training objects, parameterizations, sampling and resampling strategies, and backward policies, aiming to enhance credit assignment, exploration, or exploitation of the training process. However, the choice of regression loss, which can highly influence the exploration and exploitation behavior of the under-training policy, has been overlooked. Due to the lack of theoretical understanding for choosing an appropriate regression loss, most existing algorithms train the flow network by minimizing the squared error of the forward and backward flows in log-space, i.e., using the quadratic regression loss. In this work, we rigorously prove that distinct regression losses correspond to specific divergence measures, enabling us to design and analyze regression losses according to the desired properties of the corresponding divergence measures. Specifically, we examine two key properties: zero-forcing and zero-avoiding, where the former promotes exploitation and higher rewards, and the latter encourages exploration and enhances diversity. Based on our theoretical framework, we propose three novel regression losses, namely, Shifted-Cosh, Linex(1/2), and Linex(1). We evaluate them across three benchmarks: hyper-grid, bit-sequence generation, and molecule generation. Our proposed losses are compatible with most existing training algorithms, and significantly improve the performances of the algorithms concerning convergence speed, sample diversity, and robustness."
Poster,Beyond Surface Structure: A Causal Assessment of LLMs' Comprehension ability,https://iclr.cc//virtual/2025/poster/28795,"Yujin Han, Lei Xu, Sirui Chen, Difan Zou, Chaochao Lu","Large language models (LLMs) have shown remarkable capability in natural language tasks, yet debate persists on whether they truly comprehend deep structure (i.e., core semantics) or merely rely on surface structure (e.g., presentation format). Prior studies observe that LLMs' performance declines when intervening on surface structure, arguing their success relies on surface structure recognition. However, surface structure sensitivity does not prevent deep structure comprehension. Rigorously evaluating LLMs' capability requires analyzing both, yet deep structure is often overlooked. To this end, we assess LLMs' comprehension ability using causal mediation analysis, aiming to fully discover the capability of using both deep and surface structures. Specifically, we formulate the comprehension of deep structure as direct causal effect (DCE) and that of surface structure as indirect causal effect (ICE), respectively. To address the non-estimability of original DCE and ICE --- stemming from the infeasibility of isolating mutual influences of deep and surface structures, we develop the corresponding quantifiable surrogates, including approximated DCE (ADCE) and approximated ICE (AICE). We further apply the ADCE to evaluate a series of mainstream LLMs (and the one with random weights), showing that most of them exhibit deep structure comprehension ability, which grows along with the prediction accuracy. Comparing ADCE and AICE demonstrates closed-source LLMs (e.g., GPT) rely more on deep structure, while open-source LLMs (e.g., Llama) are more surface-sensitive, which decreases with model scale. Theoretically, ADCE is a bidirectional evaluation, which measures both the sufficiency and necessity of deep structure changes in causing output variations, thus offering a more comprehensive assessment than accuracy, a common evaluation in LLMs. Our work provides new insights into LLMs' deep structure comprehension and offers novel methods for LLMs evaluation. The code for our project is available at  [ADCE Project](https://github.com/OpenCausaLab/ADCE)."
Poster,Beyond the convexity assumption: Realistic tabular data generation under quantifier-free real linear constraints,https://iclr.cc//virtual/2025/poster/28159,"Mihaela Stoian, Eleonora Giunchiglia","Synthetic tabular data generation has traditionally been a challenging problem due to the high complexity of the underlying distributions that characterise this type of data. Despite recent advances in deep generative models (DGMs), existing methods often fail to produce realistic datapoints that are well-aligned with available background knowledge.In this paper, we address this limitation by introducing Disjunctive Refinement Layer (DRL), a novel layer designedto enforce the alignment of generated data with the background knowledge specified in user-defined constraints.DRL is the first method able to automatically make deep learning models inherently compliant with constraints as expressive as quantifier-free linear formulas, which can define non-convex and even disconnected spaces. Our experimental analysis shows that DRL not only guarantees constraint satisfaction but also improves efficacy in downstream tasks. Notably, when applied to DGMs that frequently violate constraints, DRL eliminates violations entirely. Further, it improves performance metrics by up to 21.4\% in F1-score and 20.9\% in Area Under the ROC Curve, thus demonstrating its practical impact on data generation."
Poster,Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models,https://iclr.cc//virtual/2025/poster/31514,"Clemencia Siro, Guy Gur-Ari, Gaurav Mishra, Stuart Shieber, Jason Phang, Zijie Wang, Kory Mathewson, Giorgio Mariani, Allen Nie, James Y Zou, Behnam Neyshabur, Karl Krauth, Shixiang Gu, Pablo Antonio Moreno Casares, Maarten Sap, Mohit Tiwari, Bill Yuchen Lin, Aykut Erdem, Angelica Chen, Swaroop Mishra, Chenlin Meng, Ashish Sabharwal, James Simon, Louis-Philippe Morency, Kyle Richardson, Emanuele Rodolà, Adam Fisch, Simone Melzi, Kristen Chiafullo, Rif A. Saurous, Shubh Pachchigar, Siamak Shakeri, Aitor Lewkowycz, Yonatan Belinkov, Mihir Kale, Mantas Mazeika, Dar Gilboa, Hongming Zhang, Seung Jae Lee, Owain Evans, Ambrose Slone, David Dohan, Damien Sileo, Mor Geva, Cameron Diao, Christopher Potts, Jekaterina Novikova, Alicia Parrish, Debajyoti Datta, Chitta Baral, Maarten Bosma, Michael Strube, Jiacheng Xu, Trishala Neeraj, Colin Raffel, Leo Gao, Vishakh Padmakumar, Yu (Hope) Hou, Christopher Waites, Ellie Pavlick, Pouya Pezeshkpour, Nanyun (Violet) Peng, Gerard de Melo, Martin Potthast, Aarohi Srivastava, Abhinav Rastogi, Abu Awal Md Shoeb, Adam Brown, Adam Santoro, Aditya Gupta, Agnieszka Kluska, Diyi Yang, Akshat Agarwal, Alexander Kocurek, Ali Safaya, Ali Tazarv, Alice Xiang, Aman Hussain, Amanda Askell, Amanda Dsouza, Ameet Rahane, Anantharaman S. Iyer, Andrea Madotto, Andrea Santilli, Andreas Stuhlmüller, Andrew La, Ethan Dyer, Angela Jiang, Anh Vuong, Animesh Gupta, Anna Gottardi, Antonio Norelli, Anu Venkatesh, Arash Gholamidavoodi, Arfa Tabassum, Arul Menezes, Arun Kirubarajan, Asher Mullokandov, Austin Herrick, Avia Efrat, Ayla Karakaş, B. Roberts, Bao Loe, Bartłomiej Bojanowski, Benjamin Inden, Benno Stein, Batuhan Özyurt, Behnam Hedayatnia, Blake Howald, Bryan Orinion, Cameron Dour, Catherine Stinson, Cedrick Argueta, Cesar Ferri, Chandan Singh, Charles Rathkopf, Christian Voigt, Cindy Ramirez, Clara Rivera, Noah Fiedel, Courtney Ashcraft, Dan Garrette, Dan Kilman, C. Freeman, Daniel Levy, Daniel González, Danielle Perszyk, Danny Hernandez, David Jurgens, Deep Ganguli, Denis Emelin, Denis Kleyko, Deniz Yuret, Derek Chen, Mátyás Schubert, Derek Tam, Dilyar Buzan, Shyam Upadhyay, Dimitri Coelho Mollo, Dylan Schrader, Ekaterina Shutova, Elad Segal, Eleanor Hagerman, Elizabeth Barnes, Elizabeth Donoway, Emma Lam, Eric Tang, Ernie Chang, Ethan Chi, Ethan Jerzak, Ethan Kim, Eunice Manyasi, Evgenii Zheltonozhskii, Fanyue Xia, Fernando Martínez-Plumed, Francesca Happé, Gloria X Wang, Gonzalo Jaimovitch-Lopez, Gregor Betz, Hana Galijasevic, Hannah Kim, Hannah Rashkin, Hayden Bogar, Henry Shevlin, Hiromu Yakura, Hugh Wong, Kumar Shridhar, Ian Ng, Isaac Noble, Jaap Jumelet, Jack Geissinger, Jackson Kernion, James Zheng, Jan Kocon, Jana Thompson, Janelle Wingfield, Jared Kaplan, Jarema Radom, Jelle Bosscher, Jennifer Marsh, Jeremy Kim, Jeroen Taal, Jesujoba Alabi, Jillian Tang, Joan Waweru, John Burden, Dieuwke Hupkes, John Balis, Jonathan Batchelder, Jörg Frohberg, Jose Hernandez-Orallo, Joseph Boudeman, Joseph Guerr, Joseph Jones, Joshua Rule, Joyce Chua, Kamil Kanclerz, Karthik Gopalakrishnan, Katerina Ignatyeva, Li Zhang, Liam Dugan, Katja Markert, Kaustubh Dhole, Lucas Lam, Kevin Omondi, Kyle McDonell, Laria Reynolds, Lianhui Qin, Lidia Contreras-Ochando, Lucy Noble, Ludwig Schmidt, Luheng He, Luis Oliveros-Colón, Lütfi Kerem Senel, Maria Jose Ramirez-Quintana, Maartje Ter Hoeve, Mohit Bansal, Martha Lewis, Maheen Farooqi, Marco Baturan, Marco Marelli, Marco Maru, Marie Tolkiehn, Michael A. Yee, Mario Giulianelli, Michael Gu, Michael Ivanitskiy, Matthias Hagen, Medina Baitemirova, Mike Cain, Mimee Xu, Mitch Walker, Moin Aminnaseri, Mozhdeh Gheini, Nathan Chi, Michael Starritt, Michał Swędrowski, Michele Bevilacqua, Nayeon Lee, Neta Krakover, Nicholas Cameron, Nick Doiron, Nicole Martinez, Nikita Nangia, Niklas Deckers, Niveditha Iyer, Nuan Wen, Oliver Zhang, Omar Agha, Omar Elbaghdadi, Parth Doshi, Pascale Fung, Pegah Alipoormolabashi, Liao Peiyuan, Peter W Chang, Peter Eckersley, Phu Mon Htut, Pinyu Hwang, Piotr Miłkowski, Piyush Patil, Priti Oli, Qing Lyu, Qinlang Chen, Rabin Banjade, Rachel Rudolph, Raefer Gabriel, Rahel Habacker, Ramon Risco, Raphaël Millière, Rhythm Garg, Richard Barnes, Riku Arakawa, Robbe Raymaekers, Robert Frank, Rohan Sikand, Roman Novak, Paul Pu Liang, Rowan Jacobs, Ryan Stovall, Rylan Yang, Saif Mohammad, Sajant Anand, Sam Dillavou, Sam Wiseman, Samuel Gruetter, Sanghyun Han, Mukund Varma T, Sanjeev Kwatra, Sarah Rous, Sarik Ghazarian, Sean Casey, Sebastian Bischoff, Sebastian Gehrmann, Sepideh Sadeghi, Shadi Hamdan, Sherry Shi, Shikhar Singh, Daphne Ippolito, Shima Asaadi, Shyamolima Debnath, Simon Thormeyer, Sneha Makini, Soo-Hwan Lee, Spencer Torene, Stanislas Dehaene, Stefan Divic, Hanna Hajishirzi, Stephanie Lin, Stephen Prasad, Andrew Dai, Steven Piantadosi, Summer Misherghi, Svetlana Kiritchenko, Tao Li, Tariq Ali, Te-Lin Wu, Théo Desbordes, Theodore Rothschild, Thomas Phan, Tianle Wang, Adrià Garriga-Alonso, Tiberius Nkinyili, Timofei Kornev, Titus Tunduny, Trenton Chang, Tushar Khot, Tyler Shultz, Uri Shaham, Vedant Misra, Victoria Nyamai, Vikas Raunak, vinay prabhu, William Saunders, William Zhang, Wout Vossen, Xiaoyu Tong, Xinyi Wu, Yair Lakretz, Yichi Yang, Sophie Hao, Yifu Chen, Yufang Hou, Yuntao Bai, Zachary Seid, Cristina Garbacea, Ziyi Wu, Genta Winata, Shubham Toshniwal, Abubakar Abid, John Miller, Karen Livescu, Tatsunori Hashimoto, Ekin Cubuk, Sayan Ghosh, Harsh Mehta, Jacob Hilton, Yadollah Yaghoobzadeh, Jiaming Song, Siva Reddy, Stefano Ermon, Shashank Srivastava, Percy Liang, Chiyu Wu, James Koppel, Rui Zhang, David Drakard, Germàn Kruszewski, Dong-Ho Lee, Fatemeh Siar, Luke Metz, Roman Sitelew, Dan Hendrycks, Paul Vicol, Alexander Ray, Tobias Gerstenberg, Chris Callison-Burch, Sriharsha Hatwar, Xinran Zhao, Zijian Wang, Luca Moschella, Sam Bowman, Jaime Fernández Fisac, Danqi Chen, Stella R Biderman, Nitish Shirish Keskar, Eric Chu, Manaal Faruqui, Ksenia Shkaruta, Xudong Shen, Ryan Teehan, Vinay Ramasesh, Andy Zou, Jaehoon Lee, Hinrich Schuetze, Jesse Engel, Tal Schuster, Berk Ekmekci, Yangqiu Song, Andrew Lampinen, Dan Roth, Yasaman Bahri, Jascha Sohl-Dickstein, Jason Yosinski, Sebastian Schuster, Melody Arnaud, Russ Salakhutdinov, Nicholas Roberts, William Fedus, Sam Shleifer, Vivek Srikumar, Ronan Le Bras, Jos Rozen, Kevin Gimpel, Melvin McElrath, Omer Levy, Tal Linzen, Diganta Misra, Frieda Rong, Xiang Ren, Abhishek Rao, Mirac Suzgun, Yejin Choi, Michihiro Yasunaga, Sharon Zhou, Joshua B Tenenbaum, Sahib Singh, Michael Cohen, Tao Yu, Samuel Schoenholz, Rosanne Liu, Ryan Chi, Giambattista Parascandolo, Zhuoye Zhao, Erkut Erdem, Matthew Leavitt, Francois Chollet, Anders Andreassen, Timo Schick, Vera Demberg, Qiaozhu Mei, Daniel Khashabi, Jonathan Berant, Noah Constant, Alex Warstadt, Zirui Wang, Alethea Power, Niklas Muennighoff, Barret Zoph, Jason Wei, Christopher Manning","Language models demonstrate both quantitative improvement and new qualitative capabilities with increasing scale. Despite their potentially transformative impact, these new capabilities are as yet poorly characterized. In order to inform future research, prepare for disruptive new model capabilities, and ameliorate socially harmful effects, it is vital that we understand the present and near-future capabilities and limitations of language models.
To address this challenge, we introduce the Beyond the Imitation Game benchmark (BIG- bench). BIG-bench currently consists of 204 tasks, contributed by 450 authors across 132 institutions. Task topics are diverse, drawing problems from linguistics, childhood develop- ment, math, common-sense reasoning, biology, physics, social bias, software development, and beyond. BIG-bench focuses on tasks that are believed to be beyond the capabilities of current language models. We evaluate the behavior of OpenAI's GPT models, Google- internal dense transformer architectures, and Switch-style sparse transformers on BIG-bench, across model sizes spanning millions to hundreds of billions of parameters. In addition, a team of human expert raters performed all tasks in order to provide a strong baseline. Findings include: model performance and calibration both improve with scale, but are poor in absolute terms (and when compared with rater performance); performance is remarkably similar across model classes, though with benefits from sparsity; tasks that improve gradually and predictably commonly involve a large knowledge or memorization component, whereas tasks that exhibit ""breakthrough"" behavior at a critical scale often involve multiple steps or components, or brittle metrics; social bias typically increases with scale in settings with ambiguous context, but this can be improved with prompting."
Poster,Beyond Worst-Case Dimensionality Reduction for Sparse Vectors,https://iclr.cc//virtual/2025/poster/28947,"Sandeep Silwal, David Woodruff, Qiuyi (Richard) Zhang","We study beyond worst-case dimensionality reduction for $s$-sparse vectors (vectors with at most $s$ non-zero coordinates). Our work is divided into two parts, each focusing on a different facet of beyond worst-case analysis:\noindent (a)  We first consider average-case guarantees for embedding $s$-sparse vectors. Here, a well-known folklore upper bound based on the birthday-paradox states: For any collection $X$ of $s$-sparse vectors in $\mathbb{R}^d$, there exists a linear map $A: \mathbb{R}^d \rightarrow \mathbb{R}^{O(s^2)}$ which \emph{exactly} preserves the norm of $99\%$ of the vectors in $X$ in any $\ell_p$ norm (as opposed to the usual setting where guarantees hold for all vectors). We provide novel lower bounds showing that this is indeed optimal in many settings. Specifically, any oblivious linear map satisfying similar average-case guarantees must map to $\Omega(s^2)$ dimensions. The same lower bound also holds for a wider class of sufficiently smooth maps, including `encoder-decoder schemes', where we compare the norm of the original vector to that of a smooth function of the embedding. These lower bounds reveal a surprising separation result for smooth embeddings of sparse vectors, as an upper bound of $O(s \log(d))$ is possible if we instead use arbitrary functions, e.g., via compressed sensing algorithms. (b) Given these lower bounds, we specialize to sparse \emph{non-negative} vectors to hopes of improved upper bounds. For a dataset $X$ of non-negative $s$-sparse vectors and any $p \ge 1$, we can non-linearly embed $X$ to $O(s\log(|X|s)/\varepsilon^2)$ dimensions while preserving all pairwise distances in $\ell_p$ norm up to $1\pm \varepsilon$, with no dependence on $p$. Surprisingly, the non-negativity assumption enables much smaller embeddings than arbitrary sparse vectors, where the best known bound suffers an exponential $(\log |X|)^{O(p)}$ dependence. Our map also guarantees \emph{exact} dimensionality reduction for the $\ell_{\infty}$ norm by embedding $X$ into $O(s\log |X|)$ dimensions, which is tight. We further give separation results showing that both the non-linearity of $f$ and the non-negativity of $X$ are necessary, and provide downstream algorithmic improvements using our embedding."
Poster,Bias Mitigation in Graph Diffusion Models,https://iclr.cc//virtual/2025/poster/30512,"Meng Yu, Kun Zhan","Most existing graph diffusion models have significant bias problems. We observe that the forward diffusion’s maximum perturbation distribution in most models deviates from the standard Gaussian distribution, while reverse sampling consistently starts from a standard Gaussian distribution, which results in a reverse-starting bias. Together with the inherent exposure bias of diffusion models, this results in degraded generation quality. This paper proposes a comprehensive approach to mitigate both biases. To mitigate reverse-starting bias, we employ a newly designed Langevin sampling algorithm to align with the forward maximum perturbation distribution, establishing a new reverse-starting point. To address the exposure bias, we introduce a score correction mechanism based on a newly defined score difference. Our approach, which requires no network modifications, is validated across multiple models, datasets, and tasks, achieving state-of-the-art results."
Poster,Bidirectional Decoding: Improving Action Chunking via Guided Test-Time Sampling,https://iclr.cc//virtual/2025/poster/28245,"Yuejiang Liu, Jubayer Hamid, Annie Xie, Yoonho Lee, Max Du, Chelsea Finn","Predicting and executing a sequence of actions without intermediate replanning, known as action chunking, is increasingly used in robot learning from human demonstrations. Yet, its effects on the learned policy remain inconsistent: some studies find it crucial for achieving strong results, while others observe decreased performance. In this paper, we first dissect how action chunking impacts the divergence between a learner and a demonstrator. We find that action chunking allows the learner to better capture the temporal dependencies in demonstrations but at the cost of reduced reactivity to unexpected states. To address this tradeoff, we propose Bidirectional Decoding (BID), a test-time inference algorithm that bridges action chunking with closed-loop adaptation. At each timestep, BID samples multiple candidate predictions and searches for the optimal one based on two criteria: (i) backward coherence, which favors samples that align with previous decisions; (ii) forward contrast, which seeks samples of high likelihood for future plans. By coupling decisions within and across action chunks, BID promotes both long-term consistency and short-term reactivity. Experimental results show that our method boosts the performance of two state-of-the-art generative policies across seven simulation benchmarks and two real-world tasks. Code and videos are available at https://bid-robot.github.io."
