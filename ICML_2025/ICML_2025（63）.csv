type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Cradle: Empowering Foundation Agents towards General Computer Control,https://ICML.cc//virtual/2025/poster/46393,"Weihao Tan, Wentao Zhang, Xinrun Xu, Haochong Xia, gang Ding, Boyu Li, Bohan Zhou, Junpeng Yue, Jiechuan Jiang, Yewen Li, Ruyi An, Molei Qin, Chuqiao Zong, Longtao Zheng, YuJie Wu, Xiaoqiang Chai, Yifei Bi, Tianbao Xie, Pengjie Gu, Xiyun Li, Ceyao Zhang, Long Tian, Chaojie Wang, Xinrun Wang, Börje F. Karlsson, Bo An, Shuicheng YAN, Zongqing Lu","Despite their success in specific scenarios, existing foundation agents still struggle to generalize across various virtual scenarios, mainly due to the dramatically different encapsulations of environments with manually designed observation and action spaces. To handle this issue, we propose the General Computer Control (GCC) setting to restrict foundation agents to interact with software through the most unified and standardized interface, i.e., using screenshots as input and keyboard and mouse actions as output. We introduce Cradle, a modular and flexible LMM-powered framework, as a preliminary attempt towards GCC. Enhanced by six key modules, Information Gathering, Self-Reflection, Task Inference, Skill Curation, Action Planning, and Memory, Cradle is able to understand input screenshots and output executable code for low-level keyboard and mouse control after high-level planning and information retrieval, so that Cradle can interact with any software and complete long-horizon complex tasks without relying on any built-in APIs. Experimental results show that Cradle exhibits remarkable generalizability and impressive performance across four previously unexplored commercial video games (Red Dead Redemption 2, Cities:Skylines, Stardew Valley and Dealer's Life 2), five software applications (Chrome, Outlook, Feishu, Meitu and CapCut), and a comprehensive benchmark, OSWorld. With a unified interface to interact with any software, Cradle greatly extends the reach of foundation agents thus paving the way for generalist agents.","How can we enable AI agents to perform all kinds of computer tasks—not just browsing the web, but also playing video games and operating complex software? The Cradle framework offers an answer by allowing chatbot models like GPT-4o to use computers the same way humans do: by viewing the screen and controlling the keyboard and mouse.Rather than relying on built-in shortcuts or special software access, Cradle harnesses the power of multimodal large language models to interpret screenshots and generate code that simulates human interactions. Comprising six key modules, Cradle enables models to observe ongoing activities, reflect on past actions, plan subsequent steps, and store useful skills for future tasks, thereby effectively managing challenging and intricate assignments.Cradle has successfully completed long, complex missions in demanding games like Red Dead Redemption 2, Cities: Skylines, and Stardew Valley as well as executing various software tasks, like image and video editing. This marks a significant step toward building general-purpose AI agents that are adaptable, capable, and human-like in their digital interactions."
Poster,Craftium: Bridging Flexibility and Efficiency for Rich 3D Single- and Multi-Agent Environments,https://ICML.cc//virtual/2025/poster/44390,"Mikel Malagón, Josu Ceberio, Jose A Lozano","Advances in large models, reinforcement learning, and open-endedness have accelerated progress toward autonomous agents that can learn and interact in the real world. To achieve this, flexible tools are needed to create rich, yet computationally efficient, environments. While scalable 2D environments fail to address key real-world challenges like 3D navigation and spatial reasoning, more complex 3D environments are computationally expensive and lack features like customizability and multi-agent support. This paper introduces Craftium, a highly customizable and easy-to-use platform for building rich 3D single- and multi-agent environments. We showcase environments of different complexity and nature: from single- and multi-agent tasks to vast worlds with many creatures and biomes, and customizable procedural task generators. Benchmarking shows that Craftium significantly reduces the computational cost of alternatives of similar richness, achieving +2K steps per second more than Minecraft-based frameworks.","Artificial Intelligence (AI) systems usually require vast amounts of data to learn. For example, teaching a machine to read and write involves gathering millions of text examples; similarly, computer vision demands millions of images. Thus, if we want to teach machines to operate in the real world, we have to train these systems for hundreds of years of experience. As training AIs in the real world for hundreds of years is unfeasible (and dangerous), researchers often train them in simulated (virtual) worlds. However, these simulations are too simplistic or slow to run, making them impractical for many research scenarios.In this work, we present Craftium, a tool that allows researchers to generate very rich and complex scenarios to train and analyze AI systems. You might find Craftium visually similar to Minecraft, with huge worlds with many biomes, animals, monsters, and complex tools and artifacts. However, Craftium differentiates from Minecraft in many ways, as Minecraft is a game for humans, while Craftium is built for AI systems. For instance, Craftium allows AI agents to play more than 2,000 frames per second faster than Minecraft, which translates into much faster training times, saving time and money for researchers. Moreover, Craftium also includes several features missing in existing 3D virtual worlds, such as the ability to create completely custom scenarios and to have multiple AI agents learning and interacting together. Finally, Craftium is open, free to use, modify, and distribute for everyone."
Poster,CRANE: Reasoning with constrained LLM generation,https://ICML.cc//virtual/2025/poster/43624,"Debangshu Banerjee, Tarun Suresh, Shubham Ugare, Sasa Misailovic, Gagandeep Singh","Code generation, symbolic math reasoning, and other tasks require LLMs to produce outputs that are both syntactically and semantically correct. Constrained LLM generation is a promising direction to enforce adherence to formal grammar, but prior works have empirically observed that strict enforcement of formal constraints often diminishes the reasoning capabilities of LLMs. In this work, we first provide a theoretical explanation for why constraining LLM outputs to very restrictive grammars that only allow syntactically valid final answers reduces the reasoning capabilities of the model. Second, we demonstrate that by augmenting the output grammar with carefully designed additional rules, it is always possible to preserve the reasoning capabilities of the LLM while ensuring syntactic and semantic correctness in its outputs. Building on these theoretical insights, we propose a reasoning-augmented constrained decoding algorithm, CRANE, which effectively balances the correctness of constrained generation with the flexibility of unconstrained generation. Experiments on multiple open-source LLMs and benchmarks show that CRANE significantly outperforms both state-of-the-artconstrained decoding strategies and standard unconstrained decoding, showing up to 10% points accuracy improvement over baselines on challenging symbolic reasoning benchmarks GSM-symbolic and FOLIO.","We study the relationship between reasoning and constrained LLM generation. While strict grammar constraints can hinder reasoning, we theoretically demonstrate that augmenting the output grammar with additional rules can preserve reasoning capabilities. Building on this insight, we introduce CRANE, a decoding algorithm that balances constraint enforcement with reasoning flexibility. CRANE achieves up to 10% percentage points higher accuracy than prior methods on symbolic reasoning tasks such as GSM-symbolic and FOLIO."
Poster,Critical Tokens Matter: Token-Level Contrastive Estimation Enhances LLM’s Reasoning Capability,https://ICML.cc//virtual/2025/poster/44503,"Zicheng Lin, Tian Liang, Jiahao Xu, Qiuzhi Liu, Xing Wang, Ruilin Luo, Chufan Shi, Siheng Li, Yujiu Yang, Zhaopeng Tu","Mathematical reasoning tasks pose significant challenges for large language models (LLMs) because they require precise logical deduction and sequence analysis. In this work, we introduce the concept of critical tokens -- elements within reasoning trajectories that significantly influence incorrect outcomes. We present a novel framework for identifying these tokens through rollout sampling and demonstrate their substantial divergence from traditional error tokens. Through extensive experiments on datasets such as GSM8K and MATH500, we show that identifying and replacing critical tokens significantly improves model accuracy. We propose an efficient methodology for pinpointing these tokens in large-scale datasets using contrastive estimation and extend this framework to enhance model training processes with direct preference optimization (DPO). Experimental results on GSM8K and MATH500 benchmarks with the widely used models Llama-3 (8B and 70B) and Deepseek-math (7B) demonstrate the effectiveness of the proposed approach, cDPO. Our results underscore the potential of leveraging critical tokens to reduce errors in reasoning tasks, advancing the development of AI systems capable of robust logical deduction.","Mathematical reasoning tasks pose significant challenges for AI because they require precise logical deduction and sequence analysis.  In our research, we discovered that certain specific parts (we call them ""critical tokens"") within the AI’s reasoning steps strongly affect whether the answer is correct or not. By creating a new way to spot these crucial parts, we showed we can effectively find and fix mistakes, helping the AI solve math problems better. We tested our method thoroughly on well-known math datasets and found that identifying and correcting these critical parts significantly improved accuracy. We further developed an efficient strategy to quickly pinpoint these key elements, making it practical for large datasets and advanced AI training. Our experiments using popular AI models confirmed that focusing on these critical tokens greatly enhances the AI’s ability to reason correctly, marking an important step forward in building smarter and more reliable AI systems."
Poster,Cross-City Latent Space Alignment for Consistency Region Embedding,https://ICML.cc//virtual/2025/poster/43747,"Meng Chen, Hongwei Jia, Zechen Li, Wenzhen Jia, Kai Zhao, Hongjun Dai, Weiming Huang","Learning urban region embeddings has substantially advanced urban analysis, but their typical focus on individual cities leads to disparate embedding spaces, hindering cross-city knowledge transfer and the reuse of downstream task predictors. To tackle this issue, we present Consistent Region Embedding (CoRE), a unified framework integrating region embedding learning with cross-city latent space alignment. CoRE first embeds regions from two cities into separate latent spaces, followed by the alignment of latent space manifolds and fine-grained individual regions from both cities. This ensures compatible and comparable embeddings within aligned latent spaces, enabling predictions of various socioeconomic indicators without ground truth labels by migrating knowledge from label-rich cities. Extensive experiments show CoRE outperforms competitive baselines, confirming its effectiveness for cross-city knowledge transfer via aligned latent spaces.","Cities are complex systems with distinct regions (neighborhoods), each serving different functions like residential, commercial, or industrial areas. Understanding these urban regions is useful for tasks like population estimation or infrastructure planning. However, most AI models today analyze only one city at a time, making it hard to apply insights from one city to another.We developed Consistency Region Embedding (CoRE), a method that helps AI models learn and compare neighborhood patterns across multiple cities. Instead of treating each city separately, CoRE maps different cities into their own ""concept spaces"" and then aligns these spaces so that similar regions—even from different cities—are grouped together. For example, a business district in New York and one in Tokyo would have comparable representations, even if their exact layouts differ.This alignment allows urban planners and researchers to reuse task predictors trained on one city for another. Our experiments show that CoRE works better than existing methods, making cross-city knowledge sharing more effective. This could help improve decision-making in urban development, transportation, and public policy."
Poster,Cross-environment Cooperation Enables Zero-shot Multi-agent Coordination,https://ICML.cc//virtual/2025/poster/43490,"Kunal Jha, Wilka Carvalho, Yancheng Liang, Simon Du, Max Kleiman-Weiner, Natasha Jaques","Zero-shot coordination (ZSC), the ability to adapt to a new partner in a cooperative task, is a critical component of human-compatible AI. While prior work has focused on training agents to cooperate on a single task, these specialized models do not generalize to new tasks, even if they are highly similar. Here, we study how reinforcement learning on a **distribution of environments with a single partner** enables learning general cooperative skills that support ZSC with **many new partners on many new problems**. We introduce *two* Jax-based, procedural generators that create billions of solvable coordination challenges. We develop a new paradigm called **Cross-Environment Cooperation (CEC)**, and show that it outperforms competitive baselines quantitatively and qualitatively when collaborating with real people. Our findings suggest that learning to collaborate across many unique scenarios encourages agents to develop general norms, which prove effective for collaboration with different partners. Together, our results suggest a new route toward designing generalist cooperative agents capable of interacting with humans without requiring human data.","Imagine we want to create an artificial intelligence (AI) that can work together with people on all sorts of tasks, even tasks it's never seen before. Right now, most AI systems are trained for one specific job. They get really good at it, but if you give them a slightly different task, even a very similar one, they're lost. They can't adapt. We're exploring a different way. Instead of training an AI for a single task, we train it on a wide variety of tasks with just one partner. Think of it like a human learning to play many different sports with the same friend. This helps the AI learn general teamwork skills. To make this possible, we created two special computer programs that can generate billions of unique cooperation challenges. Then, we developed a new training method called Cross-Environment Cooperation (CEC). Our CEC method proved to be much better than other approaches when we tested our AI collaborating with real people. It seems that by learning to cooperate in many different situations, the AI develops a sense of ""general norms"" or unspoken rules for teamwork. These general norms then allow it to work effectively with completely different partners on brand new problems. Our research suggests a promising path toward creating AI that can genuinely work alongside humans without needing a lot of human-specific training data."
Poster,Cross-Modal Alignment via Variational Copula Modelling,https://ICML.cc//virtual/2025/poster/46358,"Feng Wu, Tsai Hor Chan, Fuying Wang, Guosheng Yin, Lequan Yu","Various data modalities are common in real-world applications. (e.g., EHR, medical images and clinical notes in healthcare). Thus, it is essential to develop multimodal learning methods to aggregate information from multiple modalities. The main challenge is appropriately aligning and fusing the representations of different modalities into a joint distribution. Existing methods mainly rely on concatenation or the Kronecker product, oversimplifying interactions structure between modalities and indicating a need to model more complex interactions. Additionally, the joint distribution of latent representations with higher-order interactions is underexplored. Copula is a powerful statistical structure in modelling the interactions between variables, as it bridges the joint distribution and marginal distributions of multiple variables. In this paper, we propose a novel copula modelling-driven multimodal learning framework, which focuses on learning the joint distribution of various modalities to capture the complex interaction among them. The key idea is interpreting the copula model as a tool to align the marginal distributions of the modalities efficiently. By assuming a Gaussian mixture distribution for each modality and a copula model on the joint distribution, our model can also generate accurate representations for missing modalities. Extensive experiments on public MIMIC datasets demonstrate the superior performance of our model over other competitors. The code is anonymously available at https://github.com/HKU-MedAI/CMCM.","Many healthcare records contain information in different formats, such as medical images, time-series signals, and clinical notes. Combining these various types of data can help doctors better understand a patient’s condition and make more accurate predictions. However, it's not easy to merge information from different sources because each type of data has its own unique structure and meaning. Existing methods often use simple ways to combine data, which may ignore important interactions between them.In this study, we introduce a new method called $\textbf{CM}^2$ (Cross-Modal alignment via variational Copula Modelling). This method uses a statistical approach known as a $\textit{copula}$ to better understand how different types of data relate to each other. By doing so, it builds a more accurate and flexible combined data representation. Even when some types of data are missing (which is common in real hospitals), $\textbf{CM}^2$ can still generate reliable predictions using the available information.We tested $\textbf{CM}^2$ using real-world hospital datasets, including electronic health records and chest X-ray images. Our results showed that $\textbf{CM}^2$ outperformed other methods in predicting important outcomes such as whether a patient might pass away during their hospital stay or return shortly after discharge. This suggests that $\textbf{CM}^2$ could help build smarter healthcare systems that work well even with incomplete data."
Poster,Cross-regularization: Adaptive Model Complexity through Validation Gradients,https://ICML.cc//virtual/2025/poster/45862,Carlos Stein Naves de Brito,"Model regularization requires extensive manual tuning to balance complexity against overfitting. Cross-regularization resolves this tradeoff by computing validation gradients that directly adapt regularization parameters during training. The method splits parameter optimization - training data guides feature learning while validation data shapes complexity controls - converging provably to cross-validation optima with computational cost scaling only in regularization dimension. When implemented through noise injection in neural networks, this approach reveals striking patterns: unexpectedly high noise tolerance and architecture-specific regularization that emerges organically during training. Beyond complexity control, the framework integrates seamlessly with data augmentation and uncertainty calibration while maintaining single-run efficiency through a simple gradient-based approach.","Computer models learning effectively from data must balance grasping general patterns for new predictions against the pitfall of overfitting. Overfitting—learning training data too perfectly, including its noise and specific details—leads to poor performance on unseen information. To prevent this, scientists use ""regularization"" techniques, like constraining model complexity or introducing ""noise"" during training. Yet, achieving optimal generalization through these methods often requires extensive, inefficient manual expert tuning. Our research introduces ""Cross-regularization,"" a method allowing models to automatically find this crucial balance. The model learns from one dataset and uses a separate generalization set to continuously fine-tune its complexity, guiding itself towards optimal generalization without manual intervention. This automated approach simplifies training and reveals how models can adapt complexity in unique ways, sometimes thriving with surprisingly high internal ""noise."" Ultimately, cross-regularization efficiently helps create robust, reliable AI systems that learn general principles, avoiding overfitting, and can adapt to growing data or provide more trustworthy predictions."
Poster,CROW: Eliminating Backdoors from Large Language Models via Internal Consistency Regularization,https://ICML.cc//virtual/2025/poster/44866,"Nay Myat Min, Long H. Pham, Yige Li, Jun Sun","Large Language Models (LLMs) are vulnerable to backdoor attacks that manipulate outputs via hidden triggers. Existing defense methods—designed for vision/text classification tasks—fail for text generation. We propose *Internal Consistency Regularization (CROW)*, a defense leveraging the observation that backdoored models exhibit unstable layer-wise hidden representations when triggered, while clean models show smooth transitions. CROW enforces consistency across layers via adversarial perturbations and regularization during finetuning, neutralizing backdoors without requiring clean reference models or trigger knowledge—only a small clean dataset. Experiments across Llama-2 (7B, 13B), CodeLlama (7B, 13B), and Mistral-7B demonstrate CROW’s effectiveness: it achieves significant reductions in attack success rates across diverse backdoor strategies (sentiment steering, targeted refusal, code injection) while preserving generative performance. CROW’s architecture-agnostic design enables practical deployment.","How can we strip hidden “trigger phrases” out of a large language model without knowing what the trigger is or retraining the model from scratch? That was the driving question.  Backdoor attacks let an adversary poison a model during training so that a secret phrase (for example *BadMagic*) makes it spout toxic text or insert malicious code while behaving normally the rest of the time.  Existing defenses either rely on an untouched reference model, often unavailable in practice, or blunt the model’s usefulness by heavy pruning or full retraining.  The authors set out to discover whether a single, lightweight tune-up could erase such backdoors.Their answer is CROW, a minimalist “internal consistency” finetune.  In a healthy transformer, hidden activations flow smoothly from one layer to the next; a backdoor trigger disrupts that smoothness.  CROW first magnifies any potential disruption by adding small adversarial nudges to the input embeddings, then penalizes large layer-to-layer jumps during a brief LoRA finetune on just one hundred clean prompts.  This short procedure, finished in minutes on a single GPU, leans on a simple loss term that encourages every layer to behave almost isometrically, starving hidden triggers of the amplification they need.The result is a practical detox recipe: after one pass of CROW, a wide range of poisoned models behave as if the trigger were never planted, while their helpfulness on everyday tasks stays intact.  Because the method needs no knowledge of the trigger, no separate clean model, and only a handful of clean examples, it turns the once daunting task of “backdoor removal” into something a small team or an open-source community can do in an afternoon.  By enforcing this internal consistency, CROW points the way to safer, more trustworthy LLM deployments in customer service, coding assistance, and other high-stakes domains."
Poster,CSG-ODE: ControlSynth Graph ODE For Modeling Complex Evolution of Dynamic Graphs,https://ICML.cc//virtual/2025/poster/46309,"Zhiqiang Wang, Xiaoyi Wang, Jianqing Liang","Graph Neural Ordinary Differential Equations (GODE) integrate the Variational Autoencoder (VAE) framework with differential equations, effectively modeling latent space uncertainty and continuous dynamics, excelling in graph data evolution and incompleteness. However, existing GODE face challenges in capturing time-varying relationships and nonlinear node state evolution, which limits their ability to model complex dynamic graphs. To address these issues, we propose the ControlSynth Graph ODE (CSG-ODE). In the VAE encoding phase, CSG-ODE introduces an information transmission-based inter-node importance weighting mechanism, integrating it with latent correlations to guide adaptive graph convolutional recurrent networks for temporal node embedding. During decoding, CSG-ODE employs ODE to model node dynamics, capturing nonlinear evolution through sub-networks with nonlinear activations. For scenarios or prediction tasks that require stability, we extend CSG-ODE to stable CSG-ODE (SCSG-ODE) by constraining weight matrices to learnable anti-symmetric forms, theoretically ensuring enhanced stability. Experiments on traffic, motion capture, and simulated physical systems datasets demonstrate that CSG-ODE outperforms state-of-the-art GODE, while SCSG-ODE achieves both superior performance and optimal stability.","Graph Neural ODE (GODE) integrate the Variational Autoencoder (VAE) framework with differential equations to model uncertainty and continuous dynamics in evolving graphs. However, they struggle with capturing time-varying relationships and nonlinear node state evolution. To overcome these limitations, we propose ControlSynth Graph ODE (CSG-ODE). In the VAE encoding phase, CSG-ODE introduces an information transmission-based inter-node importance weighting mechanism, guiding adaptive graph convolutional recurrent networks for temporal node embeddings. During decoding, it models nonlinear node dynamics using ODE with sub-networks and nonlinear activations. For scenarios or tasks that require stability, we extend CSG-ODE to SCSG-ODE by using learnable anti-symmetric weight matrices, theoretically ensuring enhanced stability. Experiments show that CSG-ODE outperforms existing methods, and SCSG-ODE offers both accuracy and optimal stability."
