type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Addressing Imbalanced Domain-Incremental Learning through Dual-Balance Collaborative Experts,https://ICML.cc//virtual/2025/poster/44608,"Lan Li, Da-Wei Zhou, Han-Jia Ye, De-Chuan Zhan","Domain-Incremental Learning (DIL) focuses on continual learning in non-stationary environments, requiring models to adjust to evolving domains while preserving historical knowledge. DIL faces two critical challenges in the context of imbalanced data: intra-domain class imbalance and cross-domain class distribution shifts.  These challenges significantly hinder model performance, as intra-domain imbalance leads to underfitting of few-shot classes, while cross-domain shifts require maintaining well-learned many-shot classes and transferring knowledge to improve few-shot class performance in old domains. To overcome these challenges, we introduce the Dual-Balance Collaborative Experts (DCE) framework. DCE employs a frequency-aware expert group, where each expert is guided by specialized loss functions to learn features for specific frequency groups, effectively addressing intra-domain class imbalance. Subsequently, a dynamic expert selector is learned by synthesizing pseudo-features through balanced Gaussian sampling from historical class statistics. This mechanism navigates the trade-off between preserving many-shot knowledge of previous domains and leveraging new data to improve few-shot class performance in earlier tasks. Extensive experimental results on four benchmark datasets demonstrate DCE’s state-of-the-art performance.","Many machine learning systems struggle to keep learning over time, especially when the data they receive comes from different environments and is unevenly distributed. For example, in some domains, a system may get many examples of certain categories and very few of others. When these imbalances exist both within and across learning stages, the model may forget what it learned before or fail to learn the less frequent categories well.Our research addresses this problem by designing a method that helps the model balance both old and new knowledge. We train a group of specialized networks, each focusing on different types of categories — from common to rare — to better handle uneven data. Then, we teach the system how to choose and combine these networks based on past experience and new data. This dual approach helps the model remember important past knowledge while still adapting to new information, especially for rare or previously under-learned categories. We show that our method significantly improves learning on several benchmark tasks."
Poster,Addressing Misspecification in Simulation-based Inference through Data-driven Calibration,https://ICML.cc//virtual/2025/poster/43556,"Antoine Wehenkel, Juan L. Gamella, Ozan Sener, Jens Behrmann, Guillermo Sapiro, Jörn Jacobsen, Marco Cuturi","Driven by steady progress in deep generative modeling, simulation-based inference (SBI) has emerged as the workhorse for inferring the parameters of stochastic simulators. However, recent work has demonstrated that model misspecification can harm SBI's reliability, preventing its adoption in important applications where only misspecified simulators are available.This work introduces robust posterior estimation (RoPE), a framework that overcomes model misspecification with a small real-world calibration set of ground truth parameter measurements.We formalize the misspecification gap as the solution of an optimal transport (OT) problem between learned representations of real-world and simulated observations, allowing RoPE to learn a model of the misspecification without placing additional assumptions on its nature. RoPE shows how the calibration set and OT together offer a controllable balance between calibrated uncertainty and informative inference even under severely misspecified simulators. Results on four synthetic tasks and two real-world problems with ground-truth labels demonstrate that RoPE outperforms baselines and consistently returns informative and calibrated credible intervals.","When scientists use computer simulations to understand real-world systems, the simulations are often imperfect and can lead to incorrect conclusions. This paper introduces a method called RoPE that helps fix these problems by using a small amount of real-world data to adjust the simulation results. This way, the method gives more accurate and trustworthy answers, even when the original simulation isn't perfect."
Poster,ADHMR: Aligning Diffusion-based Human Mesh Recovery via Direct Preference Optimization,https://ICML.cc//virtual/2025/poster/43558,"Wenhao Shen, Wanqi Yin, Xiaofeng Yang, Cheng Chen, Chaoyue Song, Zhongang Cai, Lei Yang, Hao Wang, Guosheng Lin","Human mesh recovery (HMR) from a single image is inherently ill-posed due to depth ambiguity and occlusions. Probabilistic methods have tried to solve this by generating numerous plausible 3D human mesh predictions, but they often exhibit misalignment with 2D image observations and weak robustness to in-the-wild images. To address these issues, we propose ADHMR, a framework that **A**ligns a **D**iffusion-based **HMR** model in a preference optimization manner. First, we train a human mesh prediction assessment model, HMR-Scorer, capable of evaluating predictions even for in-the-wild images without 3D annotations. We then use HMR-Scorer to create a preference dataset, where each input image has a pair of winner and loser mesh predictions. This dataset is used to finetune the base model using direct preference optimization. Moreover, HMR-Scorer also helps improve existing HMR models by data cleaning, even with fewer training samples. Extensive experiments show that ADHMR outperforms current state-of-the-art methods. Code is available at: [*https://github.com/shenwenhao01/ADHMR*](https://github.com/shenwenhao01/ADHMR).","Turning a single photo into an accurate 3D model of a person is tricky: the picture hides parts of the body and gives no depth information, so computers must guess. Modern systems tackle this by generating many plausible body shapes through an iterative noise‑removal process called diffusion, but they still often misplace joints or fail on everyday “in‑the‑wild” photos.We introduce ADHMR, a technique that teaches the computer to prefer the guesses that actually line up with the picture. First, we build an automatic scorer that, like a referee, rates each 3D guess according to how well it matches visible body landmarks. Using these scores, we form pairs of “better” and “worse” examples and retrain the diffusion model—borrowing a learning rule from language models—so it consistently chooses the better one.ADHMR cuts pose‑position errors and works with far fewer guesses. The same scorer can also weed out bad training data, boosting other human‑modeling tools. More reliable 3D people models will enhance virtual try‑on, animation, and augmented‑reality applications."
Poster,Ad-Hoc Human-AI Coordination Challenge,https://ICML.cc//virtual/2025/poster/45867,"Tin Dizdarevic, Ravi Hammond, Tobias Gessler, Anisoara Calinescu, Jonathan Cook, Matteo Gallici, Andrei Lupu, Jakob Foerster","Achieving seamless coordination between AI agents and humans is crucial for real-world applications, yet it remains a significant open challenge. Hanabi is a cooperative card game featuring imperfect information, constrained communication, theory of mind requirements, and coordinated action -- making it an ideal testbed for human-AI coordination. However, its use for human-AI interaction has been limited by the challenges of human evaluation. In this work, we introduce the Ad-Hoc Human-AI Coordination Challenge (AH2AC2) to overcome the constraints of costly and difficult-to-reproduce human evaluations. We develop \textit{human proxy agents} on a large-scale human dataset that serve as robust, cheap, and reproducible human-like evaluation partners in AH2AC2. To encourage the development of data-efficient methods, we open-source a dataset of 3,079 games, deliberately limiting the amount of available human gameplay data. We present baseline results for both two- and three- player Hanabi scenarios. To ensure fair evaluation, we host the proxy agents through a controlled evaluation system rather than releasing them publicly. The code is available at \href{https://github.com/FLAIROx/ah2ac2}{https://github.com/FLAIROx/ah2ac2}.","Making AI that can smoothly work with humans is a big challenge, especially because testing if an AI is a good human teammate is often costly, inconsistent, and hard to repeat. To tackle this, we created the ""Ad-Hoc Human-AI Coordination Challenge"" (AH2AC2), using the cooperative card game Hanabi as a testing ground. We trained special AI ""stand-ins"" (human proxies) on thousands of real human games to act like human players. Researchers can now test their own AI agents by having them play Hanabi with our proxies through a controlled online system, and we provide a small public dataset of human games to help them get started. This new challenge provides a fair, affordable, and repeatable way to see how well AIs can coordinate with human-like partners, aiming to speed up progress in building AI that can truly collaborate with people and learn to do so without needing massive amounts of human data."
Poster,Ad Hoc Teamwork via Offline Goal-Based Decision Transformers,https://ICML.cc//virtual/2025/poster/43765,"Xinzhi Zhang, Hoehi Chan, Deheng Ye, Yi Cai, Mengchen Zhao","The ability of agents to collaborate with previously unknown teammates on the fly, known as ad hoc teamwork (AHT), is crucial in many real-world applications. Existing approaches to AHT require online interactions with the environment and some carefully designed teammates. However, these prerequisites can be infeasible in practice. In this work, we extend the AHT problem to the offline setting, where the policy of the ego agent is directly learned from a multi-agent interaction dataset. We propose a hierarchical sequence modeling framework called TAGET that addresses critical challenges in the offline setting, including limited data, partial observability and online adaptation. The core idea of TAGET is to dynamically predict teammate-aware rewards-to-go and sub-goals, so that the ego agent can adapt to the changes of teammates’ behaviors in real time. Extensive experimental results show that TAGET significantly outperforms existing solutions to AHT in the offline setting.","This study proposes TAGET, a method that enables agents to learn how to cooperate with unknown teammates using offline data, without requiring real-time interaction. By predicting team-level goals, the agent is able to adapt dynamically to changing teammate behaviors, achieving strong performance in various cooperative tasks and showing potential for real-world applications such as autonomous driving and disaster response."
Poster,ADIOS: Antibody Development via Opponent Shaping,https://ICML.cc//virtual/2025/poster/45636,"Sebastian Towers, Aleksandra Kalisz, Philippe Robert, Alicia Higueruelo, Francesca Vianello, Chloe Tsai, Harrison Steel, Jakob Foerster","Anti-viral therapies are typically designed to target only the current strains of a virus, a *myopic* response. However, therapy-induced selective pressures drive the emergence of new viral strains, against which the original myopic therapies are no longer effective. This evolutionary response presents an opportunity: our therapies could both *defend against and actively influence viral evolution*. This motivates our method ADIOS: Antibody Development vIa Opponent Shaping. ADIOS is a meta-learning framework where the process of antibody therapy design, the *outer loop*, accounts for the virus's adaptive response, the *inner loop*. With ADIOS, antibodies are not only robust against potential future variants, they also influence, i.e. *shape*, which future variants emerge. In line with the opponent shaping literature, we refer to our optimised antibodies as *shapers*. To demonstrate the value of ADIOS, we build a viral evolution simulator using the Absolut! framework, in which shapers successfully target both current and future viral variants, outperforming myopic antibodies. Furthermore, we show that shapers modify the distribution over viral evolutionary trajectories to result in weaker variants.We believe that our ADIOS paradigm will facilitate the discovery of long-lived vaccines and antibody therapies while also generalising to other domains. Specifically, domains such as antimicrobial resistance, cancer treatment, and others with evolutionarily adaptive opponents. Our code is available at https://github.com/olakalisz/adios.","When scientists develop vaccines or antibody treatments, they typically design them to fight viruses as they exist today. However, viruses constantly evolve to escape our defences, making treatments less effective over time, as we saw with COVID-19 variants that reduced vaccine effectiveness.We created ADIOS, a computer system that designs smarter antibodies called ""shapers."" Instead of just defending against current viruses like traditional approaches, shapers actively influence how viruses evolve, like a chess master who forces their opponent into weak positions several moves ahead. Our system simulates hundreds of generations of viral evolution to find antibodies that remain effective and actually steer viruses toward weaker forms that are easier to target.In our computer simulations across multiple viruses, including dengue, West Nile, and influenza, shapers significantly outperformed traditional antibodies and successfully guided viral evolution toward more vulnerable variants. By using more powerful simulations, this approach could lead to longer-lasting vaccines and treatments that stay ahead of viral evolution. The same strategy could also be applied beyond infectious diseases to cancer treatment, where tumours similarly evolve to escape therapies, potentially transforming how we develop treatments for any rapidly evolving disease."
Poster,Adjoint Sampling: Highly Scalable Diffusion Samplers via Adjoint Matching,https://ICML.cc//virtual/2025/poster/46388,"Aaron Havens, Benjamin Kurt Miller, Bing Yan, Carles Domingo i Enrich, Anuroop Sriram, Daniel S. Levine, Brandon Wood, Bin Hu, Brandon Amos, Brian Karrer, Xiang Fu, Guan-Horng Liu, Ricky T. Q. Chen","We introduce Adjoint Sampling, a highly scalable and efficient algorithm for learning diffusion processes that sample from unnormalized densities, or energy functions. It is the first on-policy approach that allows significantly more gradient updates than the number of energy evaluations and model samples, allowing us to scale to much larger problem settings than previously explored by similar methods.Our framework is theoretically grounded in stochastic optimal control and shares the same theoretical guarantees as Adjoint Matching, being able to train without the need for corrective measures that push samples towards the target distribution.We show how to incorporate key symmetries, as well as periodic boundary conditions, for modeling molecules in both cartesian and torsional coordinates.We demonstrate the effectiveness of our approach through extensive experiments on classical energy functions, and further scale up to neural network-based energy models where we perform amortized conformer generation across many molecular systems.To encourage further research in developing highly scalable sampling methods, we plan to open source these challenging benchmarks, where successful methods can directly impact progress in computational chemistry. Code \& and benchmarks provided at https://github.com/facebookresearch/adjoint_sampling.","Many machine learning problems involve sampling from distributions that are defined by an energy function, where lower energy corresponds to higher probability. In molecular modeling, for example, stable molecular structures correspond to low-energy stable configurations, so sampling from these distributions helps predict likely structures. Training samplers for these problems is often expensive, since each update usually requires generating new samples and evaluating the energy function which may be costly.We introduce Adjoint Sampling, a method that makes training much more efficient by reusing model samples across many updates. By looking backward through a related idealized process, the method extracts more learning signal from each sample, reducing the number of costly energy evaluations while still converging to the correct solution.This leads to high-quality samplers that are significantly cheaper to train. We show strong results on molecular structure generation across a wide range of molecule types, along with benchmarks to support future work on efficient, scalable sampling."
Poster,Adjusting Model Size in Continual Gaussian Processes: How Big is Big Enough?,https://ICML.cc//virtual/2025/poster/46194,"Guiomar Pescador-Barrios, Sarah Filippi, Mark van der Wilk","Many machine learning models require setting a parameter that controls their size before training, e.g. number of neurons in DNNs, or inducing points in GPs. Increasing capacity typically improves performance until all the information from the dataset is captured. After this point, computational cost keeps increasing, without improved performance. This leads to the question ""How big is big enough?"" We investigate this problem for Gaussian processes (single-layer neural networks) in continual learning. Here, data becomes available incrementally, and the final dataset size will therefore not be known before training, preventing the use of heuristics for setting a fixed model size. We develop a method to automatically adjust model size while maintaining near-optimal performance. Our experimental procedure follows the constraint that any hyperparameters must be set without seeing dataset properties, and we show that our method performs well across diverse datasets without the need to adjust its hyperparameter, showing it requires less tuning than others.","How can we build machine learning models that are just the right size, not too small, not too big, especially when we do not know how much data we will have?Many ML models require a size parameter that is fixed before training, e.g. number of neurons in DNNs, or inducing points in GPs. Choosing this size is important: if the model is too small, it will not perform well; if it is too large, it wastes computational resources. This raises a key question: _how big is big enough?_ We focus on this problem for a specific type of model called a Gaussian Process in a continual learning setting, where data arrives over time and cannot be stored. Since we do not know in advance how much data there will be, we cannot set the best model size at the start of training. We propose a new method that automatically adjusts the model's size as new data arrive, aiming to maintain near-optimal performance without unnecessary computation. Our results show that this method performs well across diverse datasets without the need to adjust its hyperparameter, demonstrating that it requires less tuning than other approaches."
Poster,Adjustment for Confounding using Pre-Trained Representations,https://ICML.cc//virtual/2025/poster/46028,"Rickmer Schulte, David Rügamer, Thomas Nagler","There is growing interest in extending average treatment effect (ATE) estimation to incorporate non-tabular data, such as images and text, which may act as sources of confounding. Neglecting these effects risks biased results and flawed scientific conclusions. However, incorporating non-tabular data necessitates sophisticated feature extractors, often in combination with ideas of transfer learning. In this work, we investigate how latent features from pre-trained neural networks can be leveraged to adjust for sources of confounding. We formalize conditions under which these latent features enable valid adjustment and statistical inference in ATE estimation, demonstrating results along the example of double machine learning. We discuss critical challenges inherent to latent feature learning and downstream parameter estimation arising from the high dimensionality and non-identifiability of representations. Common structural assumptions for obtaining fast convergence rates with additive or sparse linear models are shown to be unrealistic for latent features. We argue, however, that neural networks are largely insensitive to these issues. In particular, we show that neural networks can achieve fast convergence rates by adapting to intrinsic notions of sparsity and dimension of the learning problem.","Scientists often want to understand if a treatment or intervention genuinely works. But when analyzing data, factors not initially obvious, like images or text, could secretly affect the results. Ignoring these hidden factors, known as “confounders”, can lead to incorrect conclusions about a treatment’s real effect.This study investigates a novel way to handle these hidden confounders using advanced methods from deep learning. It explores how features extracted from pre-trained deep learning models, such as those trained to recognize images or interpret text, can help identify and adjust for confounding factors. The paper examines under which conditions these deep learning-derived features allow for accurate estimation of treatment effects.While the study highlights challenges that traditional statistical methods face in this context, such as the high dimensionality of deep learning-generated features, it investigates the use of neural networks, which are particularly well suited in this case. Neural networks are shown to effectively handle these complexities, producing more reliable and accurate estimates of treatment effects."
Poster,AdvAgent: Controllable Blackbox Red-teaming on Web Agents,https://ICML.cc//virtual/2025/poster/44710,"Chejian Xu, Mintong Kang, Jiawei Zhang, Zeyi Liao, Lingbo Mo, Mengqi Yuan, Huan Sun, Bo Li","Foundation model-based agents are increasingly used to automate complex tasks, enhancing efficiency and productivity. However, their access to sensitive resources and autonomous decision-making also introduce significant security risks, where successful attacks could lead to severe consequences. To systematically uncover these vulnerabilities, we propose AdvAgent, a black-box red-teaming framework for attacking web agents. Unlike existing approaches, AdvAgent employs a reinforcement learning-based pipeline to train an adversarial prompter model that optimizes adversarial prompts using feedback from the black-box agent. With careful attack design, these prompts effectively exploit agent weaknesses while maintaining stealthiness and controllability. Extensive evaluations demonstrate that AdvAgent achieves high success rates against state-of-the-art GPT-4-based web agents across diverse web tasks. Furthermore, we find that existing prompt-based defenses provide only limited protection, leaving agents vulnerable to our framework. These findings highlight critical vulnerabilities in current web agents and emphasize the urgent need for stronger defense mechanisms. We release code at https://ai-secure.github.io/AdvAgent/.","Web agents powered by large language models are being used to automate online tasks, but they can be vulnerable to manipulation. We introduce AdvAgent, a method that learns to probe these agents for weaknesses using only their output—no internal access required. Our system reliably uncovers security flaws in advanced agents and shows that current defenses provide limited protection. This work highlights the need for stronger safeguards as AI agents take on more complex, real-world responsibilities."
