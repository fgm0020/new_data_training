type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Structure-informed Risk Minimization for Robust Ensemble Learning,https://ICML.cc//virtual/2025/poster/45805,"Fengchun Qiao, Yanlin Chen, Xi Peng","Ensemble learning is a powerful approach for improving generalization under distribution shifts, but its effectiveness heavily depends on how individual models are combined. Existing methods often optimize ensemble weights based on validation data, which may not represent unseen test distributions, leading to suboptimal performance in out-of-distribution (OoD) settings. Inspired by Distributionally Robust Optimization (DRO), we propose Structure-informed Risk Minimization (SRM), a principled framework that learns robust ensemble weights without access to test data. Unlike standard DRO, which defines uncertainty sets based on divergence metrics alone, SRM incorporates structural information of training distributions, ensuring that the uncertainty set aligns with plausible real-world shifts. This approach mitigates the over-pessimism of traditional worst-case optimization while maintaining robustness. We introduce a computationally efficient optimization algorithm with theoretical guarantees and demonstrate that SRM achieves superior OoD generalization compared to existing ensemble combination strategies across diverse benchmarks. Code is available at: https://github.com/deep-real/SRM.","Machine learning models often fail when deployed in environments different from their training conditions. A common solution is ensemble learning—combining predictions from multiple models like getting several doctors' opinions. However, determining how much weight to give each model's prediction is challenging, as current methods rely on validation data that may not reflect real deployment conditions.We introduce Structure-informed Risk Minimization (SRM), which learns robust ensemble weights by preparing for realistic worst-case scenarios rather than relying on potentially mismatched validation data. Unlike traditional approaches that consider any possible worst case (overly pessimistic), SRM uses knowledge about how different data sources relate to each other to focus on plausible scenarios."
Poster,Structure Is All You Need: Structural Representation Learning on Hyper-Relational Knowledge Graphs,https://ICML.cc//virtual/2025/poster/46565,"Jaejun Lee, Joyce Whang","Hyper-relational knowledge graphs (HKGs) enrich knowledge graphs by extending a triplet to a hyper-relational fact, where a set of qualifiers adds auxiliary information to a triplet. While many HKG representation learning methods have been proposed, they often fail to effectively utilize the HKG's structure. This paper demonstrates that thoroughly leveraging the structure of an HKG is crucial for reasoning on HKGs, and a purely structure-based representation learning method can achieve state-of-the-art performance on various link prediction tasks. We propose MAYPL, which learns to initialize representation vectors based on the structure of an HKG and employs an attentive neural message passing consisting of fact-level message computation and entity-centric and relation-centric aggregations, thereby computing the representations based solely on the structure. Due to its structure-driven learning, MAYPL can conduct inductive inferences on new entities and relations. MAYPL outperforms 40 knowledge graph completion methods in 10 datasets, compared with different baseline methods on different datasets to be tested from diverse perspectives.","Hyper-relational knowledge graphs (HKGs) represent human knowledge using facts, each of which consists of a triplet and a set of qualifiers that provides auxiliary information to the triplet. While many representation learning methods have been proposed for HKGs, these methods often fail to effectively utilize the rich structural information of HKGs.We introduce MAYPL, the first structure-oriented representation learning method for HKGs. MAYPL computes entity and relation representations by capturing their interconnections, co-occurrence and positions, which are then refined by considering the specific facts in which entities and relations belong to. Experimental results show that MAYPL achieves state-of-the-art performance on various link prediction tasks. This demonstrates that thoroughly learning and exploiting the structure of an HKG is necessary and sufficient for learning representations on HKGs."
Poster,Subgoal-Guided Policy Heuristic Search with Learned Subgoals,https://ICML.cc//virtual/2025/poster/45623,"Jake Tuero, Michael Buro, Levi Lelis","Policy tree search is a family of tree search algorithms that use a policy to guide the search. These algorithms provide guarantees on the number of expansions required to solve a given problem that are based on the quality of the policy. While these algorithms have shown promising results, the process in which they are trained requires complete solution trajectories to train the policy. Search trajectories are obtained during a trial-and-error search process. When the training problem instances are hard, learning can be prohibitively costly, especially when starting from a randomly initialized policy. As a result, search samples are wasted in failed attempts to solve these hard instances. This paper introduces a novel method for learning subgoal-based policies for policy tree search algorithms. The subgoals and policies conditioned on subgoals are learned from the trees that the search expands while attempting to solve problems, including the search trees of failed attempts. We empirically show that our policy formulation and training method improve the sample efficiency of learning a policy and heuristic function in this online setting.","This paper looks at a type of problem-solving method called tree search, where a system explores different options (like branches on a tree) to find a solution. These methods use a *policy* to guide the search, which provides a recommendation to the algorithm for which actions to examine first. These algorithms provide guarantees on the number of expansions required to solve a given problem that are based on the quality of the policy. The better the policy is, the faster the search algorithm can find the solution state.However, teaching the system to create an informative policy usually requires knowing the full solution to each training problem, which can be *expensive* in terms of time and how much *work* the search algorithm needs to do to find a solution, when starting from scratch. Often, the system wastes effort trying and failing, and those failures don't help to learn the policy.Our work proposes a new way to help the system learn more effectively by using *subgoals*, which can be thought of as a series of waypoints, that make the big problem easier to solve. Instead of the system having to learn how to solve the entire problem, it now only needs to learn how to solve easier subgoals, which can be strung together to solve the global problem. This enables our method to learn from failed attempts where we do not solve the problem outright, but solve some of the subgoals. The results show that this approach helps the system learn faster and more efficiently, without sacrificing the quality of the policy."
Poster,Subgroups Matter for Robust Bias Mitigation,https://ICML.cc//virtual/2025/poster/45405,"Anissa Alloula, Charles Jones, Ben Glocker, Bartlomiej W. Papiez","Despite the constant development of new bias mitigation methods for machine learning, no method consistently succeeds, and a fundamental question remains unanswered: when and why do bias mitigation techniques fail? In this paper, we hypothesise that a key factor may be the often-overlooked but crucial step shared by many bias mitigation methods: the definition of subgroups. To investigate this, we conduct a comprehensive evaluation of state-of-the-art bias mitigation methods across multiple vision and language classification tasks, systematically varying subgroup definitions, including coarse, fine-grained, intersectional, and noisy subgroups. Our findings reveal that subgroup choice significantly impacts performance, with certain groupings paradoxically leading to worse outcomes than no mitigation at all. They suggest that observing a disparity between a set of subgroups is not a sufficient reason to use those subgroups for mitigation. Through theoretical analysis, we explain these phenomena and uncover a counter-intuitive insight that, in some cases, improving fairness with respect to a particular set of subgroups is best achieved by using a different set of subgroups for mitigation. Our work highlights the importance of careful subgroup definition in bias mitigation and presents it as an alternative lever for improving the robustness and fairness of machine learning models.","There are increasing reports of bias in the performance of machine learning models. This can manifest for example as unequal performance across key population subgroups, such as between men and women. Methods called ``bias mitigation methods'' have been developed to try to prevent machine learning models from learning these biases. For instance, a very simple method involves rebalancing a model's training data so that the model learns from a more equal number of data from the population subgroups of interest (e.g. equal representation of men and women). However, recently, many works have highlighted that these bias mitigation methods often fail in practice. In this paper, we seek to understand why these methods are failing so often. We consider a crucial but under-looked step of the bias mitigation process, subgroup definition. This step is required by almost all methods, but very little work has looked into whether this step could actually be optimised, and most of the time the same, coarse subgroups are used (e.g. male/female or white/non-white). To understand this, we do extensive experiments in four different datasets applying a range of established bias mitigation methods to different possible subgroup combinations. We find that performance is very dependent on the subgroups used, and we gather key insights on how to best define subgroups for optimal mitigation. Overall, our work highlights the importance of careful subgroup definition in bias mitigation and suggest it as a alternative lever for improving the robustness and fairness of machine learning models."
Poster,Subobject-level Image Tokenization,https://ICML.cc//virtual/2025/poster/44334,"Delong Chen, Samuel Cahyawijaya, Jianfeng Liu, Baoyuan Wang, Pascale FUNG","Patch-based image tokenization ignores the morphology of the visual world, limiting effective and efficient learning of image understanding. Inspired by subword tokenization, we introduce subobject-level adaptive token segmentation and explore several approaches, including superpixel, SAM, and a proposed Efficient and PanOptiC (EPOC) image tokenizer. Our EPOC combines boundary detection--a simple task that can be handled well by a compact model--with watershed segmentation, which inherently guarantees no pixels are left unsegmented. Intrinsic evaluations across 5 datasets demonstrate that EPOC's segmentation aligns well with human annotations of both object- and part-level visual morphology, producing more monosemantic tokens and offering substantial efficiency advantages. For extrinsic evaluation, we designed a token embedding that handles arbitrary-shaped tokens, and trained VLMs with different tokenizers on 4 datasets of object recognition and detailed captioning. The results reveal that subobject tokenization enables faster convergence and better generalization while using fewer visual tokens.","Understanding images with AI typically involves breaking pictures into fixed grids of squares, which often misses the natural boundaries and meaningful parts of objects. Our research addresses this limitation by proposing a new way to divide images, called subobject-level tokenization, that dynamically adapts to the actual shapes and structures within the image. Instead of uniform squares, our method identifies and segments the image into visually coherent parts, much like how words in language are composed of smaller meaningful units (subwords).We integrated this adaptive segmentation with vision-language models, which combine visual perception with text understanding. We found that this more intuitive division of images significantly improved the model’s ability to accurately interpret and reason about pictures. This innovation makes AI systems more aligned with human visual understanding, enhancing their usefulness in real-world applications such as detailed image captioning, object recognition, and visual question answering, ultimately making AI vision models both smarter and more intuitive."
Poster,Sub-Sequential Physics-Informed Learning with State Space Model,https://ICML.cc//virtual/2025/poster/45079,"Chenhui Xu, Dancheng Liu, Yuting Hu, Jiajie Li, Ruiyang Qin, Qingxiao Zheng, Jinjun Xiong","Physics-Informed Neural Networks (PINNs) are a kind of deep-learning-based numerical solvers for partial differential equations (PDEs). Existing PINNs often suffer from failure modes of being unable to propagate patterns of initial conditions. We discover that these failure modes are caused by the simplicity bias of neural networks and the mismatch between PDE's continuity and PINN's discrete sampling. We reveal that the State Space Model (SSM) can be a continuous-discrete articulation allowing initial condition propagation, and that simplicity bias can be eliminated by aligning a sequence of moderate granularity. Accordingly, we propose PINNMamba, a novel framework that introduces sub-sequence modeling with SSM. Experimental results show that PINNMamba can reduce errors by up to 86.3\% compared with state-of-the-art architecture. Our code is available at Supplementary Material.","When scientists use today’s artificial intelligence tools to solve physics problems—like forecasting how heat moves through a material or how waves travel—they sometimes find that the computer’s answers gradually drift away from reality. Our study pinpoints two reasons for this: (1) the networks prefer unnaturally “smooth” solutions, and (2) they learn only from a handful of sample points and therefore fail to carry the correct patterns forward in time.We introduce PINNMamba, a new AI framework that acts like a long-term memory for these simulations while still working quickly. It slices each problem into short, overlapping time snippets and equips the network with a built-in mechanism that continuously links the snippets together, so information from the starting conditions is preserved all the way through the calculation. In tests on several difficult physics equations, this strategy slashed errors by as much as 86 percent compared with the best previous designs, giving far more trustworthy results without extra data or hand-tuning."
Poster,Subspace Optimization for Large Language Models with Convergence Guarantees,https://ICML.cc//virtual/2025/poster/46498,"Yutong He, Pengrui Li, Yipeng Hu, Chuyan Chen, Kun Yuan","Subspace optimization algorithms, such as GaLore (Zhao et al., 2024), have gained attention for pre-training and fine-tuning large language models (LLMs) due to their memory efficiency. However, their convergence guarantees remain unclear, particularly in stochastic settings. In this paper, we reveal that GaLore does not always converge to the optimal solution and provide an explicit counterexample to support this finding. We further explore the conditions under which GaLore achieves convergence, showing that it does so when either (i) a sufficiently large mini-batch size is used or (ii) the gradient noise is isotropic. More significantly, we introduce **GoLore** (**G**radient rand**o**m **Lo**w-**r**ank proj**e**ction), a novel variant of GaLore that provably converges in typical stochastic settings, even with standard batch sizes. Our convergence analysis extends naturally to other subspace optimization algorithms. Finally, we empirically validate our theoretical results and thoroughly test the proposed mechanisms. Codes are available at https://github.com/pkumelon/Golore.","Training large AI models like ChatGPT requires significant computing power, making the process expensive and energy-intensive. GaLore, a recent method, helps reduce memory usage during training, making it more efficient. However, GaLore sometimes fails to produce strong results, especially when training with the small batch sizes typically used in practice. This is due to its sensitivity to the random noise present in the training process.To better understand this issue, we analyzed GaLore’s performance and found that while large batch sizes can help, they aren’t always practical due to hardware limits. To overcome this, we developed GoLore, an improved training method that uses random projections to reduce the impact of noise. GoLore keeps the memory efficiency of GaLore while achieving more stable and accurate training, even with small batches.Our work identifies a key limitation of GaLore and offers a practical solution. GoLore makes it easier to train large models efficiently and reliably, helping lower the barriers to building powerful AI systems."
Poster,SUICA: Learning Super-high Dimensional Sparse Implicit Neural Representations for Spatial Transcriptomics,https://ICML.cc//virtual/2025/poster/44957,"Qingtian Zhu, Yumin Zheng, Yuling Sang, Yifan Zhan, Ziyan Zhu, Jun Ding, Yinqiang Zheng","Spatial Transcriptomics (ST) is a method that captures gene expression profiles aligned with spatial coordinates. The discrete spatial distribution and the super-high dimensional sequencing results make ST data challenging to be modeled effectively. In this paper, we manage to model ST in a continuous and compact manner by the proposed tool, SUICA, empowered by the great approximation capability of Implicit Neural Representations (INRs) that can enhance both the spatial density and the gene expression. Concretely within the proposed SUICA, we incorporate a graph-augmented Autoencoder to effectively model the context information of the unstructured spots and provide informative embeddings that are structure-aware for spatial mapping. We also tackle the extremely skewed distribution in a regression-by-classification fashion and enforce classification-based loss functions for the optimization of SUICA. By extensive experiments of a wide range of common ST platforms under varying degradations, SUICA outperforms both conventional INR variants and SOTA methods regarding numerical fidelity, statistical correlation, and bio-conservation. The prediction by SUICA also showcases amplified gene signatures that enriches the bio-conservation of the raw data and benefits subsequent analysis.","Spatial Transcriptomics (ST) is a technology that allows scientists to understanding how genes are expressed across different regions of tissues is crucial for studying biological processes and diseases. However, analyzing this kind of data is challenging because it is both very large and highly complex. To address this, we developed a new computational tool called SUICA, which uses advanced deep learning techniques to model gene expression in a more continuous and compact way. Overall, SUICA not only improves the quality of spatial gene expression maps but also enhances the biological insights that researchers can gain from these datasets, opening new possibilities for studying tissue biology and disease mechanisms."
Poster,Suitability Filter: A Statistical Framework for Classifier Evaluation in Real-World Deployment Settings,https://ICML.cc//virtual/2025/poster/45090,"Angéline Pouget, Mohammad Yaghini, Stephan Rabanser, Nicolas Papernot","Deploying machine learning models in safety-critical domains poses a key challenge: ensuring reliable model performance on downstream user data without access to ground truth labels for direct validation. We propose the _suitability filter_, a novel framework designed to detect performance deterioration by utilizing _suitability signals_—model output features that are sensitive to covariate shifts and indicative of potential prediction errors. The suitability filter evaluates whether classifier accuracy on unlabeled user data shows significant degradation compared to the accuracy measured on the labeled test dataset. Specifically, it ensures that this degradation does not exceed a pre-specified margin, which represents the maximum acceptable drop in accuracy. To achieve reliable performance evaluation, we aggregate suitability signals for both test and user data and compare these empirical distributions using statistical hypothesis testing, thus providing insights into decision uncertainty. Our modular method adapts to various models and domains. Empirical evaluations across different classification tasks demonstrate that the suitability filter reliably detects performance deviations due to covariate shift. This enables proactive mitigation of potential failures in high-stakes applications.","Machine learning models learn from data to make decisions, but it can be tricky to ensure they remain dependable when they encounter new, real-world situations. This research introduces a new way to check if these models are starting to make more mistakes with new data, particularly when we can't easily verify whether their decisions are correct. The method works by examining subtle clues in how the model behaves with both familiar and new data to detect if its decision-making quality has declined. Experiments showed this approach can successfully flag when a model is struggling because the new information is different from what it was prepared for. This helps build confidence that these machine learning models are working correctly and can be trusted, especially in important everyday applications."
Poster,Sum-of-Parts: Self-Attributing Neural Networks with End-to-End Learning of Feature Groups,https://ICML.cc//virtual/2025/poster/43907,"Weiqiu You, Helen Qu, Marco Gatti, Bhuvnesh Jain, Eric Wong","Self-attributing neural networks (SANNs) present a potential path towards interpretable models for high-dimensional problems, but often face significant trade-offs in performance. In this work, we formally prove a lower bound on errors of per-feature SANNs, whereas group-based SANNs can achieve zero error and thus high performance. Motivated by these insights, we propose Sum-of-Parts (SOP), a framework that transforms any differentiable model into a group-based SANN, where feature groups are learned end-to-end without group supervision. SOP achieves state-of-the-art performance for SANNs on vision and language tasks, and we validate that the groups are interpretable on a range of quantitative and semantic metrics. We further validate the utility of SOP explanations in model debugging and cosmological scientific discovery.","Machine learning models are incredibly powerful, but often work like ""black boxes"" --- we can't understand how they make decisions. This makes it hard to trust them in important applications like medical diagnosis or scientific research.We developed a new approach that combines the power of deep learning with interpretability. Our method breaks down the input into meaningful groups of features and uses a powerful deep learning model to analyze each group separately. These predictions from all groups are then combined using simple linear weights, so we can see exactly how much each group contributes to the final decision.This framework automatically learns which features should be grouped together during training, and it works with any existing pretrained model. When we tested it on cosmology data, our method achieved the best performance among interpretable models that explicitly show which input features they rely on. The learned feature groups corresponded to meaningful physical concepts that helped cosmologists gain new scientific insights about the universe."
