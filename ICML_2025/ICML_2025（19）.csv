type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,A Near-Optimal Single-Loop Stochastic Algorithm for Convex Finite-Sum Coupled Compositional Optimization,https://ICML.cc//virtual/2025/poster/44872,"Bokun Wang, Tianbao Yang","This paper studies a class of convex Finite-sum Coupled Compositional Optimization (cFCCO) problems with applications including group distributionally robust optimization (GDRO) and learning with imbalanced data. To better address these problems, we introduce an efficient single-loop primal-dual block-coordinate stochastic algorithm called ALEXR. The algorithm employs block-coordinate stochastic mirror ascent with extrapolation for the dual variable and stochastic proximal gradient descent updates for the primal variable. We establish the convergence rates of ALEXR in both convex and strongly convex cases under smoothness and non-smoothness conditions of involved functions, which not only improve the best rates in previous works on smooth cFCCO problems but also expand the realm of cFCCO for solving more challenging non-smooth problems such as the dual form of GDRO.  Finally, we derive lower complexity bounds, demonstrating the (near-)optimality of ALEXR within a broad class of stochastic algorithms for cFCCO. Experimental results on GDRO and partial Area Under the ROC Curve (pAUC) maximization demonstrate the promising performance of our algorithm.",Many real-world machine-learning tasks can be formulated as ``finite-sum coupled compositional optimization'' such as maximizing the model performance on a highly imbalanced dataset. What we contributed: A new algorithm (ALEXR) with stronger convergence guarantees than previous algorithms under the same or weaker assumptions; We also show the optimality of the proposed algorithm; We validate the effectiveness of our algorithm on real-world datasets.
Poster,An Effective and Secure Federated Multi-View Clustering Method with Information-Theoretic Perspective,https://ICML.cc//virtual/2025/poster/44587,"Xinyue Chen, Jinfeng Peng, Yuhao Li, Xiaorong Pu, Yang Yang, Yazhou Ren","Recently, federated multi-view clustering (FedMVC) has gained attention for its ability to mine complementary clustering structures from multiple clients without exposing private data. Existing methods mainly focus on addressing the feature heterogeneity problem brought by views on different clients and mitigating it using shared client information. Although these methods have achieved performance improvements, the information they choose to share, such as model parameters or intermediate outputs, inevitably raises privacy concerns. In this paper, we propose an Effective and Secure Federated Multi-view Clustering method, ESFMC, to alleviate the dilemma between privacy protection and performance improvement. This method leverages the information-theoretic perspective to split the features extracted locally by clients, retaining sensitive information locally and only sharing features that are highly relevant to the task. This can be viewed as a form of privacy-preserving information sharing, reducing privacy risks for clients while ensuring that the server can mine high-quality global clustering structures. Theoretical analysis and extensive experiments demonstrate that the proposed method more effectively mitigates the trade-off between privacy protection and performance improvement compared to state-of-the-art methods.","Imagine a group of hospitals, each with valuable patient data, trying to work together to discover patterns that could improve healthcare. However, they can’t share patient records directly because of privacy laws and ethical concerns. So how can they collaborate without exposing sensitive information?Our research offers a solution. We propose a new method that lets different organizations, like hospitals, banks, or schools, work together to find useful insights without sharing private data. Instead of sending raw data or detailed personal information, our method allows each participant to keep the private details safely on their own system. They only share carefully chosen pieces of information that are essential for the group task. This helps build a clearer overall picture while still respecting everyone’s privacy. What’s more, our method works even when some participants don’t have complete data. For example, there is only partial overlap between the patients of one hospital and those of another hospital. We've designed a way for the method to still make sense of the incomplete puzzle. Tests show our method is not only safer but also more effective than existing techniques. It’s a step forward in allowing different groups to collaborate safely and intelligently in the digital age."
Poster,An Efficient Matrix Multiplication Algorithm for Accelerating Inference in Binary and Ternary Neural Networks,https://ICML.cc//virtual/2025/poster/45473,"Mohsen Dehghankar, Mahdi Erfanian, Abolfazl Asudeh","Despite their tremendous success and versatility, Deep Neural Networks (DNNs) such as Large Language Models (LLMs) suffer from inference inefficiency and rely on advanced computational infrastructure.To address these challenges and make these models more accessible and cost-effective, in this paper, we propose algorithms to improve the inference time and memory efficiency of DNNs with binary and ternary weight matrices.Particularly focusing on matrix multiplication as the bottleneck operation of inference, we observe that, once trained, the weight matrices of a model no longer change. This allows us to preprocess these matrices and create indices that help reduce the storage requirements by a logarithmic factor while enabling our efficient inference algorithms.Specifically, for a $n\times n$ weight matrix, our efficient algorithm guarantees a time complexity of $O(\frac{n^2}{\log n})$, a logarithmic factor improvement over the standard vector-matrix multiplication.Besides theoretical analysis, we conduct extensive experiments to evaluate the practical efficiency of our algorithms. Our results confirm the superiority of our approach both with respect to time and memory, as we observed a reduction in the multiplication time up to 29x and memory usage up to 6x. When applied to LLMs, our experiments show up to a 5.24x speedup in the inference time.","Deep Neural Networks and Large Language Models (LLMs), like ChatGPT, are very powerful but require expensive hardware and a lot of energy to run. This makes it difficult to use them on everyday devices like smartphones or in situations where computing resources are limited. Our research addresses this challenge by making these models much faster and more memory-efficient during the inference stage, when the model is used to generate answers.We focus on quantized models, where the weights (the core numerical values that define the model) are simplified to a small set of possible numerical values. This kind of quantization already reduces cost, but we take it further by designing algorithms that exploit the fact that these weights don’t change after training these models.Our approach compresses and preprocesses these fixed weights to build special ""indices"" that significantly speed up the model's computations. As a result, we reduce the time it takes to perform the most common operation, matrix multiplication. These improvements make it more practical to efficiently run advanced AI models on less powerful, more affordable hardware."
Poster,An Efficient Private GPT Never Autoregressively Decodes,https://ICML.cc//virtual/2025/poster/45418,"Zhengyi Li, Yue Guan, Kang Yang, Yu Feng, Ning Liu, Yu Yu, Jingwen Leng, Minyi Guo","The wide deployment of the generative pre-trained transformer (GPT) has raised privacy concerns for both clients and servers. While cryptographic primitives can be employed for secure GPT inference to protect the privacy of both parties, they introduce considerable performance overhead. To accelerate secure inference, this study proposes a public decoding and secure verification approach that utilizes public GPT models, motivated by the observation that securely decoding one and multiple tokens takes a similar latency. The client uses the public model to generate a set of tokens, which are then securely verified by the private model for acceptance. The efficiency of our approach depends on the acceptance ratio of tokens proposed by the public model, which we improve from two aspects: (1) a private sampling protocol optimized for cryptographic primitives and (2) model alignment using knowledge distillation. Our approach improves the efficiency of secure decoding while maintaining the same level of privacy and generation quality as standard secure decoding. Experiments demonstrate a $2.1\times \sim 6.0\times$ speedup compared to standard decoding across three pairs of public-private models and different network conditions.","As AI tools like ChatGPT become more widely used, protecting clients' privacy when accessing this service becomes increasingly important. One way to ensure privacy is for the client to upload cryptographic ciphertext, allowing the private model to generate responses using this ciphertext. The magic cryptographic techniques guarantee that the private model cannot see the client's words but can respond accurately. However, these methods often result in a significant slowdown in performance.Our research accelerates secure conversations with a private GPT by introducing the public GPT model into the process for the first time. Instead of performing all generation tasks in the secure world, we divide the task into a public part and a private part: the client uses the public GPT to suggest several possible next words. The suggested words are then encrypted, and a private GPT privately checks which words are acceptable. Since verifying suggestions is much easier than generating them, this division allows us to greatly reduce the computational burden on the secure world.Importantly, our method maintains full privacy protection and does not compromise the quality of the generated responses. An especially promising aspect of our approach is that its performance improvement depends on the strength of the public GPT model—meaning it will only get better as public models continue to advance."
Poster,An Efficient Pruner for Large Language Model with Theoretical Guarantee,https://ICML.cc//virtual/2025/poster/44100,"Canhong Wen, Yihong Zuo, Wenliang Pan","Large Language Models (LLMs) have showcased remarkable performance across a range of tasks but are hindered by their massive parameter sizes, which impose significant computational and storage demands. Pruning has emerged as an effective solution to reduce model size, but traditional methods often involve inefficient retraining or rely on heuristic-based one-shot approaches that lack theoretical guarantees. In this paper, we reformulate the pruning problem as an $\ell_0$-penalized optimization problem and propose a monotone accelerated Iterative Hard Thresholding (mAIHT) method. Our approach combines solid theoretical foundations with practical effectiveness, offering a detailed theoretical analysis that covers convergence, convergence rates, and risk upper bounds. Through extensive experiments, we demonstrate that mAIHT outperforms state-of-the-art pruning techniques by effectively pruning the LLaMA-7B model across various evaluation metrics.","Large Language Models (LLMs), like ChatGPT, have shown incredible capabilities in language understanding and generation. However, they come with a major drawback: their enormous size, which makes them slow, expensive, and difficult to use on many devices. To address this, researchers often use pruning — removing parts of the model that seem less important — to reduce size while maintaining performance. But common pruning methods can be either inefficient or based on heuristic strategies with little mathematical justification.In our work, we introduce a new pruning method with strong theoretical backing. We treat pruning as a mathematical problem that balances performance and simplicity, and solve it using a technique called monotone accelerated Iterative Hard Thresholding (mAIHT). Unlike many existing methods, ours comes with rigorous proofs showing it works reliably and efficiently. We also test it extensively on popular open-sourced LLMs, showing that our approach removes unnecessary parts better than leading pruning methods, all while preserving the model’s abilities.This research helps make LLMs faster, cheaper, and more accessible without sacrificing much intelligence."
Poster,An Efficient Search-and-Score Algorithm for Ancestral Graphs using Multivariate Information Scores for Complex Non-linear and Categorical Data,https://ICML.cc//virtual/2025/poster/45267,"Nikita Lagrange, Herve Isambert","We propose a greedy search-and-score algorithm for ancestral graphs, which include directed as well as bidirected edges, originating from unobserved latent variables. The normalized likelihood score of ancestral graphs is estimated in terms of multivariate information over relevant ""$ac$-connected subset"" of vertices, $\boldsymbol{C}$, that are connected through collider paths confined to the ancestor set of $\boldsymbol{C}$. For computational efficiency, the proposed two-step algorithm relies on local information scores limited to the close surrounding vertices of each node (step 1)  and edge (step 2). This computational strategy, although restricted to information contributions from $ac$-connected subsets containing up to two-collider paths, is shown to outperform state-of-the-art causal discovery methods on challenging benchmark datasets.","The likelihood function is a fundamental concept in machine learning, quantifying how ""likely"" a given model explains observed data. Consequently, selecting the model that maximizes likelihood provides the most plausible explanation for the data, when no prior information about possible models is available.Typically, identifying the best explanatory model involves maximizing likelihood across a set of candidate models. For directed acyclic graph (DAG) models—structures where variables are represented as nodes connected by directed edges without forming cycles—the global likelihood function conveniently decomposes into local likelihood terms, involving each observed variables and its parent nodes. However, in practice, all relevant variables might not be observed in the dataset.This paper addresses this limitation by extending the likelihood formulation to handle DAGs with unobserved variables. Such hidden variables introduce edges with two arrowheads, indicating an unobserved common cause between observed variables. We show that the likelihood for these generalized ""ancestral graphs"" similarly decomposes into local contributions involving specific subsets of observed variables, and propose an estimation of these local likelihood contributions directly from observed data. We also introduce an efficient search and score algorithm, which does not assume simple linear relations between variables (like most other state-of-the-art methods) thereby providing a causal discovery method with hidden variables for complex non-linear and categorical data, that are common in `real-word' applications."
Poster,An Empirical Study on Configuring In-Context Learning Demonstrations for Unleashing MLLMs' Sentimental Perception Capability,https://ICML.cc//virtual/2025/poster/46011,"Daiqing Wu, Dongbao Yang, Sicheng Zhao, Can Ma, Yu ZHOU","The advancements in Multimodal Large Language Models (MLLMs) have enabled various multimodal tasks to be addressed under a zero-shot paradigm. This paradigm sidesteps the cost of model fine-tuning, emerging as a dominant trend in practical application. Nevertheless, Multimodal Sentiment Analysis (MSA), a pivotal challenge in the quest for general artificial intelligence, fails to accommodate this convenience. The zero-shot paradigm exhibits undesirable performance on MSA, casting doubt on whether MLLMs can perceive sentiments as competent as supervised models. By extending the zero-shot paradigm to In-Context Learning (ICL) and conducting an in-depth study on configuring demonstrations, we validate that MLLMs indeed possess such capability. Specifically, three key factors that cover demonstrations' retrieval, presentation, and distribution are comprehensively investigated and optimized. A sentimental predictive bias inherent in MLLMs is also discovered and later effectively counteracted. By complementing each other, the devised strategies for three factors result in average accuracy improvements of 15.9% on six MSA datasets against the zero-shot paradigm and 11.2% against the random ICL baseline.","AI models struggle to understand human emotions in images or videos without being specifically trained for this task. This raises doubts about whether advanced AI systems can truly ""sense"" feelings like humans do.We discovered that by carefully selecting and organizing examples shown to the AI — like teaching a student with well-designed practice questions — its ability to analyze emotions improves dramatically. We also identified and fixed a hidden bias in how these models predict emotions.Our approach boosted accuracy by up to 15.9% across six emotion analysis datasets, proving that AI can interpret emotions effectively without costly retraining. This paves the way for more intuitive AI tools in mental health support, customer feedback analysis, and other real-world applications where understanding emotions matters."
Poster,An End-to-End Model for Logits-Based Large Language Models Watermarking,https://ICML.cc//virtual/2025/poster/46200,"KA HIM WONG, Jicheng Zhou, Jiantao Zhou, Yain-Whar Si","The rise of LLMs has increased concerns over source tracing and copyright protection for AIGC, highlighting the need for advanced detection technologies. Passive detection methods usually face high false positives, while active watermarking techniques using logits or sampling manipulation offer more effective protection. Existing LLM watermarking methods, though effective on unaltered content, suffer significant performance drops when the text is modified and could introduce biases that degrade LLM performance in downstream tasks. These methods fail to achieve an optimal tradeoff between text quality and robustness, particularly due to the lack of end-to-end optimization of the encoder and decoder. In this paper, we introduce a novel end-to-end logits perturbation method for watermarking LLM-generated text. By joint optimization, our approach achieves a better balance between quality and robustness. To address non-differentiable operations in the end-to-end training pipeline, we introduce an online-prompting technique that leverages the on-the-fly LLM as a differentiable surrogate. Our method achieves superior robustness, outperforming distortion-free methods by 37–39% under paraphrasing and 17.2% on average, while maintaining text quality on par with the distortion-free methods in terms of text perplexity and downstream tasks. Our method can be easily generalized to different LLMs. Code is available at https://github.com/KAHIMWONG/E2E_LLM_WM.","Large language models can generate text that is virtually indistinguishable from human writing, making it hard to trace AI-generated content or enforce copyright protection. Passive detection methods often produce high false-positive rates, and existing watermarking techniques tend to break when the text is edited or introduce biases that degrade LLM performance.We introduce an end-to-end watermarking method that subtly perturbs the LLM’s output logits via a jointly optimized encoder–decoder pair. To handle non-differentiable parts of this pipeline, we employ an online prompting technique that treats the LLM itself as a differentiable surrogate during training. This design lets us integrate watermark insertion seamlessly into the text-generation process.Our approach remains robust under paraphrasing and other transformations, boosting detection performance by up to 39% under paraphrasing and 17% on average. At the same time, it preserves text fluency, perplexity, and downstream-task performance on par with existing distortion-free methods. Because it can be applied to any LLM, this versatile solution helps reliably trace AI-generated text and safeguard intellectual property."
Poster,An Entropy-Based Model for Hierarchical Learning,https://ICML.cc//virtual/2025/poster/46717,Amir R. Asadi,"Machine learning, the predominant approach in the field of artificial intelligence, enables computers to learn from data and experience. In the supervised learning framework, accurate and efficient learning of dependencies between data instances and their corresponding labels requires auxiliary information about the data distribution and the target function. This central concept aligns with the notion of regularization in statistical learning theory. Real-world datasets are often characterized by multiscale data instance distributions and well-behaved, smooth target functions. Scale-invariant probability distributions, such as power-law distributions, provide notable examples of multiscale data instance distributions in various contexts. This paper introduces a hierarchical learning model that leverages such a multiscale data structure with a multiscale entropy-based training procedure and explores its statistical and computational advantages. The hierarchical learning model is inspired by the logical progression in human learning from easy to complex tasks and features interpretable levels. In this model, the logarithm of any data instance’s norm can be construed as the data instance's complexity, and the allocation of computational resources is tailored to this complexity, resulting in benefits such as increased inference speed. Furthermore, our multiscale analysis of the statistical risk yields stronger guarantees compared to conventional uniform convergence bounds.",
Poster,An Error Analysis of Flow Matching for Deep Generative Modeling,https://ICML.cc//virtual/2025/poster/43685,"Zhengyu Zhou, Weiwei Liu","Continuous Normalizing Flows (CNFs) have proven to be a highly efficient technique for generative modeling of complex data since the introduction of Flow Matching (FM). The core of FM is to learn the constructed velocity fields of CNFs through deep least squares regression. Despite its empirical effectiveness, theoretical investigations of FM remain limited. In this paper, we present the first end-to-end error analysis of CNFs built upon FM. Our analysis shows that for general target distributions with bounded support, the generated distribution of FM is guaranteed to converge to the target distribution in the sense of the Wasserstein-2 distance. Furthermore, the convergence rate is significantly improved under an additional mild Lipschitz condition of the target score function.","While Flow Matching has shown great results in practice, scientists didn't have a strong theoretical understanding of why it works so well or guarantees about how close the generated data can get to the real data. This research paper provides the first complete theoretical analysis of how errors can build up when using Flow Matching, from the initial training data all the way to the final generated data.The researchers proved that for most types of complex data (as long as the data doesn't spread out infinitely, which they call ""bounded support""), the data generated by a model trained with Flow Matching is guaranteed to get closer and closer to the real data. We use a mathematical measuring called the ""Wasserstein-2 distance"" to show this convergence.In essence, this paper mathematically confirms that Flow Matching is a solid technique for teaching computers to generate complex, realistic data, and it even explains how certain properties of the data can make the learning process more efficient."
