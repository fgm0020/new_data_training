type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,EcoMapper: Generative Modeling for Climate-Aware Satellite Imagery,https://ICML.cc//virtual/2025/poster/44910,"Muhammed Göktepe, Amir Hossein Shamseddin, Erencan Uysal, Javier Monteagudo, Lukas Drees, Aysim Toker, Senthold Asseng, Malte von Bloh","Satellite imagery is essential for Earth observation, enabling applications like crop yield prediction, environmental monitoring, and climatechange assessment. However, integrating satellite imagery with climate data remains a challenge, limiting its utility for forecasting and scenario analysis. We introduce a novel dataset of 2.9 million Sentinel-2 images spanning 15 land cover types with corresponding climate records, forming the foundation for two satellite image generation approaches using fine-tuned Stable Diffusion 3 models. The first is a text-to-image generation model that uses textual prompts with climate and land cover details to produce realistic synthetic imagery for specific regions. The second leverages ControlNet for multi-conditional image generation, preserving spatial structures while mapping climate data or generating time-series to simulate landscape evolution. By combining synthetic image generation with climate and land cover data, our work advances generative modeling in remote sensing, offering realistic inputs for environmental forecasting and new possibilities for climate adaptation and geospatial analysis.","Our work introduces EcoMapper, a generative machine learning model that creates realistic satellite images based on climate data. Trained on over 2.9 million satellite images linked with weather records, EcoMapper can simulate how specific landscapes (e.g. cropland or forest) might look under different weather or climate scenarios - whether next week's forecast or the conditions expected in 2050.EcoMapper generates synthetic satellite images that reflect expected changes in vegetation, land cover, or surface conditions. It can also fill data gaps caused by clouds and extend satellite monitoring into the future - without needing new observations.By connecting climate projections with satellite imagery, EcoMapper helps scientists, policymakers, and planners explore the effects of both short-term weather events and long-term climate change, improving environmental forecasting, disaster preparedness, and sustainable land use strategies."
Poster,Edge-Colored Clustering in Hypergraphs: Beyond Minimizing Unsatisfied Edges,https://ICML.cc//virtual/2025/poster/45350,"Alex Crane, Thomas Stanley, Blair D. Sullivan, Nate Veldt","We consider a framework for clustering edge-colored hypergraphs, where the goal is to cluster (equivalently, to *color*) objects based on the primary type of multiway interactions they participate in. One well-studied objective is to color nodes to minimize the number of *unsatisfied* hyperedges---those containing one or more nodes whose color does not match the hyperedge color. We motivate and present advances for several directions that extend beyond this minimization problem. We first provide new algorithms for maximizing *satisfied* edges, which is the same at optimality but is much more challenging to approximate, with all prior work restricted to graphs. We develop the first approximation algorithm for hypergraphs, and then refine it to improve the best-known approximation factor for graphs. We then introduce new objective functions that incorporate notions of balance and fairness, and provide new hardness results, approximations, and fixed-parameter tractability results.","Clustering is the fundamental computational task of partitioning a dataset into groups of similar data objects. We present new algorithms and complexity results for a framework for clustering objects based on categorical, multiway interactions. For example, in a dataset of workers, prior team assignments can be modeled as multiway interactions with categorical labels (where the category can indicate the type of task that team worked on). Here, our clustering framework could be used to assign workers to future tasks based on prior experience. Among other results, we present new approaches for ensuring the output clustering satisfies certain balance requirements with respect to different categories of interactions. In our example, one such balance condition would be that workers are assigned to task types in such a way that certain types of tasks are not favored far more than others."
Poster,Editable Concept Bottleneck Models,https://ICML.cc//virtual/2025/poster/45301,"Lijie Hu, Chenyang Ren, Zhengyu Hu, Hongbin Lin, Chenglong Wang, Zhen Tan, Weimin Lyu, Jingfeng Zhang, Hui Xiong, Di Wang","Concept Bottleneck Models (CBMs) have garnered much attention for their ability to elucidate the prediction process through a human-understandable concept layer. However, most previous studies focused on cases where the data, including concepts, are clean. In many scenarios, we always need to remove/insert some training data or new concepts from trained CBMs due to different reasons, such as privacy concerns, data mislabelling, spurious concepts, and concept annotation errors. Thus, the challenge of deriving efficient editable CBMs without retraining from scratch persists, particularly in large-scale applications. To address these challenges, we propose Editable Concept Bottleneck Models (ECBMs). Specifically, ECBMs support three different levels of data removal: concept-label-level, concept-level, and data-level. ECBMs enjoy mathematically rigorous closed-form approximations derived from influence functions that obviate the need for re-training. Experimental results demonstrate the efficiency and effectiveness of our ECBMs, affirming their adaptability within the realm of CBMs.","Most previous studies on Concept Bottleneck Models (CBMs) focused on cases where the data, including concepts, are clean. In many scenarios, we always need to remove/insert some training data or new concepts from trained CBMs due to different reasons, such as privacy concerns, data mislabelling, spurious concepts, and concept annotation errors. Thus, to address these challenges, we propose Editable Concept Bottleneck Models (ECBMs), which support three different levels of data removal: concept-label-level, concept-level, and data-level. ECBMs enjoy mathematically rigorous closed-form approximations derived from influence functions that obviate the need for re-training."
Poster,Editable Noise Map Inversion: Encoding Target-image into Noise For High-Fidelity Image Manipulation,https://ICML.cc//virtual/2025/poster/43497,"Mingyu Kang, Yong Suk Choi","Text-to-image diffusion models have achieved remarkable success in generating high-quality and diverse images. Building on these advancements, diffusion models have also demonstrated exceptional performance in text-guided image editing. A key strategy for effective image editing involves inverting the source image into editable noise maps associated with the target image. However, previous inversion methods face challenges in adhering closely to the target text prompt. The limitation arises because inverted noise maps, while enabling faithful reconstruction of the source image, restrict the flexibility needed for desired edits. To overcome this issue, we propose Editable Noise Map Inversion (ENM Inversion), a novel inversion technique that searches for optimal noise maps to ensure both content preservation and editability. We analyze the properties of noise maps for enhanced editability. Based on this analysis, our method introduces an editable noise refinement that aligns with the desired edits by minimizing the difference between the reconstructed and edited noise maps. Extensive experiments demonstrate that ENM Inversion outperforms existing approaches across a wide range of image editing tasks in both preservation and edit fidelity with target prompts. Our approach can also be easily applied to video editing, enabling temporal consistency and content manipulation across frames.","Recent advances in AI have made it possible to create highly realistic and diverse images from text descriptions. But what if we want to edit an existing image — like changing a cat into a dog, or making a beach scene look like a winter landscape — based on a new text prompt? This is tricky, because current methods that reverse an image into a format the model can work with often stick too closely to the original, limiting how much can be changed.To address this, we propose a new method called Editable Noise Map Inversion (ENM Inversion). This technique finds the right ""noise map"" (an internal representation in the model) that keeps the image's key details while allowing for flexible edits guided by text. Our approach leads to better results in a wide range of editing tasks, staying true to both the original image and the new prompt. ENM Inversion also works for video editing, helping create smooth, consistent changes across frames."
Poster,EditLord: Learning Code Transformation Rules for Code Editing,https://ICML.cc//virtual/2025/poster/46032,"Weichen Li, Albert Jan, Baishakhi Ray, Junfeng Yang, Chengzhi Mao, Kexin Pei","Code editing is a foundational task in software development, where its effectiveness depends on whether it introduces desired code property changes without changing the original code's intended functionality. Existing approaches often formulate code editing as an implicit end-to-end task, omitting the fact that code-editing procedures inherently consist of discrete and explicit steps, and thus suffer from suboptimal performance and lack of robustness and generalization. We introduce EditLord, a code editing framework that makes the code transformation steps explicit. Our key insight is to employ a language model (LM) as an inductive learner to extract code editing rules from the training code pairs as concise meta-rule sets.Such rule sets will be manifested for each training sample to augment them for finetuning or assist in prompting- and iterative-based code editing.EditLord outperforms the state-of-the-art by an average of 22.7% in editing performance and 58.1% in robustness while achieving 20.2% higher functional correctness, across critical software engineering and security applications, LM models, and editing modes.","Editing code is a common but complex part of software development. Most current tools try to do this automatically, but they often treat the process as one big step, which can make the results unreliable or hard to generalize.We created a new tool called EditLord that takes a more structured approach. Instead of treating code editing as a black box, EditLord breaks the process down into clear steps. EditLord uses a powerful language model to learn simple editing rules from examples of how code was changed. These rules can then help guide future edits, whether the model is being fine-tuned or used directly.EditLord consistently outperforms other tools across various real-world programming tasks, e.g., performance optimization, readability improvement, and security hardening.It makes more accurate edits, handles different situations better, and maintains the original function of the code more reliably."
Poster,EduLLM: Leveraging Large Language Models and Framelet-Based Signed Hypergraph Neural Networks for Student Performance Prediction,https://ICML.cc//virtual/2025/poster/46399,"Ming Li, Yukang Cheng, Lu Bai, Feilong Cao, Ke Lv, Jiye Liang, Pietro Lió","The growing demand for personalized learning underscores the importance of accurately predicting students' future performance to support tailored education and optimize instructional strategies. Traditional approaches predominantly focus on temporal modeling using historical response records and learning trajectories. While effective, these methods often fall short in capturing the intricate interactions between students and learning content, as well as the subtle semantics of these interactions. To address these gaps, we present EduLLM, the first framework to leverage large language models in combination with hypergraph learning for student performance prediction. The framework incorporates FraS-HNN ($\underline{\mbox{Fra}}$melet-based $\underline{\mbox{S}}$igned $\underline{\mbox{H}}$ypergraph $\underline{\mbox{N}}$eural $\underline{\mbox{N}}$etworks), a novel spectral-based model for signed hypergraph learning, designed to model interactions between students and multiple-choice questions. In this setup, students and questions are represented as nodes, while response records are encoded as positive and negative signed hyperedges, effectively capturing both structural and semantic intricacies of personalized learning behaviors. FraS-HNN employs framelet-based low-pass and high-pass filters to extract multi-frequency features. EduLLM integrates fine-grained semantic features derived from LLMs, synergizing with signed hypergraph representations to enhance prediction accuracy. Extensive experiments conducted on multiple educational datasets demonstrate that EduLLM significantly outperforms state-of-the-art baselines, validating the novel integration of LLMs with FraS-HNN for signed hypergraph learning.","To support more personalized and effective education, it is important to understand how students are likely to perform in the future. Our research introduces a new approach, called EduLLM, that combines the power of large language models with a novel type of network analysis known as signed hypergraph neural networks. This method allows us to model complex learning behaviors by capturing not only who interacts with what learning content, but also whether those interactions are positive or negative, such as correct or incorrect answers. By combining these structural patterns with deeper language understanding, EduLLM offers more accurate predictions of student performance. Beyond educational use, our proposed signed hypergraph neural networks also show strong potential for advancing hypergraph learning and enabling more powerful applications in other domains."
Poster,EEG-Language Pretraining for Highly Label-Efficient Clinical Phenotyping,https://ICML.cc//virtual/2025/poster/43523,"Sam Gijsen, Kerstin Ritter","Multimodal language modeling has enabled breakthroughs for representation learning, yet remains unexplored in the realm of functional brain data for clinical phenotyping. This paper pioneers EEG-language models (ELMs) trained on clinical reports and 15000 EEGs. We propose to combine multimodal alignment in this novel domain with timeseries cropping and text segmentation, enabling an extension based on multiple instance learning to alleviate misalignment between irrelevant EEG or text segments. Our multimodal models significantly improve over EEG-only models across four clinical evaluations and for the first time enable zero-shot classification as well as retrieval of both neural signals and reports. In sum, these results highlight the potential of ELMs, representing significant progress for clinical applications.","AI models are capable of detecting abnormal brain activity indicative of disease, yet require extensive data labeling by experts. We present a novel approach that combines brain models and large language models. This enables brain models to teach themselves using existing natural language clinical reports which describe the patient and brain recording. We show such models are significantly better at disease detection, performing well with minimal or even no expert labels whatsoever."
Poster,EFDTR: Learnable Elliptical Fourier Descriptor Transformer for Instance Segmentation,https://ICML.cc//virtual/2025/poster/44105,"Jiawei Cao, Chaochen Gu, Hao Cheng, Xiaofeng Zhang, Kaijie Wu, Changsheng Lu","Polygon-based object representations efficiently model object boundaries but are limited by high optimization complexity, which hinders their adoption compared to more flexible pixel-based methods. In this paper, we introduce a novel vertex regression loss grounded in Fourier elliptic descriptors, which removes the need for rasterization or heuristic approximations and resolves ambiguities in boundary point assignment through frequency-domain matching.To advance polygon-based instance segmentation, we further propose EFDTR (\textbf{E}lliptical \textbf{F}ourier \textbf{D}escriptor \textbf{Tr}ansformer), an end-to-end learnable framework that leverages the expressiveness of Fourier-based representations. The model achieves precise contour predictions through a two-stage approach: the first stage predicts elliptical Fourier descriptors for global contour modeling, while the second stage refines contours for fine-grained accuracy. Experimental results on the COCO dataset show that EFDTR outperforms existing polygon-based methods, offering a promising alternative to pixel-based approaches. Code is available at \url{https://github.com/chrisclear3/EFDTR}.","Most image segmentation methods work by teaching computers to label every pixel in a picture, creating detailed object masks. While accurate, these masks can be large and take more effort for the computer to handle. A more compact alternative is to trace just the outlines — the contours — of objects. But earlier attempts at this often struggled with figuring out exactly where the boundary points should go, making them less accurate than pixel-based methods.We introduce EFDTR, a new approach that solves this problem using elliptical Fourier descriptors — a mathematical tool that captures object boundaries as smooth curves. By expressing contours in the frequency domain, EFDTR avoids the ambiguity in point matching and improves prediction accuracy.Built with a transformer-based architecture, EFDTR combines the global modeling power of Fourier descriptors with precise boundary refinement. It outperforms previous contour-based methods and narrows the accuracy gap with pixel-based techniques, offering a promising direction for applications like autonomous driving or medical image analysis."
Poster,Effective and Efficient Masked Image Generation Models,https://ICML.cc//virtual/2025/poster/44006,"Zebin You, Jingyang Ou, Xiaolu Zhang, Jun Hu, JUN ZHOU, Chongxuan Li","Although masked image generation models and masked diffusion models are designed with different motivations and objectives, we observe that they can be unified within a single framework. Building upon this insight, we carefully explore the design space of training and sampling, identifying key factors that contribute to both performance and efficiency. Based on the improvements observed during this exploration, we develop our model, referred to as \textbf{eMIGM}. Empirically, eMIGM demonstrates strong performance on ImageNet generation, as measured by Fréchet Inception Distance (FID). In particular, on ImageNet $256\times256$, with similar number of function evaluations (NFEs) and model parameters, eMIGM outperforms the seminal VAR. Moreover, as NFE and model parameters increase, eMIGM achieves performance comparable to the state-of-the-art continuous diffusion model REPA while requiring less than 45\% of the NFE. Additionally, on ImageNet $512\times512$, eMIGM outperforms the strong continuous diffusion model EDM2. Code is available at \url{https://github.com/ML-GSAI/eMIGM}.","Our new AI, eMIGM, creates realistic pictures by learning to fill in missing parts of images, much like solving a puzzle. We discovered that by combining the strengths of two existing image generation methods into a unified system, and carefully refining how it learns and creates, we could significantly boost both image quality and generation speed. eMIGM learns more effectively when more of an image is hidden during its training. When generating new pictures, it cleverly predicts fewer details initially and only receives stronger guidance later on, making it much faster. As a result, eMIGM produces high-quality images, outperforming standard methods and matching top-tier ones with significantly less computational power, even on large images. This work makes high-quality AI image generation more effective and efficient, and our code is publicly available."
Poster,Efficient and Privacy-Preserving Soft Prompt Transfer for LLMs,https://ICML.cc//virtual/2025/poster/44996,"Xun Wang, Jing Xu, Franziska Boenisch, Michael Backes, Christopher A. Choquette Choo, Adam Dziedzic","Prompting has become a dominant paradigm for adapting large language models (LLMs).While discrete (textual) prompts are widely used for their interpretability, soft (parameter) prompts have recently gained traction in APIs. This is because they can encode information from more training samples while minimizing the user's token usage, leaving more space in the context window for task-specific input. However, soft prompts are tightly coupled to the LLM they are tuned on, limiting their generalization to other LLMs. This constraint is particularly problematic for *efficiency* and *privacy*: (1) tuning prompts on each LLM incurs high computational costs, especially as LLMs continue to grow in size. Additionally, (2) when the LLM is hosted externally, soft prompt tuning often requires sharing private data with the LLM provider. For instance, this is the case with the NVIDIA NeMo API.To address these issues, we propose POST (**P**rivacy **O**f **S**oft prompt **T**ransfer), a framework that enables private tuning of soft prompts on a small model and subsequently transfers these prompts to a larger LLM.POST uses knowledge distillation to derive a small model directly from the large LLM to improve prompt transferability, tunes the soft prompt locally, optionally with differential privacy guarantees, and transfers it back to the larger LLM using a small public dataset. Our experiments show that POST reduces computational costs, preserves privacy, and effectively transfers high-utility soft prompts.","Large language models (LLMs) like ChatGPT have become powerful tools for various tasks, but customizing them for specific needs often requires sharing sensitive data with the model providers, raising privacy concerns. Additionally, tailoring these massive models can be computationally intensive.This paper introduces POST, a novel method that allows users to personalize LLMs without compromising their private data or needing significant computational resources. The approach works by first creating a smaller version of the large model. Users can then fine-tune this compact model locally using their own data, ensuring privacy. After this local tuning, the adjustments are transferred back to the original large model using publicly available data, eliminating the need to share any private information.POST paves the way for broader and more responsible use of AI technologies by enabling secure and efficient customization of LLMs."
