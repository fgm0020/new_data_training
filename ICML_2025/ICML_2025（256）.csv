type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Revisiting Continuity of Image Tokens for Cross-domain Few-shot Learning,https://ICML.cc//virtual/2025/poster/45416,"Shuai Yi, Yixiong Zou, Yuhua Li, Ruixuan Li","Vision Transformer (ViT) has achieved remarkable success due to its large-scale pretraining on general domains, but it still faces challenges when applying it to downstream distant domains that have only scarce training data, which gives rise to the Cross-Domain Few-Shot Learning (CDFSL) task. Inspired by Self-Attention's insensitivity to token orders, we find an interesting phenomenon neglected in current works: disrupting the continuity of image tokens (i.e., making pixels not smoothly transited across patches) in ViT leads to a noticeable performance decline in the general (source) domain but only a marginal decrease in downstream target domains. This questions the role of image tokens' continuity in ViT's generalization under large domain gaps. In this paper, we delve into this phenomenon for an interpretation. We find continuity aids ViT in learning larger spatial patterns, which are harder to transfer than smaller ones, enlarging domain distances. Meanwhile, it implies that only smaller patterns within each patch could be transferred under extreme domain gaps. Based on this interpretation, we further propose a simple yet effective method for CDFSL that better disrupts the continuity of image tokens, encouraging the model to rely less on large patterns and more on smaller ones. Extensive experiments show the effectiveness of our method in reducing domain gaps and outperforming state-of-the-art works. Codes and models are available at https://github.com/shuaiyi308/ReCIT.","We find a phenomenon that disrupting image patches' continuity (e.g., shuffle patches) affects differently on source and target domains. We delve into it for an interpretation and propose a method based on it for CDFSL."
Poster,Revisiting Convergence: Shuffling Complexity Beyond Lipschitz Smoothness,https://ICML.cc//virtual/2025/poster/43996,"Qi He, Peiran Yu, Ziyi Chen, Heng Huang","Shuffling-type gradient methods are favored in practice for their simplicity and rapid empirical performance. Despite extensive development of convergence guarantees under various assumptions in recent years, most require the Lipschitz smoothness condition, which is often not met in common machine learning models. We highlight this issue with specific counterexamples. To address this gap, we revisit the convergence rates of shuffling-type gradient methods without assuming Lipschitz smoothness. Using our stepsize strategy, the shuffling-type gradient algorithm not only converges under weaker assumptions but also match the current best-known convergence rates, thereby broadening its applicability. We prove the convergence rates for nonconvex, strongly convex, and non-strongly convex cases, each under both random reshuffling and arbitrary shuffling schemes, under a general bounded variance condition. Numerical experiments further validate the performance of our shuffling-type gradient algorithm, underscoring its practical efficacy.","Many AI engineers speed up learning by shuffling the order of training examples, yet proofs of its reliability have existed only for the ideal case where the loss surface is perfectly smooth. Modern models—from image classifiers to language models—violate that tidy assumption, belonging instead to a broader “generalized smoothness” family whose bumps and plateaus were not covered by earlier theory.Our study shows that shuffling‑type gradient methods still converge rapidly under this more permissive generalized‑smoothness condition. We supply tight rate guarantees for both easy (convex) and hard (non‑convex) objectives and present a simple formula for picking step sizes that keeps training on track in these rougher landscapes. By extending the safety net around a technique practitioners already trust, our results let developers use shuffling with mathematical confidence on today’s messier problems and point to step‑size schedules that can make training even faster in practice."
Poster,Revisiting Cooperative Off-Policy Multi-Agent Reinforcement Learning,https://ICML.cc//virtual/2025/poster/45696,"yueheng li, Guangming Xie, Zongqing Lu","Cooperative Multi-Agent Reinforcement Learning (MARL) has become a critical tool for addressing complex real-world problems. However, off-policy MARL methods, which rely on joint Q-functions, face significant scalability challenges due to the exponentially growing joint action space.In this work, we highlight a critical yet often overlooked issue: erroneous Q-target estimation, primarily caused by extrapolation error.Our analysis reveals that this error becomes increasingly severe as the number of agents grows, leading to unique challenges in MARL due to its expansive joint action space and the decentralized execution paradigm.To address these challenges, we propose a suite of techniques tailored for off-policy MARL, including annealed multi-step bootstrapping, averaged Q-targets, and restricted action representation. Experimental results demonstrate that these methods effectively mitigate erroneous estimations, yielding substantial performance improvements in challenging benchmarks such as SMAC, SMACv2, and Google Research Football.","In cooperative Multi-Agent Reinforcement Learning (MARL), multiple agents learn to work together to solve complex tasks. Off-policy methods—which aim to train agents more efficiently—are popular in this area. However, they often struggle when the number of agents grows. This is because these methods must consider all possible combinations of team actions, which quickly becomes overwhelming and leads to inaccurate predictions during training.Our research shows that these prediction errors, though often overlooked, play a major role in the poor performance of off-policy MARL at larger scales. Existing solutions only partially address the issue, leaving room for improvement.To tackle this, we introduce three simple and broadly applicable techniques that make the learning process more reliable. These strategies help the system focus on more useful training signals and reduce the impact of inaccurate predictions.We test our methods on several challenging multi-agent tasks, and see consistent improvements in performance. Our findings not only enhance current off-policy MARL approaches but also offer a new perspective on how to train large teams of AI agents more effectively."
Poster,Revisiting Differentially Private Algorithms for Decentralized Online Learning,https://ICML.cc//virtual/2025/poster/46656,"Xiaoyu Wang, Wenhao Yang, Chang Yao, Mingli Song, Yuanyu Wan","Although the differential privacy (DP) of decentralized online learning has garnered considerable attention recently, existing algorithms are unsatisfactory due to their inability to achieve $(\epsilon, 0)$-DP over all $T$ rounds, recover the optimal regret in the non-private case, and maintain the lightweight computation under complex constraints. To address these issues, we first propose a new decentralized online learning algorithm satisfying $(\epsilon, 0)$-DP over $T$ rounds, and show that it can achieve $\widetilde{O}(n(\rho^{-1/4}+\epsilon^{-1}\rho^{1/4})\sqrt{T})$ and $\widetilde{O}(n (\rho^{-1/2}+\epsilon^{-1}))$ regret bounds for convex and strongly convex functions respectively, where $n$ is the number of local learners and $\rho$ is the spectral gap of the communication matrix. As long as $\epsilon=\Omega(\sqrt{\rho})$, these bounds nearly match existing lower bounds in the non-private case, which implies that $(\epsilon, 0)$-DP of decentralized online learning may be ensured nearly for free. Our key idea is to design a block-decoupled accelerated gossip strategy that can be incorporated with the classical tree-based private aggregation, and also enjoys a faster average consensus among local learners. Furthermore, we develop a projection-free variant of our algorithm to keep the efficiency under complex constraints. As a trade-off, the above regret bounds degrade to $\widetilde{O}(n(T^{3/4}+\epsilon^{-1}T^{1/4}))$ and $\widetilde{O}(n(T^{2/3}+\epsilon^{-1}))$ respectively, which however are even better than the existing private centralized projection-free online algorithm.","In this paper, we first propose a new decentralized online learning algorithm satisfying $(\epsilon, 0)$-DP over $T$ rounds, and show that its regret bounds can nearly match existing lower bounds in the non-private case for some $\epsilon$. Our key idea is to design a block-decoupled accelerated gossip strategy that can be incorporated with the classical tree-based private aggregation, and also enjoys a faster average consensus among local learners. Furthermore, we develop a projection-free variant of our algorithm to keep the efficiency under complex constraints."
Poster,Revisiting Diffusion Models: From Generative Pre-training to One-Step Generation,https://ICML.cc//virtual/2025/poster/44635,"Bowen Zheng, Tianming Yang","Diffusion distillation is a widely used technique to reduce the sampling cost of diffusion models, yet it often requires extensive training, and the student performance tends to be degraded. Recent studies show that incorporating a GAN objective may alleviate these issues, yet the underlying mechanism remains unclear. In this work, we first identify a key limitation of distillation: mismatched step sizes and parameter numbers between the teacher and the student model lead them to converge to different local minima, rendering direct imitation suboptimal. We further demonstrate that a standalone GAN objective, without relying a distillation loss, overcomes this limitation and is sufficient to convert diffusion models into efficient one-step generators. Based on this finding, we propose that diffusion training may be viewed as a form of generative pre-training, equipping models with capabilities that can be unlocked through lightweight GAN fine-tuning. Supporting this view, we create a one-step generation model by fine-tuning a pre-trained model with 85% of parameters frozen, achieving strong performance with only 0.2M images and near-SOTA results with 5M images. We further present a frequency-domain analysis that may explain the one-step generative capability gained in diffusion training. Overall, our work provides a new perspective for diffusion training, highlighting its role as a powerful generative pre-training process, which can be the basis for building efficient one-step generation models.","Modern generative models, like diffusion models, often require a slow and computationally expensive process to create high-quality images. To make them faster, a common technique called diffusion distillation trains a simpler and faster single-step student model to mimic a larger diffusion model. However, this approach typically requires extensive training and often leads to reduced performance in the student model. In this work, we show that by not strictly training the student model to mimic the teacher and allowing the student model to discover its own solution, we can leverage the knowledge already acquired during diffusion pretraining to achieve fast and effective one-step generation. Our method uses fewer than 1/100 training images than the previous ones and achieves performance near the best models to date. Our research provides a new perspective to understand what diffusion training does and provides an efficient way to create one-step generative models."
Poster,Revisiting Instance-Optimal Cluster Recovery in the Labeled Stochastic Block Model,https://ICML.cc//virtual/2025/poster/44276,"Kaito Ariu, Alexandre Proutiere, Se-Young Yun","In this paper, we investigate the problem of recovering hidden communities in the Labeled Stochastic Block Model (LSBM) with a finite number of clusters whose sizes grow linearly with the total number of nodes. We derive the necessary and sufficient conditions under which the expected number of misclassified nodes is less than $ s $, for any number $ s = o(n) $. To achieve this, we propose IAC (Instance-Adaptive Clustering), the first algorithm whose performance matches the instance-specific lower bounds both in expectation and with high probability.IAC is a novel two-phase algorithm that consists of a one-shot spectral clustering step followed by iterative likelihood-based cluster assignment improvements. This approach is based on the instance-specific lower bound and notably does not require any knowledge of the model parameters, including the number of clusters. By performing the spectral clustering only once, IAC maintains an overall computational complexity of $ \mathcal{O}(n\, \text{polylog}(n)) $, making it scalable and practical for large-scale problems.","**(1) Problem:**Many modern applications—from social networks to biology—seek to uncover “communities” or groups within large, complex networks. Detecting these hidden groups accurately and efficiently, especially as networks grow larger, is a longstanding and challenging problem.**(2) Solution:**Our research tackles this challenge by designing a new algorithm, called IAC, which can reveal these groups without knowing any details about the network in advance—such as how many groups there are. IAC works in two main steps: it first takes a quick overall look to find an initial guess of the groups, and then iteratively refines these groupings to improve accuracy, relying on advanced mathematical principles.**(3) Impact:**What sets IAC apart is that it not only finds almost all communities correctly, but does so with less computational effort than previous methods, making it suitable for very large datasets. Our work offers new mathematical guarantees for detecting hidden communities and provides a practical tool for analyzing complex networks in a wide range of real-world settings."
Poster,Revisiting Neural Networks for Few-Shot Learning: A Zero-Cost NAS Perspective,https://ICML.cc//virtual/2025/poster/44527,Haidong Kang,"Neural Architecture Search (NAS) has recently outperformed hand-designed networks in various artificial intelligence areas. However, previous works only target a pre-defined task. For a new task in few-shot learning (FSL) scenarios, the architecture is either searched from scratch, which is neither efficient nor flexible, or borrowed architecture from the ones obtained on other tasks, which may lead to sub-optimal. Can we select the best neural architectures without involving any training and eliminate a significant portion of the search cost for new tasks in FSL? In this work, we provide an affirmative answer by proposing a novel information bottleneck (IB) theory driven \textit{Few-shot Neural Architecture Search} (dubbed, IBFS) framework to address this issue. We first derive that the global convergence of Model-agnostic meta-learning (MAML) can be guaranteed by only considering the first-order loss landscape. Moreover, motivated by the observation that IB provides a unified view toward understanding machine learning models, we propose a novel Zero-Cost method tailored for FSL to rank and select architectures based on their \textit{expressivity} obtained by IB mechanisms. Extensive experiments show that IBFS achieves state-of-the-art performance in FSL without training, which demonstrates the effectiveness of our IBFS.","Can we design the best neural network for a new task without any training? This is an extremely challenging question for the deep learning community, especially when only a few datas are available. We wanted to answer this question by using a method called IB driven Few-shot Neural Architecture Search (IBFS) to well evaluate the expressivity of the architecture sampled from the search space for few-shot learning in a training-free manner.Our paper presents the surprising result that for few-shot learning problems, and obtain state-of-the-art performance. Our findings have implications for how we measure expressivity of the architecture tailored for few-shot learning, generalize to unseen tasks without expensive trial-and-error training, and demonstrate that neural networks play an important role in few-shot learning."
Poster,Revisiting Noise Resilience Strategies in Gesture Recognition: Short-Term Enhancement in sEMG Analysis,https://ICML.cc//virtual/2025/poster/46085,"Weiyu Guo, Ziyue Qiao, Ying Sun, Yijie Xu, Hui Xiong","Gesture recognition based on surface electromyography (sEMG) has been gaining importance in many 3D Interactive Scenes. However, sEMG is easily influenced by various forms of noise in real-world environments, leading to challenges in providing long-term stable interactions through sEMG. Existing methods often struggle to enhance model noise resilience through various predefined data augmentation techniques.In this work, we revisit the problem from a short-term enhancement perspective to improve precision and robustness against various common noisy scenarios with learnable denoise using sEMG intrinsic pattern information and sliding-window attention. We propose a Short Term Enhancement Module(STEM), which can be easily integrated with various models. STEM offers several benefits: 1) Noise-resistant, enhanced robustness against noise without manual data augmentation; 2) Adaptability, adaptable to various models; and 3) Inference efficiency, achieving short-term enhancement through minimal weight-sharing in an efficient attention mechanism.In particular, we incorporate STEM into a transformer, creating the Short-Term Enhanced Transformer (STET).Compared with best-competing approaches, the impact of noise on STET is reduced by more than 20\%. We report promising results on classification and regression tasks and demonstrate that STEM generalizes across different gesture recognition tasks. The code is available at https://anonymous.4open.science/r/short_term_semg.","Gesture recognition technology, which translates human movements into digital commands, is growing increasingly popular in virtual reality, robotics, and assistive devices. This technology often uses electrical signals from muscles (known as sEMG signals). However, these signals can easily become noisy or unreliable due to environmental factors like skin moisture or poor electrode contact, making accurate recognition difficult.In our work, we introduce a new approach to help computers better interpret these noisy signals. We created a simple yet effective technique called STEM that enhances short-term signal features, making gesture recognition significantly more reliable without needing extra data. This method can be effortlessly added to existing recognition systems. When tested, our approach showed greater accuracy and was notably less affected by noise than current methods. This innovation could substantially improve how reliably we interact with computers and robots in everyday life, especially in environments that are less controlled than laboratories."
Poster,Revisiting Non-Acyclic GFlowNets in Discrete Environments,https://ICML.cc//virtual/2025/poster/44654,"Nikita Morozov, Ian Maksimov, Daniil Tiapkin, Sergey Samsonov","Generative Flow Networks (GFlowNets) are a family of generative models that learn to sample objects from a given probability distribution, potentially known up to a normalizing constant. Instead of working in the object space, GFlowNets proceed by sampling trajectories in an appropriately constructed directed acyclic graph environment, greatly relying on the acyclicity of the graph. In our paper, we revisit the theory that relaxes the acyclicity assumption and present a simpler theoretical framework for non-acyclic GFlowNets in discrete environments. Moreover, we provide various novel theoretical insights related to training with fixed backward policies, the nature of flow functions, and connections between entropy-regularized RL and non-acyclic GFlowNets, which naturally generalize the respective concepts and theoretical results from the acyclic setting. In addition, we experimentally re-examine the concept of loss stability in non-acyclic GFlowNet training, as well as validate our own theoretical findings.","Imagine trying to guide the assembly of toy construction blocks to create the most impressive or functional structures. We work on smart AI helpers called GFlowNets that learn sequences of placing, removing, or rearranging blocks to achieve diverse successful builds. Traditionally, these helpers assume construction always moves forward linearly, never removing an already placed block or disassembling a section to try a different approach towards a specific design.Our research studies ways for these AI helpers to understand more complex assembly paths — ones where they might repeat beneficial construction techniques or take winding routes by disassembling and reconfiguring sections to discover even stronger, more creative, or more diverse finished structures. We revisit previous research on this topic, presenting a simpler and more intuitive theoretical framework for designing such models, as well as experimentally study the ways for these AI helpers to learn more efficiently. By allowing these models to explore more flexible building journeys, we're paving the way for AI that can find richer solutions to complex, real-world problems."
Poster,"Revisiting the Predictability of Performative, Social Events",https://ICML.cc//virtual/2025/poster/45352,Juan Perdomo,"Social predictions do not passively describe the future; they actively shape it. They inform actions and change individual expectations in ways that influence the likelihood of the predicted outcome. Given these dynamics, to what extent can social events be predicted? This question was discussed throughout the 20th century by authors like Merton, Morgenstern, Simon, and others who considered it a central issue in social science methodology. In this work, we provide a modern answer to this old problem. Using recent ideas from performative prediction and outcome indistinguishability, we establish that one can always efficiently predict social events accurately, regardless of how predictions influence data. While achievable, we also show that these predictions are often undesirable, highlighting the limitations of previous desiderata. We end with a discussion of various avenues forward.","When we use algorithms to make predictions about people, these predictions don’t just passively forecast the future: they actively shape it. For instance, predicting that someone is at high risk of a heart attack influences their lifestyle choices and medical treatments in ways that shape their future health outcomes. Once recognized, we see these feedback loops between algorithms and society everywhere, from traffic predictions to stock markets and politics.Given that predictions are “performative” and shape the data we see, is it possible to reliably predict social events? In this paper, I develop simple procedures that can efficiently produce valid forecasts of social events, no matter the underlying feedback loops. This result places a common issue in social science methodology on formal mathematical footing. It also challenges traditional notions of validity when forecasting social events and motivates further questions around what makes a prediction truly “valuable” if predictions shape social outcomes."
