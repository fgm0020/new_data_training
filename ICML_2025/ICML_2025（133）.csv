type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Hierarchical Equivariant Policy via Frame Transfer,https://ICML.cc//virtual/2025/poster/44116,"Haibo Zhao, Dian Wang, Yizhe Zhu, Xupeng Zhu, Owen Howell, Linfeng Zhao, Yaoyao Qian, Robin Walters, Robert Platt","Recent advances in hierarchical policy learning highlight the advantages of decomposing systems into high-level and low-level agents, enabling efficient long-horizon reasoning and precise fine-grained control. However, the interface between these hierarchy levels remains underexplored, and existing hierarchical methods often ignore domain symmetry, resulting in the need for extensive demonstrations to achieve robust performance. To address these issues, we propose Hierarchical Equivariant Policy (HEP), a novel hierarchical policy framework. We propose a frame transfer interface for hierarchical policy learning, which uses the high-level agent's output as a coordinate frame for the low-level agent, providing a strong inductive bias while retaining flexibility. Additionally, we integrate domain symmetries into both levels and theoretically demonstrate the system's overall equivariance. HEP achieves state-of-the-art performance in complex robotic manipulation tasks, demonstrating significant improvements in both simulation and real-world settings.","Robots can pick up new household or factory skills by watching human demonstrations, but they usually need hundreds of examples because even a tiny change—say, nudging an object a few centimetres—looks completely unfamiliar to them.Our solution is a “two-brain” controller:Big-picture brain: chooses the next general spot for the robot’s hand.Fine-motion brain: works out the precise path to reach that spot.Both brains are trained to recognise when the entire scene has simply been shifted or rotated, so they can recycle the same plan instead of starting over. They communicate through Frame Transfer, which lets the fine-motion brain reason in a local coordinate frame tied to the chosen spot.In simulations and on real robots, this cut the training burden from hundreds of demonstrations to just a few dozen, and let robots finish long, multi-step tasks—like stacking blocks or scrubbing a pot—after seeing only a handful of examples."
Poster,Hierarchical Graph Tokenization for Molecule-Language Alignment,https://ICML.cc//virtual/2025/poster/43604,"Yongqiang Chen, QUANMING YAO, Juzheng Zhang, James Cheng, Yatao Bian","Recently, there has been a surge of interest in extending the success of large language models (LLMs) from texts to molecules. Most existing approaches adopt a graph neural network to represent a molecule as a series of node tokens for molecule-language alignment, which, however, have overlooked the inherent hierarchical structures in molecules. Notably, higher-order molecular structures contain rich semantics of functional groups, which encode crucial biochemical functionalities of the molecules. We show that neglecting the hierarchical information in tokenization will lead to subpar molecule-language alignment and severe hallucination. To address this limitation, we propose HIerarchical GrapH Tokenization (HIGHT). HIGHT employs a hierarchical graph tokenizer that encodes the hierarchy of atom, motif, and molecular levels of informative tokens to improve the molecular perception of LLMs. HIGHT also adopts an augmented instruction tuning dataset, enriched with the hierarchical graph information, to further enhance the molecule-language alignment. Extensive experiments on 14 real-world benchmarks verify the effectiveness of HIGHT in reducing hallucination by 40%, and significant improvements in various molecule-language downstream tasks. The project is available at https: //higraphllm.github.io/.","How can we teach Large Language Models (LLMs) like ChatGPT to understand graph-structured data like molecules? Molecules are complex, with structures that go beyond individual atoms — they have functional groups and motifs that define their behavior, such as how they interact in biological or chemical processes. Current LLMs that align molecular data with language often overlook these hierarchical structures, leading to hallucinations and misinterpretations, like falsely identifying functional groups.Our paper presents HIGHT, a new technique that captures the hierarchical structure of molecules, from atoms to motifs to the entire molecule. HIGHT uses a hierarchical graph tokenizer to explicitly teach LLMs to recognize and understand the intrinsic hierarchy. Our results show significant improvements in molecule-related tasks, like predicting chemical properties and generating accurate molecule descriptions. Notably, HIGHT reduces errors (or ""hallucinations"") in identifying functional groups by 40%. This work extends the perception of LLMs to graph-structured data, and lays a foundation for more reliable AI applications in drug discovery, material science, and chemistry."
Poster,Hierarchical Masked Autoregressive Models with Low-Resolution Token Pivots,https://ICML.cc//virtual/2025/poster/43802,"Guangting Zheng, Yehao Li, Yingwei Pan, Jiajun Deng, Ting Yao, Yanyong Zhang, Tao Mei","Autoregressive models have emerged as a powerful generative paradigm for visual generation. The current de-facto standard of next token prediction commonly operates over a single-scale sequence of dense image tokens, and is incapable of utilizing global context especially for early tokens prediction. In this paper, we introduce a new autoregressive design to model a hierarchy from a few low-resolution image tokens to the typical dense image tokens, and delve into a thorough hierarchical dependency across multi-scale image tokens. Technically, we present a Hierarchical Masked Autoregressive models (Hi-MAR) that pivot on low-resolution image tokens to trigger hierarchical autoregressive modeling in a multi-phase manner. Hi-MAR learns to predict a few image tokens in low resolution, functioning as intermediary pivots to reflect global structure, in the first phase. Such pivots act as the additional guidance to strengthen the next autoregressive modeling phase by shaping global structural awareness of typical dense image tokens. A new Diffusion Transformer head is further devised to amplify the global context among all tokens for mask token prediction. Extensive evaluations on both class-conditional and text-to-image generation tasks demonstrate that Hi-MAR outperforms typical AR baselines, while requiring fewer computational costs.","Autoregressive models are a new type of AI system for generating images. They create images piece by piece at a time, like assembling a puzzle. However, this process often starts without a clear idea of the full picture, which can lead to images that are locally correct but globally inconsistent. We propose a new approach that helps the AI start with a rough sketch of the image — a low-resolution version that captures the global layout. This sketch acts as a guide, allowing the model to better fill in the fine details in a more coherent and structured way. Our method, called Hi-MAR, builds the image in multiple stages, first focusing on the overall structure and then refining the finer details. We also design a new component that improves the model’s ability to maintain global consistency. This leads to better image quality with lower computational cost. Our work improves how AI models generate images, making them more efficient and reliable for applications like art, design, and virtual content creation."
Poster,"Hierarchical Overlapping Clustering on Graphs: Cost Function, Algorithm and Scalability",https://ICML.cc//virtual/2025/poster/46447,"Yicheng Pan, Renjie Chen, Pengyu Long, Bingchen Fan","Overlap and hierarchy are two prevalent phenomena in clustering, and usually coexist in a single system. There are several studies on each of them separately, but it is unclear how to characterize and evaluate the hybrid structures yet. To address this issue, we initiate the study of hierarchical overlapping clustering on graphs by introducing a new cost function for it. We show the rationality of our cost function via several intuitive properties, and develop an approximation algorithm that achieves a constant approximation factor for its dual version. Our algorithm is a recursive process of overlapping bipartition based on local search, which makes a speed-up version of it extremely scalable. Our experiments demonstrate that the speed-up algorithm has significantly better performances than all the baseline methods in both effectiveness and scalability on synthetic and real datasets.","In a social network, individuals often belong to organizations with layered structures. For example, a person might be part of a research group under a specific department at a university, while also having multiple roles like being a teacher, a father, and the captain of a local amateur soccer team. Social networks connect people through this mix of layered and overlapping group structures, a pattern also seen in many other complex networks or systems. A key question is: how can we represent, measure, and analyze such structures?Our paper pioneers this research direction. We use a mathematical tool called a ""directed acyclic graph"" (a non-looping node-link structure) to describe these organizational patterns. For any network and its corresponding directed acyclic graph, we developed a method to evaluate how accurately the graph captures the network's layered and overlapping group structures. Additionally, we designed an algorithm that efficiently generates such graphs for any network. This algorithm works even on personal computers, handling networks with tens of thousands of nodes in minutes.We believe this theory is crucial for uncovering the true architecture of complex networks and systems and understanding their evolution. The code for this tool has been made freely available online for public use."
Poster,Hierarchical Planning for Complex Tasks with Knowledge Graph-RAG and Symbolic Verification,https://ICML.cc//virtual/2025/poster/43660,"Flavio Petruzzellis, Cristina Cornelio, Pietro Lió","Large Language Models (LLMs) have shown promise as robotic planners but often struggle with long-horizon and complex tasks, especially in specialized environments requiring external knowledge. While hierarchical planning and Retrieval-Augmented Generation (RAG) address some of these challenges, they remain insufficient on their own and a deeper integration is required for achieving more reliable systems. To this end, we propose a neuro-symbolic approach that enhances LLMs-based planners with Knowledge Graph-based RAG for hierarchical plan generation. This method decomposes complex tasks into manageable subtasks, further expanded into executable atomic action sequences. To ensure formal correctness and proper decomposition, we integrate a Symbolic Validator, which also functions as a failure detector by aligning expected and observed world states. Our evaluation against baseline methods demonstrates the consistent significant advantages of integrating hierarchical planning, symbolic verification, and RAG across tasks of varying complexity and different LLMs. Additionally, our experimental setup and novel metrics not only validate our approach for complex planning but also serve as a tool for assessing LLMs' reasoning and compositional capabilities. Code available at https://github.com/corneliocristina/HVR.","Robots are getting better at understanding everyday language, but they still struggle to plan and execute complicated tasks, especially when those tasks involve many steps, objects, or require outside knowledge. To address this, we developed a new method that helps robots think and plan more like humans do.Our system breaks down complicated problems into smaller, manageable parts using a knowledge graph using the aid of a knowledge graph, a tool that organizes facts describing the environment. The robot uses this structure to generate a plan composed by high-level instructions and then expands each of them into specific actions it can perform. To make sure these plans are not just plausible but also correct, we added a ""Symbolic Validator."" This component double-checks the robot’s plan to ensure that it makes sense and can be executed in the real world, based on what’s actually happening in the environment, and it flags any failures if something goes wrong.We tested our method on a range of tasks and showed it works better than existing techniques. This approach not only helps robots plan more reliably but also gives researchers a new way to understand how well AI systems reason and adapt."
Poster,Hierarchical Refinement: Optimal Transport to Infinity and Beyond,https://ICML.cc//virtual/2025/poster/45965,"Peter Halmos, Julian Gold, Xinhao Liu, Benjamin Raphael","Optimal transport (OT) has enjoyed great success in machine learning as a principled way to align datasets via a least-cost correspondence, driven in large part by the runtime efficiency of the Sinkhorn algorithm (Cuturi, 2013). However, Sinkhorn has quadratic space complexity in the number of points, limiting scalability to larger datasets. Low-rank OT achieves linear-space complexity, but by definition, cannot compute a one-to-one correspondence between points. When the optimal transport problem is an assignment problem between datasets then an optimal mapping, known as the _Monge map_, is guaranteed to be a bijection. In this setting, we show that the factors of an optimal low-rank coupling co-cluster each point with its image under the Monge map. We leverage this invariant to derive an algorithm, _Hierarchical Refinement_ (`HiRef`), that dynamically constructs a multiscale partition of each dataset using low-rank OT subproblems, culminating in a bijective coupling. Hierarchical Refinement uses linear space and has log-linear runtime, retaining the space advantage of low-rank OT while overcoming its limited resolution. We demonstrate the advantages of Hierarchical Refinement on several datasets, including ones containing over a million points, scaling full-rank OT to problems previously beyond Sinkhorn's reach.","Imagine trying to match one million points from  a cube to one million points on a sphere in the most efficient way possible; e.g. by minimizing the distance between matched points. One solution would be to compute distances between every pair of points and then to find the best matching. However, this requires evaluating a trillion possibilities, and becomes challenging even for the most powerful computers.To solve this matching problem at scale, we use the following strategy. First, we find a way to “cut” both shapes together so that two halves of each shape are on the same side of this cut. This is done in a way that minimizes the effort to transform one half to the other, where we discard any connections that cross the cut. We repeat this recursively, refining across a hierarchy of cuts, until we reach a one-to-one mapping between the points.This divide-and-conquer strategy, which we call **hierarchical refinement**, is guided by the recent technique of **low-rank optimal transport** which helps us find the most efficient way to make each cut. Importantly, this technique is extensible to any type of space with a notion of “distance” and allows for highly flexible, even non-linear, ways of splitting the space.We show that, given an optimal way to make each “cut,” hierarchical refinement can recover the best possible matching between any two datasets, such as physical shapes, images, or biological data like cells."
Poster,Hierarchical Reinforcement Learning with Targeted Causal Interventions,https://ICML.cc//virtual/2025/poster/44521,"Mohammadsadegh Khorasani, Saber Salehkaleybar, Negar Kiyavash, Matthias Grossglauser","Hierarchical reinforcement learning (HRL) improves the efficiency of long-horizon reinforcement-learning tasks with sparse rewards by decomposing the task into a hierarchy of subgoals. The main challenge of HRL is efficient discovery of the hierarchical structure among subgoals and utilizing this structure to achieve the final goal. We address this challenge by modeling the subgoal structure as a causal graph and propose a causal discovery algorithm to learn it. Additionally, rather than intervening on the subgoals at random during exploration, we harness the discovered causal model to prioritize subgoal interventions based on their importance in attaining the final goal. These targeted interventions result in a significantly more efficient policy in terms of the training cost. Unlike previous work on causal HRL, which lacked theoretical analysis, we provide a formal analysis of the problem. Specifically, for tree structures and, for a variant of Erdős-Rényi random graphs, our approach results in remarkable improvements. Our experimental results on HRL tasks also illustrate that our proposed framework outperforms existing work in terms of training cost.","Many real-world tasks, such as building a tool in Minecraft, require achieving several intermediate milestones, like collecting wood or crafting a pickaxe, before any reward is obtained. This makes it difficult for agents to determine which milestones are important.We investigated whether viewing these milestones as a chain of causes and effects could help. In our approach, each milestone is represented as a node in a causal graph, allowing us to uncover the relationships between them. Through targeted experiments, the agent learns which milestones enable progress toward others. Armed with this knowledge, the agent can then focus its efforts on the milestones that have the greatest impact on the final reward, rather than exploring all milestones at random.In both simple tests and a challenging environment (Minecraft), our method enabled the agent to reach its goal faster than leading alternatives. We also provide theoretical analysis and guarantees that explain how and why our approach can lead to improvements. This approach could make it easier for agents to solve complex, multi-step tasks, both in games and in real-world scenarios."
Poster,Hierarchical Reinforcement Learning with Uncertainty-Guided Diffusional Subgoals,https://ICML.cc//virtual/2025/poster/46632,"Vivienne Huiling Wang, Tinghuai Wang, Joni Pajarinen","Hierarchical reinforcement learning (HRL) learns to make decisions on multiple levels of temporal abstraction. A key challenge in HRL is that the low-level policy changes over time, making it difficult for the high-level policy to generate effective subgoals. To address this issue, the high-level policy must capture a complex subgoal distribution while also accounting for uncertainty in its estimates. We propose an approach that trains a conditional diffusion model regularized by a Gaussian Process (GP) prior to generate a complex variety of subgoals while leveraging principled GP uncertainty quantification. Building on this framework, we develop a strategy that selects subgoals from both the diffusion policy and GP's predictive mean. Our approach outperforms prior HRL methods in both sample efficiency and performance on challenging continuous control benchmarks.","Think of teaching a robot a complex job, like tidying a room. Instead of one giant instruction, a ""manager"" robot gives a ""worker"" robot a series of smaller, achievable steps, like ""pick up the toy"" then ""put it in the box."" This is called Hierarchical Reinforcement Learning. A big problem is that the worker robot is always learning and improving, so the manager struggles to give good, up-to-date steps.Our new method helps the manager robot choose better steps. We use a smart system (a ""conditional diffusion model"") that can imagine many possible good next steps. To make sure these imagined steps are sensible and achievable, we use another system (a ""Gaussian Process"") that learns from past successes and warns about risky steps. By combining these two, the manager robot gives better instructions, helping the worker robot learn faster and do its job more effectively."
Poster,High-Dimensional Prediction for Sequential Decision Making,https://ICML.cc//virtual/2025/poster/43729,"Georgy Noarov, Ramya Ramalingam, Aaron Roth, Stephan Xie","We give an efficient algorithm for producing multi-dimensional forecasts in an online adversarial environment that have low bias subject to any polynomial number of conditioning events, that can depend both on external context and on our predictions themselves. We demonstrate the use of this algorithm with several applications. We show how to make predictions that can be transparently consumed by any polynomial number of downstream decision makers with different utility functions, guaranteeing them diminishing swap regret at optimal rates. We also give the first efficient algorithms for guaranteeing diminishing conditional regret in online combinatorial optimization problems for an arbitrary polynomial number of conditioning events --- i.e. on an arbitrary number of intersecting subsequences determined both by context and our own predictions. Finally, we give the first efficient algorithm for online multicalibration with $O(T^{2/3})$ rates in the ECE metric.","Consider one or more agents who must sequentially take actions, playing in a nonstationary (possibly adversarially changing) environment; each action incurs some reward in each round of the interaction. (For instance, imagine the online routing game in which people living in the same city each want to get from home to work as fast as possible each morning.) There exist a variety of online learning algorithms which can directly optimize various performance benchmarks for any one agent, e.g. guaranteeing that the agent's taken actions will give them cumulative reward at least as high as if they always played the best fixed action. However, most such algorithms have one or more of these undesirable traits: (1) don't offer simultaneous guarantees to multiple agents at once, (2) are very inefficient when the action space is very large (e.g. the number of home-work routes is exponentially sized), and (3) cannot give these performance guarantees conditionally on various relevant events (i.e. they don't offer guarantees specifically on days when it rains, or on national holidays, or on days when an agent uses a particular road, etc). We develop an algorithmic framework that can solve all these issues in a large variety of sequential settings such as the one above! It lets us issue a single coordinated vector-forecast each day that is appropriately unbiased/calibrated such that all agents --- if they trust and use our forecast --- will all get strong performance guarantees."
Poster,High-Dimensional Tensor Regression With Oracle Properties,https://ICML.cc//virtual/2025/poster/43721,"Wenbin Wang, Yu Shi, Ziping Zhao","The emergence of multi-dimensional data presents significant challenges for traditional regression models based on matrices or vectors, particularly in capturing multi-directional correlations. In response, tensor regression has been proposed as a powerful framework for modeling linear relationships among multi-dimensional variables. In this paper, we introduce a high-dimensional tensor-response tensor regression model under low-dimensional structural assumptions, such as sparsity and low-rankness. Assuming the underlying tensor lies within an unknown low-dimensional subspace, we consider a least squares estimation framework with non-convex penalties. Theoretically, we derive general risk bounds for the resulting estimators and demonstrate that they achieve the oracle statistical rates under mild technical conditions. To compute the proposed estimators efficiently, we introduce an accelerated proximal gradient algorithm demonstrating rapid convergence in practice. Extensive experiments on synthetic and real-world datasets validate the effectiveness of the proposed regression model and showcase the practical utility of the theoretical findings.","Modern data often come in the form of tensors, which are multi-dimensional arrays extending beyond simple tables or lists. Traditional statistical methods, which work with simpler data formats like vectors or matrices, struggle to accurately capture the complex relationships across these multiple dimensions.To overcome these limitations, our research introduces a new regression method specifically designed for tensor data. This method efficiently identifies underlying simple patterns, like sparsity (where many elements are zero or irrelevant) or low-rank structures (where the data can be simplified into fewer meaningful dimensions). By assuming such underlying simplicity, our method effectively estimates the relationships between multiple high-dimensional datasets.We provide a rigorous theoretical analysis showing that our approach accurately recovers these relationships, even when the datasets are large and complicated. To make our method practical, we also develop a fast and effective algorithm to solve the regression model efficiently.Through comprehensive experiments using both artificial and real-world data, we demonstrate that our method works very well in practice, providing accurate predictions and meaningful insights. This approach helps researchers and practitioners analyze complex data easily, effectively, and with greater confidence."
