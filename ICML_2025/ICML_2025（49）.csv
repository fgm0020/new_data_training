type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Clipping Improves Adam-Norm and AdaGrad-Norm when the Noise Is Heavy-Tailed,https://ICML.cc//virtual/2025/poster/45593,"Savelii Chezhegov, Klyukin Yaroslav, Andrei Semenov, Aleksandr Beznosikov, Alexander Gasnikov, Samuel Horváth, Martin Takac, Eduard Gorbunov","Methods with adaptive stepsizes, such as AdaGrad and Adam, are essential for training modern Deep Learning models, especially Large Language Models. Typically, the noise in the stochastic gradients is heavy-tailed for the later ones. Gradient clipping provably helps to achieve good high-probability convergence for such noises. However, despite the similarity between AdaGrad/Adam and Clip-SGD, the current understanding of the high-probability convergence of AdaGrad/Adam-type methods is limited in this case. In this work, we prove that AdaGrad/Adam (and their delayed version) can have provably bad high-probability convergence if the noise is heavy-tailed. We also show that gradient clipping fixes this issue, i.e., we derive new high-probability convergence bounds with polylogarithmic dependence on the confidence level for AdaGrad-Norm and Adam-Norm with clipping and with/without delay for smooth convex/non-convex stochastic optimization with heavy-tailed noise. We extend our results to the case of AdaGrad/Adam with delayed stepsizes. Our empirical evaluations highlight the superiority of clipped versions of AdaGrad/Adam in handling the heavy-tailed noise.","Modern AI models, including large language models like ChatGPT and BERT, are trained using optimization techniques that adjust the model based on noisy feedback. Two popular techniques for this are Adam and AdaGrad, which adapt their learning speed over time. However, in many real-world cases, the noise in the feedback is unpredictable and extreme — known as heavy-tailed noise — which can cause these methods to behave unreliably.In our study, we show that without any fixes, Adam and AdaGrad can perform poorly under such noisy conditions. To address this, we apply a technique called gradient clipping, which limits extreme updates and helps stabilize learning. We provide new mathematical guarantees that clipped versions of Adam and AdaGrad work reliably even when the noise is heavy and erratic. We also show through experiments — including fine-tuning real-world language models — that clipping consistently improves their performance.Our findings suggest that using clipped adaptive methods can make AI training not only faster but also more reliable when the training environment is noisy and unpredictable — a common situation in today’s large-scale AI systems."
Poster,Clone-Robust AI Alignment,https://ICML.cc//virtual/2025/poster/43664,"Ariel Procaccia, Benjamin Schiffer, Shirley Zhang","A key challenge in training Large Language Models (LLMs) is properly aligning them with human preferences. Reinforcement Learning with Human Feedback (RLHF) uses pairwise comparisons from human annotators to train reward functions and has emerged as a popular alignment method. However, input datasets in RLHF can be unbalanced due to adversarial manipulation or inadvertent repetition. Therefore, we want RLHF algorithms to perform well even when the set of alternatives is not uniformly distributed. Drawing on insights from social choice theory, we introduce robustness to approximate clones, a desirable property of RLHF algorithms which requires that adding near-duplicate alternatives does not significantly change the learned reward function. We first demonstrate that the standard RLHF algorithm based on regularized maximum likelihood estimation (MLE) fails to satisfy this property. We then propose the weighted MLE, a new RLHF algorithm that modifies the standard regularized MLE by weighting alternatives based on their similarity to other alternatives. This new algorithm guarantees robustness to approximate clones while preserving desirable theoretical properties.","A key challenge in training Large Language Models (LLMs) is properly aligning an LLM with human preferences. This is important because this helps the LLM give answers that are similar to answers that a human would give. Current methods do this alignment by generating pairs of answers and asking humans to choose which answer they prefer. The current method then uses the human preferences to help train the LLM. However, this method may result in different LLM behavior depending on which answers are shown to humans. We study what happens when the answers that are shown to humans are biased. We then introduce a new method that will give the same result even when the humans are shown a biased set of answers."
Poster,Closed-form Solutions: A New Perspective on Solving Differential Equations,https://ICML.cc//virtual/2025/poster/46180,"Shu Wei, Yanjie Li, Lina Yu, Weijun Li, Min Wu, Linjun Sun, Jingyi Liu, Hong Qin, Deng Yusong, Jufeng Han, Yan Pang","The quest for analytical solutions to differential equations has traditionally been constrained by the need for extensive mathematical expertise.Machine learning methods like genetic algorithms have shown promise in this domain, but are hindered by significant computational time and the complexity of their derived solutions. This paper introduces **SSDE** (Symbolic Solver for Differential Equations), a novel reinforcement learning-based approach that derives symbolic closed-form solutions for various differential equations. Evaluations across a diverse set of ordinary and partial differential equations demonstrate that SSDE outperforms existing machine learning methods, delivering superior accuracy and efficiency in obtaining analytical solutions.","Solving differential equations—mathematical formulas used to describe how things change over time and space—is a fundamental task in science and engineering. Traditionally, finding exact solutions to these equations requires advanced math skills and often involves tedious manual work. While machine learning has offered some help, existing methods are often slow and produce results that are hard to understand.In this work, we present SSDE, a new AI-based tool that uses reinforcement learning to automatically discover clean, human-readable solutions to different types of differential equations. Unlike previous methods, SSDE is both faster and more accurate. This makes it a promising step toward making powerful mathematical tools more accessible and automating complex tasks in physics, biology, and beyond."
Poster,Closed-Loop Long-Horizon Robotic Planning via Equilibrium Sequence Modeling,https://ICML.cc//virtual/2025/poster/45554,"Jinghan Li, Zhicheng Sun, Yadong Mu","In the endeavor to make autonomous robots take actions, task planning is a major challenge that requires translating high-level task descriptions to long-horizon action sequences. Despite recent advances in language model agents, they remain prone to planning errors and limited in their ability to plan ahead. To address these limitations in robotic planning, we advocate a self-refining scheme that iteratively refines a draft plan until an equilibrium is reached. Remarkably, this process can be optimized end-to-end from an analytical perspective without the need to curate additional verifiers or reward models, allowing us to train self-refining planners in a simple supervised learning fashion. Meanwhile, a nested equilibrium sequence modeling procedure is devised for efficient closed-loop planning that incorporates useful feedback from the environment (or an internal world model). Our method is evaluated on the VirtualHome-Env benchmark, showing advanced performance with improved scaling w.r.t. inference-time computation. Code is available at https://github.com/anonymous-icml-2025/equilibrium-planner.","Task planning  is a major challenge in robotics, which requires translating high-level task descriptions to long-horizon action sequences. For example, ""Get me a glass of juice"" needs to be decomposed into ""Walk To Refrigerator, Open Refrigerator, Pick Up Juice, Close Refrigerator, Put Juice On Table"". Current large language model(LLM)-based methods remain unsatisfactory. We hope to improve the performance of LLMs in task planning.We advocate training LLM planners to self-refine, enabling them to achieve better results by correcting themselves. However, such training is costly and complex using traditional methods. We propose a new method named equilibrium sequence modeling, which can be optimized in a simple supervised learning fashion. This allows us to train self-refining plannes easily. Meanwhile, we design mutiple components to process feedback and achieve closed-loop planning. Our method performed well in experiments.Our method has implications for exploring the planning capabilities of LLMs. It is a novel approach that encourages LLMs to think more deeply and plan ahead."
Poster,CLOVER: Cross-Layer Orthogonal Vectors Pruning,https://ICML.cc//virtual/2025/poster/44877,"Fanxu Meng, Pingzhi Tang, Fan Jiang, Muhan Zhang","Decoder-only models generate tokens autoregressively by caching key/value vectors, but as the cache grows, inference becomes memory-bounded. To address this challenge, we introduce CLOVER (Cross-Layer Orthogonal Vectors) pruning, a novel approach that treats pairs of components of the attention mechanism as low-rank decompositions. CLOVER applies Singular Value Decomposition (SVD) to the Q-K and V-O pairs within each attention head. The resulting singular values, in turn, guide pruning and further serve as trainable parameters for efficient fine-tuning, ultimately enabling the model to recover its performance to the level before pruning.After pruning and fine-tuning, these values are reintegrated into the model without increasing its parameter count. Visualizations across various models show that CLOVER effectively removes linear redundancies within attention heads, greatly improving pruning efficiency. For example, pruning 70\% of the Q-K head dimension in GPT-2 XL results in a perplexity comparable to that of pruning just 8\% using vanilla pruning. The combination of CLOVER and TransMLA achieves a speedup of up to 11.1$\times$ over LLaMA-2-7B.","Large language models (LLMs) like GPT-2 and GPT-3 have revolutionized many fields by generating human-like text, but they face challenges as they grow in size. One of the main issues is the memory needed for their key-value (KV) caching system, which can slow down performance, especially in models with long contexts. To tackle this, we introduce a new method called CLOVER (Cross-Layer Orthogonal Vectors), which helps make these models more efficient without compromising their ability to generate accurate text.CLOVER works by rethinking how attention mechanisms in LLMs handle their internal data. It focuses on reducing unnecessary redundancy in the model’s memory usage, particularly in the key-value pairs used for attention. By applying a mathematical technique called Singular Value Decomposition (SVD), CLOVER identifies and removes unimportant components from the model’s attention heads. This allows the model to maintain strong performance while using less memory.The key benefit of CLOVER is its ability to prune or remove parts of the model without losing accuracy. In fact, we show that CLOVER can prune up to 70% of a model’s key-value memory while keeping the performance almost identical to using just 8% pruning with traditional methods. Additionally, CLOVER is highly efficient in both fine-tuning models and improving their inference speed, even making models run up to 11 times faster on some tasks.Overall, CLOVER offers a new way to make large AI models more efficient, making them faster and less resource-hungry without sacrificing their ability to generate high-quality outputs."
Poster,Clustering Items through Bandit Feedback: Finding the Right Feature out of Many,https://ICML.cc//virtual/2025/poster/46248,"Maximilian Graf, Victor Thuot, Nicolas Verzelen","We study the problem of clustering a set of items based on bandit feedback. Each of the $n$ items is characterized by a feature vector, with a possibly large dimension $d$. The items are  partitioned into two unknown groups, such that items within the same group share the same feature vector. We consider a sequential and adaptive setting in which, at each round, the learner selects one item and one feature, then observes a noisy evaluation of the item's feature. The learner's objective is to recover the correct partition of the items, while keeping the number of observations as small as possible. We provide an algorithm which relies on finding a relevant feature for the clustering task, leveraging the Sequential Halving algorithm. With probability at least $1-\delta$, we obtain an accurate recovery of the partition and derive an upper bound on the required budget . Furthermore, we derive an instance-dependent lower bound, which is tight in some relevant cases.","Imagine you're trying to group a collection of objects—like images of vehicles—into two categories, but you don’t know the properties that define those categories. Each object has many characteristics (such as the number of visible wheels), but checking a characteristic takes time and resources. On top of that, each observation is noisy—it can contain errors. To solve this task, we proceed sequentially: one step at a time, we choose an object and which characteristic to observe on that object, aiming to gradually uncover both which characteristic matter and how the objects are grouped. We ask the following question: can we correctly sort all the objects while observing as few characteristics as possible?The key idea is that some features are especially informative for distinguishing between the two groups. Our method learns to identify and focus on these useful features throughout the observation process. We evaluate the performance of our method by measuring the number of observations it requires, and we show that no other method can achieve the same goal with significantly fewer observations."
Poster,Clustering Properties of Self-Supervised Learning,https://ICML.cc//virtual/2025/poster/44318,"Xi Weng, Jianing An, Xudong Ma, Binhang Qi, Jie Luo, Xi Yang, Jin Song Dong, Lei Huang","Self-supervised learning (SSL) methods via joint embedding architectures have proven remarkably effective at capturing semantically rich representations with strong clustering properties, magically in the absence of label supervision. Despite this, few of them have explored leveraging these untapped properties to improve themselves. In this paper, we provide an evidence through various metrics that the encoder's output *encoding* exhibits superior and more stable clustering properties compared to other components. Building on this insight, we propose a novel positive-feedback SSL method, termed **Re**presentation **S**elf-**A**ssignment (ReSA), which leverages the model's clustering properties to promote learning in a self-guided manner. Extensive experiments on standard SSL benchmarks reveal that models pretrained with ReSA outperform other state-of-the-art SSL methods by a significant margin. Finally, we analyze how ReSA facilitates better clustering properties, demonstrating that it effectively enhances clustering performance at both fine-grained and coarse-grained levels, shaping representations that are inherently more structured and semantically meaningful.","Computers can now teach themselves by simply looking at huge piles of data, without anyone telling them what each piece is. These “self-taught” systems naturally sort what they see into loose groups, a bit like stacking photos into family albums. Strangely, most existing methods ignore those home-made albums instead of using them to learn even better.Our work asks: What if the computer paid attention to its own sorting? First, we show that the raw groups formed inside the network are surprisingly neat and stable. Then we introduce ReSA — Representation Self-Assignment. ReSA is a simple method that lets the network look at its own groups and refine them further, giving itself instant feedback, much like a student who double-checks their notes while studying.Across standard image benchmarks, ReSA-trained models consistently beat the best previous self-learning methods. The result is a smarter system that learns faster, organizes information more clearly, and needs no extra human labels."
Poster,Clustering via Self-Supervised Diffusion,https://ICML.cc//virtual/2025/poster/46196,"Roy Uziel, Irit Chelly, Oren Freifeld, Ari Pakman","Diffusion models, widely recognized for their success in generative tasks, have not yet been applied to clustering. We introduce Clustering via Diffusion (CLUDI), a self-supervised framework that combines the generative power of diffusion models with pre-trained Vision Transformer features to achieve robust and accurate clustering. CLUDI is trained via a teacher–student paradigm: the teacher uses stochastic diffusion-based sampling to produce diverse cluster assignments, which the student refines into stable predictions. This stochasticity acts as a novel data augmentation strategy, enabling CLUDI to uncover intricate structures in high-dimensional data. Extensive evaluations on challenging datasets demonstrate that CLUDI achieves state-of-the-art performance in unsupervised classification, setting new benchmarks in clustering robustness and adaptability to complex data distributions.","Deep-learning methods for grouping unlabeled images often fall into two pitfalls: they either collapse to a single, undifferentiated group or rely on heavy data-augmentation tricks. Our approach, Clustering via Diffusion (CLUDI), breaks that pattern by exploiting the incremental denoising approach of modern diffusion generators. Guided by Vision Transformer features, the diffusion process begins with pure noise and gradually sculpts a compact embedding whose coordinates act like votes for each class. Re-running the process with different noise seeds produces diverse candidate class assignments. The model is trained using a student-teacher siamese architecture, where a self-supervised student network distills noisy versions of the teacher data into one stable assignment. Evaluated across multiple datasets, including challenging ImageNet subsets and several other vision benchmarks, CLUDI consistently outperforms strong Vision Transformer baselines in clustering accuracy, normalized mutual information, and adjusted Rand index. By turning a generative diffusion model into a dependable classifier, CLUDI offers researchers and engineers a novel, annotation-free way to uncover structure in massive image collections."
Poster,CMoS: Rethinking Time Series Prediction Through the Lens of Chunk-wise Spatial Correlations,https://ICML.cc//virtual/2025/poster/44558,"Haotian Si, Changhua Pei, Jianhui LI, Dan Pei, Gaogang Xie","Recent advances in lightweight time series forecasting models suggest the inherent simplicity of time series forecasting tasks. In this paper, we present CMoS, a super-lightweight time series forecasting model. Instead of learning the embedding of the shapes, CMoS directly models the spatial correlations between different time series chunks. Additionally, we introduce a Correlation Mixing technique that enables the model to capture diverse spatial correlations with minimal parameters, and an optional Periodicity Injection technique to ensure faster convergence. Despite utilizing as low as 1% of the lightweight model DLinear's parameters count, experimental results demonstrate that CMoS outperforms existing state-of-the-art models across multiple datasets. Furthermore, the learned weights of CMoS exhibit great interpretability, providing practitioners with valuable insights into temporal structures within specific application scenarios.","(1)Accurate time series forecastingis crucial for decision-making in many industries, but predicting future values remains difficult. (2)We developed a lightweight time series forecasting models that analyze large volumes of sequential data to predict future outcomes with high precision. (3)This allows analysts to quickly obtain accurate forecasting results on their personal computers, thereby supporting decision-making."
Poster,CoastalBench: A Decade-Long High-Resolution Dataset to Emulate Complex Coastal Processes,https://ICML.cc//virtual/2025/poster/44437,"Zelin Xu, Yupu Zhang, Tingsong Xiao, Maitane Lizaso, Jose Gonzalez-Ondina, Zibo Liu, Shigang Chen, Zhe Jiang","Over 40\% of the global population lives within 100 kilometers of the coast, which contributes more than \$8 trillion annually to the global economy. Unfortunately, coastal ecosystems are increasingly vulnerable to more frequent and intense extreme weather events and rising sea levels. Coastal scientists use numerical models to simulate complex physical processes, but these models are often slow and expensive. In recent years, deep learning has become a promising alternative to reduce the cost of numerical models. However, progress has been hindered by the lack of a large-scale, high-resolution coastal simulation dataset to train and validate deep learning models. Existing studies often focus on relatively small datasets and simple processes. To fill this gap, we introduce a decade-long, high-resolution (<100m) coastal circulation modeling dataset on a real-world 3D mesh in southwest Florida with around 6 million cells. The dataset contains key oceanography variables (e.g., current velocities, free surface level, temperature, salinity) alongside external atmospheric and river forcings. We evaluated a customized Vision Transformer model that takes initial and boundary conditions and external forcings and predicts ocean variables at varying lead times. The dataset provides an opportunity to benchmark novel deep learning models for high-resolution coastal simulations (e.g., physics-informed machine learning, neural operator learning).The code and dataset can be accessed at https://github.com/spatialdatasciencegroup/CoastalBench.","Coastal areas are home to over 40% of the global population, but modeling coastal ocean dynamics remains computationally expensive and data-limited. We introduce a decade-long, high-resolution simulation dataset and develop a deep learning model that can emulate complex coastal circulation processes. This enables faster forecasting of coastal phenomena like storm surges and water quality changes, and contributes to the broader landscape of AI for scientific discovery, highlighting both the opportunities and responsibilities involved in applying machine learning to Earth system modeling."
