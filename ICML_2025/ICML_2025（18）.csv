type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Analytical Construction on Geometric Architectures: Transitioning from Static to Temporal Link Prediction,https://ICML.cc//virtual/2025/poster/46676,"Yadong Sun, Xiaofeng Cao, Ivor Tsang, Heng Tao Shen","Static systems exhibit diverse structural properties, such as hierarchical, scale-free, and isotropic patterns, where different geometric spaces offer unique advantages. Methods combining multiple geometries have proven effective in capturing these characteristics. However, real-world systems often evolve dynamically, introducing significant challenges in modeling their temporal changes. To overcome this limitation, we propose a unified cross-geometric learning framework for dynamic systems, which synergistically integrates Euclidean and hyperbolic spaces, aligning embedding spaces with structural properties through fine-grained substructure modeling. Our framework further incorporates a temporal state aggregation mechanism and an evolution-driven optimization objective, enabling comprehensive and adaptive modeling of both nodal and relational dynamics over time. Extensive experiments on diverse real-world dynamic graph datasets highlight the superiority of our approach in capturing complex structural evolution, surpassing existing methods across multiple metrics.","Many real-world networks, such as social interactions, communication patterns, or biological systems, change over time and current embedding methods in Euclidean or hyperbolic space cannot simultaneously capture their evolving structures and hierarchical relationships.We propose a unified framework that aligns each graph substructure with the most suitable geometry—Euclidean for flat regions and hyperbolic for hierarchical regions—while using a temporal state aggregator and an evolution-driven objective to learn how nodes and links develop.By adapting the embedding space as the graph evolves, our approach more accurately tracks complex structural changes and greatly improves temporal link prediction performance, enabling better modeling for applications like recommendation systems, epidemic monitoring, and evolving knowledge graphs."
Poster,Analytical Lyapunov Function Discovery: An RL-based Generative Approach,https://ICML.cc//virtual/2025/poster/43865,"Haohan Zou, Jie Feng, Hao Zhao, Yuanyuan Shi","Despite advances in learning-based methods, finding valid Lyapunov functions for nonlinear dynamical systems remains challenging. Current neural network approaches face two main issues:  challenges in scalable verification and limited interpretability. To address these, we propose an end-to-end framework using transformers to construct analytical Lyapunov functions (local), which simplifies formal verification, enhances interpretability, and provides valuable insights for control engineers. Our framework consists of a transformer-based trainer that generates candidate Lyapunov functions and a falsifier that verifies candidate expressions and refines the model via risk-seeking policy gradient. Unlike Alfarano et al. (2024), which utilizes pre-training and seeks global Lyapunov functions for low-dimensional systems, our model is trained from scratch via reinforcement learning (RL) and succeeds in finding local Lyapunov functions for *high-dimensional* and *non-polynomial* systems. Given the symbolic nature of the Lyapunov function candidates, we employ efficient optimization methods for falsification during training and formal verification tools for the final verification. We demonstrate the efficiency of our approach on a range of nonlinear dynamical systems with up to ten dimensions and show that it can discover Lyapunov functions not previously identified in the control literature. Full implementation is available on [Github](https://github.com/JieFeng-cse/Analytical-Lyapunov-Function-Discovery).","Certifying the stability of complex systems—like robots or aircraft—requires special mathematical formulas called Lyapunov functions, which satisfies two Lyapunov conditions on the function values. While deep learning has shown promise in finding such functions, current methods often struggle with condition verification and are difficult for engineers to interpret. We introduce a new learning-based approach that uses a symbolic transformer model to generate Lyapunov functions in clear, analytical form. This makes output expressions easier to understand and verify. Unlike prior methods that rely on extensive pre-training and are limited to low-dimensional systems, our model learns from scratch and can handle more complex, high-dimensional systems. It combines a learning component that proposes candidate expressions with a verification tool that checks Lyapunov conditions on candidate expressions and iteratively improves the transformer model by reinforcement learning (RL) techniques.Compared with existing works, our method not only improves the efficiency of discovery process but also identifies new Lyapunov functions that experts hadn’t identified before, offering valuable insights for designing safe and stable systems."
Poster,Analyze Feature Flow to Enhance Interpretation and Steering in Language Models,https://ICML.cc//virtual/2025/poster/45235,"Daniil Laptev, Nikita Balagansky, Yaroslav Aksenov, Daniil Gavrilov","We introduce a new approach to systematically map features discovered by sparse autoencoder across consecutive layers of large language models, extending earlier work that examined inter-layer feature links. By using a data-free cosine similarity technique, we trace how specific features persist, transform, or first appear at each stage. This method yields granular flow graphs of feature evolution, enabling fine-grained interpretability and mechanistic insights into model computations. Crucially, we demonstrate how these cross-layer feature maps facilitate direct steering of model behavior by amplifying or suppressing chosen features, achieving targeted thematic control in text generation. Together, our findings highlight the utility of a causal, cross-layer interpretability framework that not only clarifies how features develop through forward passes but also provides new means for transparent manipulation of large language models.","This research investigates how large language models internally store, organize, and transform concepts across their different layers. By analyzing how specific features emerge, evolve, or disappear as they move through the model, the study creates detailed maps of these relationships, revealing patterns that were previously unclear. These insights not only improve our understanding of how these complex systems process information but also enable more precise control over their behavior. By modifying key concepts, users can now guide the model’s internal mechanisms more effectively, leading to greater transparency and better-controlled outcomes."
Poster,An Analysis for Reasoning Bias of Language Models with Small Initialization,https://ICML.cc//virtual/2025/poster/46492,"Junjie Yao, zhongwang zhang, Zhi-Qin John Xu","Transformer-based Large Language Models (LLMs) have revolutionized Natural Language Processing by demonstrating exceptional performance across diverse tasks. This study investigates the impact of the parameter initialization scale on the training behavior and task preferences of LLMs. We discover that smaller initialization scales encourage models to favor reasoning tasks, whereas larger initialization scales lead to a preference for memorization tasks. We validate this reasoning bias via real datasets and meticulously designed anchor functions. Further analysis of initial training dynamics suggests that specific model components, particularly the embedding space and self-attention mechanisms, play pivotal roles in shaping these learning biases. We provide a theoretical framework from the perspective of model training dynamics to explain these phenomena. Additionally, experiments on real-world language tasks corroborate our theoretical insights. This work enhances our understanding of how initialization strategies influence LLM performance on reasoning tasks and offers valuable guidelines for training models.","Large language models have revolutionized our daily life and work, particularly through their ability to perform reasoning tasks. However, a critical question remains: Do these models truly possess reasoning capabilities, or do they merely memorize answers? And how can we develop language models that prioritize genuine reasoning?Our research reveals that a model's initialization settings significantly influence its learning bias. We demonstrate that for identical tasks, certain initialization configurations lead the model to memorize answers, while others enable it to truly grasp underlying principles and rules.This work helps developers design smarter models by adjusting initial settings. These insights offer a roadmap to train more efficient AI systems."
Poster,An Analysis of Quantile Temporal-Difference Learning,https://ICML.cc//virtual/2025/poster/46716,"Mark Rowland, Remi Munos, Mohammad Gheshlaghi Azar, Yunhao Tang, Georg Ostrovski, Anna Harutyunyan, Karl Tuyls, Marc G. Bellemare, Will Dabney","We analyse quantile temporal-difference learning (QTD), a distributional reinforcement learning algorithm that has proven to be a key component in several successful large-scale applications of reinforcement learning. Despite these empirical successes, a theoretical understanding of QTD has proven elusive until now. Unlike classical TD learning, which can be analysed with standard stochastic approximation tools, QTD updates do not approximate contraction mappings, are highly non-linear, and may have multiple fixed points. The core result of this paper is a proof of convergence to the fixed points of a related family of dynamic programming procedures with probability 1, putting QTD on firm theoretical footing. The proof establishes connections between QTD and non-linear differential inclusions through stochastic approximation theory and non-smooth analysis.",
Poster,An analytic theory of creativity in convolutional diffusion models,https://ICML.cc//virtual/2025/poster/44336,"Mason Kamb, Surya Ganguli","We obtain an analytic, interpretable and predictive theory of creativity in convolutional diffusion models. Indeed, score-matching diffusion models can generate highly original images that lie far from their training data.  However, optimal score-matching theory suggests that these models should only be able to produce memorized training examples. To reconcile this theory-experiment gap, we identify two simple inductive biases, locality and equivariance, that: (1) induce a form of combinatorial creativity by preventing optimal score-matching; (2) result in fully analytic, completely mechanistically interpretable, local score (LS) and equivariant local score (ELS) machines that, (3) after calibrating a single time-dependent hyperparameter can quantitatively predict the outputs of trained convolution only diffusion models (like ResNets and UNets) with high accuracy (median $r^2$ of $0.95, 0.94, 0.94, 0.96$ for our top model on CIFAR10, FashionMNIST, MNIST, and CelebA). Our model reveals a {\it locally consistent patch mosaic} mechanism of creativity, in which diffusion models create exponentially many novel images by mixing and matching different local training set patches at different scales and image locations. Our theory also partially predicts the outputs of pre-trained self-attention enabled UNets (median $r^2 \sim 0.77$ on CIFAR10), revealing an intriguing role for attention in carving out semantic coherence from local patch mosaics.","Modern generative AI is capable of producing a seemingly unlimited amount of apparently ""creative"" output, showing the capacity to mix and match features from the data it was trained on in novel and often unpredictable ways. Understanding how this process occurs, and how the outputs that these models produce relates to the task that they were trained to performed and the data that they learned from, is a key question for understanding the nature of artificial intelligence. To understand where this ""creativity"" emerges from, we decided to study the simplest models that we could find that exhibited this ability, called a ""convolutional diffusion model."" We developed a mathematical theory to explain their behavior, based on a handful of properties that they exhibit. This theory predicted that, while ""smarter"" models might be able to recall their training data, these simple models could only ""mix and match"" bits and pieces of the dataset at a time-- forming ""patchwork quilts"" of all of the images that they had ever seen in their training set. While seemingly far-fetched, this theory was remarkably predictive, and in fact, we were able to reproduce *almost exactly* the images that they produced, directly from their training data-- a first in the field of generative AI. Our theory also explained why AI makes certain common mistakes when generating images, such as putting in incorrect numbers of limbs."
Poster,An Architecture Search Framework for Inference-Time Techniques,https://ICML.cc//virtual/2025/poster/45959,"Jon Saad-Falcon, Adrian Lafuente, Shlok Natarajan, Nahum Maru, Hristo Todorov, Etash Guha, Estefany Kelly Buchanan, Mayee Chen, Neel Guha, Christopher Re, Azalia Mirhoseini","Inference-time techniques, such as repeated sampling or iterative revisions, are emerging as powerful ways to enhance large-language models (LLMs) at test time. However, best practices for developing systems that combine these techniques remain underdeveloped due to our limited understanding of the utility of each technique across models and tasks, the interactions between them, and the massive search space for combining them. To address these challenges, we introduce Archon, a modular and automated framework for optimizing the process of selecting and combining inference-time techniques and LLMs. Given a compute budget and a set of available LLMs,Archon explores a large design space to discover optimized configurations tailored to target benchmarks. It can design custom or general-purpose architectures that advance the Pareto frontier of accuracy vs. maximum token budget compared to top-performing baselines. Across instruction-following, reasoning, and coding tasks, we show that Archon can leverage additional inference compute budget to design systems that outperform frontier models such as OpenAI’s o1, GPT-4o, and Claude 3.5 Sonnet by an average of 15.1%.","Large language models like GPT-4 or Claude are powerful — but they get even better if you let them generate multiple answers, vote on the best one, or combine ideas from different models. These tricks, called inference-time techniques, can boost accuracy at test time without retraining the model. The challenge is that there are many such techniques, and figuring out which ones to use — and in what order — is a complex puzzle.That’s where Archon comes in. Archon is an open-source framework that acts like an AI systems architect. You give it a compute budget, a set of models, and a target task — like solving math problems or writing code — and it automatically designs the best way to combine techniques like generation ensembling, ranking, fusion, and verification.Archon uses smart search algorithms (like Bayesian optimization) to explore thousands of possible configurations and find high-performing combinations. It can even tailor its design for specific tasks or discover general-purpose strategies that work across many benchmarks.In our experiments, Archon beat state-of-the-art systems like GPT-4o and Claude 3.5 Sonnet by over 15%, while using fewer compute resources. By helping users get more out of existing models, Archon makes advanced AI both more powerful and more accessible."
Poster,An Asymptotically Optimal Approximation Algorithm for Multiobjective Submodular Maximization at Scale,https://ICML.cc//virtual/2025/poster/45564,"Fabian Spaeh, Atsushi Miyauchi","Maximizing a single submodular set function subject to a cardinality constraint is a well-studied and central topic in combinatorial optimization. However, finding a set that maximizes multiple functions at the same time is much less understood, even though it is a formulation which naturally occurs in robust maximization or problems with fairness considerations such as fair influence maximization or fair allocation. In this work, we consider the problem of maximizing the minimum over many submodular functions subject to a cardinality constraint, which is known as multiobjective submodular maximization. All known polynomial-time approximation algorithms either obtain a weak approximation guarantee or rely on the evaluation of the multilinear extension. The latter is expensive to evaluate and renders such algorithms impractical. We bridge this gap and introduce the first scalable and practical algorithm that obtains the best-known approximation guarantee. We furthermore introduce a novel application fair centrality maximization and show how it can be addressed via multiobjective submodular maximization. In our experimental evaluation, we show that our algorithm outperforms known algorithms in terms of objective value and running time.","Many decision-making problems in machine learning and AI involve selecting a limited set of items to optimize multiple objectives at once. For instance, when ensuring fairness across different groups. This is challenging when these objectives conflict and the mathematical tools used in single-objective problems no longer apply. Previous algorithms that give strong guarantees often rely on complex continuous relaxations that are too slow for large datasets, while faster methods offer much weaker performance.We designed a new algorithm that directly tackles this multiobjective optimization problem in a scalable and principled way. Our method avoids the need for costly continuous relaxations and instead uses a novel probabilistic strategy with strong theoretical backing. It nearly matches the best-known performance guarantee and works efficiently even on large datasets.To demonstrate its usefulness, we applied our algorithm to a new fairness-oriented problem: ensuring that a target node in a network is visible to all demographic groups. We also tested it on problems like fair influence and coverage maximization, where it consistently outperformed previous methods in both accuracy and speed."
Poster,An Augmentation-Aware Theory for Self-Supervised Contrastive Learning,https://ICML.cc//virtual/2025/poster/44689,"Jingyi Cui, Hongwei Wen, Yisen Wang","Self-supervised contrastive learning has emerged as a powerful tool in machine learning and computer vision to learn meaningful representations from unlabeled data. Meanwhile, its empirical success has encouraged many theoretical studies to reveal the learning mechanisms. However, in the existing theoretical research, the role of data augmentation is still under-exploited, especially the effects of specific augmentation types. To fill in the blank, we for the first time propose an augmentation-aware error bound for self-supervised contrastive learning, showing that the supervised risk is bounded not only by the unsupervised risk, but also explicitly by a trade-off induced by data augmentation. Then, under a novel semantic label assumption, we discuss how certain augmentation methods affect the error bound. Lastly, we conduct both pixel- and representation-level experiments to verify our proposed theoretical results.","Machine learning models often need large amounts of labeled data, but labeling data can be costly and time-consuming. A promising solution is self-supervised learning, where models learn patterns from unlabeled data by creating their own learning signals. One popular method is contrastive learning, which teaches models to recognize similarities and differences between data points. In this work, we look at an important, but underexplored, part of contrastive learning: data augmentation. Data augmentation involves slightly changing data samples (like cropping or color distortion) to help the model learn more robustly. We develop a new theoretical framework that connects how well a contrastive learning model performs to the types of data augmentation used. We introduce an augmentation-aware error bound, showing that the choice of augmentation affects the model’s overall accuracy and generalization. This result enables discussions on the impact of specific types of data augmentation. We also back up our theory with experiments on real datasets, showing how different augmentation choices influence the model’s learning."
Poster,A Near Linear Query Lower Bound for Submodular Maximization,https://ICML.cc//virtual/2025/poster/45604,"Binghui Peng, Aviad Rubinstein","We revisit the problem of selecting $k$-out-of-$n$ elements with the goal of optimizing an objective function, and ask whether it can be solved approximately with sublinear query complexity. For objective functions that are monotone submodular, [Li, Feldman, Kazemi, Karbasi, NeurIPS'22; Kuhnle, AISTATS'21] gave an $\Omega(n/k)$ query lower bound for approximating to within any constant factor. We strengthen their lower bound to a nearly tight  $\tilde{\Omega}(n)$. This lower bound holds even for estimating the value of the optimal subset. When the objective function is additive, we prove that finding an approximately optimal subset still requires near-linear query complexity, but we can estimate the value of the optimal subset in $\tilde{O}(n/k)$ queries, and that this is tight up to polylog factors.","This paper investigates how efficiently we can select the best subset of items (specifically, choosing k out of n items) to maximize a certain benefit or objective. It asks if we can do this by examining fewer items than it would normally take to check each one. For objective functions that exhibit a common property known as ""monotone submodularity""—where adding an item helps less as more items are already selected—the authors show that achieving a good approximation still requires checking nearly all items. For simpler objective functions (additive ones, where each item's contribution is independent and straightforward), the authors show that  estimating just the value (or quality) of the optimal selection can be done with significantly fewer queries, and the paper precisely determines these limits"
