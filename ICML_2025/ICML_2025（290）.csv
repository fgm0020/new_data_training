type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Symmetry-Driven Discovery of Dynamical Variables in Molecular Simulations,https://ICML.cc//virtual/2025/poster/45068,"Jeet Mohapatra, Nima Dehmamy, Csaba Both, Subhro Das, Tommi Jaakkola","We introduce a novel approach for discovering effective degrees of freedom (DOF) in molecular dynamics simulations by mapping the DOF to approximate symmetries of the energy landscape. Unlike most existing methods, we do not require trajectory data but instead rely on knowledge of the forcefield (energy function) around the initial state. We present a scalable symmetry loss function compatible with existing force-field frameworks and a Hessian-based method efficient for smaller systems. Our approach enables systematic exploration of conformational space by connecting structural dynamics to energy landscape symmetries. We apply our method to two systems, Alanine dipeptide and Chignolin, recovering their known important conformations. Our approach can prove useful for efficient exploration in molecular simulations with potential applications in protein folding and drug discovery.","This research introduces a new way to identify the most important molecular movements in computer simulations of proteins and other molecules. Our approach works by examining the energy landscape around a molecule's starting position and identifying patterns of symmetry - essentially, finding directions where the molecule can move without significantly changing its energy. The key innovation is that your method doesn't need extensive simulation data upfront. It only requires knowledge of the forces acting on the molecule at its initial state. To test our approach, we applied it to two well-studied protein systems: alanine dipeptide and Chignolin. In both cases, our method successfully identified the important molecular conformations that were already known from previous studies. This technique could help researchers explore the conformational landscape without requiring long simulation runs."
Poster,Symmetry-Robust 3D Orientation Estimation,https://ICML.cc//virtual/2025/poster/43883,"Christopher Scarvelis, David Benhaim, Paul Zhang","Orientation estimation is a fundamental task in 3D shape analysis which consists of estimating a shape's orientation axes: its side-, up-, and front-axes. Using this data, one can rotate a shape into canonical orientation, where its orientation axes are aligned with the coordinate axes. Developing an orientation algorithm that reliably estimates complete orientations of general shapes remains an open problem. We introduce a two-stage orientation pipeline that achieves state of the art performance on up-axis estimation and further demonstrate its efficacy on full-orientation estimation, where one seeks all three orientation axes. Unlike previous work, we train and evaluate our method on all of Shapenet rather than a subset of classes. We motivate our engineering contributions by theory describing fundamental obstacles to orientation estimation for rotationally-symmetric shapes, and show how our method avoids these obstacles.","Estimating the orientation of 3D shapes – figuring out which way is up, front, and side – is key to many tasks in computer graphics and vision. This helps standardize how shapes are viewed and used by aligning them with a common frame of reference. However, building a method that works reliably for all kinds of shapes, especially those with rotational symmetries, is still a challenge. In this work, we present a two-step method that sets a new standard for estimating a shape’s upright direction and shows strong results for estimating its full orientation, which includes its front and side-facing directions. Unlike earlier approaches that were tested only on a few shape categories, our method is trained and tested on the entire ShapeNet dataset. We also offer a theoretical explanation for why shapes with rotational symmetries are harder to orient, and we specifically design our approach to overcome these challenges."
Poster,SyncMind: Measuring Agent Out-of-Sync Recovery in Collaborative Software Engineering,https://ICML.cc//virtual/2025/poster/46372,"Xuehang Guo, Xingyao Wang, Yangyi Chen, Sha Li, Chi Han, Manling Li, Heng Ji","Software engineering (SE) is increasingly collaborative, with developers working together on shared complex codebases. Effective collaboration in shared environments requires participants---whether humans or AI agents---to stay on the same page as their environment evolves. When a collaborator's understanding diverges from the current state---what we term the *out-of-sync* challenge---the collaborator's actions may fail, leading to integration issues. In this work, we introduce **SyncMind**, a framework that systematically defines the *out-of-sync* problem faced by large language model (LLM) agents in collaborative software engineering (CSE). Based on ***SyncMind***, we create **SyncBench**, a benchmark featuring 24,332 instances of agent *out-of-sync* scenarios in real-world CSE derived from 21 popular *GitHub* repositories with executable verification tests. Experiments on ***SyncBench*** uncover critical insights into existing LLM agents' capabilities and limitations. Besides substantial performance gaps among agents (from *Llama-3.1* agents $\leq 3.33\%$ to *Claude-3.5-Sonnet* $\geq 28.18\%$), their consistently low collaboration willingness ($\le 4.86\%$) suggests fundamental limitations of existing LLM in CSE. However, when collaboration occurs, it positively correlates with *out-of-sync* recovery success. Minimal performance differences in agents' resource-aware *out-of-sync* recoveries further reveal their significant lack of resource awareness and adaptability, shedding light on future development of resource-efficient collaborative systems. Our code and data are openly available on our project website: https://xhguo7.github.io/SyncMind/.","What happens when your teammates contribute new updates to your collaborative project while you're away, leaving you out of the loop? In collaborative scenarios, team members can fall ""out-of-sync"" with the current state of the project—missing crucial changes and potentially introducing bugs or causing integration issues. This problem becomes increasingly significant as more collaborative environments incorporate AI assistants that need to stay aligned with human collaborators.Our research tackles this challenge through the lens of collaborative software engineering, where we introduce SyncMind, a framework that systematically measures how well large language model (LLM) agents recover when they lose synchronization with the coding environment. We constructed SyncBench, a scalable benchmark with an open-source construction method to evaluate agents' ability in detecting, localizing, and fixing synchronization issues. Our experiments not only revealed striking performance and ability differences across LLM agents, but also provided insights into resource-efficient collaboration in future collaborative systems.As agents can fall out-of-sync in various collaborative scenarios beyond software engineering, our findings carry implications for broad collaborative systems—whether among humans, AIs, or mixed teams—highlighting the need for better collaborative mechanisms, improved resource awareness in AI assistants, as well as strategic reasoning, planning, and decision-making capabilities to help agents efficiently and effectively recover from state misalignments."
Poster,SynEVO: A neuro-inspired spatiotemporal evolutional framework for cross-domain adaptation,https://ICML.cc//virtual/2025/poster/45354,"jiayue Liu, Zhongchao Yi, Zhengyang Zhou, Qihe Huang, Kuo Yang, Xu Wang, Yang Wang","Discovering regularities from spatiotemporal systems can benefit various scientific and social planning. Current spatiotemporal learners usually train an independent model from a specific source data that leads to limited transferability among sources, where even correlated tasks requires new design and training. The key towards increasing cross-domain knowledge is to enable collective intelligence and model evolution. In this paper, inspired by neuroscience theories, we theoretically derive the increased information boundary via learning cross-domain collective intelligence and propose a Synaptic EVOlutional spatiotemporal network, SynEVO, where SynEVO breaks the model independence and enables cross-domain knowledge to be shared and aggregated. Specifically, we first re-order the sample groups to imitate the human curriculum learning, and devise two complementary learners, elastic common container and task-independent extractor to allow model growth and task-wise commonality and personality disentanglement. Then an adaptive dynamic coupler with a new difference metric determines whether the new sample group should be incorporated into common container to achieve model evolution under various domains. Experiments show that SynEVO improves the generalization capacity by at most 42\% under cross-domain scenarios and SynEVO provides a paradigm of NeuroAI for knowledge transfer and adaptation.Code available at [https://github.com/Rodger-Lau/SynEVO](https://github.com/Rodger-Lau/SynEVO).","The growing amount and diversity of urban data brings in the requirement of model generalization, expansion and evolution for cross-temporal and cross-source domain transfer. It has been demonstrated that the process of acquiring skills in human brain is analogous to machine learning model evolution. This paper built a neuroscience-inspired deep learning framework, SynEVO, for efficient and effective model evolution.SynEVO inherits the most important information sharing scheme, synaptic structure in brain and implement three key mechanisms of brain, progressive curriculum learning, information transfer and expansion, as well as complementary structured learning to realize iterative information aggregation and expansion. These three components can work cooperatively to construct the overall synaptic structure for collective intelligence, and enable model evolution across temporal and source domains. Experiments show the collective intelligence increases the model generalization capacity under both source and temporal shifts by at 0.5% to 42%, and validate the efficient convergency of progressive curriculum learning. The extremely reduced memory cost, i.e., only 21.75% memory cost against SOTA on model training and evolution advances urban computing towards efficient model deployment and sustainable computing paradigm."
Poster,Synonymous Variational Inference for Perceptual Image Compression,https://ICML.cc//virtual/2025/poster/44349,"Zijian Liang, Kai Niu, Changshuo Wang, Jin Xu, Ping Zhang","Recent contributions of semantic information theory reveal the set-element relationship between semantic and syntactic information, represented as synonymous relationships. In this paper, we propose a synonymous variational inference (SVI) method based on this synonymity viewpoint to re-analyze the perceptual image compression problem. It takes perceptual similarity as a typical synonymous criterion to build an ideal synonymous set (Synset), and approximate the posterior of its latent synonymous representation with a parametric density by minimizing a partial semantic KL divergence. This analysis theoretically proves that the optimization direction of perception image compression follows a triple tradeoff that can cover the existing rate-distortion-perception schemes. Additionally, we introduce synonymous image compression (SIC), a new image compression scheme that corresponds to the analytical process of SVI, and implement a progressive SIC codec to fully leverage the model's capabilities. Experimental results demonstrate comparable rate-distortion-perception performance using a single progressive SIC codec, thus verifying the effectiveness of our proposed analysis method.","When we compress images to save space or share them, we hope to reduce the file size without harming how they look. While traditional image compression technologies focus on pixel accuracy, which unfortunately doesn't always match human perception, some AI-driven methods have achieved better results in practice. We aim to explore the underlying theory behind these works.We noticed that two or more images can be mathematically ""synonymous"" and belong to a ""synonymous set (synset)"" if they look alike to people, even if their pixel-level details differ. Building on this idea, we develop an analysis framework called Synonymous Variational Inference (SVI), using ideas of semantic information theory. It not only theoretically explains why the AI-driven compression's three-way trade-off among compression rates, pixel distortions, and distribution divergence, but also points out future improvements. We put it into practice with a progressive codec, Synonymous Image Compression (SIC), that compresses images across diverse file sizes while keeping them visually faithful.We state that our work not only supports perceptual image compression in theory, but also contributes to semantic information theory by linking the synonymy perspective to practical image coding problems, helping move toward a unified viewpoint of semantic information."
Poster,Synthesizing Images on Perceptual Boundaries of ANNs for Uncovering and Manipulating Human Perceptual Variability,https://ICML.cc//virtual/2025/poster/45211,"Chen Wei, Chi Zhang, Jiachen Zou, Haotian Deng, Dietmar Heinke, Quanying Liu","Human decision-making in cognitive tasks and daily life exhibits considerable variability, shaped by factors such as task difficulty, individual preferences, and personal experiences. Understanding this variability across individuals is essential for uncovering the perceptual and decision-making mechanisms that humans rely on when faced with uncertainty and ambiguity. We propose a systematic Boundary Alignment Manipulation (BAM) framework for studying human perceptual variability through image generation. BAM combines perceptual boundary sampling in ANNs and human behavioral experiments to systematically investigate this phenomenon. Our perceptual boundary sampling algorithm generates stimuli along ANN perceptual boundaries that intrinsically induce significant perceptual variability. The efficacy of these stimuli is empirically validated through large-scale behavioral experiments involving 246 participants across 116,715 trials, culminating in the variMNIST dataset containing 19,943 systematically annotated images.Through personalized model alignment and adversarial generation, we establish a reliable method for simultaneously predicting and manipulating the divergent perceptual decisions of pairs of participants.This work bridges the gap between computational models and human individual difference research, providing new tools for personalized perception analysis. Code and data for this work are publicly available.","Human decision-making in everyday tasks varies widely due to differences in difficulty, personal preferences, and past experiences. Understanding why and how people perceive things differently helps us learn more about how the brain processes uncertain or ambiguous information. In this work, we introduce a new approach to study these differences by creating special images that reveal how people’s perceptions change. We tested these images with hundreds of volunteers and collected a large dataset to better understand individual perception patterns. Our method also allows us to predict and influence how different people might see the same image differently. This research helps connect computer models with human behavior, offering new ways to analyze how perception varies from person to person. All related data and code are shared openly for others to explore."
Poster,Synthesizing Privacy-Preserving Text Data via Finetuning *without* Finetuning Billion-Scale LLMs,https://ICML.cc//virtual/2025/poster/45901,"Bowen Tan, Zheng Xu, Eric Xing, Zhiting Hu, Shanshan Wu","Synthetic data offers a promising path to train models while preserving data privacy. Differentially private (DP) finetuning of large language models (LLMs) as data generator is effective, but is impractical when computation resources are limited. Meanwhile, prompt-based methods such as private evolution depend heavily on the manual prompts, and ineffectively use private information in their iterative data selection process. To overcome these limitations, we propose CTCL (Data Synthesis with **C**on**T**rollability and **CL**ustering), a novel framework for generating privacy-preserving synthetic data without extensive prompt engineering or billion-scale LLM finetuning. CTCL pretrains a lightweight 140M conditional generator and a  clustering-based topic model on large-scale public data. To further adapt to the private domain, the generator is DP finetuned on private data for fine-grained textual information, while the topic model extracts a DP histogram representing distributional information. The DP generator then samples according to the DP histogram to synthesize a desired number of data examples. Evaluation across five diverse domains demonstrates the effectiveness of our framework, particularly in the strong privacy regime. Systematic ablation validates the design of each framework component and highlights the scalability of our approach.",Synthetic data presents a viable solution for training models while safeguarding privacy. We propose a novel framework for generating privacy-preserving synthetic data that avoids the limitations of extensive prompt engineering and billion-scale model finetuning. Our method can be used in the resource-constrained setting to synthesize data for domains that require strong provable privacy guarantees.
Poster,Synthesizing Software Engineering Data in a Test-Driven Manner,https://ICML.cc//virtual/2025/poster/45400,"Lei Zhang, Jiaxi Yang, Min Yang, Jian Yang, Mouxiang Chen, Jiajun Zhang, Zeyu Cui, Binyuan Hui, Junyang Lin","We introduce **SWE-Flow**, a novel data synthesis framework grounded in Test-Driven Development (TDD).Unlike existing software engineering data that rely on human-submitted issues, **SWE-Flow** automatically infers incremental development steps directly from unit tests, which inherently encapsulate high-level requirements.The core of **SWE-Flow** is the construction of a Runtime Dependency Graph (RDG), which precisely captures function interactions, enabling the generation of a structured, step-by-step *development schedule*.At each step, **SWE-Flow** produces a partial codebase, the corresponding unit tests, and the necessary code modifications, resulting in fully verifiable TDD tasks.With this approach, we generated 16,061 training instances and 2,020 test instances from real-world GitHub projects, creating the **SWE-Flow-Eval** benchmark.Our experiments show that fine-tuning open model on this dataset significantly improves performance in TDD-based coding.To facilitate further research, we release all code, datasets, models, and Docker images at [Github](https://github.com/Hambaobao/SWE-Flow).","Modern software development often involves writing tests to ensure code works correctly. Inspired by this practice, we created **SWE-Flow**, a new system that helps machines learn how to build software step by step by following test instructions. Unlike previous methods that depend on manually written issue reports, **SWE-Flow** learns directly from unit tests, which naturally reflect what the software is supposed to do. At each step, it provides a small piece of code, a test to check it, and suggestions on what needs to be changed—just like how a real developer would work. We used this approach to build a large dataset from real-world projects and showed that it helps AI models do a better job at writing software in a test-driven way. All our tools, data, and code are freely available at https://github.com/Hambaobao/SWE-Flow."
Poster,Synthetic Face Datasets Generation via Latent Space Exploration from Brownian Identity Diffusion,https://ICML.cc//virtual/2025/poster/45306,"David Geissbühler, Hatef Otroshi Shahreza, Sébastien Marcel","Face recognition models are trained on large-scale datasets, which have privacy and ethical concerns. Lately, the use of synthetic data to complement or replace genuine data for the training of face recognition models has been proposed. While promising results have been obtained, it still remains unclear if generative models can yield diverse enough data for such tasks. In this work, we introduce a new method, inspired by the physical motion of soft particles subjected to stochastic Brownian forces, allowing us to sample identities distributions in a latent space under various constraints. We introduce three complementary algorithms, called Langevin, Dispersion, and DisCo, aimed at generating large synthetic face datasets. With this in hands, we generate several face datasets and benchmark them by training face recognition models, showing that data generated with our method exceeds the performance of previously GAN-based datasets and achieves competitive performance with state-of-the-art diffusion-based synthetic datasets. While diffusion models are shown to memorize training data, we prevent leakage in our new synthetic datasets, paving the way for more responsible synthetic datasets. Project page: https://www.idiap.ch/paper/synthetics-disco","Existing real face recognition datasets are collected from the web, raising ethical and privacy concerns. This paper presents a new method for generating synthetic face recognition datasets, inspired by physics motion (i.e., Brownian motion) of tiny particles in fluids based on granular mechanics. Three algorithms are developed (called Langevin, Dispersion, and DisCo) that generate diverse synthetic faces by applying these physical processes to image generation. The generated datasets are used to train face recognition models, which are evaluated on a diverse set of benchmarks. Furthermore, this work promotes safe and ethical use of AI technologies in face recognition applications."
Poster,Synthetic Text Generation for Training Large Language Models via Gradient Matching,https://ICML.cc//virtual/2025/poster/44161,"Dang Nguyen, Zeman Li, MohammadHossein Bateni, Vahab Mirrokni, Meisam Razaviyayn, Baharan Mirzasoleiman","Synthetic data has the potential to improve the performance, training efficiency, and privacy of real training examples. Nevertheless, existing approaches for synthetic text generation are mostly heuristics and cannot generate human-readable text without compromising the privacy of real data, or provide performance guarantees for training Large Language Models (LLMs). In this work, we propose the first theoretically rigorous approach for generating synthetic human-readable text that provides convergence, performance, and privacy guarantees for fine-tuning LLMs on a target task. To do so, we leverage Alternating Direction Method of Multipliers (ADMM) that iteratively optimizes the embeddings of synthetic examples to match the noisy gradient of the target training or validation data, and maps them to a sequence of text tokens with low perplexity. In doing so, the generated synthetic text guarantees convergence of the model to a close neighborhood of the solution obtained by fine-tuning on real data and preserves their privacy. Experiments on various classification tasks confirm the effectiveness of our proposed approach. Our code is available at [https://github.com/BigML-CS-UCLA/GRADMM](https://github.com/BigML-CS-UCLA/GRADMM).","Large Language Models (LLMs) require massive amounts of high-quality data, but collecting and using such data raises concerns about privacy, cost, and efficiency. Our work introduces GRADMM, the first method that can generate readable synthetic text with strong theoretical guarantees for training LLMs. Unlike existing methods that rely on expensive prompts or unreadable embeddings, GRADMM creates human-like text that mimics how real data trains the model—without leaking sensitive information.We achieve this by matching the training dynamics (gradients) of real data using a technique called ADMM, while ensuring the output is coherent and diverse. This allows us to train LLMs using only a handful of real examples or replace real data entirely with synthetic ones. Our experiments show that GRADMM outperforms both traditional data selection and LLM-generated text in accuracy—while being significantly more private and efficient. This opens the door to safer and more accessible LLM training."
