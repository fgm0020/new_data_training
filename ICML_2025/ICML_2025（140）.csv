type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Identifying Neural Dynamics Using Interventional State Space Models,https://ICML.cc//virtual/2025/poster/44119,"Amin Nejatbakhsh, Yixin Wang","Neural circuits produce signals that are complex and nonlinear. To facilitate the understanding of neural dynamics, a popular approach is to fit state space models (SSM) to the data and analyze the dynamics of the low-dimensional latent variables. Despite the power of SSM to explain the dynamics of neural circuits, these models have been shown to merely capture statistical associations in the data and cannot be causally interpreted. Therefore, an important research problem is to build models that can predict neural dynamics under causal manipulations. Here, we propose interventional state-space models (iSSM), a class of causal models that can predict neural responses to novel perturbations. We draw on recent advances in causal dynamical systems and present theoretical results for the identifiability of iSSM. In simulations of the motor cortex, we show that iSSM can recover the true latents and the underlying dynamics. In addition, we illustrate two applications of iSSM in biological datasets. First, we applied iSSM to a dataset of calcium recordings from ALM neurons in mice during photostimulation. Second, we applied iSSM to a dataset of electrophysiological recordings from macaque dlPFC during micro-stimulation. In both cases, we show that iSSM outperforms SSM and results in identifiable parameters. The code is available at https://github.com/amin-nejat/issm.","Understanding how the brain works is complicated because the signals produced by neural circuits are complex and constantly changing. To make sense of this activity, scientists often use mathematical tools called state space models (SSMs), which help simplify and analyze brain signals. However, these models only show patterns in the data — they can’t explain how the brain would respond to changes or interventions.To address this, we developed a new kind of model called the interventional state space model (iSSM). Unlike traditional models, iSSM can predict how the brain will react when it’s actively stimulated or changed, making it useful for understanding cause-and-effect relationships in the brain.We tested this new model using simulations of brain activity in the motor cortex and found it could accurately recover the hidden dynamics behind the signals. We also applied it to two real-world brain datasets: one from mice that were exposed to light stimulation, and another from monkeys that received tiny electric pulses in their brain. In both cases, our model performed better than traditional ones and gave more meaningful, interpretable results."
Poster,Idiosyncrasies in Large Language Models,https://ICML.cc//virtual/2025/poster/45902,"Mingjie Sun, Yida Yin, Zhiqiu (Oscar) Xu, Zico Kolter, Zhuang Liu","In this work, we unveil and study idiosyncrasies in Large Language Models (LLMs) -- unique patterns in their outputs that can be used to distinguish the models. To do so, we consider a simple classification task: given a particular text output, the objective is to predict the source LLM that generates the text. We evaluate this synthetic task across various groups of LLMs and find that simply fine-tuning text embedding models on LLM-generated texts yields excellent classification accuracy. Notably, we achieve 97.1\% accuracy on held-out validation data in the five-way classification problem involving ChatGPT, Claude, Grok, Gemini, and DeepSeek. Our further investigation reveals that these idiosyncrasies are rooted in word-level distributions. These patterns persist even when the texts are rewritten, translated, or summarized by an external LLM, suggesting that they are also encoded in the semantic content. Additionally, we leverage LLM as judges to generate detailed, open-ended descriptions of each model's idiosyncrasies. Finally, we discuss the broader implications of our findings, including training on synthetic data, inferring model similarity, and robust evaluation of LLMs.","We study the problem of distinguishing large language models (LLMs) based on their outputs. We find that neural networks can reliably distinguish the texts from different LLMs. Our results have several implications: first it can help people develop tools for detecting LLM generated texts; it could shed light on the relative uptake of different LLMs, beyond what is reported by individual companies, and on the nature of data used to build different models in the first place."
Poster,iDPA: Instance Decoupled Prompt Attention for Incremental Medical Object Detection,https://ICML.cc//virtual/2025/poster/44405,"Huahui Yi, Wei Xu, Ziyuan Qin, Xi Chen, Xiaohu Wu, Kang Li, Qicheng Lao","Existing prompt-based approaches have demonstrated impressive performance in continual learning, leveraging pre-trained large-scale models for classification tasks; however, the tight coupling between foreground-background information and the coupled attention between prompts and image-text tokens present significant challenges in incremental medical object detection tasks, due to the conceptual gap between medical and natural domains. To overcome these challenges, we introduce the iDPA framework, which comprises two main components: 1) Instance-level Prompt Generation (IPG), which decouples fine-grained instance-level knowledge from images and generates prompts that focus on dense predictions, and 2) Decoupled Prompt Attention (DPA), which decouples the original prompt attention, enabling a more direct and efficient transfer of prompt information while reducing memory usage and mitigating catastrophic forgetting. We collect 13 clinical, cross-modal, multi-organ, and multi-category datasets, referred to as ODinM-13, and experiments demonstrate that iDPA outperforms existing SOTA methods, with FAP improvements of f 5.44%, 4.83%, 12.88%, and 4.59% in full data, 1-shot, 10-shot, and 50-shot settings, respectively.","Modern AI models can perform well on specific medical tasks, but struggle to continuously learn new ones without forgetting previous knowledge — especially in complex object detection tasks across different diseases and imaging types. While recent prompt-based methods help AI models remember better, they are mainly designed for natural images and simple classification tasks.We introduce a new method called iDPA, which helps models incrementally learn medical tasks more effectively. It does this in two ways: first, it creates custom prompts based on specific objects in medical images (like tumors or lesions); second, it restructures how prompts interact with the model, making learning more efficient and reducing memory costs.We tested our method on 13 diverse medical datasets, covering different organs, image types, and clinical scenarios. Our approach consistently outperformed existing methods, especially when very few training examples were available. This makes iDPA a promising tool for building adaptable, general-purpose medical AI systems."
Poster,IL-SOAR : Imitation Learning with Soft Optimistic  Actor cRitic,https://ICML.cc//virtual/2025/poster/45502,"Stefano Viel, Luca Viano, Volkan Cevher","This paper introduces the SOAR framework for imitation learning. SOAR is an algorithmic template which learns a policy from expert demonstrations with a primal-dual style algorithm which alternates cost and policy updates. Within the policy updates the SOAR framework prescribe to use an actor critic method with multiple critics to estimate the critic uncertainty and therefore build an optimistic critic fundamental to drive exploration.When instantiated to the tabular setting, we get a provable algorithms dubbed FRA with guarantees matching the best known results in $\epsilon$.Practically, the SOAR template is shown to boost consistently the performance of primal dual IL algorithms building on actor critic routines for the policy updates. Approximately, thanks to SOAR, the required number of episodes to achieve the same performance is reduced by a half.","Imitation learning is a way for artificial intelligence (AI) systems to learn new skills by watching and copying expert behavior—much like how a child learns by observing adults. However, making AI learn efficiently from demonstrations can be challenging, especially in complex environments.This paper introduces a new framework called SOAR (Soft Optimistic Actor cRitic) to improve how AI learns from experts. The key idea behind SOAR is to help the AI not just copy what it sees, but also to explore actions it’s less sure about, guided by a sense of “optimism” about what might work well. This is achieved by using multiple “critics” (advisors) within the AI that estimate how good different actions might be, and then encouraging the AI to try actions where these critics are most optimistic.The authors show that SOAR can be used as a flexible template, improving several popular imitation learning algorithms. In practical tests with simulated robots (using the MuJoCo environment), SOAR helped these algorithms learn faster and more efficiently—cutting the amount of training needed by half to reach the same level of performance.In summary, SOAR is a promising step towards making AI systems better at learning from demonstrations, allowing them to master new tasks more quickly and with less data."
Poster,Imagine While Reasoning in Space: Multimodal Visualization-of-Thought,https://ICML.cc//virtual/2025/poster/46352,"Chengzu Li, Wenshan Wu, Huanyu Zhang, Yan Xia, Shaoguang Mao, Li Dong, Ivan Vulić, Furu Wei","Chain-of-Thought (CoT) prompting has proven highly effective for enhancing complex reasoning in Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs). Yet, it struggles in complex spatial reasoning tasks. Nonetheless, human cognition extends beyond language alone, enabling the remarkable capability to think in both words and images. Inspired by this mechanism, we propose a new reasoning paradigm, Multimodal Visualization-of-Thought (MVoT). It enables visual thinking in MLLMs by generating image visualizations of their reasoning traces. To ensure high-quality visualization, we introduce token discrepancy loss into autoregressive MLLMs. This innovation significantly improves both visual coherence and fidelity. We validate this approach through several dynamic spatial reasoning tasks. Experimental results reveal that MVoT demonstrates competitive performance across tasks. Moreover, it exhibits robust and reliable improvements in the most challenging scenarios where CoT fails. Ultimately, MVoT establishes new possibilities for complex reasoning tasks where visual thinking can effectively complement verbal reasoning.","AI models like ChatGPT are good at solving problems by thinking step-by-step in words. But they often struggle with tasks that involve understanding space, like imagining how objects move or fit together. Humans, on the other hand, use both language and mental pictures to reason through such challenges.We created a new method called Multimodal Visualization-of-Thought (MVoT) that allows AI to “draw out” its thoughts as it reasons. Just like a person might sketch a diagram to solve a puzzle, our method lets the model generate helpful images to support its thinking. We also trained it to make these images clearer and more accurate.This helps AI handle more complex problems, especially those that require visual thinking. MVoT brings us closer to building smarter, more human-like AI that can think in both words and pictures."
Poster,Imitation Learning from a Single Temporally Misaligned Video,https://ICML.cc//virtual/2025/poster/44909,"William Huey, Yuki (Huaxiaoyue) Wang, Anne Wu, Yoav Artzi, Sanjiban Choudhury","We examine the problem of learning sequential tasks from a single visual demonstration.A key challenge arises when demonstrations are temporally misaligned due to variations in timing, differences in embodiment, or inconsistencies in execution. Existing approaches treat imitation as a distribution-matching problem, aligning individual frames between the agent and the demonstration. However, we show that such frame-level matching fails to enforce temporal ordering or ensure consistent progress.Our key insight is that matching should instead be defined at the level of sequences. We propose that perfect matching occurs when one sequence successfully covers all the subgoals in the same order as the other sequence. We present ORCA (ORdered Coverage Alignment), a dense per-timestep reward function that measures the probability of the agent covering demonstration frames in the correct order. On temporally misaligned demonstrations, we show that agents trained with the ORCA reward achieve $4.5$x improvement ($0.11 \rightarrow 0.50$ average normalized returns) for Meta-world tasks and $6.6$x improvement ($6.55 \rightarrow 43.3$ average returns) for Humanoid-v4 tasks compared to the best frame-level matching algorithms. We also provide empirical analysis showing that ORCA is robust to varying levels of temporal misalignment. The project website is at https://portal-cornell.github.io/orca/","Teaching robots new tasks usually requires detailed instructions about what actions are good at every moment, which we call “designing a reward function.” This is difficult and time consuming. An easier alternative is to show the robot a video demonstrating how to solve the task. However, these demonstrations often move at a different speed compared to how the robot can move. This makes it difficult or even impossible for the robot to follow them exactly. We find, both in theory and practice, that traditional methods fail when the demonstration is at a different speed.Our solution is to treat the frames of the video as a sequence of subgoals that the robot must achieve at some point in time instead of matching the timing exactly. Specifically, we define the reward function as how well the robot can match ALL the subgoals in the EXACT SAME order as the video. Then, we can teach the robot to try different actions and repeat actions that have high rewards, a technique known as reinforcement learning. Our work focuses on robot video, but it sets the foundation for learning from human videos, which typically have different speeds from robots."
Poster,IMPACT: Iterative Mask-based Parallel Decoding for Text-to-Audio Generation with Diffusion Modeling,https://ICML.cc//virtual/2025/poster/46189,"Kuan Po Huang, Shu-wen Yang, Huy Phan, Bo-Ru Lu, Byeonggeun Kim, Sashank Macha, Qingming Tang, Shalini Ghosh, Hung-yi Lee, Chieh-Chi Kao, Chao Wang","Text-to-audio generation synthesizes realistic sounds or music given a natural language prompt. Diffusion-based frameworks, including the Tango and the AudioLDM series, represent the state-of-the-art in text-to-audio generation. Despite achieving high audio fidelity, they incur significant inference latency due to the slow diffusion sampling process. MAGNET, a mask-based model operating on discrete tokens, addresses slow inference through iterative mask-based parallel decoding. However, its audio quality still lags behind that of diffusion-based models. In this work, we introduce IMPACT, a text-to-audio generation framework that achieves high performance in audio quality and fidelity while ensuring fast inference. IMPACT utilizes iterative mask-based parallel decoding in a continuous latent space powered by diffusion modeling. This approach eliminates the fidelity constraints of discrete tokens while maintaining competitive inference speed. Results on AudioCaps demonstrate that IMPACT achieves state-of-the-art performance on key metrics including Fréchet Distance (FD) and Fréchet Audio Distance (FAD) while significantly reducing latency compared to prior models. The project website is available at https://audio-impact.github.io/.","Imagine typing a sentence like “a dog barking in the park” and having a computer generate a realistic audio clip to match. This is the goal of text-to-audio generation, but current methods often take a long time to produce high-quality sounds. Some fast models generate sound quickly but sacrifice realism; others sound great but are painfully slow.Our research introduces IMPACT, a new method that combines the best of both worlds. It generates audio using a smart technique that masks and fills in missing parts step by step, guided by a simplified version of a powerful method called diffusion modeling. Unlike earlier systems that use inefficient components or only work with rough sound units, IMPACT works in a smooth, continuous space, enabling both realism and speed.Why does this matter? IMPACT achieves state-of-the-art audio quality on standard benchmarks while being much faster than previous high-quality models. This opens the door for real-time applications like sound design, immersive gaming, and creative tools where both fidelity and responsiveness are crucial."
Poster,Implicit Bias of Gradient Descent for Non-Homogeneous Deep Networks,https://ICML.cc//virtual/2025/poster/43862,"Yuhang Cai, Kangjie Zhou, Jingfeng Wu, Song Mei, Michael Lindsey, Peter Bartlett","We establish the asymptotic implicit bias of gradient descent (GD) for generic non-homogeneous deep networks under exponential loss. Specifically, we characterize three key properties of GD iterates starting from a sufficiently small empirical risk, where the threshold is determined by a measure of the network's non-homogeneity. First, we show that a normalized margin induced by the GD iterates increases nearly monotonically. Second, we prove that while the norm of the GD iterates diverges to infinity, the iterates themselves converge in direction. Finally, we establish that this directional limit satisfies the Karush–Kuhn–Tucker (KKT) conditions of a margin maximization problem. Prior works on implicit bias have focused exclusively on homogeneous networks; in contrast, our results apply to a broad class of non-homogeneous networks satisfying a mild near-homogeneity condition. In particular, our results apply to networks with residual connections and non-homogeneous activation functions, thereby resolving an open problem posed byJi & Telgarsky (2020).","When we train deep neural networks with gradient descent, the method subconsciously nudges the model toward a particular kind of solution, even when many solutions could fit the data. We show this “steering effect” holds not just for idealized, perfectly uniform networks studied before, but also for more realistic architectures that include skip-connections and varied activation functions. As training continues, the model’s confidence gap (margin) on the right answers steadily grows; the weights themselves get larger and larger, yet the direction they point settles into a single orientation. That final direction is exactly the one that maximizes the margin according to standard optimality rules, helping explain why over-parameterized networks often end up with simple, well-generalizing solutions. Compared to previous results, we provide a detailed analysis for much more practical neural networks including residual connection and many activations."
Poster,Implicit degree bias in the link prediction task,https://ICML.cc//virtual/2025/poster/44481,"Rachith Aiyappa, Xin Wang, Munjung Kim, Ozgur Can Seckin, Yong-Yeol Ahn, Sadamori Kojaku","Link prediction---a task of distinguishing actual hidden edges from random unconnected node pairs---is one of the quintessential tasks in graph machine learning. Despite being widely accepted as a universal benchmark and a downstream task for representation learning, the link prediction benchmark's validity has rarely been questioned. Here, we show that the common edge sampling procedure in the link prediction task has an implicit bias toward high-degree nodes. This produces a highly skewed evaluation that favors methods overly dependent on node degree. In fact  a ``null'' link prediction method based solely on node degree can yield nearly optimal performance in this setting. We propose a degree-corrected link prediction benchmark that offers a more reasonable assessment and better aligns with the performance on the recommendation task. Finally, we demonstrate that the degree-corrected benchmark can more effectively train graph machine-learning models by reducing overfitting to node degrees and facilitating the learning of relevant structures in graphs.","From suggesting new friends to recommending products, machine learning models are increasingly used to predict connections in networks. But the way we test these systems has a serious flaw: it favors popular items, such as people who already have many connections. In network terms, these are the ""high-degree"" nodes, i.e., those linked to many others. As a result, even simple models that just recommend these well-connected nodes can appear to perform well. We found that this flaw comes from how test data is built: popular nodes are sampled more often as examples of true connections simply because they have more links, while non-connections are sampled randomly, regardless of how popular the nodes are. This gives models a shortcut: they can classify connections and non-connections within the test data based on popularity alone. So much so that predictions sorely based on popularity can achieve nearly optimal performance without actually learning meaningful structure. To address this, we introduce a new testing method that balances the visibility of popular and less-popular nodes. This prevents models from relying only on popularity and encourages learning real patterns. Our approach can improves the usefulness of machine learning systems in recommendations, scientific discovery, and other applications where identifying genuine connections is critical."
Poster,Implicit Language Models are RNNs: Balancing Parallelization and Expressivity,https://ICML.cc//virtual/2025/poster/46440,"Mark Schoene, Babak Rahmani, Heiner Kremer, Fabian Falck, Hitesh Ballani, Jannes Gladrow","State-space models (SSMs) and transformers dominate the language modeling landscape. However, they are constrained to a lower computational complexity than classical recurrent neural networks (RNNs), limiting their expressivity. In contrast, RNNs lack parallelization during training, raising fundamental questions about the trade off between parallelization and expressivity. We propose implicit SSMs, which iterate a transformation until convergence to a fixed point. Theoretically, we show that implicit SSMs implement the non-linear state-transitions of RNNs. Empirically, we find that only approximate fixed-point convergence suffices, enabling the design of a scalable training curriculum that largely retains parallelization, with full convergence required only for a small subset of tokens. Our approach demonstrates superior state-tracking capabilities on regular languages, surpassing transformers and SSMs. We further scale implicit SSMs to natural language reasoning tasks and pretraining of large-scale language models up to 1.3B parameters on 207B tokens - representing, to our knowledge, the largest implicit model trained to date. Notably, our implicit models outperform their explicit counterparts on standard benchmarks. Our code is publicly available at github.com/microsoft/implicit_languagemodels","Current state-of-the-art language models are pretrained over a large number of tokens requiring token-parallel training. However, it is known in the literature that the architectures enabling token-parallelism come with an inherent weakness, limiting what thought-patterns or algorithms such models can express internally. Most noticeably, it limits their ability to keep track of sustained changes to their environment.  We seek to alleviate this weakness by providing language models with an internal and hidden monologue for every token, which, as we show, qualitatively increases the expressiveness of such models. We then validate our results using larger models and show improvements on various benchmarks, particularly on benchmarks that require language models to keep a collection of entities in their mind. Our research demonstrably improves generalization-abilities of language models, enabling them to solve problems that they have not seen before."
