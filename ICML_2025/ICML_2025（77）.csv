type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Discriminative Policy Optimization for Token-Level Reward Models,https://ICML.cc//virtual/2025/poster/44776,"Hongzhan Chen, Tao Yang, Shiping Gao, Ruijun Chen, Xiaojun Quan, Hongtao Tian, Ting Yao","Process reward models (PRMs) provide more nuanced supervision compared to outcome reward models (ORMs) for optimizing policy models, positioning them as a promising approach to enhancing the capabilities of LLMs in complex reasoning tasks. Recent efforts have advanced PRMs from step-level to token-level granularity by integrating reward modeling into the training of generative models, with reward scores derived from token generation probabilities. However, the conflict between generative language modeling and reward modeling may introduce instability and lead to inaccurate credit assignments. To address this challenge, we revisit token-level reward assignment by decoupling reward modeling from language generation and derive a token-level reward model through the optimization of a discriminative policy, termed the Q-function Reward Model (Q-RM). We theoretically demonstrate that Q-RM explicitly learns token-level Q-functions from preference data without relying on fine-grained annotations. In our experiments, Q-RM consistently outperforms all baseline methods across various benchmarks. For example, when integrated into PPO/REINFORCE algorithms, Q-RM enhances the average Pass@1 score by 5.85/4.70 points on mathematical reasoning tasks compared to the ORM baseline, and by 4.56/5.73 points compared to the token-level PRM counterpart. Moreover, reinforcement learning with Q-RM significantly enhances training efficiency, achieving convergence 12× faster than ORM on GSM8K and 11× faster than step-level PRM on MATH. Code and data are available at https://github.com/homzer/Q-RM.","Training AI to solve complex problems, like math puzzles, often involves giving feedback on each step it takes rather than just the final answer. However, current methods that provide this step-by-step feedback can clash with how the AI generates text, leading to unstable training and unreliable learning.  To fix this, we developed a new approach called the Q-function Reward Model (Q-RM). Instead of mixing feedback with text generation, Q-RM evaluates each step independently, like a coach focusing on individual moves rather than the whole game.When tested on math challenges, AI trained with Q-RM scored significantly higher than methods using only final-answer feedback. It also learned faster, reaching solutions 12 times quicker on some tasks. By making training both more efficient and effective, Q-RM helps AI tackle complicated problems with greater reliability."
Poster,Disentangled Graph Spectral Domain Adaptation,https://ICML.cc//virtual/2025/poster/46292,"Liang Yang, Xin Chen, Jiaming Zhuo, Di Jin, Chuan Wang, Xiaochun Cao, Zhen Wang, Yuanfang Guo","The distribution shifts and the scarcity of labels prevent graph learning methods, especially graph neural networks (GNNs), from generalizing across domains. Compared to Unsupervised Domain Adaptation (UDA) with embedding alignment, Unsupervised Graph Domain Adaptation (UGDA) becomes more challenging in light of the attribute and topology entanglement in the representation. Beyond embedding alignment, UGDA turns to topology alignment but is limited by the ability of the employed topology model and the estimation of pseudo labels. To alleviate this issue, this paper proposed a Disentangled Graph Spectral Domain adaptation (DGSDA) by disentangling attribute and topology alignments and directly aligning flexible graph spectral filters beyond topology. Specifically, Bernstein polynomial approximation, which mimics the behavior of the function to be approximated to a remarkable degree, is employed to capture complicated topology characteristics and avoid the expensive eigenvalue decomposition. Theoretical analysis reveals the tight GDA bound of DGSDA and the rationality of polynomial coefficient regularization. Quantitative and qualitative experiments justify the superiority of the proposed DGSDA.","Imagine training a recommendation system on Twitter to predict user interests, then deploying it on Facebook. Even though both are social platforms, differences in attributes (user profiles) and topology (connection patterns) cause performance drops. Traditional adaptation methods blend these two aspects together, trying to adjust both at the same time, which leads to suboptimal adaptation. In this work, we propose a method named DGSDA, which separately aligns topology and attributes. We begin with attribute alignment using a conventional method, and we then focus on addressing the differences in topology patterns. However, existing methods are limited by the ability of the employed model and the estimation of pseudo-labels. Fortunately, the spectral information of a network is closely related to its topology. Therefore, instead of directly aligning the topology of the two networks, we align their graph spectral filters by adjusting the polynomial parameters of the filters, which is equivalent to adjusting the spectral information in the network. DGSDA is not only more flexible but also avoids costly computations."
Poster,Disentangling and Integrating Relational and Sensory Information in Transformer Architectures,https://ICML.cc//virtual/2025/poster/44191,"Awni Altabaa, John Lafferty","Relational reasoning is a central component of generally intelligent systems, enabling robust and data-efficient inductive generalization. Recent empirical evidence shows that many existing neural architectures, including Transformers, struggle with tasks requiring relational reasoning. In this work, we distinguish between two types of information: *sensory* information about the properties of individual objects, and *relational* information about the relationships between objects. While neural attention provides a powerful mechanism for controlling the flow of sensory information between objects, the Transformer lacks an explicit computational mechanism for routing and processing relational information. To address this limitation, we propose an architectural extension of the Transformer framework that we call the *Dual Attention Transformer (DAT)*, featuring two distinct attention mechanisms: sensory attention for directing the flow of sensory information, and a novel relational attention mechanism for directing the flow of relational information. We empirically evaluate *DAT* on a diverse set of tasks ranging from synthetic relational benchmarks to complex real-world tasks such as language modeling and visual processing. Our results demonstrate that integrating explicit relational computational mechanisms into the Transformer architecture leads to significant performance gains in terms of data efficiency and parameter efficiency.","Current artificial intelligence models are often good at recognizing objects (sensory information) but can struggle with reasoning about how objects relate or interact with each other (relational information). But relational reasoning is central to human intelligence, underpinning the ability to make analogies, comparisons, abstractions, and generalizations. This work develops a new kind of AI model, called the Dual Attention Transformer (DAT), that has enhanced relational reasoning abilities over the standard Transformer architecture. By processing both sensory and relational information, the model becomes more efficient and better at tasks requiring complex reasoning, from understanding language to interpreting visual scenes. This advancement could lead to AI systems that learn more like humans and can tackle more sophisticated problems, while requiring less data than current systems."
Poster,Disentangling Invariant Subgraph via Variance Contrastive Estimation under Distribution Shifts,https://ICML.cc//virtual/2025/poster/44901,"Haoyang Li, Xin Wang, Xueling Zhu, Weigao Wen, Wenwu Zhu","Graph neural networks (GNNs) have achieved remarkable success, yet most are developed under the in-distribution assumption and fail to generalize to out-of-distribution (OOD) environments. To tackle this problem, some graph invariant learning methods aim to learn invariant subgraph against distribution shifts, which heavily rely on predefined or automatically generated environment labels. However, directly annotating or estimating such environment labels from biased graph data is typically impractical or inaccurate for real-world graphs. Consequently, GNNs may become biased toward variant patterns, resulting in poor OOD generalization. In this paper, we propose to learn disentangled invariant subgraph via self-supervised contrastive variant subgraph estimation for achieving satisfactory OOD generalization. Specifically, we first propose a GNN-based invariant subgraph generator to disentangle the invariant and variant subgraphs. Then, we estimate the degree of the spurious correlations by conducting self-supervised contrastive learning on variant subgraphs. Thanks to the accurate identification and estimation of the variant subgraphs, we can capture invariant subgraphs effectively and further eliminate spurious correlations by inverse propensity score reweighting. We provide theoretical analyses to show that our model can disentangle the ground-truth invariant and variant subgraphs for OOD generalization. Extensive experiments demonstrate the superiority of our model over state-of-the-art baselines.","Graphs are everywhere in the real world, from molecules and recommendation systems to social networks. However, AI models trained on graphs often struggle to make accurate predictions when faced with unfamiliar or biased data. This challenge is commonly referred to as out-of-distribution (OOD) generalization failure.To address this problem, we propose a new approach that helps models focus on the stable, meaningful parts of a graph that reliably influence the outcome, while reducing the impact of misleading patterns that are specific to certain environments. Our method combines subgraph disentanglement, self-supervised contrastive learning, and reweighting techniques to eliminate spurious correlations.As a result, our approach enables AI models to generalize more effectively across diverse types of graph data and remain reliable under distribution shifts. This has important applications in real-world scenarios such as molecular property prediction, recommendation systems, and social network analysis, where data conditions frequently change and stable performance is critical."
Poster,Disparate Conditional Prediction in Multiclass Classifiers,https://ICML.cc//virtual/2025/poster/45683,"Sivan Sabato, Eran Treister, Elad Yom-Tov","We propose methods for auditing multiclass classifiers for fairness under multiclass equalized odds, by estimating the deviation from equalized odds when the classifier is not completely fair. We generalize to multiclass classifiers the measure of Disparate Conditional Prediction (DCP), originally suggested by Sabato & Yom-Tov (2020) for binary classifiers. DCP is defined as the fraction of the population for which the classifier predicts with conditional prediction probabilities that differ from the closest common baseline. We provide new local-optimization methods for estimating the multiclass DCP under two different regimes, one in which the conditional confusion matrices for each protected sub-population are known, and one in which these cannot be estimated, for instance, because the classifier is inaccessible orbecause good-quality individual-level data is not available. These methods can be used to detect classifiers that likely treat a significant fraction of the population unfairly. Experiments demonstrate the accuracy of the methods. The code for the experiments is provided as supplementary material.","Many machine learning systems make decisions that affect people's lives, like approving loans or recommending medical treatments. When access to the underlying system is difficult, it becomes harder to check if they are treating all groups of people fairly. Moreover, existing fairness checks often do not address cases where these systems handle more than two possible outcomes.  We introduce new methods to audit these multiclass decision systems for fairness. We build on a fairness measure called Disparate Conditional Prediction (DCP), which looks at how many people receive predictions that differ from a fair baseline. We extend this measure to work with systems that support more than two outcomes, and provide two ways to estimate the DCP, one for cases in which we have detailed data about how the system behaves for different groups, and the other for cases when we do not have access to the system or high-quality individual data. These tools make it easier to detect when a decision-making system is likely treating a significant portion of the population unfairly and thus helps organizations and regulators identify and address bias leading to fairer outcomes for everyone."
Poster,Dissecting Submission Limit in Desk-Rejections: A Mathematical Analysis of Fairness in AI Conference Policies,https://ICML.cc//virtual/2025/poster/43632,"Yuefan Cao, Xiaoyu Li, Yingyu Liang, Zhizhou Sha, Zhenmei Shi, Zhao Song, Jiahao Zhang","As AI research surges in both impact and volume, conferences have imposed submission limits to maintain paper quality and alleviate organizational pressure. In this work, we examine the fairness of desk-rejection systems under submission limits and reveal that existing practices can result in substantial inequities. Specifically, we formally define the paper submission limit problem and identify a critical dilemma: when the number of authors exceeds three, it becomes impossible to reject papers solely based on excessive submissions without negatively impacting innocent authors. Thus, this issue may unfairly affect early-career researchers, as their submissions may be penalized due to co-authors with significantly higher submission counts, while senior researchers with numerous papers face minimal consequences. To address this, we propose an optimization-based fairness-aware desk-rejection mechanism and formally define two fairness metrics: worst-case fairness and average fairness. We prove that optimizing worst-case fairness is NP-hard, whereas average fairness can be efficiently optimized via linear programming. Through case studies, we demonstrate that our proposed system ensures greater equity than existing methods, including those used in CVPR 2025, offering a more socially just approach to managing excessive submissions in AI conferences.","In recent years, AI conferences have received an excessive number of submissions. To alleviate the review workload, many major conferences have imposed submission limit policies, meaning that if an author has submitted more than a specific number of papers, their additional submissions will be rejected. In this work, we present a mathematical analysis of such submission-limit-based desk rejection policies, showing that these policies inevitably reject papers from innocent authors who comply with the limits while unfairly benefiting senior researchers with multiple submissions and disadvantaging junior researchers with fewer. We propose a novel fairness-aware desk rejection method, which prioritizes rejecting papers from senior authors to protect junior researchers. This helps advance equity and fairness in the AI community."
Poster,Diss-l-ECT: Dissecting Graph Data with Local Euler Characteristic Transforms,https://ICML.cc//virtual/2025/poster/45849,"Julius Von Rohrscheidt, Bastian Rieck","The Euler Characteristic Transform (ECT) is an efficiently computable geometrical-topological invariant that characterizes the global shape of data. In this paper, we introduce the local Euler Characteristic Transform ($\ell$-ECT), a novel extension of the ECT designed to enhance expressivity and interpretability in graph representation learning. Unlike traditional Graph Neural Networks (GNNs), which may lose critical local details through aggregation, the $\ell$-ECT provides a lossless representation of local neighborhoods. This approach addresses key limitations in GNNs by preserving nuanced local structures while maintaining global interpretability. Moreover, we construct a rotation-invariant metric based on $\ell$-ECTs for spatial alignment of data spaces. Our method demonstrates superior performance compared to standard GNNs on various benchmarking node classification tasks, while also offering theoretical guarantees of its effectiveness.","Graphs are used to represent complex systems like social networks, molecules, or traffic maps, where the relationships between entities matter. Most current methods for analyzing graphs use so-called *message-passing neural networks* that blend information from neighboring nodes. However, this blending can wash out important local details.Our work introduces a new tool, called the Local Euler Characteristic Transform ($\ell$-ECT), which captures the *shape* and *structure* around each point in the graph, giving every node its own ""fingerprint."" This fingerprint is lossless and mathematically robust, meaning it retains all relevant local information without distortion!Unlike typical graph neural network methods, the $\ell$-ECT works out-of-the-box with standard machine-learning tools and performs particularly well in settings where neighboring nodes are very different—a case where traditional methods often struggle. We also show that $\ell$-ECT fingerprints can help align and compare graphs in space, even if they’ve been rotated.By combining topology with geometry and mathematical insights with practical benefits, the $\ell$-ECT offers a new, interpretable way to learn from graph data."
Poster,Distillation of Discrete Diffusion through Dimensional Correlations,https://ICML.cc//virtual/2025/poster/44314,"Satoshi Hayakawa, Yuhta Takida, Masaaki Imaizumi, Hiromi Wakaki, Yuki Mitsufuji","Diffusion models have demonstrated exceptional performances in various fields of generative modeling, but suffer from slow sampling speed due to their iterative nature. While this issue is being addressed in continuous domains, discrete diffusion models face unique challenges, particularly in capturing dependencies between elements (e.g., pixel relationships in image, sequential dependencies in language) mainly due to the computational cost of processing high-dimensional joint distributions. In this paper, (i) we propose ""mixture"" models for discrete diffusion that are capable of treating dimensional correlations while remaining scalable, and (ii) we provide a set of loss functions for distilling the iterations of existing models. Two primary theoretical insights underpin our approach: First, conventional models with element-wise independence can well approximate the data distribution, but essentially require *many sampling steps*. Second, our loss functions enable the mixture models to distill such many-step conventional models into just a few steps by learning the dimensional correlations. Our experimental results show the effectiveness of the proposed method in distilling pretrained discrete diffusion models across image and language domains. The code used in the paper is available at https://github.com/sony/di4c.","Many modern machine learning systems generate images or text by slowly refining a noisy input over many small steps. However, this slow process makes it difficult to use these models in real-time applications. Moreover, many existing methods ignore the natural dependencies among parts of the data (for example, relationships between neighboring image pixels), which becomes a bigger issue when fewer sampling steps are used.We introduce a new method called Di4C that “distills” a well-trained but slow diffusion model into a faster version in discrete domains. By using a mixture model, Di4C captures the hidden relationships (or correlations) between different parts of the data, and a specially designed loss function teaches the fast model to closely mimic the original, multi-step process even when using just a few steps.This work allows for much quicker generation of high-quality images and language, making advanced machine learning tools more practical and accessible for real-world applications."
Poster,Distillation Scaling Laws,https://ICML.cc//virtual/2025/poster/46615,"Dan Busbridge, Amitis Shidani, Floris Weers, Jason Ramapuram, Etai Littwin, Russell Webb","We propose a distillation scaling law that estimates distilled model performance based on a compute budget and its allocation between the student and teacher. Our findings mitigate the risks associated with large-scale distillation by enabling compute-optimal allocation for both the teacher and student to maximize student performance. We provide compute-optimal distillation recipes for two key scenarios: when a teacher already exists, and when a teacher needs training. In settings involving many students or an existing teacher, distillation outperforms supervised learning  up to a compute level that scales predictably with student size. Conversely, if only one student is to be distilled and a teacher also requires training, supervised learning is generally preferable. Additionally, our large-scale study of distillation increases our understanding of the process and helps inform experimental design.","(1) Training powerful machine learning models is very expensive. A technique called ""distillation"" can create smaller, more efficient ""student"" models by having them learn from more capable ""teacher"" models. But figuring out how to best spend limited computing power to train both and get a good student is a major challenge, making large projects risky.(2) We developed a predictive formula – a ""distillation scaling law"" – that estimates how well the student will perform based on the total computing budget and how it's split between training the teacher and the student. This allowed us to create practical ""recipes"" for the best way to allocate these resources, whether a teacher model already exists or also needs to be built.(3) Our research helps take the guesswork out of distillation, reducing costs and risks. These recipes guide users to get the best possible student for their budget, showing that distillation can outperform traditional methods in specific situations, especially when an expert ""teacher"" model is already available or many ""students"" need training. Ultimately, this work improves our understanding of how machine learning models can efficiently learn from each-other."
Poster,Distilling the Knowledge in Data Pruning,https://ICML.cc//virtual/2025/poster/46023,"Emanuel Ben Baruch, Adam Botach, Igor Kviatkovsky, Manoj Aggarwal, Gerard Medioni","With the increasing size of datasets used for training neural networks, data pruning has gained traction in recent years. However, most current data pruning algorithms are limited in their ability to preserve accuracy compared to models trained on the full data, especially in high pruning regimes. In this paper we explore the application of data pruning while incorporating knowledge distillation (KD) when training on a pruned subset. That is, rather than relying solely on ground-truth labels, we also use the soft predictions from a teacher network pre-trained on the complete data. By integrating KD into training, we demonstrate significant improvement across datasets, pruning methods, and on all pruning fractions. We first establish a theoretical motivation for employing self-distillation to improve training on pruned data. Then, we empirically make a compelling and highly practical observation: using KD, simple random pruning is comparable or superior to sophisticated pruning methods across all pruning regimes. On ImageNet for example, we achieve superior accuracy despite training on a random subset of only 50% of the data. Additionally, we demonstrate a crucial connection between the pruning factor and the optimal knowledge distillation weight. This helps mitigate the impact of samples with noisy labels and low-quality images retained by typical pruning algorithms. Finally, we make an intriguing observation: when using lower pruning fractions, larger teachers lead to accuracy degradation, while surprisingly, employing teachers with a smaller capacity than the student's may improve results. Our code will be made available.","Modern artificial intelligence models are trained on massive datasets, but not all of that data is equally important. Researchers have been exploring ways to shrink these datasets — a process called data pruning — to make training faster and cheaper. The challenge is doing so without hurting the model’s performance.Our work shows that combining pruning with a technique called knowledge distillation can solve this problem. Knowledge distillation means that, instead of just learning from the original labels, the model also learns from the predictions made by a more experienced ""teacher"" model trained on the full dataset. This extra guidance helps the new model stay accurate even when trained on far less data.Surprisingly, we found that even randomly selected data can work as well as — or better than — carefully chosen examples, as long as knowledge distillation is used. We also discovered how to adjust this technique depending on how much data is removed, and even found cases where using a smaller teacher model worked better than a larger one. This makes AI training more efficient and practical for real-world use."
