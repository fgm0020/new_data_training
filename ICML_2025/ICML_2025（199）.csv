type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Non-asymptotic Error Bounds in $\mathcal{W}_2$-Distance with Sqrt(d) Dimension Dependence and First Order Convergence for Langevin Monte Carlo beyond Log-Concavity,https://ICML.cc//virtual/2025/poster/43718,"Bin Yang, Xiaojie Wang","Generating samples from a high dimensional probability distribution is a fundamental task with wide-ranging applications in the area of scientific computing, statistics and machine learning. This article revisits the popular Langevin Monte Carlo (LMC) sampling algorithms and provides a non-asymptotic error analysis in $\mathcal{W}_2$-distance in a non-convex setting. In particular, we prove an error bound $O(\sqrt{d} h)$, which guarantees a mixing time $ \tilde{O} (\sqrt{d} \epsilon^{-1})$ to achieve the accuracy tolerance $\epsilon$, under certain log-smooth conditions and the assumption that the target distribution satisfies a log-Sobolev inequality, as opposed to the strongly log-concave condition used in (Li et al., 2019; 2022). This bound matches the best one in the strongly log-concave case and improves upon the best-known convergence rates in non-convex settings. To prove it, we establish a new framework of uniform-in-time convergence for discretizations of SDEs. Distinct from (Li et al., 2019; 2022), we start from the finite-time mean-square fundamental convergence theorem, which combined with uniform-in-time moment bounds of LMC and the exponential ergodicity of SDEs in the non-convex setting gives the desired uniform-in-time convergence. Our framework also applies to the case when the gradient of the potential $U$ is non-globally Lipschitz with superlinear growth, for which modified LMC samplers are proposed and analyzed, with a non-asymptotic error bound in $\mathcal{W}_2$-distance obtained. Numerical experiments corroborate the theoretical analysis.","Sampling from complex and high-dimensional probability distributions is a fundamental task with wide-ranging applications in the area of scientific computing, statistics and machine learning.  Among classical sampling algorithms, Langevin Monte Carlo (LMC) stands out as a powerful and widely adopted approach. While the theoretical analysis of LMC is well-established for strongly convex target distributions, the error analysis in non-convex settings, more relevant in applications, is rather challenging and is far from being well-understood.To illustrate it, consider an analogy where the sampling process resembles an explorer navigating a rugged terrain. In a convex landscape, the explorer faces a single dominant peak with a straightforward ascent path. In contrast, non-convex landscapes exhibit multiple isolated peaks separated by deep valleys, where the explorer risks becoming trapped in local regions, potentially overlooking other critical areas of the distribution. This inherent complexity poses substantial challenges to guaranteeing both sampling accuracy and computational efficiency.In this work, we develop a novel theoretical framework to carry out a non-asymptotic error analysis in a non-convex setting. Our results show that the error bound of LMC is of order $O(\sqrt{d}h)$ in the non-convex setting of log-Sobolev inequality, which matchs the best one in the strongly convex case."
Poster,Non-Asymptotic Length Generalization,https://ICML.cc//virtual/2025/poster/45010,"Thomas Chen, Tengyu Ma, Zhiyuan Li","Length generalization is the ability of a learning algorithm to learn a hypothesis which generalizes to longer inputs than the inputs in the training set. In this paper, we provide provable guarantees of length generalization for various classes of functions in an idealized setting. First, we formalize the framework of non-asymptotic length generalization, which requires a computable upper bound for the minimum input length that guarantees length generalization, as a function of the complexity of ground-truth function under some given complexity measure. We refer to this minimum input length to length generalize as length complexity. We show the Minimum-Complexity Interpolator learning algorithm achieves optimal length complexity. We further show that whether a function class admits non-asymptotic length generalization is equivalent to the decidability of its language equivalence problem, which implies that there is no computable upper bound for the length complexity of Context-Free Grammars. On the positive side, we show that the length complexity of Deterministic Finite Automata is $2n - 2$ where $n$ is the number of states of the ground-truth automaton. Our main results are upper bounds of length complexity for a subset of a transformer-related function class called C-RASP (Yang & Chiang, 2024). We show that the length complexity of 1-layer C-RASP functions is  $O(T^2)$ when the ground-truth function has precision $T$, and that the length complexity of 2-layer C-RASP functions is $O(T^{O(K)})$ when the ground-truth function has precision $T$ and $K$ heads.","We study Length Generalization, an empirical phenomenon observed in the training of Large Language Models (LLMs). Length generalization is when a model, which is fitted to data of a certain length, can also perform well on data of a larger length. An example is when a model which was trained to multiply 20 digit by 20 digit numbers has also learned to multiply 100 digit by 100 digit numbers correctly. Length generalization is a non-trivial phenomenon, and it is useful for training models efficiently.While most Length Generalization studies so far have been empirical, our paper provides a theoretical perspective on Length Generalization. Our paper's aim is to contribute to a better understanding of when Length Generalization occurs or does not occur.Our theoretical paper derives, with proof, mathematical expressions for the smallest length of training data which can guarantee that length generalization occurs, in an idealized setting and using an idealized learning algorithm. We prove such length-generalization guarantees for different classes of ground-truth functions that one may want their model to learn. Our main results pertain to ground-truth functions of the form of a C-RASP program, which is a theoretical abstraction of a transformer, the architecture of LLMs. We derive mathematical expressions for the smallest length of training data which can guarantee length generalization, when learning a subclass of C-RASP."
Poster,Nonconvex Theory of $M$-estimators with Decomposable Regularizers,https://ICML.cc//virtual/2025/poster/45346,Weiwei Liu,"High-dimensional inference addresses scenarios where the dimension of the data approaches, or even surpasses, the sample size. In these settings, the regularized $M$-estimator is a common technique for inferring parameters. (Negahban et al.,2009) establish a unified framework for establishing convergence rates in the context of high-dimensional scaling, demonstrating that estimation errors are confined within a restricted set, and revealing fast convergence rates. The key assumption underlying their work is the convexity of the loss function. However, many loss functions in high-dimensional contexts are nonconvex. This leads to the question: if the loss function is nonconvex, do estimation errors still fall within a restricted set? If yes, can we recover convergence rates of the estimation error under nonconvex situations? This paper provides affirmative answers to these critical questions.","We analyze the convergence properties of nonconvex loss functions in high-dimensional settings. Our findings indicate that, under mild assumptions, the estimation error convergence rates for nonconvex loss functions match those of convex loss functions. This result bridges the gap between theoretical understanding and practical applications of nonconvex optimization methods in high-dimensional statistical estimation."
Poster,Nonlinearly Preconditioned Gradient Methods under Generalized Smoothness,https://ICML.cc//virtual/2025/poster/44248,"Konstantinos Oikonomidis, Jan Quan, Emanuel Laude, Panagiotis Patrinos","We analyze nonlinearly preconditioned gradient methods for solving smooth minimization problems. We introduce a generalized smoothness property, based on the notion of abstract convexity, that is broader than Lipschitz smoothness and provide sufficient first- and second-order conditions. Notably, our framework encapsulates algorithms associated with the gradient clipping method and brings out novel insights for the class of $(L_0,L_1)$-smooth functions that has received widespread interest recently, thus allowing us to extend beyond already established methods. We investigate the convergence of the proposed method in both the convex and nonconvex setting.","Gradient descent (GD) is one of the core methods for training models in modern machine learning. Nevertheless, especially in cases where the cost function is not ""smooth"" enough gradient descent can become inefficient, requiring very small steps in order to find a solution.Our research looks at a smarter way to apply GD, by reshaping the path taken by the algorithm using what's called nonlinear preconditioning. To do this, we consider a different way of thinking about smoothness that goes beyond the standard definitions used in the optimization literature. This allows us to cover a broader class of problems, including some that have recently attracted attention for being hard to optimize but important in practice. We also show how the proposed framework includes popular techniques like ""gradient clipping"" and other similar methods, and extends them to new scenarios."
Poster,Nonlinear transformers can perform inference-time feature learning,https://ICML.cc//virtual/2025/poster/43581,"Naoki Nishikawa, Yujin Song, Kazusato Oko, Denny Wu, Taiji Suzuki","Pretrained transformers have demonstrated the ability to implement various algorithms at inference time without parameter updates. While theoretical works have established this capability through constructions and approximation guarantees, the optimization and statistical efficiency aspects remain understudied. In this work, we investigate how transformers learn features in-context -- a key mechanism underlying their inference-time adaptivity. We focus on the in-context learning of single-index models $y=\sigma_*(\langle \\boldsymbol{x},\\boldsymbol{\beta}\rangle)$, which are low-dimensional nonlinear functions parameterized by feature vector $\\boldsymbol\beta$. We prove that transformers pretrained by gradient-based optimization can perform *inference-time feature learning*, i.e., extract information of the target features $\\boldsymbol{\beta}$ solely from test prompts (despite $\\boldsymbol{\beta}$ varying across different prompts), hence achieving an in-context statistical efficiency that surpasses any non-adaptive (fixed-basis) algorithms such as kernel methods. Moreover, we show that the inference-time sample complexity surpasses the Correlational Statistical Query (CSQ) lower bound, owing to nonlinear label transformations naturally induced by the Softmax self-attention mechanism.","Modern language models can learn new tasks at test time simply by observing a few examples—a phenomenon known as in-context learning. While it is well known that these models can perform a variety of algorithms in this manner, the mechanism by which gradient-based training gives rise to such test-time adaptability remains mysterious. Our research addresses this gap by examining a class of tasks involving the prediction of outcomes based on an unknown low-dimensional feature. We demonstrate that pretrained transformers can adaptively recover these features during inference, without any need for retraining. These findings provide new theoretical insights into the sample efficiency of transformers at test time, along with provable guarantees that explain how this capability emerges from training."
Poster,Nonparametric Identification of Latent Concepts,https://ICML.cc//virtual/2025/poster/44683,"Yujia Zheng, Shaoan Xie, Kun Zhang","We are born with the ability to learn concepts by comparing diverse observations. This helps us to understand the new world in a compositional manner and facilitates extrapolation, as objects naturally consist of multiple concepts. In this work, we argue that the cognitive mechanism of comparison, fundamental to human learning, is also vital for machines to recover true concepts underlying the data. This offers correctness guarantees for the field of concept learning, which, despite its impressive empirical successes, still lacks general theoretical support. Specifically, we aim to develop a theoretical framework for the identifiability of concepts with multiple classes of observations. We show that with sufficient diversity across classes, hidden concepts can be identified without assuming specific concept types, functional relations, or parametric generative models. Interestingly, even when conditions are not globally satisfied, we can still provide alternative guarantees for as many concepts as possible based on local comparisons, thereby extending the applicability of our theory to more flexible scenarios. Moreover, the hidden structure between classes and concepts can also be identified nonparametrically. We validate our theoretical results in both synthetic and real-world settings.","Imagine how we learn about the world as children. We see many different things – a fluffy cat, a furry dog, a feathered bird – and by comparing them, we start to understand underlying concepts like ""animal,"" ""furry,"" or ""has wings."" This ability to compare diverse examples helps us make sense of new things we've never encountered before.This paper argues that a similar process of comparison is crucial for computers to truly learn the basic concepts hidden in data. While current computer learning methods are powerful, they often lack a solid guarantee that they're learning the right concepts.Our work provides a new understanding of how computers can reliably identify these hidden concepts. We show that if a computer system is fed enough varied examples across different categories, it can pinpoint the fundamental concepts without needing to be told beforehand what types of concepts to look for or how they are connected.Even when the data is not perfectly diverse, our approach can still identify as many concepts as possible by making local comparisons. Furthermore, this method can also uncover the natural relationships between different categories of data and the concepts they represent. We've tested these ideas and confirmed they work, both in controlled experiments and with real-world datasets."
Poster,Nonparametric Modern Hopfield Models,https://ICML.cc//virtual/2025/poster/43568,"Jerry Yao-Chieh Hu, Bo-Yu Chen, Dennis Wu, Feng Ruan, Han Liu","We present a nonparametric interpretation for deep learning compatible modern Hopfield models and utilize this new perspective to debut efficient variants. Our key contribution stems from interpreting the memory storage and retrieval processes in modern Hopfield models as a nonparametric regression problem subject to a set of query-memory pairs.Interestingly,our framework not only recovers the known results from the original dense modern Hopfield model but also fills the void in the literature regarding efficient modern Hopfield models, by introducing *sparse-structured* modern Hopfield models with sub-quadratic complexity.We establish that this sparse model inherits the appealing theoretical properties of its dense analogue --- connection with transformer attention,  fixed point convergence and exponential memory capacity.Additionally, we showcase the versatility of our framework by constructing a family of modern Hopfield models as extensions, including linear, random masked, top-$K$ and positive random feature modern Hopfield models.Empirically, we validate our framework in both synthetic and realistic settings for memory retrieval and learning tasks.","Modern AI systems often depend on an “attention” step that looks at every piece of data all at once, a procedure that quickly becomes slow and costly as models grow. Our work recasts a powerful alternative, the modern Hopfield network, as a simple form of pattern-matching regression. This fresh view lets us build sparse-structured Hopfield memories that ignore the many data items that do not matter, slashing the usual quadratic compute cost to nearly linear while keeping three key benefits: (i) one-shot recall of stored patterns, (ii) strong resistance to noise, and (iii) the ability to hold an exponential number of memories. We back these claims with new mathematical error bounds and with experiments on images, time-series data and multiple-instance learning tasks. In practice, our layers can drop into today’s deep-learning code as a cheaper replacement for attention, delivering similar or better accuracy while using far less computation."
Poster,Nonparametric Teaching for Graph Property Learners,https://ICML.cc//virtual/2025/poster/43614,"Chen Zhang, Weixin Bu, Zeyi Ren, Zhengwu Liu, Yik-Chung WU, Ngai Wong","Inferring properties of graph-structured data, *e.g.*, the solubility of molecules, essentially involves learning the implicit mapping from graphs to their properties. This learning process is often costly for graph property learners like Graph Convolutional Networks (GCNs). To address this, we propose a paradigm called Graph Nonparametric Teaching (GraNT) that reinterprets the learning process through a novel nonparametric teaching perspective. Specifically, the latter offers a theoretical framework for teaching implicitly defined (*i.e.*, nonparametric) mappings via example selection. Such an implicit mapping is realized by a dense set of graph-property pairs, with the GraNT teacher selecting a subset of them to promote faster convergence in GCN training. By analytically examining the impact of graph structure on parameter-based gradient descent during training, and recasting the evolution of GCNs—shaped by parameter updates—through functional gradient descent in nonparametric teaching, we show *for the first time* that teaching graph property learners (*i.e.*, GCNs) is consistent with teaching structure-aware nonparametric learners. These new findings readily commit GraNT to enhancing learning efficiency of the graph property learner, showing significant reductions in training time for graph-level regression (-36.62\%), graph-level classification (-38.19\%), node-level regression (-30.97\%) and node-level classification (-47.30\%), all while maintaining its generalization performance.","Graphs, like molecular structures or social networks, hold valuable information, but extracting useful insights from these complex structures can be time-consuming and computationally expensive. Current methods, such as Graph Convolutional Networks (GCNs), require extensive training, which slows down progress in fields like drug discovery or network analysis.We developed a novel approach called Graph Neural Teaching (GraNT), which reimagines the learning process. Instead of training GCNs on all available data, GraNT strategically selects the most informative examples to teach the model faster and more effectively. By analyzing how graph structures influence training and leveraging a theoretical framework called nonparametric teaching, GraNT optimizes the learning process without sacrificing accuracy.GraNT significantly reduces training time—up to 47% in some tasks—while maintaining high performance. This means faster and more efficient predictions for real-world problems, from identifying drug properties to detecting patterns in social networks. By making graph-based learning more efficient, GraNT opens the door to broader applications and quicker advancements in science and technology."
Poster,Non-stationary Diffusion For Probabilistic Time Series Forecasting,https://ICML.cc//virtual/2025/poster/44783,"Weiwei Ye, Zhuopeng Xu, Ning Gui","Due to the dynamics of underlying physics and external influences, the uncertainty of time series often varies over time. However, existing Denoising Diffusion Probabilistic Models (DDPMs) often fail to capture this non-stationary nature, constrained by their constant variance assumption from the additive noise model (ANM). In this paper, we innovatively utilize the Location-Scale Noise Model (LSNM) to relax the fixed uncertainty assumption of ANM. A diffusion-based probabilistic forecasting framework, termed Non-stationary Diffusion (NsDiff), is designed based on LSNM that is capable of modeling the changing pattern of uncertainty. Specifically, NsDiff combines a denoising diffusion-based conditional generative model with a pre-trained conditional mean and variance estimator, enabling adaptive endpoint distribution modeling. Furthermore, we propose an uncertainty-aware noise schedule, which dynamically adjusts the noise levels to accurately reflect the data uncertainty at each step and integrates the time-varying variances into the diffusion process. Extensive experiments conducted on nine real-world and synthetic datasets demonstrate the superior performance of NsDiff compared to existing approaches. Code is available at https://github.com/wwy155/NsDiff.","Current prediction models treat uncertainty as constant, but real-world uncertainty fluctuates dramatically, making these predictions unreliable precisely when we need them most.We developed NsDiff, the first diffusion-based framework that learns how uncertainty changes over time. Unlike standard models, it automatically adjusts its predictions by analyzing patterns in historical data. Our key innovation enables the prediction distribution to dynamically adapt to forecasted features.In experiments across critical applications, from weather forecasting to patient hospitalization estimates, NsDiff consistently provided more accurate and robust uncertainty estimates than existing models, demonstrating wide potential for real-world applications."
Poster,Non-stationary Online Learning for Curved Losses: Improved Dynamic Regret via Mixability,https://ICML.cc//virtual/2025/poster/45165,"Yu-Jie Zhang, Peng Zhao, Masashi Sugiyama","Non-stationary online learning has drawn much attention in recent years. Despite considerable progress, dynamic regret minimization has primarily focused on convex functions, leaving the functions with stronger curvature (e.g., squared or logistic loss) underexplored. In this work, we address this gap by showing that the regret can be substantially improved by leveraging the concept of mixability, a property that generalizes exp-concavity to effectively capture loss curvature. Let $d$ denote the dimensionality and $P_T$ the path length of comparators that reflects the environmental non-stationarity. We demonstrate that an exponential-weight method with fixed-share updates achieves an $\mathcal{O}(d T^{1/3} P_T^{2/3} \log T)$ dynamic regret for mixable losses, improving upon the best-known $\mathcal{O}(d^{10/3} T^{1/3} P_T^{2/3} \log T)$ result (Baby & Wang, 2021) in $d$. More importantly, this improvement arises from a simple yet powerful analytical framework that exploits the mixability, which avoids the Karush–Kuhn–Tucker-based analysis required by existing work.","In this paper, we study how to learn from and make predictions with streaming data in non-stationary environments, where data arrive sequentially and their patterns can change over time. Our goal is to maintain a model that consistently makes accurate predictions throughout the entire sequence. This work is primarily theoretical, focusing on developing methods with strong mathematical guarantees on their performance. Specifically, we measure the performance of our methods using dynamic regret, where lower values indicate better adaptability to changing environments. Our main result is that by leveraging the curvature of the loss function, one can achieve better theoretical guarantees than methods that do not exploit this property. Similar results were achieved by previous work, but our method further improves the theoretical guarantees while using a simple yet effective analytical framework that avoids the complex analysis employed in earlier work."
