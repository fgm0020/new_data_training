type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Graph4MM: Weaving Multimodal Learning with Structural Information,https://ICML.cc//virtual/2025/poster/45904,"Xuying Ning, Dongqi Fu, Tianxin Wei, Wujiang Xu, Jingrui He","Real-world multimodal data usually exhibit complex structural relationships beyond traditional one-to-one mappings like image-caption pairs. Entities across modalities interact in intricate ways, with images and text forming diverse interconnections through contextual dependencies and co-references. Graphs provide powerful structural information for modeling intra-modal and inter-modal relationships. However, previous works fail to distinguish multi-hop neighbors and treat the graph as a standalone modality, which fragments the overall understanding. This limitation presents two key challenges in multimodal learning: (1) integrating structural information from multi-hop neighbors into foundational models, and (2) fusing modality-specific information in a principled manner. To address these challenges, we revisit the role of graphs in multimodal learning within the era of foundation models and propose Graph4MM, a graph-based multimodal learning framework. To be specific, we introduce Hop-Diffused Attention, which integrates multi-hop structural information into self-attention through causal masking and hop diffusion. Furthermore, we design MM-QFormer, a multi-mapping querying transformer for cross-modal fusion. Through theoretical and empirical analysis, we show that leveraging structures to integrate both intra- and inter-modal interactions improves multimodal understanding beyond treating them as a standalone modality. Experiments on both generative and discriminative tasks show that Graph4MM outperforms larger VLMs, LLMs, and multimodal graph baselines, achieving a 6.93% average improvement.","We often teach AI to understand images or text separately, or to match them in simple one-to-one ways, like pairing a product photo with its caption. But real-world content — like webpages, research papers, or shopping platforms — is much more complex. Images and texts are connected in many-to-many ways, across pages and sections.We built a new system called Graph4MM that uses graphs to help AI understand these complex structures. Each piece of content (an image, a paragraph, or a caption) becomes a node, and we connect them based on their relationships. Then, we introduce a technique called Hop-Diffused Attention that teaches the AI to reason across not just direct links, but also multi-step connections.This helps AI better understand and generate information from rich, structured content. On tasks like summarizing web content or classifying products without prior labels, Graph4MM outperforms even much larger models. Our work shows that bringing structure into foundation models can make them perform better."
Poster,Graph Adaptive Autoregressive Moving Average Models,https://ICML.cc//virtual/2025/poster/45132,"Moshe Eliasof, Alessio Gravina, Andrea Ceni, Claudio Gallicchio, Davide Bacciu, Carola-Bibiane Schönlieb","Graph State Space Models (SSMs) have recently been introduced to enhance Graph Neural Networks (GNNs) in modeling long-range interactions. Despite their success, existing methods either compromise on permutation equivariance or limit their focus to pairwise interactions rather than sequences. Building on the connection between Autoregressive Moving Average (ARMA)  and SSM, in this paper, we introduce GRAMA, a Graph Adaptive method based on a learnable ARMA framework that addresses these limitations. By transforming from static to sequential graph data, GRAMA leverages the strengths of the ARMA framework, while preserving permutation equivariance. Moreover, GRAMA incorporates a selective attention mechanism for dynamic learning of ARMA coefficients, enabling efficient and flexible long-range information propagation. We also establish theoretical connections between GRAMA and Selective SSMs, providing insights into its ability to capture long-range dependencies. Experiments on 26 synthetic and real-world datasets demonstrate that GRAMA consistently outperforms backbone models and performs competitively with state-of-the-art methods.","Graphs are used to represent complex systems like social networks, molecules, or traffic patterns, by capturing interactions between different nodes within the graph. However, many machine learning models, especially graph neural networks (GNNs), struggle to capture long-range interactions, where distant parts of the graph need to influence each other. This limitation, known as oversquashing, occurs when information becomes bottlenecked as it moves across the graph, preventing the model from effectively learning global patterns.Our research introduces GRAMA, a new method that reimagines how graphs are processed within sequential frameworks such as ARMA and state-space models. Unlike earlier approaches that flatten a graph into a sequence, GRAMA constructs a sequence of graphs, enabling the model to capture long-range interactions while preserving permutation equivariance -- a principle that ensures the output remains consistent regardless of how the graph’s nodes are ordered. This is essential for respecting the symmetry and structure of graph data. Inspired by signal processing methods, GRAMA selectively integrates past and current graph states and residuals, functioning like a memory mechanism to retain and propagate information more effectively across the graph.We also provide a theoretical analysis showing how the framework offered by GRAMA mitigates oversquashing, improving the ability to capture long-range dependencies. In our empirical experiments, across 26 diverse datasets, GRAMA consistently outperforms standard GNNs while remaining efficient and robust."
Poster,Graph-Assisted Stitching for Offline Hierarchical Reinforcement Learning,https://ICML.cc//virtual/2025/poster/46345,"Seungho Baek, Taegeon Park, Jongchan Park, Seungjun Oh, Yusung Kim","Existing offline hierarchical reinforcement learning methods rely on high-level policy learning to generate subgoal sequences. However, their efficiency degrades as task horizons increase, and they lack effective strategies for stitching useful state transitions across different trajectories. We propose Graph-Assisted Stitching (GAS), a novel framework that formulates subgoal selection as a graph search problem rather than learning an explicit high-level policy. By embedding states into a Temporal Distance Representation (TDR) space, GAS clusters semantically similar states from different trajectories into unified graph nodes, enabling efficient transition stitching. A shortest-path algorithm is then applied to select subgoal sequences within the graph, while a low-level policy learns to reach the subgoals. To improve graph quality, we introduce the Temporal Efficiency (TE) metric, which filters out noisy or inefficient transition states, significantly enhancing task performance. GAS outperforms prior offline HRL methods across locomotion, navigation, and manipulation tasks. Notably, in the most stitching-critical task, it achieves a score of 88.3, dramatically surpassing the previous state-of-the-art score of 1.0. Our source code is available at: https://github.com/qortmdgh4141/GAS.","To accomplish complex tasks, AI robots benefit from breaking down long-horizon goals into smaller, manageable subgoals and learning how to act at each step. This approach is known as Hierarchical Reinforcement Learning (HRL), where a high-level policy learns to generate subgoals and a low-level policy learns to reach them through appropriate actions.However, existing HRL methods typically learn within individual trajectories, which limits their ability to generalize when only fragmented or subtask-level trajectories are available. These methods often struggle to stitch together knowledge across different experiences, resulting in poor performance on long-horizon tasks.To address this challenge, we propose an unsupervised graph construction method that learns potential connectivity between states across different trajectories using a temporal distance representation. The high-level planner builds a path toward long-horizon goals over this graph, while the low-level policy learns to navigate between connected nodes. Our method achieves superior performance compared to existing offline HRL approaches across a variety of tasks, demonstrating its effectiveness."
Poster,Graph Attention is Not Always Beneficial: A Theoretical Analysis of Graph Attention Mechanisms via Contextual Stochastic Block Models,https://ICML.cc//virtual/2025/poster/46423,"Zhongtian Ma, Qiaosheng Zhang, Bocheng Zhou, Yexin Zhang, Shuyue Hu, Zhen Wang","Despite the growing popularity of graph attention mechanisms, their theoretical understanding remains limited. This paper aims to explore the conditions under which these mechanisms are effective in node classification tasks through the lens of Contextual Stochastic Block Models (CSBMs). Our theoretical analysis reveals that incorporating graph attention mechanisms is *not universally beneficial*. Specifically, by appropriately defining *structure noise* and *feature noise* in graphs, we show that graph attention mechanisms can enhance classification performance when structure noise exceeds feature noise. Conversely, when feature noise predominates, simpler graph convolution operations are more effective. Furthermore, we examine the over-smoothing phenomenon and show that, in the high signal-to-noise ratio (SNR) regime, graph convolutional networks suffer from over-smoothing, whereas graph attention mechanisms can effectively resolve this issue. Building on these insights, we propose a novel multi-layer Graph Attention Network (GAT) architecture that significantly outperforms single-layer GATs in achieving *perfect node classification* in CSBMs, relaxing the SNR requirement from $\omega(\sqrt{\log n})$ to $\omega(\sqrt{\log n} / \sqrt[3]{n})$. To our knowledge, this is the first study to delineate the conditions for perfect node classification using multi-layer GATs. Our theoretical contributions are corroborated by extensive experiments on both synthetic and real-world datasets, highlighting the practical implications of our findings.","(1) As a core component of GNNs, is the graph attention mechanism always effective, or under what conditions does it work? (2) We conduct a theoretical analysis using the CSBM and define two types of noise—feature noise and structure noise. Our results show that graph attention is not always effective and only provides benefits when structure noise dominates. Furthermore, we establish the first upper bound for exact recovery using multi-layer GATs. (3) Our results offer valuable guidance for the future design and application of graph attention mechanisms."
Poster,Graph-Based Algorithms for Diverse Similarity Search,https://ICML.cc//virtual/2025/poster/44618,"Piyush Anand, Piotr Indyk, Ravishankar Krishnaswamy, Sepideh Mahabadi, Vikas Raykar, Kirankumar Shiragur, Haike Xu","Nearest neighbor search is a fundamental data structure problem with many applications. Although the main objective of the data structure is to quickly report data points that are closest to a given query, it has long been noted that without additional constraints the reported answers can be redundant and/or duplicative. This issue is typically addressed in two stages: in the first stage, the algorithm retrieves a (large) number $r$ of points closest to the query, while in the second stage, the $r$ points are post-processed and a small subset is selected to maximize the desired diversity objective. Although popular, this method suffers from a fundamental efficiency bottleneck, as the set of points retrieved in the first stage often needs to be much larger than the final output. In this paper we present provably efficient algorithms for approximate nearest neighbor search with diversity constraints that bypass this two stage process. Our algorithms are based on popular graph-based methods, which allows us to ``piggy-back'' on the existing efficient implementations.  These are the first graph-based algorithms for nearest neighbor search with diversity constraints.   For data sets with low intrinsic dimension, our data structures report a diverse set of $k$ points approximately closest to the query, in time that only depends on $k$ and $\log \Delta$, where $\Delta$ is the ratio of the diameter to the closest pair distance in the data set. This bound is qualitatively similar to the best known bounds for standard (non-diverse) graph-based algorithms. Our experiments show that the search time of our algorithms is substantially lower than that using the standard two-stage approach.","Nearest neighbor search (NNS) is a fundamental problem to model the search task. Its goal is to quickly find data points (like images, documents, or user profiles) that are most similar to a given query point, and is widely used in applications like search, recommendations, and machine learning. A known issue with traditional NNS is that the results it returns can be very redundant — the top matches might all be nearly identical. To fix this, most systems use a two-stage approach:In the first stage, the algorithm retrieves a large number (say, hundreds or thousands) of the nearest points to the query, while in the second stage, the algorithm post-processes that list to select a smaller, more diverse subset. While effective, this method can be inefficient because it processes many more points than it actually needs to return.In this paper, we present provably efficient algorithms for approximate nearest neighbor search with diversity constraints that bypass this two-stage process. Our algorithms are based on popular graph-based methods, which allows us to ""piggy-back"" on existing efficient implementations. These are the first graph-based algorithms for nearest neighbor search with diversity constraints. The theoretical guarantees of our algorithm are qualitatively similar to the best known bounds for standard (non-diverse) graph-based algorithms. We further run experiments showing that the search time of our algorithms is substantially lower than that of using the standard two-stage approach."
Poster,GraphCL: Graph-based Clustering for Semi-Supervised Medical Image Segmentation,https://ICML.cc//virtual/2025/poster/45355,"Mengzhu Wang, houcheng su, Jiao Li, Chuan Li, Nan Yin, Li Shen, Jingcai Guo","Semi-supervised learning (SSL) has made notable advancements in medical image segmentation (MIS), particularly in scenarios with limited labeled data and significantly enhancing data utilization efficiency. Previous methods primarily focus on complex training strategies to utilize unlabeled data but neglect the importance of graph structural information. Different from existing methods, we propose a graph-based clustering for semi-supervised medical image segmentation (GraphCL) by jointly modeling graph data structure in a unified deep model. The proposed GraphCL model enjoys several advantages. Firstly, to the best of our knowledge, this is the first work to model the data structure information for semi-supervised medical image segmentation (SSMIS). Secondly, to get the clustered features across different graphs, we integrate both pairwise affinities between local image features and raw features as inputs. Extensive experimental results on three standard benchmarks show that the proposed GraphCL algorithm outperforms state-of-the-art semi-supervised medical image segmentation methods.","Semi-supervised learning (SSL) has made notable advancements in medical image segmentation (MIS), particularly in scenarios with limited labeled data and significantly enhancing data utilization efficiency. Previous methods primarily focus on complex training strategies to utilize unlabeled data but neglect the importance of graph structural information. Different from existing methods, we propose a graph-based clustering for semi-supervised medical image segmentation (GraphCL) by jointly modeling graph data structure in a unified deep model. The proposed GraphCL model enjoys several advantages. Firstly, to the best of our knowledge, this is the first work to model the data structure information for semi-supervised medical image segmentation (SSMIS). Secondly, to get the clustered features across different graphs, we integrate both pairwise affinities between local image features and raw features as inputs. Extensive experimental results on three standard benchmarks show that the proposed GraphCL algorithm outperforms state-of-the-art semi-supervised medical image segmentation methods."
Poster,Graph-constrained Reasoning: Faithful Reasoning on Knowledge Graphs with Large Language Models,https://ICML.cc//virtual/2025/poster/45868,"Linhao Luo, Zicheng Zhao, Reza Haffari, Yuan-Fang Li, Chen Gong, Shirui Pan","Large language models (LLMs) have demonstrated impressive reasoning abilities, but they still struggle with faithful reasoning due to knowledge gaps and hallucinations. To address these issues, knowledge graphs (KGs) have been utilized to enhance LLM reasoning through their structured knowledge. However, existing KG-enhanced methods, either retrieval-based or agent-based, encounter difficulties in accurately retrieving knowledge and efficiently traversing KGs at scale. In this work, we introduce graph-constrained reasoning (GCR), a novel framework that bridges structured knowledge in KGs with unstructured reasoning in LLMs. To eliminate hallucinations, GCR ensures faithful KG-grounded reasoning by integrating KG structure into the LLM decoding process through KG-Trie, a trie-based index that encodes KG reasoning paths. KG-Trie constrains the decoding process, allowing LLMs to directly reason on graphs and generate faithful reasoning paths grounded in KGs. Additionally, GCR leverages a lightweight KG-specialized LLM for graph-constrained reasoning alongside a powerful general LLM for inductive reasoning over multiple reasoning paths, resulting in accurate reasoning with zero reasoning hallucination. Extensive experiments on several KGQA benchmarks demonstrate that GCR achieves state-of-the-art performance and exhibits strong zero-shot generalizability to unseen KGs without additional training.","Large language models (LLMs), like ChatGPT, are good at solving complex problems with reasoning. However, they sometimes “hallucinate” — meaning they make up facts — especially when they don’t have the right knowledge at hand. To help fix this, researchers have tried connecting these models with knowledge graphs — structured databases that store facts as networks of concepts and their relationships.But most existing approaches either struggle to find the right facts or get stuck navigating these complex graphs efficiently.In this work, we propose a new method called graph-constrained reasoning (GCR) that tightly integrates LLMs with knowledge graphs. We use a special technique called KG-Trie to guide the LLM so it only follows valid paths in the knowledge graph when answering a question. This prevents the model from making things up and helps it reason more accurately.Our system combines two models — one specialized in graph reasoning and another in general language — to achieve state-of-the-art performance, even on unfamiliar domains, without extra training. This brings us closer to trustworthy AI."
Poster,Graph Diffusion for Robust Multi-Agent Coordination,https://ICML.cc//virtual/2025/poster/45189,"Xianghua Zeng, Hang Su, Zhengyi Wang, Zhiyuan LIN","Offline multi-agent reinforcement learning (MARL) struggles to estimate out-of-distribution states and actions due to the absence of real-time environmental feedback. While diffusion models show promise in addressing these challenges, their application primarily focuses on independently diffusing the historical trajectories of individual agents, neglecting crucial multi-agent coordination dynamics and reducing policy robustness in dynamic environments. In this paper, we propose MCGD, a novel Multi-agent Coordination framework based on Graph Diffusion models to improve the effectiveness and robustness of collaborative policies. Specifically, we begin by constructing a sparse coordination graph that includes continuous node attributes and discrete edge attributes to effectively identify the underlying dynamics of multi-agent interactions. Next, we derive transition probabilities between edge categories and present adaptive categorical diffusion to capture the structure diversity of multi-agent coordination. Leveraging this coordination structure, we define neighbor-dependent forward noise and develop anisotropic diffusion to enhance the action diversity of each agent. Extensive experiments across various multi-agent environments demonstrate that MCGD significantly outperforms existing state-of-the-art baselines in coordination performance and policy robustness in dynamic environments.","Training multiple agents to cooperate effectively in complex environments—known as multi-agent reinforcement learning (MARL)—is difficult when there is no real-time feedback from the environment. Traditional methods often fail when faced with unfamiliar situations, partly because they ignore the essential coordination between agents. Recent diffusion models have shown potential but mostly focus on each agent individually, missing the critical group dynamics.In our work, we introduce MCGD, a novel framework that uses graph diffusion models to better capture and enhance multi-agent coordination. We first represent the agents and their interactions in a coordination graph that accounts for both the agents’ continuous states and the discrete relationships between them. We then propose a new method called adaptive categorical diffusion to understand the changing interaction patterns among agents. Additionally, we develop an anisotropic diffusion process to improve the variety and robustness of each agent’s actions.Our extensive experiments show that MCGD leads to superior coordination and more reliable decision-making across multiple test environments, outperforming current state-of-the-art methods."
Poster,Graph Generative Pre-trained Transformer,https://ICML.cc//virtual/2025/poster/45870,"Xiaohui Chen, Yinkai Wang, JIAXING HE, Yuanqi Du, Soha Hassoun, Xiaolin Xu, Liping Liu","Graph generation is a critical task in numerous domains, including molecular design and social network analysis, due to its ability to model complex relationships and structured data. While most modern graph generative models utilize adjacency matrix representations, this work revisits an alternative approach that represents graphs as sequences of node set and edge set. We advocate for this approach due to its efficient encoding of graphs and propose a novel representation. Based on this representation, we introduce the Graph Generative Pre-trained Transformer (G2PT), an auto-regressive model that learns graph structures via next-token prediction. To further exploit G2PT's capabilities as a general-purpose foundation model, we explore fine-tuning strategies for two downstream applications: goal-oriented generation and graph property prediction. We conduct extensive experiments across multiple datasets. Results indicate that G2PT achieves superior generative performance on both generic graph and molecule datasets. Furthermore, G2PT exhibits strong adaptability and versatility in downstream tasks from molecular design to property prediction.","This paper revisits how to build auto-regressive models from generative pre-trained transformers for graph generation- The key is tokenization. Specifically, we tokenize graphs into node and edge sets. This tokenization differs significantly from commonly used adjacency matrix representation, which greatly saves comp. and memory costs by exploiting sparsity of graphs. Building on this tokenization, we can adopt all existing recipes for generative pre-trained transformers in LLMs.We further expand the capability of G2PT to goal-oriented generation via post-training techniques: (1) rejection sampling fine-tuning and (2) Reinforcement learning.We also validate the quality of the learned embedding on graph property prediction problems and achieve better or on-par performance with other graph contrastive and generative pre-training methods. In the end, we analyze the scaling behavior of G2PT and find on molecular graph generation, it scales very well with the data and model size and saturates when getting close to 100% validity."
Poster,GraphGPT: Generative Pre-trained Graph Eulerian Transformer,https://ICML.cc//virtual/2025/poster/46483,"Qifang Zhao, Weidong Ren, Tianyu Li, Hong Liu, Xingsheng He, Xiaoxiao Xu","We introduce *GraphGPT*, a novel self-supervised *generative pre-trained* model for graph learning based on the *Graph Eulerian Transformer* (**GET**). First, we propose **GET**, which combines a standard transformer encoder or decoder architecture with an innovative graph-to-sequence transformation method. This method converts graphs or sampled subgraphs into sequences of tokens representing nodes, edges, and attributes in a reversible manner using Eulerian paths. We pre-train **GET** using either of the two self-supervised tasks: next-token prediction (NTP) and scheduled masked-token prediction (SMTP). The pre-trained model is then fine-tuned for downstream tasks such as graph-, edge-, and node-level prediction. Despite its simplicity, GraphGPT achieves performance comparable to or surpassing state-of-the-art methods on multiple large-scale Open Graph Benchmark (OGB) datasets. It demonstrates exceptional results on the molecular property prediction dataset PCQM4Mv2 and the protein-protein interaction dataset ogbl-ppa. Notably, generative pre-training enables scaling GraphGPT to 2 billion parameters while maintaining performance gains — a breakthrough that overcomes the scalability limitations of traditional Graph Neural Networks (GNNs) and prior graph transformers (GTs). To advance research in graph foundation models and facilitate scientific discovery in chemistry, materials science, and related fields, we have released thesource code (https://github.com/alibaba/graph-gpt) and model checkpoints (https://www.modelscope.cn/organization/Alibaba-DT).","Analyzing complex networks like molecular structures or social connections is challenging for AI. Traditional methods struggle with large-scale data, limiting advancements in related research areas like material and drug discovery.Inspired by language models that learn from vast text data, we developed GraphGPT. It converts graphs into sequences using a novel method that captures all connections without losing information. This allows the model to learn patterns through self-supervised tasks, eliminating the need for manual adjustments.GraphGPT excels at predicting molecular properties and protein interactions, outperforming existing methods. It scales to billions of parameters, enabling analysis of massive networks like those in chemistry and biology. By releasing our code and models, we aim to accelerate scientific discoveries in medicine, materials science, and beyond, empowering researchers to tackle real-world challenges more effectively."
