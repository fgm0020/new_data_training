type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,On the Tension between Byzantine Robustness and No-Attack Accuracy in Distributed Learning,https://ICML.cc//virtual/2025/poster/43477,"Yi-Rui Yang, Chang-Wei Shi, Wu-Jun Li","Byzantine-robust distributed learning (BRDL), which refers to distributed learning that can work with potential faulty or malicious workers (also known as Byzantine workers), has recently attracted much research attention. Robust aggregators are widely used in existing BRDL methods to obtain robustness against Byzantine workers. However, Byzantine workers do not always exist in applications. As far as we know, there is almost no existing work theoretically investigating the effect of using robust aggregators when there are no Byzantine workers. To bridge this knowledge gap, we theoretically analyze the aggregation error for robust aggregators when there are no Byzantine workers. Specifically, we show that the worst-case aggregation error without Byzantine workers increases with the increase of the number of Byzantine workers that a robust aggregator can tolerate. The theoretical result reveals the tension between Byzantine robustness and no-attack accuracy, which refers to accuracy without faulty workers and malicious workers in this paper. Furthermore, we provide lower bounds for the convergence rate of gradient descent with robust aggregators for non-convex objective functions and objective functions that satisfy the Polyak-Lojasiewicz (PL) condition, respectively. We also prove the tightness of the lower bounds. The lower bounds for convergence rate reveal similar tension between Byzantine robustness and no-attack accuracy. Empirical results further support our theoretical findings.","Byzantine-robust distributed learning (BRDL), which refers to distributed learning with potential faulty workers (also known as Byzantine workers), has recently attracted much research attention. Robust aggregators are widely used in existing BRDL methods to obtain robustness against Byzantine workers. However, Byzantine workers do not always exist in applications. As far as we know, there is almost no existing work theoretically investigating the effect of using robust aggregators when there is no Byzantine worker. In view of this challenge, we theoretically reveal the tension between Byzantine robustness and no-attack accuracy. Specifically, we prove that to obtain robustness against more Byzantine workers, the worst-case performance in no-attack cases is inevitably degraded."
Poster,On the Training Convergence of Transformers for In-Context Classification of Gaussian Mixtures,https://ICML.cc//virtual/2025/poster/44358,"Wei Shen, Ruida Zhou, Jing Yang, Cong Shen","Although transformers have demonstrated impressive capabilities for in-context learning (ICL) in practice, theoretical understanding of the underlying mechanism that allows transformers to perform ICL is still in its infancy. This work aims to theoretically study the training dynamics of transformers for in-context classification tasks. We demonstrate that, for in-context classification of Gaussian mixtures under certain assumptions, a single-layer transformer trained via gradient descent converges to a globally optimal model at a linear rate. We further quantify the impact of the training and testing prompt lengths on the ICL inference error of the trained transformer. We show that when the lengths of training and testing prompts are sufficiently large, the prediction of the trained transformer approaches the ground truth distribution of the labels. Experimental results corroborate the theoretical findings.","Transformers are powerful models known for their ability to learn new tasks by observing just a few examples and without updating their parameters—a capability known as in-context learning (ICL). While this ability performs well in practice,  theoretical understanding of its underlying mechanisms is still in its infancy. This study takes a step toward addressing that gap by analyzing how transformers are trained to acquire the ability to perform in-context classification of different groups of data (Gaussian mixtures). We show that, under certain conditions, a simple one-layer transformer can successfully learn such tasks. We also provide a theoretical explanation of how using longer examples during both training and testing can help the model make more accurate predictions."
Poster,On the Vulnerability of Applying Retrieval-Augmented Generation within Knowledge-Intensive Application Domains,https://ICML.cc//virtual/2025/poster/45226,"Xun Xian, Ganghua Wang, Xuan Bi, Rui Zhang, Jayanth Srinivasa, Ashish Kundu, Charles Fleming, Mingyi Hong, Jie Ding","Retrieval-Augmented Generation (RAG) has been empirically shown to enhance the performance of large language models (LLMs) in knowledge-intensive domains such as healthcare, finance, and legal contexts. Given a query, RAG retrieves relevant documents from a corpus and integrates them into the LLMs’ generation process. In this study, we investigate the adversarial robustness of RAG, focusing specifically on examining the retrieval system. First, across 225 different setup combinations of corpus, retriever, query, and targeted information, we show that retrieval systems are vulnerable to universal poisoning attacks in medical Q&A. In such attacks, adversaries generate poisoned documents containing a broad spectrum of targeted information, such as personally identifiable information. When these poisoned documents are inserted into a corpus, they can be accurately retrieved by any users, as long as attacker-specified queries are used. To understand this vulnerability, we discovered that the deviation from the query’s embedding to that of the poisoned document tends to follow a pattern in which the high similarity between the poisoned document and the query is retained, thereby enabling precise retrieval. Based on these findings, we develop a new detection-based defense to ensure the safe use of RAG. Through extensive experiments spanning various Q&A domains, we observed that our proposed method consistently achieves excellent detection rates in nearly all cases.","Retrieval-Augmented Generation has been shown to enhance the performance of large language models in knowledge-intensive domains such as healthcare, finance, and legal contexts. Given a query, it retrieves relevant documents from a database and integrates them into the generation process. In this study, we investigate the security robustness of these systems, focusing specifically on examining the retrieval system. First, across 225 different setup combinations, we show that retrieval systems are vulnerable to universal poisoning attacks in medical Q&A. In such attacks, adversaries generate poisoned documents containing targeted information, such as personal data. When these poisoned documents are inserted into a database, they can be accurately retrieved by any users, as long as attacker-specified queries are used. To understand this vulnerability, we discovered that the high similarity between the poisoned document and the query is retained, thereby enabling precise retrieval. Based on these findings, we develop a new detection-based defense to ensure safe use. Through extensive experiments spanning various Q&A domains, we observed that our proposed method consistently achieves excellent detection rates in nearly all cases."
Poster,On Understanding Attention-Based In-Context Learning for Categorical Data,https://ICML.cc//virtual/2025/poster/46334,"Aaron Wang, William Convertino, Xiang Cheng, Ricardo Henao, Lawrence Carin","In-context learning based on attention models is examined for data with categorical outcomes, with inference in such models viewed from the perspective of functional gradient descent (GD). We develop a network composed of attention blocks, with each block employing a self-attention layer followed by a cross-attention layer, with associated skip connections. This model can exactly perform multi-step functional GD inference for in-context inference with categorical observations. We perform a theoretical analysis of this setup, generalizing many prior assumptions in this line of work, including the class of attention mechanisms for which it is appropriate. We demonstrate the framework empirically on synthetic data, image classification and language generation.","The Transformer is widely used as a generative model in virtually all language models being deployed in practice today. In spite of the success of such models, little is known about how they work. This paper has sought to provide insight on the mechanisms by which Transformers respond and adapt to the prompt that is provided as input. A key advance of this paper concerns the form of observed data, which is categorical. By this we mean that the observations are from a finite (but large) discrete set, which corresponds to the vocabulary of   tokens used in language models. We have shown that the Transformer can learn to perform prompt-dependent inference based on a widely studied mathematical framework called gradient descent. This insight suggests ways in which the Transformer can adapt to prompts as applied to language."
Poster,On Volume Minimization in Conformal Regression,https://ICML.cc//virtual/2025/poster/44555,"Batiste Le Bars, Pierre Humbert","We study the question of volume optimality in split conformal regression, a topic still poorly understood in comparison to coverage control. Using the fact that the calibration step can be seen as an empirical volume minimization problem, we first derive a finite-sample upper-bound on the excess volume loss of the interval returned by the classical split method. This important quantity measures the difference in length between the interval obtained with the split method and the shortest oracle prediction interval.    Then, we introduce *EffOrt*, a methodology that modifies the learning step so that the base prediction function is selected in order to minimize the length of the returned intervals.     In particular, our theoretical analysis of the excess volume loss of the prediction sets produced by *EffOrt* reveals the links between the learning and calibration steps, and notably the impact of the choice of the function class of the base predictor. We also introduce *Ad-EffOrt*, an extension of the previous method, which produces intervals whose size adapts to the value of the covariate. Finally, we evaluate the empirical performance and the robustness of our methodologies.","Machine learning models often make predictions without saying how confident they are. Conformal Prediction (CP) is a technique that fixes this by giving not just one answer, but a range (or interval) where the true answer is likely to fall, like saying “we think the house price will be between \$200K and 250K.”Most existing work on conformal prediction focuses on making sure these ranges are reliable, that is, the true answer really is inside the range most of the time. But less is known about how to make these ranges as short and useful as possible, without losing that reliability.In our work, we explore how to shrink these intervals. First, we analyze the most used CP method and show how close it gets to the shortest possible range. Then, we propose a new method called EffOrt that changes how the model is trained so that it naturally produces shorter, more informative intervals. We also introduce Ad-EffOrt, a version that makes the range bigger or smaller depending on how uncertain the model is — for example, giving narrower ranges for well-understood data and wider ones when it’s less sure.We test these methods and show they perform well in practice, giving reliable predictions that are also more precise."
Poster,On Zero-Initialized Attention: Optimal Prompt and Gating Factor Estimation,https://ICML.cc//virtual/2025/poster/44772,"Nghiem Diep, Huy Nguyen, Chau Nguyen, Minh Le, Duy Nguyen, Daniel Sonntag, Mathias Niepert, Nhat Ho","LLaMA-Adapter has recently emerged as an efficient fine-tuning technique for LLaMA models, leveraging zero-initialized attention to stabilize training and enhance performance. However, despite its empirical success, the theoretical foundations of zero-initialized attention remain largely unexplored. In this paper, we provide a rigorous theoretical analysis, establishing a connection between zero-initialized attention and mixture-of-expert models. We prove that both linear and non-linear prompts, along with gating functions, can be optimally estimated, with non-linear prompts offering greater flexibility for future applications. Empirically, we validate our findings on the open LLM benchmarks, demonstrating that non-linear prompts outperform linear ones. Notably, even with limited training data, both prompt types consistently surpass vanilla attention, highlighting the robustness and adaptability of zero-initialized attention.","This paper investigates the theory behind LLaMA-Adapter, a fine-tuning method for LLaMA models that uses zero-initialized attention to improve training stability and performance. Although this technique has shown strong practical results, its underlying principles were not well understood. The authors provide a theoretical explanation, linking zero-initialized attention to mixture-of-expert models and proving that both linear and non-linear prompts can be optimally estimated, with non-linear prompts offering greater flexibility for future applications. Experiments on open LLM benchmarks confirm that non-linear prompts outperform linear ones, and importantly, both consistently perform better than standard attention even with limited training data, highlighting the method’s robustness and adaptability."
Poster,OOD-Chameleon: Is Algorithm Selection for OOD Generalization Learnable?,https://ICML.cc//virtual/2025/poster/46662,"Liangze Jiang, Damien Teney","Out-of-distribution (OOD) generalization is challenging because distribution shifts come in many forms. Numerous algorithms exist to address specific settings, but *choosing the right training algorithm for the right dataset* without trial and error is difficult. Indeed, real-world applications often involve multiple types and combinations of shifts that are hard to analyze theoretically.**Method.**  This work explores the possibility of *learning* the selection of a training algorithm for OOD generalization. We propose a proof of concept (OOD-Chameleon) that formulates the selection as a multi-label classification over candidate algorithms, trained on a *dataset of datasets* representing a variety of shifts. We evaluate the ability of OOD-Chameleon to rank algorithms on unseen shifts and datasets based only on dataset characteristics, i.e., without training models first, unlike traditional model selection.**Findings.**  Extensive experiments show that the learned selector identifies high-performing algorithms across synthetic, vision, and language tasks. Further inspection shows that it learns non-trivial decision rules, which provide new insights into the applicability of existing algorithms. Overall, this new approach opens the possibility of better exploiting and understanding the plethora of existing algorithms for OOD generalization.","Machine learning models often lose their predictive power when applied outside the distribution of their training data. Different forms of such scenarios, known as ""distribution shifts"" have been studied, and can be each addressed with specialized methods. However, identifying the right method for the right scenario typically requires guesswork and experimentation.This paper introduces an approach that automatically identifies which existing method to apply to a given use case that involves distribution shifts. Our approach, dubbed OOD-Chameleon, is itself a learned model, that we train on a collection of distribution shift scenarios generated semi-synthetically. We train this model to associate measurable properties of the data with suitable methods that can address the specific form(s) of distribution shift(s) present in the data. After this preparatory phase, our model can recommend a suitable method for a new use case that can produce a model with high robustness to the distribution shifts in this use case.Overall, this work provides a new approach to handling distribution shifts by adaptively leveraging the variety of already-existing methods. Moreover, it also provides new insights into the applicability of these existing methods that address the reliability of AI systems."
Poster,Open-Det: An Efficient Learning Framework for Open-Ended Detection,https://ICML.cc//virtual/2025/poster/45000,"Guiping Cao, Tao Wang, Wenjian Huang, Xiangyuan Lan, Jianguo Zhang, Dongmei Jiang","Open-Ended object Detection (OED) is a novel and challenging task that detects objects and generates their category names in a free-form manner, without requiring additional vocabularies during inference. However, the existing OED models, such as GenerateU, require large-scale datasets for training, suffer from slow convergence, and exhibit limited performance. To address these issues, we present a novel and efficient Open-Det framework, consisting of four collaborative parts. Specifically, Open-Det accelerates model training in both the bounding box and object name generation process by reconstructing the Object Detector and the Object Name Generator. To bridge the semantic gap between Vision and Language modalities, we propose a Vision-Language Aligner with V-to-L and L-to-V alignment mechanisms, incorporating with the Prompts Distiller to transfer knowledge from the VLM into VL-prompts, enabling accurate object name generation for the LLM. In addition, we design a Masked Alignment Loss to eliminate contradictory supervision and introduce a Joint Loss to enhance classification, resulting in more efficient training. Compared to GenerateU, Open-Det, using only 1.5% of the training data (0.077M vs. 5.077M), 20.8% of the training epochs (31 vs. 149), and fewer GPU resources (4 V100 vs. 16 A100), achieves even higher performance (+1.0% in APr). The source codes are available at: https://github.com/Med-Process/Open-Det.","How to detect novel objects in open-world scenes and name them freely without predefined category lists? This capability, known as Open-Ended Object Detection, presents practical value but remains challenging. Existing approaches like GenerateU suffer from three critical limitations: (1) dependence on massive training data (millions of images), (2) slow convergence (requiring hundreds of training epochs), and (3) suboptimal detection accuracy. We propose Open-Det, a novel and efficient learning framework that accelerates model training in both the visual localization and open-vocabulary name generation. The modality gap between vision and language is mitigated by Vision-to-Language and Language-to-Vision alignment and knowledge transferring from the VLM model. Additionally, we optimize the training process by modeling inter-object relations, achieving significantly improved data efficiency and accuracy.Our work demonstrates that the predefined categories priors are unnecessary for novel categories detection in open-world settings. This enables practical and flexible vocabulary-free open-world detection. These advancements hold significant potential for real-world applications, such as autonomous driving and security, while also advancing research in Open-Ended Detection."
Poster,Open Materials Generation with Stochastic Interpolants,https://ICML.cc//virtual/2025/poster/44483,"Philipp Höllmer, Thomas Egg, Maya Martirossyan, Eric Fuemmeler, Zeren Shui, Amit Gupta, Pawan Prakash, Adrian Roitberg, Mingjie Liu, George Karypis, Mark Transtrum, Richard Hennig, Ellad Tadmor, Stefano Martiniani","The discovery of new materials is essential for enabling technological advancements. Computational approaches for predicting novel materials must effectively learn the manifold of stable crystal structures within an infinite design space. We introduce Open Materials Generation (OMatG), a unifying framework for the generative design and discovery of inorganic crystalline materials. OMatG employs stochastic interpolants (SI) to bridge an arbitrary base distribution to the target distribution of inorganic crystals via a broad class of tunable stochastic processes, encompassing both diffusion models and flow matching as special cases. In this work, we adapt the SI framework by integrating an equivariant graph representation of crystal structures and extending it to account for periodic boundary conditions in unit cell representations. Additionally, we couple the SI flow over spatial coordinates and lattice vectors with discrete flow matching for atomic species. We benchmark OMatG's performance on two tasks: Crystal Structure Prediction (CSP) for specified compositions, and de novo generation (DNG) aimed at discovering stable, novel, and unique structures. In our ground-up implementation of OMatG, we refine and extend both CSP and DNG metrics compared to previous works. OMatG establishes a new state of the art in generative modeling for materials discovery, outperforming purely flow-based and diffusion-based implementations. These results underscore the importance of designing flexible deep learning frameworks to accelerate progress in materials science. The OMatG code is available at https://github.com/FERMat-ML/OMatG.","The number of possible inorganic crystal structures is vast, and traditional simulations are too slow to explore them efficiently. We present OMatG, an open-source AI framework for generating realistic crystal structures. It uses stochastic interpolants—a flexible and highly customizable approach that transforms random atomic arrangements into stable, physically valid crystals. The model architecture enforces essential crystal properties, such as periodicity, and jointly learns atomic positions and element types. OMatG can accurately reconstruct known crystals from their chemical formulas and also propose entirely new, chemically plausible candidate crystals. In benchmarks, it surpasses previous AI methods in both accuracy and the discovery of unique, low-energy crystals. By reducing reliance on slow and costly trial-and-error searches, OMatG accelerates the search for new materials. This capability can help drive innovation in fields such as electronics, batteries, and clean energy."
Poster,OpenworldAUC: Towards Unified Evaluation and Optimization for Open-world Prompt Tuning,https://ICML.cc//virtual/2025/poster/46099,"Cong Hua, Qianqian Xu, Zhiyong Yang, Zitai Wang, Shilong Bao, Qingming Huang","Prompt tuning adapts Vision-Language Models like CLIP to open-world tasks with minimal training costs. In this direction, one typical paradigm evaluates model performance **separately** on known classes (*i.e.*, base domain) and unseen classes (*i.e.*, new domain). However, real-world scenarios require models to handle inputs **without prior domain knowledge**. This practical challenge has spurred the development of **open-world prompt tuning**, which demands a unified evaluation of two stages: 1) detecting whether an input belongs to the base or new domain (**P1**), and 2) classifying the sample into its correct class (**P2**). What's more, as domain distributions are generally unknown, a proper metric should be insensitive to varying base/new sample ratios (**P3**). However, we find that current metrics, including HM, overall accuracy, and AUROC, fail to satisfy these three properties simultaneously. To bridge this gap, we propose $\mathsf{OpenworldAUC}$, a unified metric that jointly assesses detection and classification through pairwise instance comparisons. To optimize $\mathsf{OpenworldAUC}$ effectively, we introduce **Gated Mixture-of-Prompts (GMoP)**, which employs domain-specific prompts and a gating mechanism to dynamically balance detection and classification. Theoretical guarantees ensure generalization of GMoP under practical conditions. Experiments on 15 benchmarks in open-world scenarios show GMoP achieves SOTA performance on $\mathsf{OpenworldAUC}$  and other metrics.","When adapting large vision-language models like CLIP to real-world applications, it's not enough to just do well on known categories — the model must also handle unfamiliar inputs without knowing whether they belong to familiar or new domains. This problem is called open-world prompt tuning.Existing evaluation methods usually split the problem into two separate parts: detecting if the input is from a known or unknown class, and then classifying it. But in real use, these two steps are tightly connected, and traditional evaluation metrics fail to capture this.To solve this, we introduce OpenworldAUC, a new evaluation metric that jointly considers detection and classification, without being sensitive to how many known or unknown examples appear. We also propose GMoP, a method that learns different prompts for different domains and uses a gating mechanism to decide how to use them. Our approach works reliably under realistic conditions and achieves strong performance across 15 benchmark datasets."
