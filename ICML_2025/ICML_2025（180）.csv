type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Mastering Multiple-Expert Routing: Realizable $H$-Consistency and Strong Guarantees for Learning to Defer,https://ICML.cc//virtual/2025/poster/46589,"Anqi Mao, Mehryar Mohri, Yutao Zhong","The problem of learning to defer with multiple experts consists of optimally assigning input instances to experts, balancing the trade-off between their accuracy and computational cost. This is a critical challenge in natural language generation, but also in other fields such as image processing, and medical diagnostics. Recent studies have proposed surrogate loss functions to optimize deferral, but challenges remain in ensuring their consistency properties. This paper introduces novel surrogate loss functions and efficient algorithms with strong theoretical learning guarantees. We address open questions regarding realizable $H$-consistency, $H$-consistency bounds, and Bayes-consistency for both single-stage (jointly learning predictor and deferral function) and two-stage (learning only the deferral function with a fixed expert) learning scenarios. For single-stage deferral, we introduce a family of new realizable $H$-consistent surrogate losses and further prove $H$-consistency for a selected member. For two-stage deferral, we derive new surrogate losses that achieve realizable $H$-consistency, $H$-consistency bounds, and Bayes-consistency for the two-expert scenario and, under natural assumptions, multiple-expertscenario. Additionally, we provide enhanced theoretical guarantees under low-noise assumptions for both scenarios. Finally, we report the results of experiments using our proposed surrogate losses, comparing their performance against existing baselines.","Imagine a system using a learning algorithm that, like a person, knows when to tackle a problem itself and when to pass it on to a specialist. For example, a customer service chatbot might handle simple requests instantly but should hand off complex or sensitive issues to a human agent. Similarly, in medical imaging, a fast learning algorithm could screen for common conditions but defer ambiguous cases to a more powerful, but slower and more expensive, algorithm or a human radiologist. This ""learning to defer"" is crucial for creating efficient and reliable systems that balance speed and accuracy.The challenge is teaching a learning algorithm how to make this deferral decision optimally. If it defers too often, it loses the benefit of its speed; if it rarely defers, it might make critical mistakes. Previous methods for training this skill have had a key weakness: it was hard to guarantee that the learning algorithm was actually learning the best deferral strategy. The training process might reward the algorithm for behaviors that seem good during training but don't hold up in real-world situations.Our research solves this problem by developing a new and more principled way to train learning algorithms to defer. We have created new ""scoring rules"" for the learning algorithm during its training that are provably linked to good real-world performance. These rules ensure that when the algorithm gets a better score in training, it will also make better deferral decisions in practice. We have rigorously proven that our method works under a variety of conditions, both when the learning algorithm learns to solve and defer tasks simultaneously and when it only learns how to defer to a pre-existing expert. Experiments show that our approach is more effective than previous techniques, leading to intelligent systems that can more reliably decide when to ask for help."
Poster,MathConstruct: Challenging LLM Reasoning with Constructive Proofs,https://ICML.cc//virtual/2025/poster/44502,"Mislav Balunovic, Jasper Dekoninck, Nikola Jovanović, Ivo Petrov, Martin Vechev","While Large Language Models (LLMs) demonstrate impressive performance in mathematics, existing math benchmarks come with significant limitations. Many focus on problems with fixed ground-truth answers, and are often saturated due to problem simplicity or the viability of guessing or memorization. Crucially, they capture only a narrow subset of relevant math problems. To address this research gap, we introduce MathConstruct, a new benchmark of 127 challenging problems sourced from various math competitions, which targets *constructive proofs*, a widely encountered problem type requiring the construction of mathematical objects with specific properties. These proofs are particularly suitable for LLM evaluation, as solution correctness can be easily verified. Our automated verifiers also enable MathConstruct to generate problem variations, used to evaluate robustness. State-of-the-art LLMs solve only 41\% of MathConstruct problems, highlighting its complexity and importance for LLM evaluation.",Existing mathematics benchmarks are predominantly focused on problems with either unique answers or formal proofs.We introduce new type of benchmark where the models have a goal to construct a mathematical object with certain properties (so-called constructive proofs). This new benchmark will allow evaluating LLMs at broader set of capabilities through which LLMs could help mathematicians.
Poster,MATH-Perturb: Benchmarking LLMs' Math Reasoning Abilities against Hard Perturbations,https://ICML.cc//virtual/2025/poster/45435,"Kaixuan Huang, Jiacheng Guo, Zihao Li, Xiang Ji, Jiawei Ge, Wenzhe Li, Yingqing Guo, Tianle Cai, Hui Yuan, Runzhe Wang, Yue Wu, Ming Yin, Shange Tang, Yangsibo Huang, Chi Jin, Xinyun Chen, Chiyuan Zhang, Mengdi Wang","Large language models have demonstrated impressive performance on challenging mathematical reasoning tasks, which has triggered the discussion of whether the performance is achieved by true reasoning capability or memorization. To investigate this question, prior work has constructed mathematical benchmarks when questions undergo simple perturbations -- modifications that still preserve the underlying reasoning patterns of the solutions. However, no work has explored hard perturbations, which fundamentally change the nature of the problem so that the original solution steps do not apply. To bridge the gap, we construct MATH-P-Simple and MATH-P-Hard via simple perturbation and hard perturbation, respectively. Each consists of 279 perturbed math problems derived from level-5 (hardest) problems in the MATH dataset (Hendrycks et al., 2021). We observe significant performance drops on  MATH-P-Hard across various models, including o1-mini (-16.49%) and gemini-2.0-flash-thinking (-12.9%). We also raise concerns about a novel form of memorization where models blindly apply learned problem-solving skills without assessing their applicability to modified contexts. This issue is amplified when using original problems for in-context learning. We call for research efforts to address this challenge, which is critical for developing more robust and reliable reasoning models. The project is available at https://math-perturb.github.io/.","Large language models have recently shown impressive performance on challenging mathematical reasoning tasks. But are these models truly reasoning through the problems, or are they just repeating what they have seen during training?We tested how these models perform when math problems are changed in ways that break the patterns they see during training. Specifically, we created two types of modified problems based on a popular math dataset:- Simple perturbations: Slight changes that keep the problem-solving steps the same.- Hard perturbations: Deeper changes that require a different solution strategy.We observe significant performance drops on hard perturbations across various models, including OpenAI's o1-mini (-16.49%) and DeepMind's gemini-2.0-flash-thinking (-12.9%). Models often try to blindly apply learned strategies to problems even if they no longer work. Our findings highlight an important challenge in AI research: making sure models truly understand problems rather than just mimicking familiar patterns."
Poster,Matrix Completion with Incomplete Side Information via Orthogonal Complement Projection,https://ICML.cc//virtual/2025/poster/44462,"Gengshuo Chang, Wei Zhang, Lehan Zhang","Matrix completion aims to recover missing entries in a data matrix using a subset of observed entries. Previous studies show that side information can greatly improve completion accuracy, but most assume perfect side information, which is rarely available in practice.   In this paper, we propose an orthogonal complement matrix completion (OCMC) model to address the challenge of matrix completion with incomplete side information. The model leverages the orthogonal complement projection derived from the available side information,   generalizing the traditional perfect side information matrix completion to the scenarios with incomplete side information.  Moreover, using probably approximately correct (PAC) learning theory, we show that the sample complexity of OCMC model decreases quadratically with the completeness level. To efficiently solve the OCMC model, a linearized Lagrangian algorithm is developed with convergence guarantees. Experimental results show that the proposed OCMC model outperforms state-of-the-art methods on both synthetic data and real-world applications.","Many real-world systems, such as movie recommendation or multi-label tagging, rely on making predictions from partially observed data. Fortunately, extra information — such as user profiles or known relationships between labels — is often available to improve these predictions. However, this additional knowledge, known as side information, is typically incomplete in practice. To explore whether systems can still make better predictions using incomplete side information, we introduce a novel method called orthogonal complement matrix completion (OCMC). This method leverages the low-rank structure not only of the target data itself, but also of the part that is not captured by the available side information. When evaluated on both synthetic and real-world datasets, the proposed OCMC outperforms existing state-of-the-art methods, demonstrating that even incomplete side information can be effectively used to improve prediction accuracy."
Poster,Matryoshka Quantization,https://ICML.cc//virtual/2025/poster/43985,"Pranav Nair, Puranjay Datta, Jeff Dean, Prateek Jain, Aditya Kusupati","Quantizing model weights is critical for reducingthe communication and inference costs of largemodels. However, quantizing models – especiallyto low precisions like int4 or int2 – requires atrade-off in model quality; int2, in particular, isknown to severely degrade model quality. Consequently, practitioners are often forced to maintainmultiple models with different quantization levels or serve a single model that best satisfies thequality-latency trade-off. On the other hand, integer data types, such as int8, inherently possessa nested (Matryoshka) structure where smallerbit-width integers, like int4 or int2, are nestedwithin the most significant bits. Leveraging thisinsight, in this paper, we propose MatryoshkaQuantization (MatQuant), a novel multi-scalequantization technique that alleviates the aforementioned challenge. This technique allows us totrain and maintain a single quantized model butserve it with the precision demanded by the deployment. Furthermore, leveraging MatQuant’sco-training and co-distillation, int2 precision models extracted by MatQuant outperform standardint2 quantization by up to 4% and 7% with OmniQuant and QAT as base algorithms respectively.Finally, we demonstrate that by using an extra bitto represent outliers, a model with an effectiveprecision of 2.05-bit improves further by 6% withOmniQuant as the base algorithm.","Large artificial intelligence models demand substantial memory for their intricate weight parameters. Quantization, representing these weights with lower bit precision, mitigates this memory footprint but often at the cost of reduced accuracy. Consequently, practitioners frequently maintain multiple distinct model versions, each tailored to specific trade-offs between accuracy and computational speed, posing a practical challenge.Matryoshka Quantization (MatQuant) presents an innovative solution: a single, unified model trained with nested precision levels, conceptually akin to Russian Matryoshka dolls. In this framework, models with lower bit precision are intrinsically embedded within their higher-precision counterparts. These more compact versions can be readily accessed by selectively ""slicing"" the appropriate weight parameters from the larger model.This approach provides deployment flexibility, enabling the model to operate at various precision levels for either high-quality results or faster, compact execution. Notably, MatQuant's joint training process surprisingly improves the performance of the lower-bit precision models compared to when they are trained independently, offering a significant advantage beyond mere efficiency."
Poster,MATS: An Audio Language Model under Text-only Supervision,https://ICML.cc//virtual/2025/poster/44538,"Wen Wang, Ruibing Hou, Hong Chang, Shiguang Shan, Xilin Chen","Large audio-language models (LALMs), built upon powerful Large Language Models (LLMs), have exhibited remarkable audio comprehension and reasoning capabilities. However, the training of LALMs demands a large corpus of audio-language pairs, which requires substantial costs in both data collection and training resources. In this paper, we propose **MATS**, an audio-language multimodal LLM designed to handle **M**ultiple **A**udio task using solely **T**ext-only **S**upervision. By leveraging pre-trained audio-language alignment models such as CLAP, we develop a text-only training strategy that projects the shared  audio-language latent space into LLM latent space, endowing the LLM with audio comprehension capabilities without relying on audio data during training. To further bridge the modality gap between audio and language embeddings within CLAP, we propose the **S**trongly-rel**a**ted **n**oisy **t**ext with **a**udio (**Santa**) mechanism. Santa maps audio embeddings into CLAP language embedding space while preserving essential information from the audio input. Extensive experiments demonstrate that MATS, despite being trained exclusively on text data, achieves competitive performance compared to recent LALMs trained on large-scale audio-language pairs. The code is publicly available in [https://github.com/wangwen-banban/MATS](https://github.com/wangwen-banban/MATS)","Training large audio-language models (LALMs) is often expensive, as it requires large-scale paired audio-text data, which is costly to collect and process. To address this limitation, we ask: can a model learn to understand audio without ever being exposed to audio during training?\We present **MATS**, a multimodal large language model designed to perform a wide range of audio tasks using only text supervision. Our core idea is to leverage pre-trained audio-language alignment models such as CLAP, which embed audio and text into a shared latent space. By projecting this shared space into the language model’s embedding space, we enable MATS to acquire audio comprehension abilities without any audio data during training. To further enhance the audio-language alignment, we propose **Santa**, a mechanism that balances the similarity-weighted language representations of audio embeddings and the original audio features, preserving essential audio information. \Remarkably, despite never seeing audio during training, MATS achieves competitive performance compared to models trained on large-scale audio-language datasets. Our approach offers a promising direction for building cost-efficient, scalable multimodal systems."
Poster,Maximizing Intermediate Checkpoint Value in LLM Pretraining with Bayesian Optimization,https://ICML.cc//virtual/2025/poster/45091,"Deyuan Liu, Zecheng Wang, Bingning Wang, Weipeng Chen, Chunshan Li, Zhiying Tu, Dianhui Chu, Dianbo Sui","The rapid proliferation of large language models (LLMs), such as GPT-4 and Gemini, underscores the intense demand for resources during their training processes, posing significant challenges due to substantial computational and environmental costs. In this paper, we introduce a novel checkpoint merging strategy aimed at making efficient use of intermediate checkpoints during LLM pretraining. This method utilizes intermediate checkpoints with shared training trajectories, and is rooted in an extensive search space exploration for the best merging weight via Bayesian optimization. Through various experiments, we demonstrate that: (1) Our proposed methodology exhibits the capacity to augment pretraining, presenting an opportunity akin to obtaining substantial benefits at minimal cost; (2) Our proposed methodology, despite requiring a given held-out dataset, still demonstrates robust generalization capabilities across diverse domains, a pivotal aspect in pretraining.","Training large language models (LLMs) like GPT-4 demands immense computational resources, contributing to high costs and environmental impact. A key challenge is making better use of intermediate checkpoints saved during this lengthy pretraining process, as current methods primarily focus on architectural improvements. Merging these checkpoints could be beneficial but is complex due to the intricate loss landscapes and the need to find optimal parameter combinations.We introduce a novel strategy that merges intermediate LLM checkpoints by linearly combining their parameters. To overcome the complexity of finding the best combination, we leverage Bayesian optimization. This powerful technique efficiently searches for optimal merging weights, focusing on combining adjacent checkpoints in the training trajectory, guided by pilot experiments.Our method acts as a ""free lunch"" for LLM pretraining, significantly boosting model performance with minimal additional computational cost. Importantly, the improved models demonstrate strong generalization capabilities across diverse tasks and languages, even to unseen data. This approach offers a practical way to maximize the value of LLM pretraining and reduce its resource footprint."
Poster,Maximum Coverage in Turnstile Streams with Applications to Fingerprinting Measures,https://ICML.cc//virtual/2025/poster/44112,"Alina Ene, Alessandro Epasto, Vahab Mirrokni, Hoai-An Nguyen, Huy Nguyen, David Woodruff, Peilin Zhong","In the maximum coverage problem we are given $d$ subsets from a universe $[n]$, and the goal is to output $k$ subsets such that their union covers the largest possible number of distinct items. We present the first algorithm for maximum coverage in the turnstile streaming model, where updates which insert or delete an item from a subset come one-by-one. Notably our algorithm only uses $poly\log n$ update time. We also present turnstile streaming algorithms for targeted and general fingerprinting for risk management where the goal is to determine which features pose the greatest re-identification risk in a dataset. As part of our work, we give a result of independent interest: an algorithm to estimate the complement of the $p^{\text{th}}$ frequency moment of a vector for $p \geq 2$. Empirical evaluation confirms the practicality of our fingerprinting algorithms demonstrating a speedup of up to $210$x over prior work.","Modern datasets often involve enormous amounts of information arriving over time — think of monitoring website visits, social media posts, or network activity. In these settings, it's crucial to make fast, smart decisions using limited memory. This paper tackles the classic maximum coverage problem: imagine you're allowed to pick a few groups (like news sources) to follow, and you want to cover as many different topics (items) as possible. We design the first algorithm that solves this problem in a challenging setting where the data is constantly changing — items can be added or removed from groups — and the algorithm must update its decisions quickly and with very little memory.Beyond this, we apply our techniques to a timely and important task: figuring out which features in a dataset could make individuals easy to identify. This is vital for protecting privacy in fields like healthcare or finance. Our approach leads to a massive speedup — up to 210 times faster — compared to previous solutions."
Poster,Maximum Entropy Reinforcement Learning with Diffusion Policy,https://ICML.cc//virtual/2025/poster/46039,"Xiaoyi Dong, Jian Cheng, Xi Zhang","The Soft Actor-Critic (SAC) algorithm with a Gaussian policy has become a mainstream implementation for realizing the Maximum Entropy Reinforcement Learning (MaxEnt RL) objective, which incorporates entropy maximization to encourage exploration and enhance policy robustness. While the Gaussian policy performs well on simpler tasks, its exploration capacity and potential performance in complex multi-goal RL environments are limited by its inherent unimodality.  In this paper, we employ the diffusion model, a powerful generative model capable of capturing complex multimodal distributions, as the policy representation to fulfill the MaxEnt RL objective, developing a method named MaxEnt RL with Diffusion Policy (MaxEntDP). Our method enables efficient exploration and brings the policy closer to the optimal MaxEnt policy. Experimental results on Mujoco benchmarks show that MaxEntDP outperforms the Gaussian policy and other generative models within the MaxEnt RL framework, and performs comparably to other state-of-the-art diffusion-based online RL algorithms. Our code is available at https://github.com/diffusionyes/MaxEntDP.","The Soft Actor-Critic (SAC) algorithm is a popular method in reinforcement learning, which is a type of artificial intelligence where agents learn by trial and error. SAC helps agents learn better by encouraging them to explore different actions instead of always choosing the same ones. This is done using a technique called ""maximum entropy,"" which promotes more varied and flexible decision-making. Traditionally, SAC uses something called a Gaussian policy to decide what actions to take. This works well in simple situations, but it struggles with more complex tasks that involve multiple goals, because it's only good at focusing on one option at a time. In our work, we introduce a new method called MaxEntDP. Instead of using the traditional approach, we use a powerful AI tool known as a diffusion model. This model can represent many different possibilities at once, helping the agent explore more efficiently and make better decisions. We test our method in simulated environments and find that it performs better than the standard approach and even matches the performance of some of the best modern methods. Our code is available at: https://github.com/diffusionyes/MaxEntDP."
Poster,Maximum Total Correlation Reinforcement Learning,https://ICML.cc//virtual/2025/poster/46265,"Bang You, Puze Liu, Huaping Liu, Jan Peters, Oleg Arenz","Simplicity is a powerful inductive bias. In reinforcement learning, regularization is used for simpler policies, data augmentation for simpler representations, and sparse reward functions for simpler objectives, all that, with the underlying motivation to increase generalizability and robustness by focusing on the essentials. Supplementary to these techniques, we investigate how to promote simple behavior throughout the episode. To that end, we introduce a modification of the reinforcement learning problem that additionally maximizes the total correlation within the induced trajectories. We propose a practical algorithm that optimizes all models, including policy and state representation, based on a lower-bound approximation. In simulated robot  environments, our method naturally generates policies that induce periodic and compressible trajectories, and that exhibit superior robustness to noise and changes in dynamics compared to baseline methods, while also improving performance in the original tasks.","When training artificial intelligence (AI) to perform in the real world, we want them to perform as simply as possible while still being able to solve their tasks. This is because simpler behavior is easier to understand and predict, and is more likely to still work in situations the AI didn't encounter during training. However, it is difficult to increase the simplicity of behavior without a clear way to measure it.In this work, we investigate a concept called total correlation to quantify the simplicity of an AI's behavior. Think of total correlation as measuring how many fewer bytes you would need to describe the behavior to someone else if your communication was optimized for describing the full behavior as a whole instead of the individual time steps. For example, a humanoid robot that uses a clean, periodic gait has higher total correlation than a slightly irregular gait that performs unnecessary adaptations to sensor noise.We propose a method to learn behaviors with higher total correlations, and our tests on simulated robots yielded impressive results. Our method naturally generated highly predictable and compressible behaviors. For tasks that benefit from it, like a robot's gait, this often meant periodic movements (like a regular walking pattern). We observed these significant advantages, including superior robustness to unexpected noise and modeling errors (such as inaccurate mass during training), across various tasks, even those requiring complex, non-periodic movements. Crucially, these advantages came without sacrificing performance; in fact, our robots actually improved at their original tasks compared to standard methods.This research offers a new perspective on training AI, suggesting that explicitly optimizing for simplicity in behavior can lead to more reliable, adaptable, and ultimately more trustworthy intelligent systems for real-world applications."
