type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Accelerating Spectral Clustering under Fairness Constraints,https://ICML.cc//virtual/2025/poster/45681,"Francesco Tonin, Alex Lambert, Johan Suykens, Volkan Cevher","Fairness of decision-making algorithms is an increasingly important issue. In this paper, we focus on spectral clustering with group fairness constraints, where every demographic group is represented in each cluster proportionally as in the general population. We present a new efficient method for fair spectral clustering (Fair SC) by casting the Fair SC problem within the difference of convex functions (DC) framework. To this end, we introduce a novel variable augmentation strategy and employ an alternating direction method of multipliers type of algorithm adapted to DC problems. We show that each associated subproblem can be solved efficiently, resulting in higher computational efficiency compared to prior work, which required a computationally expensive eigendecomposition. Numerical experimentsdemonstrate the effectiveness of our approach on both synthetic and real-world benchmarks, showing significant speedups in computation time over prior art, especially as the problem size grows. This work thus represents a considerable step forward towards the adoption of fair clustering in real-world applications.","Clustering is a technique that helps computers automatically group similar data points: for example, organizing patients based on medical profiles or categorizing users by purchasing preferences. However, in applications involving sensitive attributes such as healthcare or hiring, it's important that these groupings treat different demographic groups fairly.Our work focuses on spectral clustering, a widely used method that analyzes relationships between data points using network structures. Existing approaches to enforcing fairness in spectral clustering rely on computationally intensive operations, which makes them unsuitable for large-scale datasets.We introduce a new, efficient algorithm that achieves fair clustering without the need for expensive computations. By reformulating the problem using a mathematical framework known as ""difference of convex functions,"" and by designing a tailored optimization method, we significantly reduce the computational cost.This advancement enables fair clustering to be applied more broadly in real-world scenarios, such as healthcare, education, and public policy, where fairness and efficiency are both critical."
Poster,Accelerating Unbiased LLM Evaluation via Synthetic Feedback,https://ICML.cc//virtual/2025/poster/46205,"Zhaoyi Zhou, Yuda Song, Andrea Zanette","When developing new large language models (LLMs), a key step is evaluating their final performance, often by computing the win-rate against a reference model based on external feedback. Human feedback is the gold standard, particularly for capturing nuanced qualities like coherence, readability, and alignment with human expectations. However, human evaluations are costly—even for large tech companies—and when conducted with active users, they may negatively impact user experience.A promising alternative is synthetic feedback, where evaluations are conducted by other large language models, including reward models. While this eliminates the need for costly human annotations, it introduces biases that may distort the evaluation process.In this work, we propose a statistically principled framework that integrates human and synthetic feedback to reduce reliance on human annotations while maintaining unbiased win-rate calculations. Our experiments demonstrate a reduction in human annotations by up to 12.2\% with an off-the-shelf synthetic evaluator and up to 24.8\% with a finetuned variant. Apart from being generalizable, scalable, and free of hyper-parameter tuning, our method offers predictable annotation savings, which can be estimated based on data-dependent characteristics.","Evaluating how well a new AI language model performs—especially compared to existing models—usually requires human judgment. People are great at spotting whether responses sound natural, make sense, and align with what users expect. But relying on human feedback is expensive and time-consuming, even for big tech companies. It can also interfere with the experience of real users.To address this, researchers often use other AI systems to provide feedback instead of humans. While this saves time and money, it can introduce hidden biases that affect how fairly the new model is judged.In this work, we introduce a new approach that combines human and AI feedback in a statistically sound way. Our method reduces the need for human involvement while still producing reliable and unbiased results. We show that it can cut the amount of human feedback needed by up to 12% with a public model and up to 25% with slight training. This makes it easier and cheaper to evaluate AI models without sacrificing accuracy."
Poster,Accurate and Efficient World Modeling with Masked Latent Transformers,https://ICML.cc//virtual/2025/poster/43479,"Maxime Burchi, Radu Timofte","The Dreamer algorithm has recently obtained remarkable performance across diverse environment domains by training powerful agents with simulated trajectories. However, the compressed nature of its world model's latent space can result in the loss of crucial information, negatively affecting the agent's performance. Recent approaches, such as $\Delta$-IRIS and DIAMOND, address this limitation by training more accurate world models. However, these methods require training agents directly from pixels, which reduces training efficiency and prevents the agent from benefiting from the inner representations learned by the world model. In this work, we propose an alternative approach to world modeling that is both accurate and efficient. We introduce EMERALD (Efficient MaskEd latent tRAnsformer worLD model), a world model using a spatial latent state with MaskGIT predictions to generate accurate trajectories in latent space and improve the agent performance. On the Crafter benchmark, EMERALD achieves new state-of-the-art performance, becoming the first method to surpass human experts performance within 10M environment steps. Our method also succeeds to unlock all 22 Crafter achievements at least once during evaluation.","We introduce EMERALD, a new method in the field of world modeling that helps computers to simulate the world more accurately and efficiently compared to previous approaches. World modeling can improve sample efficiency and safety when training AI agents by generating imaginary training trajectories rather than interacting with the real world. Our proposed world model uses a spatial hidden state to carry more information and simulate the environment more accurately. This increase in precision improves the performance of the agent in complex visual environments like Crafter where details can be crucial. We also propose to use MaskGIT, an efficient prediction algorithm for image and video generation methods with spatial states. This makes EMERALD both accurate and efficient compared to previous approaches. We evaluate our method on the Crafter benchmark and demonstrate state-of-the-art performance. Our method also generalizes on Atari games that do not necessarily require the use of a spatial hidden state to perceive crucial details and achieve strong performance."
Poster,Accurate Identification of Communication Between Multiple Interacting Neural Populations,https://ICML.cc//virtual/2025/poster/45466,"Belle Liu, Jacob I Sacks, Matthew Golub","Neural recording technologies now enable simultaneous recording of population activity across multiple brain regions, motivating the development of data-driven models of communication between recorded brain regions. Existing models can struggle to disentangle communication from the effects of unrecorded regions and local neural population dynamics. Here, we introduce Multi-Region Latent Factor Analysis via Dynamical Systems (MR-LFADS), a sequential variational autoencoder composed of  region-specific recurrent networks. MR-LFADS features structured information bottlenecks, data-constrained communication, and unsupervised inference of unobserved inputs--features that specifically support disentangling of inter-regional communication, inputs from unobserved regions, and local population dynamics. MR-LFADS outperforms existing approaches at identifying communication across dozens of simulations of task-trained multi-region networks. Applied to large-scale electrophysiology, MR-LFADS predicts brain-wide effects of circuit perturbations that were not seen during model fitting. These validations on synthetic and real neural data suggest that MR-LFADS could serve as a powerful tool for uncovering the principles of brain-wide information processing.","Brain function relies on different parts of the brain working together to process our senses, generate our perceptions and thoughts, and drive our bodies into action. New technologies are allowing brain scientists to monitor the activity of large populations of individual neurons simultaneously across many brain regions. These measurements enable scientists to ask questions about how the activity in one region affects another--that is, how brain regions actually communicate. Our research introduces a new machine learning technique that uses multi-region neural activity data to infer the direction and content of communication between brain regions. Unlike existing approaches, our technique explains the neural activity in each measured brain region in terms of communication from other measured brain regions, influences from unmeasured brain regions, and how each brain region internally processes information over time. When applied to simulated brain networks designed to reflect challenging scenarios for studying communication, our technique accurately identified who was communicating with whom, and what signals were being communicated. We then applied the technique to real brain data and showed that it could predict the brain-wide effects of disrupting one region--effects our model had never seen before. Taken together, this work provides a powerful new tool for studying how different parts of the brain work together and may provide insight into developing treatments for brain injuries and disorders."
Poster,A Certified Unlearning Approach without Access to Source Data,https://ICML.cc//virtual/2025/poster/46268,"Umit Basaran, Sk Miraj Ahmed, Amit Roy-Chowdhury, Basak Guler","With the growing adoption of data privacy regulations, the ability to erase private or copyrighted information from trained models has become a crucial requirement. Traditional unlearning methods often assume access to the complete training dataset, which is unrealistic in scenarios where the source data is no longer available. To address this challenge, we propose a certified unlearning framework that enables effective data removal without access to the original training data samples. Our approach utilizes a surrogate dataset that approximates the statistical properties of the source data, allowing for controlled noise scaling based on the statistical distance between the two. While our theoretical guarantees assume knowledge of the exact statistical distance, practical implementations typically approximate this distance, resulting in potentially weaker but still meaningful privacy guarantees. This ensures strong guarantees on the model's behavior post-unlearning while maintaining its overall utility. We establish theoretical bounds, introduce practical noise calibration techniques, and validate our method through extensive experiments on both synthetic and real-world datasets. The results demonstrate the effectiveness and reliability of our approach in privacy-sensitive settings.","Machine learning models often learn from sensitive data, and new privacy laws require removing specific data from these models. However, traditional removal methods assume the original training data is still accessible, which is frequently unrealistic in practice due to storage limitations, privacy concerns, or regulatory requirements. To solve this, we propose a method which removes data points without needing access to the original training data. Our method uses a surrogate dataset—a substitute that resembles the original data—to safely guide the unlearning process. Specifically, we calculate how different the surrogate data is from the original data and adjust the removal process accordingly, introducing controlled noise to ensure the model behaves as if it never saw the removed data.This is the first approach that provides theoretical privacy guarantees even without original data access. It helps organizations efficiently comply with privacy regulations, even in complex scenarios like outsourced training or restricted data retention. By demonstrating its effectiveness through extensive experiments, including real-world scenarios, our method establishes itself as practical and reliable. This makes machine learning safer and more trustworthy, significantly broadening its potential use in sensitive applications."
Poster,A Chaotic Dynamics Framework Inspired by Dorsal Stream for Event Signal Processing,https://ICML.cc//virtual/2025/poster/43688,"yu chen, Jing Lian, Zhaofei Yu, Jizhao Liu, Jisheng Dang, Gang Wang","Event cameras are bio-inspired vision sensors that encode visual information with high dynamic range, high temporal resolution, and low latency. Current state-of-the-art event stream processing methods rely on end-to-end deep learning techniques. However, these models are heavily dependent on data structures, limiting their stability and generalization capabilities across tasks, thereby hindering their deployment in real-world scenarios. To address this issue, we propose a chaotic dynamics event signal processing framework inspired by the dorsal visual pathway of the brain. Specifically, we utilize Continuous-coupled Neural Network (CCNN) to encode the event stream. CCNN encodes polarity-invariant event sequences as periodic signals and polarity-changing event sequences as chaotic signals. We then use continuous wavelet transforms to analyze the dynamical states of CCNN neurons and establish the high-order mappings of the event stream. The effectiveness of our method is validated through integration with conventional classification networks, achieving state-of-the-art classification accuracy on the N-Caltech101 and N-CARS datasets, with results of 84.3% and 99.9%, respectively. Our method improves the accuracy of event camera-based object classification while significantly enhancing the generalization and stability of event representation.","Event cameras offer high temporal resolution, low latency, and high dynamic range, making them well-suited for capturing fast-changing scenes. However, existing processing methods heavily rely on data-specific deep learning models, which often suffer from limited generalization and robustness in real-world scenarios. Inspired by the brain’s dorsal visual pathway, we propose a biologically plausible framework for event signal processing based on chaotic dynamics. A Continuous-Coupled Neural Network (CCNN) is designed to encode polarity-invariant event sequences as periodic signals and polarity-changing ones as chaotic signals. These dynamics are then analyzed using continuous wavelet transforms to extract high-order, task-independent representations. Integrated with standard classification networks, our approach achieves state-of-the-art accuracy on N-Caltech101 (84.3%) and N-CARS (99.9%) datasets. The results demonstrate that our method not only enhances classification performance but also significantly improves the stability and generalization of event-based representations, offering a promising direction for real-world deployment."
Poster,A Checks-and-Balances Framework for Context-Aware Ethical AI Alignment,https://ICML.cc//virtual/2025/poster/46461,Edward Chang,"This paper introduces a checks-and-balances framework for ethical alignment of Large Language Models (LLMs), inspired by three-branch governmental systems. It implements three independent yet interacting components: LLMs as the executive branch for knowledge generation, DIKE as the legislative branch establishing ethical guardrails, and ERIS as the judicial branch for contextual interpretation. Beyond structural separation, we address a fundamental challenge: regulating emotion to shape behaviors. Drawing from psychological theories where managing emotional responses prevents harmful behaviors, we develop a self-supervised learning pipeline that maps emotions to linguistic behaviors, enabling precise behavioral modulation through emotional conditioning. By integrating this approach with adversarial testing, our framework demonstrates how DIKE and ERIS direct linguistic behaviors toward ethical outcomes while preserving independence throughout knowledge generation, ethical oversight, and contextual interpretation.","We built a new way to keep AI chatbots like ChatGPT helpful and well-behaved, inspired by how teams work together. Imagine three friends: one writes answers (the AI), another gives wise advice (DIKE), and the third asks tough questions (ERIS). They check each other to make sure everything stays fair and kind.Here's why this works: Just like people learn to pause when angry instead of saying something hurtful, we teach AI to spot emotional language (like frustration or bias) and respond more thoughtfully. Instead of constantly fixing mistakes after they happen, our system helps the AI develop good habits from the start—like raising a polite child rather than just scolding them for misbehaving. The result? Smarter, kinder AI that understands different cultures and situations naturally."
Poster,Achieving Linear Speedup and Near-Optimal Complexity for Decentralized Optimization over Row-stochastic Networks,https://ICML.cc//virtual/2025/poster/45127,"Liyuan Liang, Xinyi Chen, Gan Luo, Kun Yuan","A key challenge in decentralized optimization is determining the optimal convergence rate and designing algorithms to achieve it. While this problem has been extensively addressed for doubly-stochastic and column-stochastic mixing matrices, the row-stochastic scenario remains unexplored. This paper bridges this gap by introducing effective metrics to capture the influence of row-stochastic mixing matrices and establishing the first convergence lower bound for decentralized learning over row-stochastic networks.  However, existing algorithms fail to attain this lower bound due to two key issues: deviation in the descent direction caused by the adapted gradient tracking (GT) and instability introduced by the Pull-Diag protocol. To address descent deviation, we propose a novel analysis framework demonstrating that Pull-Diag-GT achieves linear speedup—the first such result for row-stochastic decentralized optimization. Moreover, by incorporating a multi-step gossip (MG) protocol, we resolve the instability issue and attain the lower bound, achieving near-optimal complexity for decentralized optimization over row-stochastic networks.","In many modern systems, groups of computers or devices work together to solve problems without relying on a central coordinator. This is known as decentralized optimization. A key challenge in this area is understanding how quickly these systems can reach a good solution and designing methods that do this as efficiently as possible.Most past research has focused on specific ways these devices share information, but one important case has not been well studied. This is the case where each device only considers its own incoming data, which requires the use of a row-stochastic mixing matrix. This paper addresses this gap by introducing new ways to measure how these matrices affect performance and by proving the first lower limit on how fast learning can happen in such systems.We find that existing algorithms fail to reach this lower bound due to two key issues: deviation in the descent direction caused by the adapted gradient tracking (GT) and instability introduced by the Pull-Diag protocol. To solve the first problem, we introduce a new way to analyze the method and show that Pull-Diag-GT can speed up learning proportionally to the number of devices. This is the first result of its kind for row-stochastic decentralized optimization. Moreover, by incorporating a multi-step gossip (MG) protocol, we resolve the instability issue and attain the lower bound, achieving near-optimal complexity for decentralized optimization over row-stochastic networks."
Poster,A Classification View on Meta Learning Bandits,https://ICML.cc//virtual/2025/poster/44061,"Mirco Mutti, Jeongyeol Kwon, Shie Mannor, Aviv Tamar","Contextual multi-armed bandits are a popular choice to model sequential decision-making. *E.g.*, in a healthcare application we may perform various tests to asses a patient condition (exploration) and then decide on the best treatment to give (exploitation). When human design strategies, they aim for the exploration to be *fast*, since the patient's health is at stake, and easy to *interpret* for a physician overseeing the process. However, common bandit algorithms are nothing like that: The regret caused by exploration scales with $\sqrt{H}$ over $H$ rounds and decision strategies are based on opaque statistical considerations. In this paper, we use an original *classification view* to meta learn interpretable and fast exploration plans for a fixed collection of bandits $\mathbb{M}$. The plan is prescribed by an interpretable *decision tree* probing decisions' payoff to classify the test bandit. The test regret of the plan in the *stochastic* and *contextual* setting scales with $O (\lambda^{-2} C_{\lambda} (\mathbb{M}) \log^2 (MH))$, being $M$ the size of $\mathbb{M}$, $\lambda$ a separation parameter over the bandits, and $C_\lambda (\mathbb{M})$ a novel *classification-coefficient* that fundamentally links meta learning bandits with classification. Through a nearly matching lower bound, we show that $C_\lambda (\mathbb{M})$ inherently captures the complexity of the setting.","In a healthcare application we may perform various tests to asses a patient condition and then decide on the best treatment to give. When human design the decision strategies, they aim for the assessment to be fast, since the patient's health is at stake, and easy to interpret for a physician overseeing the process. Instead, when the problem is tackled with AI, the resulting strategy is often opaque, hard to interpret for the end user. In this paper, we provide a template to compute decision strategies that are efficient and easy to interpret, which may be employed in the described healthcare scenario or other applications in which interpretability is important. Similar to the human approach, the strategy prescribes a sequence of simple tests to gather sufficient information, then to take optimal decisions with the given information. We analyize the proposed template both theoretically, through a formal study of its efficiency, and empirically, through numerical validation in synthetic domains. We believe our work is a first step in the direction of improving interpretability of decision strategies obtained with AI."
Poster,A Closer Look at Backdoor Attacks on CLIP,https://ICML.cc//virtual/2025/poster/46006,"Shuo He, Zhifang Zhang, Feng Liu, Roy Lee, Bo An, Lei Feng","We present a comprehensive empirical study on how backdoor attacks affect CLIP by analyzing the representations of backdoor images. Specifically, based on the methodology of representation decomposing, image representations can be decomposed into a sum of representations across individual image patches, attention heads (AHs), and multi-layer perceptrons (MLPs) in different model layers. By examining the effect of backdoor attacks on model components, we have the following empirical findings. (1) Different backdoor attacks would infect different model components, i.e., local patch-based backdoor attacks mainly affect AHs, while global perturbation-based backdoor attacks mainly affect MLPs. (2) Infected AHs are centered on the last layer, while infected MLPs are decentralized on several late layers. (3) Not all AHs in the last layer are infected and even some AHs could still maintain the original property-specific roles (e.g., ''color"" and ''location''). These observations motivate us to defend against backdoor attacks by detecting infected AHs, repairing their representations, or filtering backdoor samples with too many infected AHs, in the inference stage. Experimental results validate our empirical findings and demonstrate the effectiveness of the defense methods.","Which CLIP components are affected by various backdoor attacks? Which model layers are affected most? How's the change in the functional roles of affected components? We conducted a comprehensive empirical study to answer these questions.  We found that (1) different backdoor attacks would infect different model components, (2) Infected attention heads (AHs) are centered on the last layer, while infected multi-layer perceptrons (MLPs) are decentralized on several late layers. (3) Not all AHs in the last layer are infected, and even some ones could still maintain the original property-specific roles. Based on these findings, to defend against backdoor attacks during inference, we propose to detect infected AHs, repair their representations, or filter backdoor samples with too many infected AHs."
