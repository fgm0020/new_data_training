type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Sample Efficient Demonstration Selection for In-Context Learning,https://ICML.cc//virtual/2025/poster/44658,"Kiran Purohit, Venktesh V, Sourangshu Bhattacharya, Avishek Anand","The in-context learning paradigm with LLMs has been instrumental in advancing a wide range of natural language processing tasks. The selection of few-shot examples (exemplars / demonstration samples) is essential for constructing effective prompts under context-length budget constraints. In this paper, we formulate the exemplar selection task as a top-m best arms identification problem. A key challenge in this setup is the exponentially large number of arms that need to be evaluated to identify the m-best arms. We propose CASE (Challenger Arm Sampling for Exemplar selection), a novel sample-efficient selective exploration strategy that maintains a shortlist of “challenger” arms, which are current candidates for the top-m arms. In each iteration, only one of the arms from this shortlist or the current top-m set is pulled, thereby reducing sample complexity and, consequently, the number of LLM evaluations. Furthermore, we model the scores of exemplar subsets (arms) using a parameterized linear scoring function, leading to stochastic linear bandits setting. CASE achieves remarkable efficiency gains of up to 7× speedup in runtime while requiring 7× fewer LLM calls (87% reduction) without sacrificing performance compared to state-of-the-art exemplar selection methods. We release our code and data (https://github.com/kiranpurohit/CASE).","We make Large Language Model (LLM) solve complex tasks by providing them examples demonstrating skills needed to solve those tasks. To choose the best representative samples, we devise an algorithm that can efficiently explore all possible examples from a large database of such samples. The algorithm is similar to pulling arms in slot machines in a smart and optimal manner to obtain maximum reward with limited budget to spend on the machines. A certain combination of samples are considered to be akin to an arm in slot machines in our algorithm. At any point in time we maintain a shortlist of good arms and next best arms and seek to remove the weakest link from set of good arms. The weakest link is the arm which has the greatest threat to be replaced from an arm in the set of next best arms. The next best arms are rotated periodically to ensure we see multiple possible next best arms."
Poster,Sample-Optimal Agnostic Boosting with Unlabeled Data,https://ICML.cc//virtual/2025/poster/44406,"Udaya Ghai, Karan Singh","Boosting provides a practical and provably effective framework for constructing accurate learning algorithms from inaccurate rules of thumb. It extends the promise of sample-efficient learning to settings where direct Empirical Risk Minimization (ERM) may not be implementable efficiently. In the realizable setting, boosting is known to offer this computational reprieve without compromising on sample efficiency. However, in the agnostic case, existing boosting algorithms fall short of achieving the optimal sample complexity. We highlight a previously unexplored avenue of improvement: unlabeled samples. We design a computationally efficient agnostic boosting algorithm that matches the sample complexity of ERM, given polynomially many additional unlabeled samples. In fact, we show that the total number of samples needed, unlabeled and labeled inclusive, is never more than that for the best known agnostic boosting algorithm -- so this result is never worse -- while only a vanishing fraction of these need to be labeled for the algorithm to succeed. This is particularly fortuitous for learning-theoretic applications of agnostic boosting, which often take place in the distribution-specific setting, where unlabeled samples can be availed for free. We also prove that the resultant guarantee is resilient against mismatch between the distributions governing the labeled and unlabeled samples. Finally, we detail an application of this result in reinforcement learning.","This paper introduces a new, more efficient way to ""boost"" (think, increase the accuracy of) machine learning algorithms, especially when dealing with noisy or unpredictable data (the ""agnostic"" setting).Boosting combines many simple learning rules into one highly accurate algorithm. Traditional boosting methods in the agnostic setting require a lot of expensive ""labeled"" data (where the correct answer is known).This research shows how to use readily available ""unlabeled"" data (where the answer isn't known) to achieve the same optimal learning efficiency as the best possible methods. This means the algorithm needs far fewer expensive labeled samples. The innovation is a new mathematical approach that allows the algorithm to learn from both labeled and unlabeled data effectively.This advancement has implications for areas like reinforcement learning and can make machine learning more practical by reducing the need for costly labeled rewards."
Poster,"Sample, Scrutinize and Scale: Effective Inference-Time Search by Scaling Verification",https://ICML.cc//virtual/2025/poster/43608,"Eric Zhao, Pranjal Awasthi, Sreenivas Gollapudi","Sampling-based search, a simple paradigm for utilizing test-time compute, involves generating multiple candidate responses and selecting the best one---typically by verifying each response for correctness. In this paper, we study the scaling trends governing sampling-based search. Among our findings is that simply scaling up a minimalist implementation that uses only random sampling and direct self-verification results in sustained performance improvements that, for example, elevate the Gemini v1.5 Pro model's reasoning capabilities past that of o1-Preview on popular benchmarks. We partially attribute the scalability of sampling-based search to a phenomenon of implicit scaling, where sampling a larger pool of responses in turn improves verification accuracy. We further identify two useful principles for improving self-verification capabilities with test-time compute: (1) comparing across responses provides helpful signals about the locations of errors and hallucinations, and (2) different model output styles are useful for different contexts---chains of thought are useful for reasoning but harder to verify. We also find that, though accurate verification can be elicited,  frontier models demonstrate remarkably weak out-of-box verification capabilities and introduce a benchmark to measure progress on these deficiencies.","In sampling-based search (also known as parallel test-time compute scaling), language models are used to generate many candidate responses in parallel. The hope is that choosing from a large pool of responses is better than sampling only one. However, the utility of this approach is bottlenecked by verification: just because there is a good response (e.g., we know Pass@k often scales nicely), does not mean that you'll be able to pick it out.We study the scaling trends for sampling-based search when models need pick out good responses through self-verification. Contrary to the common belief that model self-verification is insufficient and demands interventions like custom reward models, PRMs, reinforcement learning, etc., we show that just scaling self-verification in a principled manner is remarkably effective---able to boost non-reasoning models to o1-level performance without finetuning, RL, or distillation. On the AIME exam for example, self-verification is able to pick out correct answers when <1% of generated responses are correct. We identify a counterintuitive trend behind these observations: self-verification becomes easier the larger the pool of candidate responses is, contrary to the intuition that choosing from a larger pool is a harder selection problem."
Poster,Sample-specific Noise Injection for Diffusion-based Adversarial Purification,https://ICML.cc//virtual/2025/poster/46361,"Yuhao Sun, Jiacheng Zhang, Zesheng Ye, Chaowei Xiao, Feng Liu","*Diffusion-based purification* (DBP) methods aim to remove adversarial noise from the input sample by first injecting Gaussian noise through a forward diffusion process, and then recovering the clean example through a reverse generative process. In the above process, how much Gaussian noise is injected to the input sample is key to the success of DBP methods, which is controlled by a constant noise level $t*$ for all samples in existing methods. In this paper, we discover that an optimal $t*$ for each sample indeed could be different. Intuitively, the cleaner a sample is, the less the noise it should be injected, and vice versa. Motivated by this finding, we propose a new framework, called Sample-specific Score-aware Noise Injection (SSNI). Specifically, SSNI uses a pre-trained score network to estimate how much a data point deviates from the clean data distribution (i.e., score norms). Then, based on the magnitude of score norms, SSNI applies a reweighting function to adaptively adjust $t*$ for each sample, achieving sample-specific noise injections. Empirically, incorporating our framework with existing DBP methods results in a notable improvement in both accuracy and robustness on CIFAR-10 and ImageNet-1K, highlighting the necessity to allocate *distinct noise levels to different samples* in DBP methods. Our code is available at: https://github.com/tmlr-group/SSNI.","*Diffusion-based purification* (DBP) is a promising framework to defend against \emph{adversarial examples} (AEs). However, existing DBP methods apply the same noise level to all inputs, regardless of how close they are to the clean data distribution. This sample-shared strategy can lead to over-distortion of clean examples (CEs) or insufficient purification of AEs.In this work, we propose ***S***ample-specific ***S***core-aware ***N***oise ***I***njection (SSNI), a new framework that adapts the noise injection level to each input based on its estimated distance from the clean data manifold. We compute this distance using the score norm, derived from a pre-trained score network that estimates the gradient of the log-density function. Intuitively, cleaner samples have lower score norms and are injected with less noise, while AEs with higher score norms are purified more aggressively.SSNI is lightweight, general-purpose, and easily integrable into existing DBP pipelines. Experiments on CIFAR-10 and ImageNet-1K show that SSNI improves both clean and robust accuracy across multiple baselines, while maintaining computational efficiency. By tailoring purification to each input, SSNI strikes a better balance between robustness and utility, and generalizes well to unseen attacks."
Poster,Sampling Binary Data by Denoising through Score Functions,https://ICML.cc//virtual/2025/poster/46496,"Francis Bach, Saeed Saremi","Gaussian smoothing combined with a probabilistic framework for denoising via the empirical Bayes formalism, i.e., the Tweedie-Miyasawa formula (TMF), are the two key ingredients in the success of score-based generative models in Euclidean spaces. Smoothing holds the key for easing the problem of learning and sampling in high dimensions, denoising is needed for recovering the original signal, and TMF ties these together via the score function of noisy data. In this work, we extend this paradigm to the problem of learning and sampling the distribution of binary data on the Boolean hypercube by adopting Bernoulli noise, instead of Gaussian noise, as a smoothing device. We first derive a TMF-like expression for the optimal denoiser for the Hamming loss, where a score function naturally appears. Sampling noisy binary data is then achieved using a Langevin-like sampler which we theoretically analyze for different noise levels. At high Bernoulli noise levels sampling becomes easy, akin to log-concave sampling in Euclidean spaces. In addition, we extend the sequential multi-measurement sampling of Saremi et al. (2024) to the binary setting where we can bring the ""effective noise"" down by sampling multiple noisy measurements at a fixed noise level, without the need for continuous-time stochastic processes. We validate our formalism and theoretical findings by experiments on synthetic data and binarized images.","Recent breakthroughs in data generation rely on two key ideas: adding noise to make complex data easier to model, and then learning how to reverse that noise to recover the original. These methods have worked well for images and other data in continuous spaces, where the noise is typically Gaussian.In this work, we explore how to bring these powerful tools to binary data (data made up of only 0s and 1s) by using a different kind of noise called Bernoulli noise, which is akin to randomly flipping bits. The probability of these flips defines the key parameter of our model. We show how to recover the original data from its noisy version, using a mathematical formula similar to the one that works in the continuous case. This allows us to define a new way of sampling binary data, inspired by methods originally developed for continuous spaces.We also adapt a technique for improving the quality of samples by combining multiple noisy versions of the same data. This helps us get better results without needing to simulate complex, continuous-time processes. We test our method on both synthetic data and black-and-white images, and our results support the theory."
Poster,Sampling from Binary Quadratic Distributions via Stochastic Localization,https://ICML.cc//virtual/2025/poster/43676,"Chenguang Wang, Kaiyuan Cui, Weichen Zhao, Tianshu Yu","Sampling from binary quadratic distributions (BQDs) is a fundamental but challenging problem in discrete optimization and probabilistic inference. Previous work established theoretical guarantees for stochastic localization (SL) in continuous domains, where MCMC methods efficiently estimate the required posterior expectations during SL iterations. However, achieving similar convergence guarantees for discrete MCMC samplers in posterior estimation presents unique theoretical challenges. In this work, we present the first application of SL to general BQDs, proving that after a certain number of iterations, the external field of posterior distributions constructed by SL tends to infinity almost everywhere, hence satisfy Poincaré inequalities with probability near to 1, leading to polynomial-time mixing. This theoretical breakthrough enables efficient sampling from general BQDs, even those that may not originally possess fast mixing properties. Furthermore, our analysis, covering enormous discrete MCMC samplers based on Glauber dynamics and Metropolis-Hastings algorithms, demonstrates the broad applicability of our theoretical framework.Experiments on instances with quadratic unconstrained binary objectives, including maximum independent set, maximum cut, and maximum clique problems, demonstrate consistent improvements in sampling efficiency across different discrete MCMC samplers.","In many scientific fields, researchers need to generate random samples that follow specific probability patterns—like simulating the behavior of magnetic materials in physics or modeling complex networks in computer science. These patterns involve binary variables (things that can only be ""on"" or ""off"") with intricate dependencies between them, making direct sampling extremely challenging.We developed a new sampling approach based on stochastic localization that makes this difficult task much easier. Instead of trying to directly sample from the complex target distribution, our method breaks the problem into a series of steps. Each step involves sampling from a simpler, ""smoothed-out"" version of the original distribution—like gradually removing the sharp peaks and valleys from a rugged landscape to make it easier to navigate.We proved mathematically that after enough iterations, standard sampling algorithms can efficiently generate samples from these intermediate distributions, which ultimately give us samples from our original target. Our experiments on combinatorial optimization problems demonstrate that this approach consistently improves the performance of existing sampling methods, enabling scientists to study complex systems that were previously too difficult to simulate accurately."
Poster,SANA 1.5: Efficient Scaling of Training-Time and Inference-Time Compute in Linear Diffusion Transformer,https://ICML.cc//virtual/2025/poster/46604,"Enze Xie, Junsong Chen, Yuyang Zhao, Jincheng YU, Ligeng Zhu, Yujun Lin, Zhekai Zhang, Muyang Li, Junyu Chen, Han Cai, Bingchen Liu, Zhou Daquan, Song Han","This paper presents SANA-1.5, a linear Diffusion Transformer for efficient scaling in text-to-image generation. Building upon SANA-1.0, we introduce three key innovations: (1) Efficient Training Scaling: A depth-growth paradigm that enables scaling from 1.6B to 4.8B parameters with significantly reduced computational resources, combined with a memory-efficient 8-bit optimizer.   (2) Model Depth Pruning: A block importance analysis technique for efficient model compression to arbitrary sizes with minimal quality loss.  (3) Inference-time Scaling: A repeated sampling strategy that trades computation for model capacity, enabling smaller models to match larger model quality at inference time. Through these strategies, SANA-1.5 achieves a text-image alignment score of 0.72 on GenEval, which can be further improved to 0.80 through inference scaling, establishing a new SoTA on GenEval benchmark. These innovations enable efficient model scaling across different compute budgets while maintaining high quality, making high-quality image generation more accessible.","Creating high-quality images from text descriptions typically requires massive computing power, putting advanced AI image generation out of reach for many researchers and developers.We developed SANA-1.5, a smarter AI system that achieves top-tier image generation while being dramatically more efficient. Our key breakthroughs include:1. A ""growing"" training method that builds larger models using 60% less computing power2. A compression technique that shrinks models without losing quality3. A clever sampling trick that lets smaller models temporarily boost their capabilitiesThese innovations allow SANA-1.5 to match or exceed the performance of systems like Stable Diffusion XL while being more accessible. On standard tests, it achieves record-breaking accuracy in matching images to text descriptions (80% alignment score when using our sampling boost).By making advanced image generation more efficient, SANA-1.5 helps democratize AI creativity - enabling more researchers to experiment with the technology and developers to integrate it into applications without needing expensive hardware."
Poster,SAND: One-Shot Feature Selection with Additive Noise Distortion,https://ICML.cc//virtual/2025/poster/44170,"Pedram Pad, Hadi Hammoud, Mohamad Dia, nadim maamari, Liza Dunbar","Feature selection is a critical step in data-driven applications, reducing input dimensionality to enhance learning accuracy, computational efficiency, and interpretability. Existing state-of-the-art methods often require post-selection retraining and extensive hyperparameter tuning, complicating their adoption. We introduce a novel, non-intrusive feature selection layer that, given a target feature count $k$, automatically identifies and selects the $k$ most informative features during neural network training. Our method is uniquely simple, requiring no alterations to the loss function, network architecture, or post-selection retraining. The layer is mathematically elegant and can be fully described by:\begin{align}\nonumber\tilde{x}_i = a_i x_i + (1-a_i)z_i\end{align}where $x_i$ is the input feature, $\tilde{x}_i$ the output, $z_i$ a Gaussian noise, and $a_i$ trainable gain such that $\sum_i{a_i^2}=k$.This formulation induces an automatic clustering effect, driving $k$ of the $a_i$ gains to $1$ (selecting informative features) and the rest to $0$ (discarding redundant ones) via weighted noise distortion and gain normalization. Despite its extreme simplicity, our method achieves competitive performance on standard benchmark datasets and a novel real-world dataset, often matching or exceeding existing approaches without requiring hyperparameter search for $k$ or retraining. Theoretical analysis in the context of linear regression further validates its efficacy. Our work demonstrates that simplicity and performance are not mutually exclusive, offering a powerful yet straightforward tool for feature selection in machine learning.","Feature selection is one of the long-standing and important problems in machine learning, artificial intelligence, signal processing, and related fields. It involves identifying the most relevant input variables to improve model performance, reduce complexity, and enhance interpretability. In our work, we propose a simple and efficient method that adds a special layer at the very beginning of a neural network. This layer performs feature selection automatically during training, without changing the loss function or the rest of the architecture. As a result, by the end of training, the network is both trained and the key features are selected. Unlike most existing methods, our approach offers direct control over the number of selected features and does not require any search over additional hyperparameters."
Poster,SAN: Hypothesizing Long-Term Synaptic Development and Neural Engram Mechanism in Scalable Model's Parameter-Efficient Fine-Tuning,https://ICML.cc//virtual/2025/poster/46049,"Gaole Dai, Chun-Kai Fan, Yiming Tang, Zhi Zhang, Yuan Zhang, Yulu Gan, Qizhe Zhang, Cheng-Ching Tseng, Shanghang Zhang, Tiejun Huang","Advances in Parameter-efficient Fine-tuning (PEFT) bridged the performance gap with Full Fine-Tuning (FFT) through sophisticated analysis of pre-trained parameter spaces. Starting from drawing insights from Neural Engrams (NE) in Biological Neural Networks (BNNs), we establish a connection between the low-rank property observed during PEFT's parameter space shifting and neurobiological mechanisms. This observation leads to our proposed method, **S**ynapse and **N**euron (**SAN**), which decomposes and propagates the scaling component from anterior feature adjustment vectors towards posterior weight matrices. Our approach is theoretically grounded in Long-Term Potentiation/Depression (LTP/D) phenomena, which govern synapse development through neurotransmitter release modulation. Extensive experiments demonstrate its effectiveness: on **vision tasks** across VTAB, FGVC, and GIC (25 datasets) using ViT, Swin-T and ConvNeXt architectures, SAN outperforms FFT up to *8.7%* and LoRA by *3.2%*; on **language tasks** using Commonsense Reasoning (8 datasets) with LLaMA models (all generations), surpassing ChatGPT up to *8.5%* and LoRA by *4.7%*; on **vision-language tasks** using Visual Instruction Tuning (7 datasets) with LLaVA models, it exceeds FFT up to *2.4%* and LoRA by *1.9%*. Our code and W&B log will be released","How can we teach massive AI models new skills without the huge cost and effort of retraining them entirely? Current efficient methods help, but we looked to the human brain for a smarter way.Our research introduces a method called Synapse and Neuron (SAN). It's inspired by how our brains efficiently learn by strengthening or weakening connections between neurons—a process linked to how memories form. SAN mimics this by observing early adjustments as an AI learns a new task. It then intelligently passes on a ""scaling"" signal to later parts of the model, preparing them effectively without adding new trainable components.Remarkably, SAN significantly boosted performance on diverse tasks—analyzing images, understanding language, and even combined visual-language challenges. It outperformed traditional full retraining by up to 8.7% and another popular efficient technique, LoRA, by up to 4.7% across various benchmarks. Our brain-inspired ""plug-and-play"" approach offers a more efficient and powerful path for adapting large AI models to new challenges."
Poster,Sanity Checking Causal Representation Learning on a Simple Real-World System,https://ICML.cc//virtual/2025/poster/44652,"Juan L. Gamella, Simon Bing, Jakob Runge","We evaluate methods for causal representation learning (CRL) on a simple, real-world system where these methods are expected to work. The system consists of a controlled optical experiment specifically built for this purpose, which satisfies the core assumptions of CRL and where the underlying causal factors---the inputs to the experiment---are known, providing a ground truth. We select methods representative of different approaches to CRL and find that they all fail to recover the underlying causal factors. To understand the failure modes of the evaluated algorithms, we perform an ablation on the data by substituting the real data-generating process with a simpler synthetic equivalent. The results reveal a reproducibility problem, as most methods already fail on this synthetic ablation despite its simple data-generating process. Additionally, we observe that common assumptions on the mixing function are crucial for the performance of some of the methods but do not hold in the real data. Our efforts highlight the contrast between the theoretical promise of the state of the art and the challenges in its application. We hope the benchmark serves as a simple, real-world sanity check to further develop and validate methodology, bridging the gap towards CRL methods that work in practice. We make all code and datasets publicly available at <anonymized>.","Making machine learning algorithms reason about the world using causal models is an active and open field of research, which promises to overcome many of the great challenges that current algorithms face. Progress in this field is theory-driven and evidence that these theoretical advances translate to the real world are largely missing.We address this gap between theory and real-world application by designing an experimental sanity check for algorithms that should learn causal variables and models from observational data. Our setup closely follows the assumptions required by the methods' theory and is so simple that we would expect the tested methods to easily succeed. However, our results show that none of the methods we look at pass our sanity check, indicating that existing approaches are not readily applicable to realistic data.Our work provides a controlled environment in which researchers can test their existing algorithms, or develop new ones on, with a focus on guiding development with real-world data in mind. We show that there is still a significant gap between theoretical advances an real-world applicability and we hope that our framework can break this gap down into manageable steps."
