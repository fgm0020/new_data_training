type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Feasible Action Search for Bandit Linear Programs via Thompson Sampling,https://ICML.cc//virtual/2025/poster/45807,"Aditya Gangrade, Aldo Pacchiano, Clay Scott, Venkatesh Saligrama","We study the 'feasible action search' (FAS) problem for linear bandits, wherein a learner attempts to discover a feasible point for a set of linear constraints $\Phi_* a \ge 0,$ without knowledge of the matrix $\Phi_* \in \mathbb{R}^{m \times d}$. A FAS learner selects a sequence of actions $a_t,$ and uses observations of the form $\Phi_* a_t + \mathrm{noise}$ to either find a point with nearly optimal 'safety margin', or detect that the constraints are infeasible, where the safety margin of an action measures its (signed) distance from the constraint boundary. While of interest in its own right, the FAS problem also directly addresses a key deficiency in the extant theory of 'safe linear bandits' (SLBs), by discovering a safe initialisation for low-regret SLB methods.We propose and analyse a novel efficient FAS-learner. Our method, FAST, is based on Thompson Sampling. It applies a _coupled_ random perturbation to an estimate of $\Phi_*,$ and plays a maximin point of a game induced by this perturbed matrix. We prove that FAST stops in $\tilde{O}(d^3/\varepsilon^2 M_*^2)$ steps, and incurs $\tilde{O}(d^3/|M_*|)$ safety costs, to either correctly detect infeasibility, or output a point that is at least $(1-\varepsilon) M_*$-safe, where $M_*$ is the _optimal safety margin_ of $\Phi_*$. Further, instantiating prior SLB methods with the output of FAS yields the first SLB methods that incur $\tilde{O}(\sqrt{d^3 T/M_*^2})$ regret and $O(1)$ risk without a priori knowledge of a safe action. The main technical novelty lies in the extension of Thompson Sampling to this multiobjective setting, for which we both propose a coupled noise design, and provide an analysis that avoids convexity considerations.","Practical engineering and scientific disciplines often need to find processes that satisfy a number of objectives that lie in tension with one-another. Our work describes a new method, FAST, that allows efficient and intelligent trial-and-error to quickly find a process that achieves a nearly 'best-possible,' i.e., minimax, balance between such objectives. FAST observes the results of previous experiments to select which process to try next, i.e., it is a ""sequential experimental design"". While there were some prior methods that could be used to solve this task, these methods were computationally very slow, and would have taken days or years of computation to pick the right processes to try. Our method, which is based on a technique called Thompson Sampling (TS), instead reduces this time to seconds, while using nearly the fewest-possible number of experiments (in a certain technical sense). Our basic technical contribution is to allow TS-like techniques to work with many objectives, while prior understanding of TS dealt with only one objective. For this, we both developed a new algorithmic design in the form a ""coupled noise"", and developed new wys to mathematically analyse TS with many objectives. Since the method is general, it may serve to help practitioners in diverse fields such as manufacturing, control, and resource-allocation to quickly discover good processes that balance the many needs they must address."
Poster,FEAT-KD: Learning Concise Representations for Single and Multi-Target Regression via TabNet Knowledge Distillation,https://ICML.cc//virtual/2025/poster/46151,"Kei Sen Fong, Mehul Motani","In this work, we propose a novel approach that combines the strengths of FEAT and TabNet through knowledge distillation (KD), which we term FEAT-KD. FEAT is an intrinsically interpretable machine learning (ML) algorithm that constructs a weighted linear combination of concisely-represented features discovered via genetic programming optimization, which can often be inefficient. FEAT-KD leverages TabNet's deep-learning-based optimization and feature selection mechanisms instead. FEAT-KD finds a weighted linear combination of concisely-represented, symbolic features that are derived from piece-wise distillation of a trained TabNet model. We analyze FEAT-KD on regression tasks from two perspectives: (i) compared to TabNet, FEAT-KD significantly reduces model complexity while retaining competitive predictive performance, effectively converting a black-box deep learning model into a more interpretable white-box representation, (ii) compared to FEAT, our method consistently outperforms in prediction accuracy, produces more compact models, and reduces the complexity of learned symbolic expressions. In addition, we demonstrate that FEAT-KD easily supports multi-target regression, in which the shared features contribute to the interpretability of the system. Our results suggest that FEAT-KD is a promising direction for interpretable ML, bridging the gap between deep learning's predictive power and the intrinsic transparency of symbolic models.","Many practical problems, such as those in healthcare, benefit from models that balance accuracy with explainability. In this work, we focus on tabular data. For tabular data, deep learning methods like TabNet often achieve strong performance but can be hard to interpret. Symbolic approaches like FEAT produce transparent formulas (e.g., a weighted sum of a few simple feature transformations) but can take a long time to find those formulas. FEAT-KD bridges this gap by first training a TabNet model on the dataset to learn which inputs matter most at each step. For each of TabNet’s internal steps, FEAT-KD uses the selected raw features to search for a concise equation that mimics TabNet’s learned transformation. Once all such distilled features are found, FEAT-KD fits a straightforward linear regression over them to predict the target. In many cases, this yields a model with accuracy close to TabNet’s while being much easier to inspect. Because the same distilled features can be reused, FEAT-KD also handles multi‐target regression naturally. Thus, FEAT-KD aims to combine much of TabNet’s predictive ability with a fully transparent, symbolic representation."
Poster,"FeatSharp: Your Vision Model Features, Sharper",https://ICML.cc//virtual/2025/poster/44186,"Mike Ranzinger, Greg Heinrich, Pavlo Molchanov, Bryan Catanzaro, Andrew Tao","The feature maps of vision encoders are fundamental to myriad modern AI tasks, ranging from core perception algorithms (e.g. semantic segmentation, object detection, depth perception, etc.) to modern multimodal understanding in vision-language models (VLMs). Currently, in computer vision, the frontier of general purpose vision backbones is Vision Transformers (ViT), typically trained using contrastive loss (e.g. CLIP). A key problem with most off-the-shelf ViTs, particularly CLIP, is that these models are inflexibly low resolution. Most run at $224 \times 224$px, while the ""high-resolution"" versions are around $378-448$px, but still inflexible. We introduce a novel method to coherently and cheaply upsample the feature maps of low-resolution vision encoders while picking up on fine-grained details that would otherwise be lost due to resolution. We demonstrate the effectiveness of this approach on core perception tasks as well as within agglomerative model training using RADIO as a way of providing richer targets for distillation. Code available at https://github.com/NVlabs/FeatSharp","Modern computer vision models, while powerful, often lack the ability to process high resolution images, or are only able to produce representations in low resolution. This makes them challenging to use for tasks that require high-res, such as detecting small objects in an image (e.g. find the bird flying in the sky), or labeling every pixel within the scene as some category (e.g. ""bird"", ""sky"", ""tree"", etc.). We present a method for enabling low-res-only vision models to produce hi-res representations by carefully upsampling them, combined with additional passes through the model (called tiling) to get details for small objects that are otherwise not large enough to be encoded properly. In doing so, we demonstrate that we can improve on various dense task benchmarks for numerous base vision models."
Poster,Feature Importance Metrics in the Presence of Missing Data,https://ICML.cc//virtual/2025/poster/45724,"Henrik von Kleist, Joshua Wendland, Ilya Shpitser, Carsten Marr","Feature importance metrics are critical for interpreting machine learning models and understanding the relevance of individual features. However, real-world data often exhibit missingness, thereby complicating how feature importance should be evaluated.  We introduce the distinction between two evaluation frameworks under missing data: (1) feature importance under the full data, as if every feature had been fully measured, and (2) feature importance under the observed data, where missingness is governed by the current measurement policy. While the full data perspective offers insights into the data generating process, it often relies on unrealistic assumptions and cannot guide decisions when missingness persists at model deployment. Since neither framework directly informs improvements in data collection, we additionally introduce the feature measurement importance gradient (FMIG), a novel, model-agnostic metric that identifies features that should be measured more frequently to enhance predictive performance. Using synthetic data, we illustrate key differences between these metrics and the risks of conflating them.","To understand how machine learning models make predictions, researchers often ask: which pieces of information matter most? This is known as feature importance. For example, in a clinical diagnosis model, we might want to know which symptoms or tests — like blood pressure or lab results — most influence the diagnosis. But in many real-world settings, not all information is available. Tests can be expensive or invasive, so they aren’t performed for every patient. This raises a key question: how should we think about feature importance when some data is missing? We address this by distinguishing between three goals. One asks what feature importance would look like if no data were missing — offering a clean view of each variable’s effect. Another works with the data we actually observe, accepting that missingness will persist in practice. The third asks how we should improve data collection — for example, which tests a hospital should run more often. We introduce a new metric for this third question and provide mathematical tools to compute all three. Using simple simulated datasets, we show how the answers can differ — highlighting the importance of matching the definition of feature importance to the real-world decision at hand."
Poster,Feature Learning beyond the Lazy-Rich Dichotomy: Insights from Representational Geometry,https://ICML.cc//virtual/2025/poster/44480,"Chi-Ning Chou, Hang Le, Yichen Wang, SueYeon Chung","Integrating task-relevant information into neural representations is a fundamental ability of both biological and artificial intelligence systems. Recent theories have categorized learning into two regimes: the rich regime, where neural networks actively learn task-relevant features, and the lazy regime, where networks behave like random feature models. Yet this simple lazy–rich dichotomy overlooks a diverse underlying taxonomy of feature learning, shaped by differences in learning algorithms, network architectures, and data properties. To address this gap, we introduce an analysis framework to study feature learning via the geometry of neural representations. Rather than inspecting individual learned features, we characterize how task-relevant representational manifolds evolve throughout the learning process. We show, in both theoretical and empirical settings, that as networks learn features, task-relevant manifolds untangle, with changes in manifold geometry revealing distinct learning stages and strategies beyond the lazy–rich dichotomy. This framework provides novel insights into feature learning across neuroscience and machine learning, shedding light on structural inductive biases in neural circuits and the mechanisms underlying out-of-distribution generalization.","When you arrive in a new city, how do you learn to get from your hotel to a cozy coffee shop? When researchers train a language model, how does the chatbot learn to solve new math problems? Evidence suggests that both biological neurons in our brain and artificial neurons in machine learning models learn to encode certain “features” relevant to the task they’re trained on—like detecting simple image patterns or representing decision variables.However, most neurons don’t neatly represent a single, human-interpretable feature. Instead, useful features are often encoded across complex, high-dimensional patterns of activity spread across many neurons. This mixing makes it hard for researchers to understand how neural networks actually learn to solve problems.In this work, we introduce a new analysis framework to help researchers study feature learning in both biological and artificial systems. Rather than trying to identify features neuron by neuron, we show that you can detect whether a network is learning useful features by examining the geometry of “neural manifolds”—the shapes formed by neural activity patterns. Think of it like organizing your closet: if your clothes are neatly sorted, it’s easier to find what you need. Similarly, when a network learns meaningful features, its internal representations become more organized. This geometric view also helps us distinguish between different learning strategies—like different ways of arranging your wardrobe."
Poster,Feature learning from non-Gaussian inputs: the case of Independent Component Analysis in high dimensions,https://ICML.cc//virtual/2025/poster/44234,"Fabiola Ricci, Lorenzo Bardone, Sebastian Goldt","Deep neural networks learn structured features from complex, non-Gaussian inputs, but the mechanisms behind this process remain poorly understood.   Our work is motivated by the observation that the first-layer filters learnt by deep convolutional neural networks from natural images resemble those learnt by independent component analysis (ICA), a simple unsupervised method that seeks the most non-Gaussian projections of its inputs.   This similarity suggests that ICA provides a simple, yet principled model for studying feature learning.   Here, we leverage this connection to investigate the interplay between data structure and optimisation in feature learning for the most popular ICA algorithm, FastICA, and stochastic gradient descent (SGD), which is used to train deep networks.   We rigorously establish that FastICA requires at least $n\gtrsim d^4$ samples to recover a single non-Gaussian direction from $d$-dimensional inputs on a simple synthetic data model. We show that vanilla online SGD outperforms FastICA, and prove that the optimal sample complexity $n\gtrsim d^2$ can be reached by smoothing the loss, albeit in a data-dependent way. We finally demonstrate the existence of a search phase for FastICA on ImageNet, and discuss how the strong non-Gaussianity of said images compensates for the poor sample complexity of FastICA.","How do neural networks learn to ""see""? Unlike classical machine learning methods, neural networks automatically learn image-processing filters from data -- a key advantage over classical methods, but one that remains poorly understood. The main difficulty for the analysis is that neural networks exploit complex patterns that cannot be captured by simple averages or pair-wise relations between pixels, while existing theories can at most account for pair-wise relations, captured by Gaussian distributions.In this paper, we investigate feature learning by analysing a simpler method, Independent Component Analysis (ICA). ICA seeks to find the most non-Gaussian projections of inputs -- and finds similar filters as neural networks.Comparing the two most popular algorithms for ICA when inputs are large, we find that FastICA requires a lot more data than is theoretically required, while stochastic gradient descent (with a small modification) only requires the theoretical minimum of samples for learning. Since we make some simplifying assumptions on the data, we corroborate our findings in experiments with real images.Our results improve our understanding of how to learn efficiently from the complex correlations in real data, and we provide new technical tools for future analysis."
Poster,Feature-Mapping Topology Optimization with Neural Heaviside Signed Distance Functions,https://ICML.cc//virtual/2025/poster/46233,"Aleksandr Kolomeitsev, ANH-HUY PHAN","Topology optimization plays a crucial role in designing efficient and manufacturable structures. Traditional methods often yield free-form voids that, although providing design flexibility, introduce significant manufacturing challenges and require extensive post-processing. Conversely, feature-mapping topology optimization reduces post-processing efforts by constructing topologies using predefined geometric features. Nevertheless, existing approaches are significantly constrained by the limited set of geometric features available, the variety of parameters that each type of geometric feature can possess, and the necessity of employing differentiable signed distance functions. In this paper, we present a novel method that combines Neural Heaviside Signed Distance Functions (Heaviside SDFs) with structured latent shape representations to generate manufacturable voids directly within the optimization framework. Our architecture incorporates encoder and decoder networks to effectively approximate the Heaviside function and facilitate optimization within a unified latent space, thus addressing the feature diversity limitations of current feature-mapping techniques. Experimental results validate the effectiveness of our approach in balancing structural compliance, offering a new pathway to CAD-integrated design with minimal human intervention.","Designing physical structures — like parts for machines — requires making choices that balance strength, efficiency, and how easily something can be manufactured. Specialized software aids design decisions but still requires manual input to produce manufacturable designs.One promising approach, called Topology Optimization, uses mathematical techniques to decide where material should go in a design to make it strong and lightweight. However, the shapes it produces are often too complex to be manufactured.Our work explores how machine learning can help close this gap. We are developing a framework that emulates real engineers' design principles by creating parts whose voids are represented as combinations of manufacturable geometric building blocks. Specifically, we use a kind of AI model known as a Variational Autoencoder to learn how to represent basic geometric building blocks — like triangles and quadrangles — in a common format. This makes it easier to combine and modify them in ways that meet engineering and manufacturing needs.Rethinking shape representation, our method enables efficient, manufacturable designs. We release open-source code to foster further work and drive automated tools that cut engineer time and accelerate product development."
Poster,Feature out! Let Raw Image as Your Condition for Blind Face Restoration,https://ICML.cc//virtual/2025/poster/43647,"XINMIN QIU, Gege Chen, Bonan Li, Congying Han, Tiande Guo, Zicheng Zhang","Blind face restoration (BFR), which involves converting low-quality (LQ) images into high-quality (HQ) images, remains challenging due to complex and unknown degradations.     While previous diffusion-based methods utilize feature extractors from LQ images as guidance, using raw LQ images directly as the starting point for the reverse diffusion process offers a theoretically optimal solution.     In this work, we propose Pseudo-Hashing Image-to-image Schrödinger Bridge (P-I2SB), a novel framework inspired by optimal mass transport problems, which enhances the restoration potential of Schrödinger Bridge (SB) by correcting data distributions and effectively learning the optimal transport path between any two data distributions.    Notably, we theoretically explore and identify that existing methods are limited by the optimality and reversibility of solutions in SB, leading to suboptimal performance.     Our approach involves preprocessing HQ images during training by hashing them into pseudo-samples according to a rule related to LQ images, ensuring structural similarity in distribution.    This guarantees optimal and reversible solutions in SB, enabling the inference process to learn effectively and allowing P-I2SB to achieve state-of-the-art results in BFR, with more natural textures and retained inference speed compared to previous methods.","Face image restoration (BFR) is critical for applications such as surveillance enhancement and historical photo repair. However, severely degraded inputs (e.g., blur, noise, artifacts) pose significant challenges, as neither the degradations nor their restored outputs are uniquely determined. We propose Pseudo-Hashing Image-to-image Schrödinger Bridge (P-I2SB)，, a novel framework inspired by optimal mass transport problems, which enhances the restoration potential of Schrödinger Bridge (SB) by correcting data distributions and effectively learning the optimal transport path between any two data distributions. Our approach advances restoration quality by explicitly modeling distributional relationships, offering a principled solution for ill-posed face restoration tasks."
Poster,Features are fate: a theory of transfer learning in high-dimensional regression,https://ICML.cc//virtual/2025/poster/43897,"Javan Tahir, Surya Ganguli, Grant Rotskoff","With the emergence of large-scale pre-trained neural networks, methods to adapt such ""foundation"" models to data-limited downstream tasks have become a necessity.Fine-tuning, preference optimization, and transfer learning have all been successfully employed for these purposes when the target task closely resembles the source task, but a precise theoretical understanding of ``task similarity'' is still lacking. We adopt a \emph{feature-centric} viewpoint on transfer learning and establish a number of theoretical results that demonstrate that when the target task is well represented by the feature space of the pre-trained model, transfer learning outperforms training from scratch.We study deep linear networks as a minimal model of transfer learning in which we can analytically characterize the transferability phase diagram as a function of the target dataset size and the feature space overlap.For this model, we establish rigorously that when the feature space overlap between the source and target tasks is sufficiently strong, both linear transfer and fine-tuning improve performance, especially in the low data limit. These results build on an emerging understanding of feature learning dynamics in deep linear networks, and we demonstrate numerically that the rigorous results we derive for the linear case also apply to nonlinear networks.","This paper looks at how and why transfer learning works—especially when you don’t have much data to work with. Transfer learning is a popular machine learning technique where a model trained on one task is reused or adapted to help solve a different, often smaller or harder, task. A common belief is that if two tasks are similar enough—say, they have similar data or patterns—then a model trained on one should work well on the other. However, we show that this assumption doesn’t always hold. We argue that what really matters isn’t how similar the tasks look from the outside, but whether the original model has learned features that are actually useful for the new task.To explore this, we use a simplified type of model called a ""deep linear network,"" which is easier to analyze mathematically. This allows us to clearly see what makes transfer learning succeed or fail. Our key finding is that success depends on whether the new task is aligned with the kinds of patterns, or ""features,"" the model has already learned. If the model’s internal knowledge includes the kinds of patterns needed for the new task, transfer learning can be very effective—even if the tasks don’t seem obviously similar. On the other hand, if the model hasn’t learned anything relevant to the new task, then transferring what it knows won’t help much, and might even hurt performance.Overall, we suggest that instead of relying on surface-level similarities between datasets, we should focus more on whether the model's inner understanding is a good match for the new problem. This insight could help people make better choices when reusing machine learning models, especially in situations where collecting data is expensive or difficult."
Poster,Feature Shift Localization Network,https://ICML.cc//virtual/2025/poster/44983,"Míriam Barrabés, Daniel Mas Montserrat, Kapal Dev, Alexander Ioannidis","Feature shifts between data sources are present in many applications involving healthcare, biomedical, socioeconomic, financial, survey, and multi-sensor data, among others, where unharmonized heterogeneous data sources, noisy data measurements, or inconsistent processing and standardization pipelines can lead to erroneous features. Localizing shifted features is important to address the underlying cause of the shift and correct or filter the data to avoid degrading downstream analysis. While many techniques can detect distribution shifts, localizing the features originating them is still challenging, with current solutions being either inaccurate or not scalable to large and high-dimensional datasets. In this work, we introduce the Feature Shift Localization Network (FSL-Net), a neural network that can localize feature shifts in large and high-dimensional datasets in a fast and accurate manner. The network, trained with a large number of datasets, learns to extract the statistical properties of the datasets and can localize feature shifts from previously unseen datasets and shifts without the need for re-training. The code and ready-to-use trained model are available at \url{https://github.com/AI-sandbox/FSL-Net}.","When combining data from different sources—like medical records from different hospitals or sensor readings from different devices—some measurements may be inconsistent or corrupted due to different collection methods or errors. While we can tell something is wrong with the combined data, pinpointing exactly which measurements are problematic is difficult, especially with large datasets containing many variables.We developed FSL-Net, an AI system that quickly identifies which specific measurements in your data are causing problems. The system learns patterns from thousands of example datasets and can then spot problematic measurements in completely new data without needing additional training—like a quality control inspector who has seen so many products they can instantly spot defects in new items.This helps researchers and analysts clean their data before running important analyses, preventing errors that could lead to wrong conclusions in healthcare, finance, or scientific research. We've made the tool freely available so anyone working with data from multiple sources can ensure their results are reliable."
