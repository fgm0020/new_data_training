type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,CoPINN: Cognitive Physics-Informed Neural Networks,https://ICML.cc//virtual/2025/poster/46458,"Siyuan Duan, Wenyuan Wu, Peng Hu, Zhenwen Ren, Dezhong Peng, Yuan Sun","Physics-informed neural networks (PINNs) aim to constrain the outputs and gradients of deep learning models to satisfy specified governing physics equations, which have demonstrated significant potential for solving partial differential equations (PDEs). Although existing PINN methods have achieved pleasing performance, they always treat both easy and hard sample points indiscriminately, especially ones in the physical boundaries. This easily causes the PINN model to fall into undesirable local minima and unstable learning, thereby resulting in an Unbalanced Prediction Problem (UPP). To deal with this daunting problem, we propose a novel framework named Cognitive Physical Informed Neural Network (CoPINN) that imitates the human cognitive learning manner from easy to hard. Specifically, we first employ separable subnetworks to encode independent one-dimensional coordinates and apply an aggregation scheme to generate multi-dimensional predicted physical variables. Then, during the training phase, we dynamically evaluate the difficulty of each sample according to the gradient of the PDE residuals. Finally, we propose a cognitive training scheduler to progressively optimize the entire sampling regions from easy to hard, thereby embracing robustness and generalization against predicting physical boundary regions. Extensive experiments demonstrate that our CoPINN achieves state-of-the-art performance, particularly significantly reducing prediction errors in stubborn regions.","Partial differential equations (PDEs) can describe the laws of change of natural phenomena in disciplines such as physics, chemistry, and economics. Solving PDEs has a wide range of applications in many fields of science and engineering. Physics-Informed Neural Networks (PINN) is an effective method for solving PDEs and has attracted much attention. However, existing PINN methods always treat both easy and hard sample points indiscriminately, which causes the PINN model to fall into undesirable local minima and unstable learning, thereby resulting in an Unbalanced Prediction Problem (UPP). To deal with this, we propose Cognitive Physics-Informed Neural Networks CoPINN that imitate the human cognitive learning manner from easy to hard, thereby effectively mitigating UPP and promoting the application of the PINN method in real scenarios."
Poster,Core Context Aware Transformers for Long Context Language Modeling,https://ICML.cc//virtual/2025/poster/45555,"Yaofo Chen, Zeng You, Shuhai Zhang, Haokun Li, Yirui Li, Yaowei Wang, Mingkui Tan","Transformer-based Large Language Models (LLMs) have exhibited remarkable success in extensive tasks primarily attributed to self-attention mechanism, which requires a token to consider all preceding tokens as its context to compute attention. However, when the context length L becomes very large (e.g., 128K), the amount of potentially redundant information in the context tends to increase. The redundant context not only hampers the modeling representation performance but also incurs unnecessary computational and storage overhead. In this paper, we propose a plug-and-play Core Context Aware (CCA) Attention for efficient long-context modeling, comprising two complementary modules: 1) Globality-aware pooling module groups input tokens and dynamically compresses each group into one core token based on their significance. In this way, our method automatically focuses and strengthens core context while diminishing redundancy during the learning process, leading to effective long-term dependency modeling. 2) Locality-preserving module incorporates neighboring tokens to preserve local context for detailed representation. Notably, our CCA-Attention is able to replace the self-attention module in existing LLMs with minimal fine-tuning cost. Extensive experimental results show the superiority of our method in both long-context modeling and computational efficiency over state-of-the-art methods.","Transformer-based large language models (LLMs) have achieved great success in many tasks, thanks to a mechanism called self-attention. This mechanism allows a model to consider all previous words (or tokens) as context when processing new information. However, when the context becomes very long—such as 128,000 words—the model often encounters redundant information. This redundancy not only slows down computation but also reduces the model's ability to represent important details effectively. To solve this problem, we developed a plug-and-play solution called **Core Context Aware (CCA) Attention**, which makes long-context modeling more efficient. Our approach has two key components:  1) A **globality-aware pooling module** that compresses less important parts of the context into ""core tokens,"" helping the model focus on the most meaningful information and reduce redundancy.  2) A **locality-preserving module** that retains nearby words to ensure detailed representation of local context. Importantly, our CCA-Attention can replace the self-attention module in existing LLMs with minimal fine-tuning. Experiments show that our method outperforms state-of-the-art techniques in both handling long contexts and improving computational efficiency."
Poster,Core Knowledge Deficits in Multi-Modal Language Models,https://ICML.cc//virtual/2025/poster/45955,"Yijiang Li, Qingying Gao, Tianwei Zhao, Bingyang Wang, Haoran Sun, Haiyun Lyu, Robert Hawkins, Nuno Vasconcelos, Tal Golan, Dezhi Luo, Hokin Deng","While Multi-modal Large Language Models (MLLMs) demonstrate impressive abilities over high-level perception and reasoning, their robustness in the wild remains limited, often falling short on tasks that are intuitive and effortless for humans. We examine the hypothesis that these deficiencies stem from the absence of core knowledge—rudimentary cognitive abilities innate to humans from early childhood. To explore the core knowledge representation in MLLMs, we introduce CoreCognition, a large-scale benchmark encompassing 12 core knowledge concepts grounded in developmental cognitive science.We evaluate 230 models with 11 different prompts, leading to a total of 2,530 data points for analysis. Our experiments uncover four key findings, collectively demonstrating core knowledge deficits in MLLMs: they consistently underperform and show reduced, or even absent, scalability on low-level abilities relative to high-level ones.Finally, we propose Concept Hacking, a novel controlled evaluation method that reveals MLLMs fail to progress toward genuine core knowledge understanding, but instead rely on shortcut learning as they scale.","Despite their impressive performance on perception and reasoning, today’s large AI models still struggle with basic concepts that human infants grasp early in life, such as understanding objects, space, or cause and effect. We wanted to know why.To explore this gap, we built CoreCognition, a test suite inspired by childhood cognitive science, covering 12 fundamental knowledge areas. We then evaluated hundreds of modern AI systems—230 models in total—across more than 1,500 tasks using various prompts. Our findings were revealing: while AIs improve at higher-level tasks, they consistently lag on basic, intuitive ones, and often don’t improve further when scaled up.Finally, we introduce a method called Concept Hacking. This approach digs into how AIs learn, showing that instead of genuinely understanding core ideas, they often rely on superficial shortcuts—learning patterns instead of meaning.Core message: Despite impressive gains, AI still lacks basic common-sense understanding that humans acquire effortlessly in early childhood. Recognizing and testing this gap helps guide future efforts to build models with deeper, more human-level comprehension."
Poster,CoreMatching: A Co-adaptive Sparse Inference Framework with Token and Neuron Pruning for Comprehensive Acceleration of Vision-Language Models,https://ICML.cc//virtual/2025/poster/45781,"Qinsi Wang, Hancheng Ye, Ming-Yu Chung, Yudong Liu, Yueqian Lin, Martin Kuo, Mingyuan Ma, Jianyi Zhang, Yiran Chen","Vision-Language Models (VLMs) excel across diverse tasks but suffer from high inference costs in time and memory. Token sparsity mitigates inefficiencies in token usage, while neuron sparsity reduces high-dimensional computations, both offering promising solutions to enhance efficiency.Recently, these two sparsity paradigms have evolved largely in parallel, fostering the prevailing assumption that they function independently. However, a fundamental yet underexplored question remains: Do they truly operate in isolation, or is there a deeper underlying interplay that has yet to be uncovered?In this paper, we conduct the first comprehensive investigation into this question. By introducing and analyzing the matching mechanism between Core Neurons and Core Tokens, we found that key neurons and tokens for inference mutually influence and reinforce each other. Building on this insight, we propose CoreMatching, a co-adaptive sparse inference framework, which leverages the synergy between token and neuron sparsity to enhance inference efficiency. Through theoretical analysis and efficiency evaluations, we demonstrate that the proposed method surpasses state-of-the-art baselines on ten image understanding tasks and three hardware devices. Notably, on the NVIDIA Titan Xp, it achieved 5$\times$ FLOPs reduction and a 10$\times$ overall speedup.Code is released at [https://github.com/wangqinsi1/2025-ICML-CoreMatching/tree/main](https://github.com/wangqinsi1/2025-ICML-CoreMatching/tree/main).","Modern AI models that understand both images and language are powerful but often slow and resource-hungry. To make them faster, researchers have tried two main strategies: focusing only on the most important pieces of the input (like key words in a sentence or key parts of an image) and reducing the amount of brain-like activity inside the model. So far, these two ideas have mostly been studied separately.In our work, we ask a simple but important question: what if these two strategies actually help each other? We find that the most useful parts of the input and the most important parts of the model tend to match up—and this connection can be used to make the model even more efficient.Based on this insight, we designed a new method called CoreMatching, which smartly selects both the key inputs and the key model components at the same time. This leads to much faster AI with almost no drop in performance. Our approach works well across many vision tasks and devices—on one common graphics card, it runs up to 10 times faster than current methods."
Poster,Correlated Errors in Large Language Models,https://ICML.cc//virtual/2025/poster/44225,"Elliot Myunghoon Kim, Avi Garg, Kenny Peng, Nikhil Garg","Diversity in training data, architecture, and providers is assumed to mitigate homogeneity in LLMs. However, we lack empirical evidence on whether different LLMs differ \textit{meaningfully}. We conduct a large-scale empirical evaluation on over 350 LLMs overall, using two popular leaderboards and a resume-screening task. We find substantial correlation in model errors---on one leaderboard dataset, models agree 60\% of the time when both models err. We identify factors driving model correlation, including shared architectures and providers. Crucially, however, larger and more accurate models have highly correlated errors, even with distinct architectures and providers. Finally, we show the effects of correlation in two downstream tasks: LLM-as-judge evaluation and hiring---the latter reflecting theoretical predictions regarding  algorithmic monoculture.","There are many available LLMs. One hope is these different LLMs offer some diversity. Diversity can be desirable for avoiding systemic failure (like when one job applicant is screened out of all jobs). Here, we study if different LLMs differ in a meaningful way. In particular, we study how correlated LLMs are in how they err. Using three datasets and over 350 LLMs, we find that LLMs agree on the wrong answer far more than they would at random, and that newer LLMs and LLMs from the same company tend to be more correlated. So even if LLMs differ on the surface, they may be converging under the hood."
Poster,Correlation Clustering Beyond the Pivot Algorithm,https://ICML.cc//virtual/2025/poster/45406,"Soheil Behnezhad, Moses Charikar, Vincent Cohen-Addad, Alma Ghafari, Weiyun ma","We study the classic correlation clustering problem. Given $n$ objects and a complete labeling of the object-pairs as either “similar” or “dissimilar”, the goal is to partition the objects intoarbitrarily many clusters while minimizing disagreements with the labels.A classic Pivot algorithm for this problem, due to [Ailon et al STOC'05], obtains a 3-approximation for this problem. Over the years, this algorithm has been successfully implemented in various settings. The downside of the Pivot algorithm is that the approximation analysis of 3 is tight for it. While better approximations have been achieved in some settings, these algorithms are often hard to implement in various settings. For example, [Behnezhad et al FOCS19] showed that the output of Pivot can be maintained in polylog time per update in a dynamic setting, a bound that was improved to constant by [Dalirrooyfard et al ICML'24]. But obtaining a better approximation remains open.In this paper, we present Modified Pivot, an algorithm that locally improves the output of Pivot. Our Modified Pivot algorithm can be implemented just as efficiently as Pivot in various settings. Our experiments show that the output of Modified Pivot on average makes less than 77\% of the mistakes made by Pivot. More surprisingly, we prove theoretically that Modified Pivot has approximation ratio $3-\epsilon_0$ for some absolute constant $\epsilon_0 > 0$. This, e.g., leads to a better than 3 approximation in the dynamic setting in polylog time, improving the 3-approximation obtained by [Behnezhad et al FOCS'19] and [Dalirrooyfard et al ICML'24].","We study the classic correlation clustering problem. Given objects and a complete labeling of the object-pairs as either “similar” or “dissimilar”, the goal is to partition the objects into arbitrarily many clusters while minimizing disagreements with the labels.A well‐known method (called Pivot) does a pretty good job: it picks one object at random, gathers all the objects similar to it into one group, removes them, and repeats until everything is grouped. This approach guarantees you won’t make more than three times as many mistakes in expectation. However, that “three times” bound is the best Pivot can do, and in many practical situations one would like to do a better without adding complexity.In our work, we introduce a change to Pivot that we call Modified Pivot. It still runs just as quickly and easily as the original method, but it makes noticeably fewer mistakes in practice. Our experiments show it typically cuts the number of errors compared to Pivot. Even more importantly, we prove there is a small but definite improvement in the worst‐case guarantee: Modified Pivot makes strictly fewer mistakes than three times the optimum, by some fixed amount. This small but real gain carries over to “dynamic” settings, where labels change over time, giving a more accurate grouping."
Poster,COSDA: Counterfactual-based Susceptibility Risk Framework for Open-Set Domain Adaptation,https://ICML.cc//virtual/2025/poster/43716,"Wenxu Wang, Rui Zhou, Jing Wang, Yun Zhou, Cheng Zhu, Ruichun Tang, Bo Han, Nevin Zhang","Open-Set Domain Adaptation (OSDA) aims to transfer knowledge from the labeled source domain to the unlabeled target domain that contains unknown categories, thus facing the challenges of domain shift and unknown category recognition. While recent works have demonstrated the potential of causality for domain alignment, little exploration has been conducted on causal-inspired theoretical frameworks for OSDA. To fill this gap, we introduce the concept of *Susceptibility* and propose a novel **C**ounterfactual-based susceptibility risk framework for **OSDA**, termed **COSDA**. Specifically, COSDA consists of three novel components: (i) a *Susceptibility Risk Estimator (SRE)* for capturing causal information, along with comprehensive derivations of the computable theoretical upper bound, forming a risk minimization framework under the OSDA paradigm; (ii) a *Contrastive Feature Alignment (CFA)* module, which is theoretically proven based on mutual information to satisfy the *Exogeneity* assumption and facilitate cross-domain feature alignment; (iii) a *Virtual Multi-unknown-categories Prototype (VMP)* pseudo-labeling strategy, providing label information by measuring how similar samples are to known and multiple virtual unknown category prototypes, thereby assisting in open-set recognition and intra-class discriminative feature learning. Extensive experiments demonstrate that our approach achieves state-of-the-art performance.","Machine learning systems often encounter samples with shifting features or previously unseen classes in new environments, leading to significant performance degradation. This challenge has driven the development of neural network adaptation algorithms. From the perspective of causality, such degradation often arises when models rely on features that are spuriously correlated with the class labels. To identify the key causal features, we propose a novel framework, COSDA, with susceptibility risk. COSDA leverages counterfactual tools from causal inference to measure a model’s susceptibility to input features by perturbing them and observing the resulting changes in predictions. Furthermore, COSDA is constructed from the perspectives of the optimizability, computability, and identifiability of susceptibility. To facilitate further research and practical use, we release an open-source repository containing our implementation and detailed configuration settings. This allows other researchers and practitioners to readily apply COSDA to their own open-set domain adaptation problems or related scenarios."
Poster,CoSER: Coordinating LLM-Based Persona Simulation of Established Roles,https://ICML.cc//virtual/2025/poster/46115,"Xintao Wang, Heng Wang, Yifei Zhang, Xinfeng Yuan, Rui Xu, Jen-Tse Huang, Siyu Yuan, Haoran Guo, Jiangjie Chen, Shuchang Zhou, Wei Wang, Yanghua Xiao","Role-playing language agents (RPLAs) have emerged as promising applications of large language models (LLMs). However, simulating established characters presents a challenging task for RPLAs, due to the lack of authentic character datasets and nuanced evaluation methods using such data. In this paper, we present CoSER, a collection of a high-quality dataset, open models, and an evaluation protocol towards effective RPLAs of established characters. The CoSER dataset covers 17,966 characters from 771 renowned books. It provides authentic dialogues with real-world intricacies, as well as diverse data types such as character experiences and internal thoughts. Drawing from acting methodology, we introduce given-circumstance acting for training and evaluating role-playing LLMs, where LLMs sequentially portray multiple characters in book scenes. Using our dataset, we develop CoSER 8B and CoSER 70B, i.e., advanced open role-playing LLMs built on LLaMA-3.1 models. Extensive experiments demonstrate the value of the CoSER dataset for RPLA training, evaluation and retrieval. Moreover, CoSER 70B exhibits state-of-the-art performance surpassing or matching GPT-4o on our evaluation and three existing benchmarks, i.e., achieving 75.80% and 93.47% accuracy on the InCharacter and LifeChoice benchmarks respectively. Our code, dataset and models are available at: https://github.com/Neph0s/CoSER.","Imagine chatting with AI of Harry Potter or Sherlock Holmes and having them respond exactly as they would in their original stories. While AI chatbots have become advanced, creating authentic character roleplay remains challenging: the lack of high-quality datasets and effective evaluation methods. Current systems often fail to capture the unique personalities, speaking patterns, and depth of beloved fictional characters. We present CoSER, a comprehensive collection of high-quality dataset, open models, and novel evaluation methods for authentic AI character roleplay. Our dataset is unprecedented in scale and authenticity: we extracted 29,798 real conversations involving 17,966 characters from 771 renowned books. Unlike previous work that used artificially generated dialogues, CoSER provides authentic interactions directly from acclaimed literature, including not just what characters say, but also their experiences, inner thoughts, actions, and the circumstances surrounding each conversation.We developed ""Given-Circumstance Acting"" (GCA), a novel approach for both evaluating and training AI character roleplay. For evaluation, GCA creates multi-character conversations where AI models portray different characters in authentic book scenes, then assesses their performance using expert-designed criteria. For training, we use this same approach to develop two state-of-the-art AI models, CoSER-8B and CoSER-70B, which learn to portray multiple characters within scenes while understanding context and relationships. Our models achieve remarkable performance, often surpassing advanced systems like GPT-4o, potentially transforming interactive storytelling, AI companion, and entertainment."
Poster,Cost-efficient Collaboration between On-device and Cloud Language Models,https://ICML.cc//virtual/2025/poster/43949,"Avanika Narayan, Dan Biderman, Sabri Eyuboglu, Avner May, Scott Linderman, James Zou, Christopher Re","We investigate an emerging setup in which a small, on-device language model (LM) with access to local data collaborates with a frontier, cloud-hosted LM to solve real-world tasks involving financial, medical, and scientific reasoning over long documents. *Can a local-remote collaboration reduce cloud inference costs while preserving quality?*First, we consider a naïve collaboration protocol, coined MINION, where the local and remote models simply chat back and forth. Because only the local model ingests the full context, this protocol reduces cloud costs by 30.4x, but recovers only 87% of the performance of the frontier model.We identify two key limitations of this protocol: the local model struggles to (1) follow the remote model's multi-step instructions and (2) reason over long contexts. Motivated by these observations, we propose MINIONS, a protocol in which the remote model decomposes the task into easier subtasks over shorter chunks of the document, that are executed locally in parallel. MINIONS reduces costs by 5.7× on average while recovering 97.9% of the remote-only performance. Our analysis reveals several key design choices that influence the trade-off between cost and performance in local-remote systems.","Many organizations wish to apply Large Language Models (LLMs) to large volumes of text. Current frontier models are extremely capable, but are expensive. Smaller language models are getting much better, and so does the hardware or computers and phones which can now run them. But these models on their own lag behind the frontier models and struggle even with simple tasks. We propose a way in which frontier models in the cloud can operate smaller language models on devices, to cut down on cloud costs and preserve accuracy. We show two protocols that achieve that, the strongest of which, called MinionS, cuts down costs by 5.7X and maintains 97.9% of the frontier model accuracy."
Poster,CostFilter-AD: Enhancing Anomaly Detection through Matching Cost Filtering,https://ICML.cc//virtual/2025/poster/46359,"Zhe Zhang, Mingxiu Cai, Hanxiao Wang, Gaochang Wu, Tianyou Chai, Xiatian Zhu","Unsupervised anomaly detection (UAD) seeks to localize the anomaly mask of an input image with respect to normal samples.Either by reconstructing normal counterparts (reconstruction-based) or by learning an image feature embedding space (embedding-based), existing approaches fundamentally rely on image-level or feature-level matching to derive anomaly scores. Often, such a matching process is inaccurate yet overlooked, leading to sub-optimal detection. To address this issue, we introduce the concept of cost filtering, borrowed from classical matching tasks, such as depth and flow estimation, into the UAD problem. We call this approach CostFilter-AD. Specifically, we first construct a matching cost volume between the input and normal samples, comprising two spatial dimensions and one matching dimension that encodes potential matches. To refine this, we propose a cost volume filtering network, guided by the input observation as an attention query across multiple feature layers, which effectively suppresses matching noise while preserving edge structures and capturing subtle anomalies. Designed as a generic post-processing plug-in, CostFilter-AD can be integrated with either reconstruction-based or embedding-based methods. Extensive experiments on MVTec-AD and VisA benchmarks validate the generic benefits of CostFilter-AD for both single- and multi-class UAD tasks. Code and models will be released at https://github.com/ZHE-SAPI/CostFilter-AD.","Have you ever wondered how factories manage to detect tiny defects, such as faint scratches or missing components, across thousands of products that belong to different categories? This task is more difficult than it appears. Many AI systems try to identify defects by comparing new images, which may contain hidden anomalies, with normal ones. However, this matching process is often noisy and inaccurate, especially when defects are small or subtle, leading to missed problems or false alarms.We developed a method called CostFilter-AD to enhance this process. It builds an anomaly cost volume, a detailed map showing how well each part of an image aligns with defect-free patterns. A filtering system then removes noise and highlights important details, making it easier to detect even faint or unusual issues.Our method does not require actual defective examples during training. Since most factory products are normal, the system learns from these alone and can still accurately recognize a wide range of previously unseen anomalies. CostFilter-AD can enhance many existing AI systems, helping manufacturers catch defects early, improve quality control, reduce waste, and deliver more reliable products worldwide."
