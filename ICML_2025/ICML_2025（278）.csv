type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Slimming the Fat-Tail: Morphing-Flow for Adaptive Time Series Modeling,https://ICML.cc//virtual/2025/poster/44444,"Tianyu Liu, kai sun, Fuchun Sun, Yu Luo, Yuanlong Zhang","Temporal sequences, even after stationarization, often exhibit leptokurtic distributions with fat tails and persistent distribution shifts. These properties destabilize feature dynamics, amplify model variance, and hinder model convergence in time series forecasting. To address this, we propose Morphing-Flow (MoF), a framework that combines a spline-based transform layer (Flow) and a test-time-trained method (Morph), which adaptively normalizes non-stationary, fat-tailed distributions while preserving critical extreme features. MoF ensures that inputs remain within a network’s effective activation space—a structured, normal-like distribution—even under distributional drift. Experiments across eight datasets show that MoF achieves state-of-the-art performance: With a simple linear backbone architecture, it matches the performance of state-of-the-art models on datasets such as Electricity and ETTh2. When paired with a patch-based Mamba architecture, MoF outperforms its closest competitor by 6.3% on average and reduces forecasting errors in fat-tailed datasets such as Exchange by 21.7%. Moreover, MoF acts as a plug-and-play module, boosting performance in existing models without architectural changes.","Time series data in the real world—like traffic or energy usage—often contains frequent extreme events that destabilize AI models. We developed a method called Morphing-Flow that reshapes such unpredictable data into a more balanced form while preserving important signals. This helps AI models train more reliably and make better long-term forecasts, especially in chaotic environments where surprises are the norm."
Poster,SLiM: One-shot Quantization and Sparsity with Low-rank Approximation for LLM Weight Compression,https://ICML.cc//virtual/2025/poster/46479,"Mohammad Mozaffari, Amir Yazdanbakhsh, Maryam Mehri Dehnavi","Conventional model compression techniques for LLMs address high memory consumption and slow inference challenges but typically require computationally expensive retraining to preserve accuracy. In contrast, one-shot compression methods eliminate retraining cost, but struggle to achieve accuracy comparable to dense models. This paper presents SLIM, a new one-shot compression framework that holistically integrates hardware-friendly quantization, sparsity, and low-rank approximation into a unified process. First, we formulate the quantization process using a probabilistic approach (SLIM-Quant) that enables us to apply uniform quantization. Then, we use an existing one-shot pruning method to apply semi-structured sparsity on top of the quantized weights. Finally, to compensate for the introduced aggregated quantization and sparsity error, we use a novel saliency function with unique invertible and additive features that enables us tomathematically compute the value of low-rank adapters. SLIM improves model accuracy by up to 5.66% (LLaMA-2-7B) for 2:4 sparsity with 4-bit weight quantization, outperforming prior methods. Models compressed with SLIM achieve up to 4.3× and 3.8× on Nvidia RTX3060 and A100 GPUs, respectively. Additionally, they achieve up to 0.23× end-to-end memory reduction in comparison to their dense counterparts. We also propose an optional PEFT recipe that further improves accuracyby up to 1.66% (LLaMA-2-13B) compared to SLIM without fine-tuning.","Large language models power many AI applications but often demand vast memory and compute resources, making them hard to run on everyday devices or at scale. To address this, we introduce SLiM, a “one-shot” compression method that reduces a model’s size without any expensive retraining by weaving together three contributions: uniform quantization, structured sparsity (pruning), and a low-rank adapter that mathematically corrects the compound errors from the first two steps. SLiM’s quantization step uses a probabilistic search to pick the best scaling factor; its pruning step applies a hardware-friendly pattern; and its low-rank adapter step uses a saliency measure to compute corrections in closed form. The result is an 8× smaller model that reduces the gap between its original accuracy and the compressed model's accuracy (up to 5.66% higher over state-of-the-art) and runs up to 4.3× faster and with up to 0.23× less memory on off-the-shelf GPUs. An optional, lightweight fine-tuning recipe can boost accuracy by another 1.66% with minimal overhead. By packaging SLiM as an easy-to-use tool with code publicly available, we aim to make advanced language models more accessible, energy-efficient, and ready for deployment in real-world environments."
Poster,SMART-PC: Skeletal Model Adaptation for Robust Test-Time Training in Point Clouds,https://ICML.cc//virtual/2025/poster/45641,"Ali Bahri, Moslem Yazdanpanah, Sahar Dastani Oghani, Mehrdad Noori, Gustavo Vargas Hakim, David OSOWIECHI, Farzad Beizaee, Ismail Ben Ayed, Christian Desrosiers","Test-Time Training has emerged as a promising solution to address distribution shifts in 3D point cloud classification. However, existing methods often rely on computationally expensive backpropagation during adaptation, limiting their applicability in real-world, time-sensitive scenarios. In this paper, we introduce SMART-PC, a skeleton-based framework that enhances resilience to corruptions by leveraging the geometric structure of 3D point clouds. During pre-training, our method predicts skeletal representations, enabling the model to extract robust and meaningful geometric features that are less sensitive to corruptions, thereby improving adaptability to test-time distribution shifts.Unlike prior approaches, SMART-PC achieves real-time adaptation by eliminating backpropagation and updating only BatchNorm statistics, resulting in a lightweight and efficient framework capable of achieving high frame-per-second rates while maintaining superior classification performance. Extensive experiments on benchmark datasets, including ModelNet40-C, ShapeNet-C, and ScanObjectNN-C, demonstrate that SMART-PC achieves state-of-the-art results, outperforming existing methods such as MATE in terms of both accuracy and computational efficiency. The implementation is available at: \url{https://github.com/AliBahri94/SMART-PC}.","Modern 3D systems—like those used in robotics—often struggle when real-world conditions change, such as due to weather, lighting, or sensor noise. Our research introduces SMART-PC, a method that helps 3D recognition systems stay accurate even when the input data becomes messy or unexpected. Instead of relying on all surface points of a 3D object, our method first learns a simplified “skeleton” that captures the essential shape. This makes the system better at ignoring noise and generalizing to new conditions. SMART-PC also adapts quickly in real time, making it suitable for practical use in time-sensitive applications. We tested it across several challenging datasets, and it consistently outperformed other methods in both accuracy and speed."
Poster,Smoothed Preference Optimization via ReNoise Inversion for Aligning Diffusion Models with Varied Human Preferences,https://ICML.cc//virtual/2025/poster/45858,"Yunhong Lu, Qichao Wang, Hengyuan Cao, Xiaoyin Xu, Min Zhang","Direct Preference Optimization (DPO) aligns text-to-image (T2I) generation models with human preferences using pairwise preference data. Although substantial resources are expended in collecting and labeling datasets, a critical aspect is often neglected: *preferences vary across individuals and should be represented with more granularity.* To address this, we propose SmPO-Diffusion, a novel method for modeling preference distributions to improve the DPO objective, along with a numerical upper bound estimation for the diffusion optimization objective. First, we introduce a smoothed preference distribution to replace the original binary distribution. We employ a reward model to simulate human preferences and apply preference likelihood averaging to improve the DPO loss, such that the loss function approaches zero when preferences are similar. Furthermore, we utilize an inversion technique to simulate the trajectory preference distribution of the diffusion model, enabling more accurate alignment with the optimization objective. Our approach effectively mitigates issues of excessive optimization and objective misalignment present in existing methods through straightforward modifications. Experimental results demonstrate that our method achieves state-of-the-art performance in preference evaluation tasks, surpassing baselines across various metrics, while reducing the training costs.","(1) When training AI systems to generate images using ""thumbs up/down"" feedback, current methods treat everyone’s preferences as identical—like asking people to rate art as only ""good"" or ""bad,"" ignoring the rich diversity of human taste. (2) We created SmPO-Diffusion, a new technique that captures subtle differences in preferences. Imagine a ""virtual jury"" that mimics how different people might score an image. We then teach the AI to balance these preferences mathematically, similar to a chef refining a recipe based on diners’ varied feedback. Additionally, we developed a way to track the AI’s creative decisions step-by-step, ensuring it aligns better with what users truly want. (3) Experiments show our method boosts image quality ratings by 16.7%, cuts training time by 79.8%, and generates more creative outputs."
Poster,Smooth Interpolation for Improved Discrete Graph Generative Models,https://ICML.cc//virtual/2025/poster/45438,"Yuxuan Song, Juntong Shi, Jingjing Gong, Minkai Xu, Stefano Ermon, Hao Zhou, Wei-Ying Ma","Though typically represented by the discrete node and edge attributes, the graph topological information can be sufficiently captured by the graph spectrum in a continuous space. It is believed that incorporating the continuity of graph topological information into the generative process design could establish a superior paradigm for graph generative modeling. Motivated by such prior and recent advancements in the generative paradigm, we propose Graph Bayesian Flow Networks (GraphBFN) in this paper, a principled generative framework that designs an alternative generative process emphasizing the dynamics of topological information. Unlike recent discrete-diffusion-based methods, GraphBFNemploys the continuous counts derived from sampling infinite times from a categorical distribution as latent to facilitate a smooth decomposition of topological information, demonstrating enhanced effectiveness. To effectively realize the concept, we further develop an advanced sampling strategy and new time-scheduling techniques to overcome practical barriers and boost performance. Through extensive experimental validation on both generic graph and molecular graph generation tasks, GraphBFN could consistently achieve superior or competitive performance with significantly higher training and sampling efficiency.","How can computers better generate realistic graphs like social networks or molecular structures? Graphs are everywhere-from Facebook connections to the atoms and bonds in medicines. Creating new graphs artificially is challenging because they have complex patterns and relationships.Our paper presents Graph Bayesian Flow Networks (GraphBFN), a new method that generates graphs by treating their structure as continuous information rather than discrete combinations of pieces. Think of it as the difference between a smooth water flow versus individual water droplets - our approach captures the ""flow"" of how graphs could be generated.Traditional methods work with graphs as separate nodes and connections, like building with LEGO blocks. Instead, GraphBFN leverages advanced mathematical concepts inspired by graph spectral theory to represent graph patterns more smoothly—analogous to how artists blend colors gradually from coarse to fine, rather than relying on distinct dots. This allows our method to generate more realistic graphs much faster. Our findings show that GraphBFN creates better-quality graphs while being significantly more efficient than existing methods. This could accelerate drug discovery by generating new molecular structures or help understand complex networks in biology and social sciences."
Poster,"SNS-Bench: Defining, Building, and Assessing Capabilities of  Large Language Models in Social Networking Services",https://ICML.cc//virtual/2025/poster/43831,"Hongcheng Guo, Yue Wang, Shaosheng Cao, Fei zhao, Boyang Wang, Lei Li, Liang Chen, Xinze Lyu, Zhe Xu, Yao Hu, Zhoujun Li","With the rapid advancement of Social Networking Services (SNS), the need for intelligent and efficient interaction within diverse platforms has become more crucial. Large Language Models (LLMs) play an important role in SNS as they possess the potential to revolutionize user experience, content generation, and communication dynamics. However, recent studies focus on isolated SNS tasks rather than a comprehensive evaluation.In this paper, we introduce SNS-Bench, specially constructed for assessing the abilities of large language models from different Social Networking Services, with a wide range of SNS-related information. SNS-Bench encompasses 8 different tasks such as note classification, query content relevance, and highlight words generation in comments. Finally, 6,658 questions of social media text, including subjective questions, single-choice, and multiple-choice questions, are concluded in SNS-Bench. Further, we evaluate the performance of over 25+ current diverse LLMs on our SNS-Bench. Models with different sizes exhibit performance variations, yet adhere to the scaling law.Moreover, we hope provide more insights to revolutionize the techniques of social network services with LLMs.","Social media platforms like Twitter, Instagram, and TikTok are part of our everyday lives. As these platforms grow, it becomes important to make interactions on them smarter and more helpful. Large language models (LLMs) — the same kind of AI behind tools like ChatGPT — could greatly improve how we create content, understand posts, and connect with others online. But until now, most research has only tested these models on narrow tasks, not across the full range of real-world social media needs.We built a new test called SNS-Bench to evaluate how well these AI models perform on different types of social media tasks, like figuring out what a post is about, checking if a comment matches a search, or picking out key words. Our benchmark includes over 6,600 questions and covers eight tasks. By testing more than 25 popular models, we show where they succeed and where they fall short — helping guide better design for future social media tools."
Poster,Socialized Coevolution: Advancing a Better World through Cross-Task Collaboration,https://ICML.cc//virtual/2025/poster/46680,"Xinjie Yao, Yu Wang, Pengfei Zhu, Wanyu LIN, Ruipu Zhao, Zhoupeng Guo, Weihao Li, Qinghua Hu","Traditional machine societies rely on data-driven learning, overlooking interactions and limiting knowledge acquisition from model interplay. To address these issues, we revisit the development of machine societies by drawing inspiration from the evolutionary processes of human societies. Motivated by Social Learning (SL), this paper introduces a practical paradigm of Socialized Coevolution (SC). Compared to most existing methods focused on knowledge distillation and multi-task learning, our work addresses a more challenging problem: not only enhancing the capacity to solve new downstream tasks but also improving the performance of existing tasks through inter-model interactions. Inspired by cognitive science, we propose Dynamic Information Socialized Collaboration (DISC), which achieves SC through interactions between models specialized in different downstream tasks. Specifically, we introduce the dynamic hierarchical collaboration and dynamic selective collaboration modules to enable dynamic and effective interactions among models, allowing them to acquire knowledge from these interactions. Finally, we explore potential future applications of combining SL and SC, discuss open questions, and propose directions for future research, aiming to spark interest in this emerging and exciting interdisciplinary field. Our code will be publicly available at https://github.com/yxjdarren/SC.","Current machine learning systems predominantly rely on isolated, data-driven models, neglecting the interactive dynamics among models. This limitation hampers their ability to efficiently acquire knowledge and adapt across multiple downstream tasks.Inspired by the evolutionary and social learning processes of human societies, we propose a practical paradigm termed Socialized Coevolution (SC). Our approach enables dynamic and effective interactions among specialized models through mechanisms such as dynamic hierarchical and selective collaboration, fostering knowledge exchange and joint improvement.This paradigm advances beyond traditional knowledge distillation and multi-task learning by simultaneously enhancing performance on both new and existing tasks. It opens promising directions for developing intelligent systems capable of collaborative learning, with broad implications for interdisciplinary machine learning research and practical applications."
Poster,Softmax is not Enough (for Sharp Size Generalisation),https://ICML.cc//virtual/2025/poster/45245,"Petar Veličković, Christos Perivolaropoulos, Federico Barbero, Razvan Pascanu","A key property of reasoning systems is the ability to make sharp decisions on their input data. For contemporary AI systems, a key carrier of sharp behaviour is the softmax function, with its capability to perform differentiable query-key lookups. It is a common belief that the predictive power of networks leveraging softmax arises from ""circuits"" which sharply perform certain kinds of computations consistently across many diverse inputs. However, for these circuits to be robust, they would need to generalise well to arbitrary valid inputs. In this paper, we dispel this myth: even for tasks as simple as finding the maximum key, any learned circuitry must disperse as the number of items grows at test time. We attribute this to a fundamental limitation of the softmax function to robustly approximate sharp functions with increasing problem size, prove this phenomenon theoretically, and propose adaptive temperature as an ad-hoc technique for improving the sharpness of softmax at inference time.","One of the most important components of modern deep learning models (including large language models) is the softmax function, which provides a mechanism for the AI model to carefully focus on the most important parts of the input for answering the given query -- for example, when translating a sentence between languages, an AI system may use softmax to highlight subject-object pairs, or adjective-noun relationships. It has been long presumed that this mechanism is critical for enabling AI systems to perform complex reasoning, and that the detected patterns of attention remain robust for all possible inputs. In our paper we dispel this myth, and show that, as you provide inputs that grow beyond the largest ones the AI has seen during training, the amounts of focus emitted by softmax -- at least, as it is currently leveraged in modern AI systems -- must provably disperse, converging to a situation where the model is unable to significantly focus on any specific part of the input. Appropriately addressing this challenge is therefore important for future work on open-ended or longer-horizon problems with AI."
Poster,Soft Reasoning: Navigating Solution Spaces in Large Language Models through Controlled Embedding Exploration,https://ICML.cc//virtual/2025/poster/46470,"Qinglin Zhu, Runcong Zhao, Hanqi Yan, Yulan He, Yudong Chen, Lin Gui","Large Language Models (LLMs) struggle with complex reasoning due to limited diversity and inefficient search. We propose Soft Reasoning, an embedding-based search framework that optimises the embedding of the first token to guide generation. It combines (1) embedding perturbation for controlled exploration and (2) Bayesian optimisation to refine embeddings via a verifier-guided objective, balancing exploration and exploitation. This approach improves reasoning accuracy and coherence while avoiding reliance on heuristic search. Experiments demonstrate superior correctness with minimal computation, making it a scalable, model-agnostic solution.","Large language models (LLMs), such as ChatGPT, can perform impressive tasks but often fail when faced with complex reasoning problems. Typically, these models struggle because they explore possible answers inefficiently, either sticking too closely to predictable paths or introducing excessive randomness. To address this, we developed a method called Soft Reasoning, which carefully guides these models to explore different potential solutions more efficiently and accurately.Instead of letting the model randomly guess, we slightly adjust its internal ""thought process"" at the very start of generating an answer. Specifically, we introduce tiny, controlled changes (like gentle nudges) to the model's initial direction, then refine these changes based on how promising each initial guess looks. Using a method called Bayesian optimisation, our approach systematically explores better starting points without random guessing or manual fine-tuning.Our experiments show that Soft Reasoning significantly improves the accuracy of answers from LLMs on challenging reasoning tasks, while using far fewer resources. This makes our approach highly scalable and widely applicable to different language models. Ultimately, our research helps models like ChatGPT reason more effectively, making them more reliable for solving complex problems in various real-world applications."
Poster,SOLD: Slot Object-Centric Latent Dynamics Models for Relational Manipulation Learning from Pixels,https://ICML.cc//virtual/2025/poster/44962,"Malte Mosbach, Jan Ewertz, Angel Villar-Corrales, Sven Behnke","Learning a latent dynamics model provides a task-agnostic representation of an agent's understanding of its environment. Leveraging this knowledge for model-based reinforcement learning (RL) holds the potential to improve sample efficiency over model-free methods by learning from imagined rollouts. Furthermore, because the latent space serves as input to behavior models, the informative representations learned by the world model facilitate efficient learning of desired skills. Most existing methods rely on holistic representations of the environment’s state. In contrast, humans reason about objects and their interactions, predicting how actions will affect specific parts of their surroundings. Inspired by this, we propose *Slot-Attention for Object-centric Latent Dynamics (SOLD)*, a novel model-based RL algorithm that learns object-centric dynamics models in an unsupervised manner from pixel inputs. We demonstrate that the structured latent space not only improves model interpretability but also provides a valuable input space for behavior models to reason over. Our results show that SOLD outperforms DreamerV3 and TD-MPC2 - state-of-the-art model-based RL algorithms - across a range of multi-object manipulation environments that require both relational reasoning and dexterous control. Videos and code are available at https:// slot-latent-dynamics.github.io.","Teaching robots and game-playing agents is often time-consuming because most algorithms take in every pixel instead of the handful of objects that really matter. Humans, by contrast, effortlessly track the coffee mug, the table, and our hand, and predict how each will move when we act. Our work aims to bring that object-level common sense to machines. We built SOLD, a system that receives video sequences and, with no human labels, splits the scene into individual “slots” - one compact representation per object. It then learns how each slot changes over time, letting the agent imagine how the scene will evolve under different actions. Because the agent reasons in terms of objects, its inner workings are easier for people to inspect. In simulated tasks where a robot must reason over multiple objects in a scene and manipulate a specific one, SOLD masters the required skills faster and more reliably than today’s best methods.This efficiency could help to cut training costs for real-world robots and make them more interpretable, because we can see what objects they are paying attention to in order to select their action."
