type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Discovering Latent Causal Graphs from Spatiotemporal Data,https://ICML.cc//virtual/2025/poster/45019,"Kun Wang, Sumanth Varambally, Duncan Watson-Parris, Yian Ma, Rose Yu","Many important phenomena in scientific fields like climate, neuroscience, and epidemiology are naturally represented as spatiotemporal gridded data with complex interactions.  Inferring causal relationships from these data is a challenging problem compounded by the high dimensionality of such data and the correlations between spatially proximate points. We present SPACY (SPAtiotemporal Causal discoverY), a novel framework based on variational inference, designed to model latent time series and their causal relationships from spatiotemporal data. SPACY alleviates the high-dimensional challenge by discovering causal structures in the latent space. To aggregate spatially proximate, correlated grid points, we use spatial factors, parametrized by spatial kernel functions, to map observational time series to latent representations. Theoretically, we generalize the problem to a continuous spatial domain and establish identifiability when the observations arise from a nonlinear, invertible function of the product of latent series and spatial factors. Using this approach, we avoid assumptions that are often unverifiable, including those about instantaneous effects or sufficient variability. Empirically, SPACY outperforms state-of-the-art baselines on synthetic data, even in challenging settings where existing methods struggle, while remaining scalable for large grids. SPACY also identifies key known phenomena from real-world climate data. An implementation of SPACY is available at \url{https://github.com/Rose-STL-Lab/SPACY/}","Many important problems — like tracking weather, brain activity, or disease outbreaks — involve data that change across both space and time, with nearby locations often affecting each other. Figuring out how changes in one area lead to changes in another is important but difficult, because there are so many data points and nearby locations often carry similar information.We developed SPACY, a tool that first compresses the large grid of data into a smaller set of time series, then uncovers how these series influence each other. By grouping nearby locations, SPACY reduces redundant information and focuses on meaningful connections. In tests with simulated data, SPACY accurately finds true cause-and-effect relationships even when other methods struggle. We also validate SPACY by applying it to climate data, where it successfully identifies known climate patterns. Because it works with compressed data, SPACY can handle large datasets, making it useful for studying complex systems in climate science, neuroscience, and public health. The code is freely available for others to use."
Poster,Discovering Physics Laws of Dynamical Systems via Invariant Function Learning,https://ICML.cc//virtual/2025/poster/44382,"Shurui Gui, Xiner Li, Shuiwang Ji","We consider learning underlying laws of dynamical systems governed by ordinary differential equations (ODE). A key challenge is how to discover intrinsic dynamics across multiple environments while circumventing environment-specific mechanisms. Unlike prior work, we tackle more complex environments where changes extend beyond function coefficients to entirely different function forms. For example, we demonstrate the discovery of ideal pendulum's natural motion $\alpha^2 \sin{\theta_t}$ by observing pendulum dynamics in different environments, such as the damped environment $\alpha^2 \sin(\theta_t) - \rho \omega_t$ and powered environment $\alpha^2 \sin(\theta_t) + \rho \frac{\omega_t}{\left|\omega_t\right|}$. Here, we formulate this problem as an *invariant function learning* task and propose a new method, known as **D**isentanglement of **I**nvariant **F**unctions (DIF), that is grounded in causal analysis. We propose a causal graph and design an encoder-decoder hypernetwork that explicitly disentangles invariant functions from environment-specific dynamics. The discovery of invariant functions is guaranteed by our information-based principle that enforces the independence between extracted invariant functions and environments. Quantitative comparisons with meta-learning and invariant learning baselines on three ODE systems demonstrate the effectiveness and efficiency of our method. Furthermore, symbolic regression explanation results highlight the ability of our framework to uncover intrinsic laws.","Many natural systems, like swinging pendulums or spreading diseases, follow rules that stay the same even when the environment changes. Our goal is to uncover these hidden rules, even when different situations make the system behave differently. For example, a pendulum swings differently in air, water, or when powered by a motor, but the basic motion rule stays the same. We created a new method called DIF that helps find these shared rules by separating what’s common from what’s specific to each environment. Our method learns from different examples and uses ideas from cause-and-effect reasoning to make sure it finds only the shared physical laws. We tested it on several systems and showed that it works better than existing methods, even revealing clear formulas that describe how the systems behave."
Poster,Discovering Spoofing Attempts on Language Model Watermarks,https://ICML.cc//virtual/2025/poster/44414,"Thibaud Gloaguen, Nikola Jovanović, Robin Staab, Martin Vechev","LLM watermarks stand out as a promising way to attribute ownership of LLM-generated text. One threat to watermark credibility comes from spoofing attacks, where an unauthorized third party forges the watermark, enabling it to falsely attribute arbitrary texts to a particular LLM. Despite recent work demonstrating that state-of-the-art schemes are, in fact, vulnerable to spoofing, no prior work has focused on post-hoc methods to discover spoofing attempts. In this work, we for the first time propose a reliable statistical method to distinguish spoofed from genuinely watermarked text, suggesting that current spoofing attacks are less effective than previously thought. In particular, we show that regardless of their underlying approach, all current learning-based spoofing methods consistently leave observable artifacts in spoofed texts, indicative of watermark forgery. We build upon these findings to propose rigorous statistical tests that reliably reveal the presence of such artifacts and thus demonstrate that a watermark has been spoofed. Our experimental evaluation shows high test power across all learning-based spoofing methods, providing insights into their fundamental limitations and suggesting a way to mitigate this threat.","Detecting unauthorized uses of AI-generated text is crucial, especially given the growing risk of potential misuse (academic cheating, automated disinformation campaigns…). A promising way to identify such texts involves adding hidden signals in the generated text, or watermarks, to attribute their origin to specific language models, thus holding the model providers accountable for misuse. However, recent methods have emerged allowing attackers to forge these watermarks, falsely attributing texts to certain models and threatening the credibility of this identification method.In our research, we discovered that current forgery methods—despite their apparent effectiveness—consistently leave subtle but detectable traces in the text. By studying these traces, we developed statistical tests that can reliably differentiate between genuinely watermarked texts and forged ones. Our experiments showed that our approach works effectively across various watermarking schemes and forgery methods.This research provides practical tools to maintain the trustworthiness of AI-generated text, empowering model providers to detect and eliminate forgery attempts, thus making it significantly more difficult for attackers to discredit watermarks through forgery."
Poster,Discovering Symbolic Cognitive Models from Human and Animal Behavior,https://ICML.cc//virtual/2025/poster/44627,"Pablo Samuel Castro, Nenad Tomasev, Ankit Anand, Navodita Sharma, Rishika Mohanta, Aparna Dev, Kuba Perlin, Siddhant Jain, Kyle Levin, Noemi Elteto, Will Dabney, Alexander Novikov, Glenn Turner, Maria Eckstein, Nathaniel Daw, Kevin Miller, Kimberly Stachenfeld","Symbolic models play a key role in cognitive science, expressing computationally precise hypotheses about how the brain implements a cognitive process. Identifying an appropriate model typically requires a great deal of effort and ingenuity on the part of a human scientist.Here, we adapt FunSearch (Romera-Paredes et al. 2024), a recently developed tool that uses Large Language Models (LLMs) in an evolutionary algorithm, to automatically discover symbolic cognitive models that accurately capture human and animal behavior.We consider datasets from three species performing a classic reward-learning task that has been the focus of substantial modeling effort, and find that the discovered programs outperform state-of-the-art cognitive models for each.The discovered programs can readily be interpreted as hypotheses about human and animal cognition, instantiating interpretable symbolic learning and decision-making algorithms. Broadly, these results demonstrate the viability of using LLM-powered program synthesis to propose novel scientific hypotheses regarding mechanisms of human and animal cognition.","We adapt FunSearch, a recently developed tool that uses Large Language Models (LLMs) in an evolutionary algorithm, to automatically discover symbolic cognitive models that accurately capture human and animal behavior.We consider datasets from three species performing a classic reward-learning task that has challenged the community, and find that the discovered programs outperform state-of-the-art cognitive models for each.The discovered programs can readily be interpreted as hypotheses about human and animal cognition, instantiating interpretable symbolic learning and decision-making algorithms.Broadly, these results demonstrate the viability of using LLM-powered program synthesis to propose novel scientific hypotheses regarding mechanisms of human and animal cognition."
Poster,Discrepancies are Virtue: Weak-to-Strong Generalization through Lens of Intrinsic Dimension,https://ICML.cc//virtual/2025/poster/43961,"Yijun Dong, Yicheng Li, Yunai Li, Jason Lee, Qi Lei","Weak-to-strong (W2S) generalization is a type of finetuning (FT) where a strong (large) student model is trained on pseudo-labels generated by a weak teacher. Surprisingly, W2S FT often outperforms the weak teacher. We seek to understand this phenomenon through the observation that FT often occurs in intrinsically low-dimensional spaces. Leveraging the low intrinsic dimensionality of FT, we analyze W2S in the ridgeless regression setting from a variance reduction perspective. For a strong student-weak teacher pair with sufficiently expressive low-dimensional feature subspaces $\mathcal{V}_s, \mathcal{V}_w$, we provide an exact characterization of the variance that dominates the generalization error of W2S. This unveils a virtue of discrepancy between the strong and weak models in W2S: the variance of the weak teacher is inherited by the strong student in $\mathcal{V}_s \cap \mathcal{V}_w$, while reduced by a factor of $\mathrm{dim}(\mathcal{V}_s)/N$ in the subspace of discrepancy $\mathcal{V}_w \setminus \mathcal{V}_s$ with $N$ pseudo-labels for W2S. Our analysis further casts light on the sample complexities and the scaling of performance gap recovery in W2S. The analysis is supported by experiments on synthetic regression problems, as well as real vision and NLP tasks.","When fine‑tuning a strong, pretrained student on pseudo‑labels produced by a separately fine‑tuned weak teacher, the student often ends up outperforming its teacher—an effect known as weak‑to‑strong (W2S) generalization. How can this happen when both models have more than enough capacity to learn the true data distribution? We provide a precise answer from the variance reduction perspective.Since finetuning tends to fall in the kernel regime and admit a low intrinsic dimension, we model both weak teacher and strong student as high-dimensional features operating in their respective low‑dimensional subspaces. In the regression setting, we provide an exact characterization of the W2S variance that dominates the generalization error. Our analysis unveils that the larger discrepancy between the weak and strong feature subspaces brings better W2S performance. Intuitively, this is because the pseudo‑label errors coming from teacher features absent in the student subspace act like independent label noise—and that noise is reduced in proportion to $1/N$, with $N$ being the pseudo‑label size."
Poster,Discrepancy Minimization in Input-Sparsity Time,https://ICML.cc//virtual/2025/poster/45157,"Yichuan Deng, Xiaoyu Li, Zhao Song, OMRI WEINSTEIN","A recent work by [Larsen, SODA 2023] introduced a faster combinatorial alternative to Bansal's SDP algorithm for finding a coloring $x \in \\{-1, 1\\}^n$ that approximately minimizes the discrepancy $\mathrm{disc}(A, x) := \\| A x \\|_{\infty}$ of a real-valued $m \times n$ matrix $A$. Larsen's algorithm runs in $\widetilde{O}(mn^2)$ time compared to Bansal's $\widetilde{O}(mn^{4.5})$-time algorithm, with a slightly weaker logarithmic approximation ratio in terms of the hereditary discrepancy of $A$ [Bansal, FOCS 2010]. We present a combinatorial $\widetilde{O}(\mathrm{nnz}(A) + n^3)$-time algorithm with the same approximation guarantee as Larsen's, optimal for tall matrices where $m = \mathrm{poly}(n)$. Using a more intricate analysis and fast matrix multiplication, we further achieve a runtime of $\widetilde{O}(\mathrm{nnz}(A) + n^{2.53})$, breaking the cubic barrier for square matrices and surpassing the limitations of linear-programming approaches [Eldan and Singh, RS\&A 2018]. Our algorithm relies on two key ideas: (i) a new sketching technique for finding a projection matrix with a short $\ell_2$-basis using implicit leverage-score sampling, and (ii) a data structure for efficiently implementing the iterative Edge-Walk partial-coloring algorithm [Lovett and Meka, SICOMP 2015], and using an alternative analysis to enable ``lazy'' batch updates with low-rank corrections. Our results nearly close the computational gap between real-valued and binary matrices, for which input-sparsity time coloring was recently obtained by [Jain, Sah and Sawhney, SODA 2023].","When you split a collection of items into two groups—say red and blue—you often want every predefined subset to be as evenly colored as possible. Mathematicians call the maximum imbalance across all subsets the discrepancy of the coloring. Discrepancy minimization is vital in areas ranging from computational geometry to data privacy, yet the best general-purpose algorithms were far too slow for today’s large, sparse data sets, sometimes taking days to finish. We introduce a new, purely combinatorial algorithm that balances real-valued matrices which enjoys the runtime depends on sparsity of the input data.  These advances let practitioners generate low-discrepancy colorings for million-row problems in minutes instead of hours, unlocking faster solutions in optimization, randomized algorithms, and data analysis."
Poster,Discrete and Continuous Difference of Submodular Minimization,https://ICML.cc//virtual/2025/poster/45938,"George Orfanides, Tim Hoheisel, Marwa El Halabi","Submodular functions, defined on continuous or discrete domains, arise in numerous applications. We study the minimization of the difference of submodular (DS) functions, over both domains, extending prior work restricted to set functions.We show that all functions on discrete domains and all smooth functions on continuous domains are DS. For discrete domains, we observe that DS minimization is equivalent to minimizing the difference of two convex (DC) functions, as in the set function case. We propose a novel variant of the DC Algorithm (DCA) and apply it to the resulting DC Program, obtaining comparable theoretical guarantees as in the set function case. The algorithm can be applied to continuous domains via discretization. Experiments demonstrate that our method outperforms baselines in integer compressive sensing and integer least squares.","Many real-world problems, such as wireless communications, image processing, recommendation systems, and materials property prediction, involve choosing the best combination of variables to optimize a given objective, where the variables take discrete values (e.g., whole numbers). We study a broad class of such problems where the objective has a special mathematical structure: it can be written as the difference between two submodular functions. Submodular functions are functions that exhibit a diminishing returns property, where the value of adding something decreases as more is already included. They occur naturally in various applications. We show that this structure is surprisingly general: any discrete function can be written in this form. Such problems are very hard to solve even approximately. We develop an efficient algorithm to tackle them, which is guaranteed to return locally optimal solutions, in the sense that the solution can't be improved by changing just one variable slightly, e.g., by adding or subtracting one. To do this, we transform the problem to another well-studied type of problem, where variables are continuous (real numbers), and adapt a classical method called the Difference of Convex Algorithm (DCA), commonly used for this kind of problem, to our setting. Our approach can also be used when the variables in the original problem are continuous by approximating the range of values with a grid. We tested our method on two challenging tasks and found that it consistently outperformed existing methods. This work opens up new possibilities for solving challenging real-world problems involving both discrete and continuous variables."
Poster,Discrete Markov Probabilistic Models: An Improved Discrete Score-Based  Framework with sharp convergence bounds under minimal assumptions,https://ICML.cc//virtual/2025/poster/44729,"Le Tuyet Nhi PHAM, Dario Shariatian, Antonio Ocello, Giovanni Conforti, Alain Oliviero Durmus","This paper introduces the Discrete Markov Probabilistic Model (DMPM), a novel algorithm for discrete data generation. The algorithm operates in discrete space, where the noising process is a continuous-time Markov chain that can be sampled exactly via a Poissonian clock that flips labels uniformly at random. The time-reversal process, like the forward noise process, is a jump process, with its intensity governed by a discrete analogue of the classical score function. Crucially, this intensity is proven to be the conditional expectation of a function of the forward process, strengthening its theoretical alignment with score-based generative models while ensuring robustness and efficiency. We further establish convergence bounds for the algorithm under minimal assumptions and demonstrate its effectiveness through experiments on low-dimensional Bernoulli-distributed datasets and high-dimensional binary MNIST data. The results highlight its strong performance in generating discrete structures. This work bridges theoretical foundations and practical applications, advancing the development of effective and theoretically grounded discrete generative modeling.","This paper presents a new algorithm for generating discrete data, like binary patterns or pixel images, using a mathematically grounded approach. The method works by gradually adding and removing noise in a controlled way, allowing it to learn how to produce realistic-looking data. Unlike many existing models, it is specifically designed for data made up of bits. We prove that the method is reliable and efficient, and show in experiments that it works well for both simple and complex datasets. Overall, the paper combines strong theory with practical results to advance how we generate structured, discrete data."
Poster,Discrete Neural Algorithmic Reasoning,https://ICML.cc//virtual/2025/poster/45721,"Gleb Rodionov, Liudmila Prokhorenkova","Neural algorithmic reasoning aims to capture computations with neural networks by training models to imitate the execution of classic algorithms. While common architectures are expressive enough to contain the correct model in the weights space, current neural reasoners struggle to generalize well on out-of-distribution data. On the other hand, classic computations are not affected by distributional shifts as they can be described as transitions between discrete computational states. In this work, we propose to force neural reasoners to maintain the execution trajectory as a combination of finite predefined states. To achieve this, we separate discrete and continuous data flows and describe the interaction between them. Trained with supervision on the algorithm's state transitions, such models are able to perfectly align with the original algorithm. To show this, we evaluate our approach on multiple algorithmic problems and achieve perfect test scores both in single-task and multitask setups. Moreover, the proposed architectural choice allows us to prove the correctness of the learned algorithms for any test data.","Neural networks often struggle to reliably perform algorithmic tasks, especially when tested on data that differs from what they were trained on. Unlike traditional algorithms, which follow precise, predefined steps to guarantee correct results, neural networks can produce unpredictable errors when faced with unfamiliar inputs.In this work, we design neural networks that mimic classical algorithms more closely by enforcing a structured, step-by-step approach. Our key idea is to split the computation into two parts: one that handles discrete, algorithm-like states and another that processes continuous data. By combining these two flows and training the model with explicit guidance on how algorithms transition between states, we ensure the network behaves predictably and correctly—even on unseen or larger-scale inputs.We test our approach on a variety of algorithmic tasks and show that these models achieve perfect accuracy, matching the performance of classical algorithms. Importantly, our method provides guarantees that the learned neural networks will always produce correct results, no matter the input. This advance could lead to more reliable and interpretable AI systems for tasks requiring precise, algorithmic reasoning."
Poster,Discriminative Finetuning of Generative Large Language Models without Reward Models and Human Preference Data,https://ICML.cc//virtual/2025/poster/46619,"Siqi Guo, Ilgee Hong, Vicente Balmaseda, Changlong Yu, Liang Qiu, Xin Liu, Haoming Jiang, Tuo Zhao, Tianbao Yang","Supervised fine-tuning (SFT) has become a crucial step for aligning pretrained large language models (LLMs) using supervised datasets of input-output pairs. However, despite being supervised, SFT is inherently limited by its generative training objective. To address its limitations, the existing common strategy is to follow SFT with a separate phase of preference optimization (PO), which relies on either human-labeled preference data or a strong reward model to guide the learning process. In this paper, we address the limitations of SFT by exploring one of the most successful techniques in conventional supervised learning: discriminative learning. We introduce **Discriminative Fine-Tuning (DFT)**, an improved variant of SFT, which mitigates the burden of collecting human-labeled preference data or training strong reward models. Unlike SFT that employs a generative approach and overlooks negative data, DFT adopts a **discriminative paradigm** that increases the probability of positive answers while suppressing potentially negative ones, aiming for **data prediction** instead of token prediction. Our contributions include: (i) a discriminative probabilistic framework for fine-tuning LLMs by explicitly modeling the discriminative likelihood of an answer among all possible outputs given an input; (ii) efficient algorithms to optimize this discriminative likelihood; and (iii) extensive experiments demonstrating DFT's effectiveness, achieving performance better than SFT and comparable to if not better than SFT→PO. The code can be found at https://github.com/Optimization-AI/DFT.","Training large language models typically involves supervised fine-tuning (SFT) to teach them to generate good responses from input-output examples. However, SFT has a critical limitation — it only teaches what to say, not what to avoid saying, because it focuses on generating correct tokens rather than distinguishing good answers from bad ones. To address this, researchers commonly add a second training phase called preference optimization, which requires expensive human-labeled preference data or reward models.We developed Discriminative Fine-Tuning (DFT), which solves SFT's limitations in a single training stage without needing human preference data or reward models. Instead of just learning to produce good answers like SFT, our method adopts a discriminative approach that increases the probability of correct responses while suppressing potentially incorrect ones. We achieve this by having the model generate its own negative examples during training, then using a framework that compares good answers against bad ones — shifting from token prediction to data prediction.Our experiments show that DFT outperforms standard SFT and matches two-stage training methods. On mathematical reasoning, DFT achieved state-of-the-art results among 7-billion parameter models, reaching 79.15% accuracy on GSM8K. This approach makes high-quality training more accessible by eliminating expensive human annotation requirements."
