type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Contextual Online Decision Making with Infinite-Dimensional Functional Regression,https://ICML.cc//virtual/2025/poster/44427,"Haichen Hu, Rui Ai, Stephen Bates, David Simchi-Levi","Contextual sequential decision-making is fundamental to machine learning, with applications in bandits, sequential hypothesis testing, and online risk control. These tasks often rely on statistical measures like expectation, variance, and quantiles. In this paper, we propose a universal algorithmic framework that learns the full underlying distribution, enabling a unified approach to all contextual online decision-making problems. The challenge lies in the uncountably infinite-dimensional regression, where existing contextual bandit algorithms all yield infinite regret. We innovatively propose an efficient infinite-dimensional functional regression oracle for contextual cumulative distribution functions (CDFs) and model every datum as a combination of context-dependent CDF basis functions. Our analysis reveals that the decay rate of the eigenvalue sequence of the design integral operator governs the regression error rate, and consequently, the utility regret rate. Specifically, when the eigenvalue sequence exhibits a polynomial decay of order $\frac{1}{\gamma}\ge 1$, the utility regret is bounded by $\tilde{O}( T^{\frac{3\gamma+2}{2(\gamma+2)}})$. The case that $\gamma=0$ can recover the existing optimal rate in contextual bandits literature with finite-dimensional regression and so as exponential decay. We also provide a numerical method to compute the eigenvalue sequence of integral operators, enabling the practical implementation of our framework.","Contextual sequential decision-making is fundamental to machine learning, with applications in bandits, sequential hypothesis testing, and online risk control. These tasks often rely on statistical measures like expectation, variance, and quantiles. In this paper, we provide a universal admissible algorithm framework for dealing with all kinds of contextual online decision-making problems that directly learns the whole underlying unknown distribution instead of focusing on individual statistics. The challenge lies in the uncountably infinite-dimensional regression, where existing contextual bandit algorithms all yield infinite regret. To overcome this issue, we propose an efficient infinite-dimensional functional regression oracle for contextual cumulative distribution functions (CDFs). Our analysis reveals that the decay rate of the eigenvalue sequence of the design integral operator governs the regression error rate, and consequently, the utility regret rate. We found that the eigendecay rate provides a principled way to characterize the learnability of infinite-dimensional decision-making problems."
Poster,Contextual Optimization Under Model Misspecification: A Tractable and Generalizable Approach,https://ICML.cc//virtual/2025/poster/44602,"Omar Bennouna, Jiawei Zhang, Saurabh Amin, Asuman Ozdaglar","Contextual optimization problems are prevalent in decision-making applications where historical data and contextual features are used to learn predictive models that inform optimal actions. However, practical applications often suffer from model misspecification due to incomplete knowledge of the underlying data-generating process, leading to suboptimal decisions. Existing approaches primarily address the well-specified case, leaving a critical gap in handling misspecified models. In this paper, we propose a novel Integrated Learning and Optimization (ILO) framework that explicitly accounts for model misspecification by introducing a tractable surrogate loss function with strong theoretical guarantees on generalizability, tractability, and optimality. Our surrogate loss aligns with the true decision performance objective, ensuring robustness to misspecification without imposing restrictive assumptions. The proposed approach effectively mitigates the challenges of non-convexity and non-smoothness in the target loss function, leading to efficient optimization procedures. We provide rigorous theoretical analysis and experimental validation, demonstrating superior performance compared to state-of-the-art methods. Our work offers a principled solution to the practically relevant challenge of model misspecification in contextual optimization.","We study the setting where decisions are made based on predictions given by a machine learning model. We develop a new algorithm that trains machine learning models to take into account the quality of the decision, rather than the accuracy of the prediction. When the model at hand is unable to make perfect predictions, it is unclear whether state of the art approaches are able to make predictions that yield optimal decisions. Our new approach mitigates this gap in the literature and can provably output predictions that yield the best possible decisions."
Poster,Contextures: Representations from Contexts,https://ICML.cc//virtual/2025/poster/46494,"Runtian Zhai, Kai Yang, Burak VARICI, Che-Ping Tsai, Zico Kolter, Pradeep Ravikumar","Despite the empirical success of foundation models, we do not have a systematic characterization of the representations that these models learn. In this paper, we establish the contexture theory.It shows that a large class of representation learning methods can be characterized as learning from the association between the input and a context variable. Specifically, we show that many popular methods aim to approximate the top-d singular functions of the expectation operator induced by the context, in which case we say that the representation learns the contexture.We demonstrate the generality of the contexture theory by proving that representation learning within various learning paradigms -- supervised, self-supervised, and manifold learning -- can all be studied from such a perspective.We prove that representations that learn the contexture are optimal on those tasks that are compatible with the context.One important implication of our theory is that once the model is large enough to approximate the top singular functions, scaling up the model size yields diminishing returns, so further improvement requires better contexts.To this end, we study how to evaluate a context without knowing the downstream tasks. We propose a metric and show by experiments that it correlates well with the actual performance of the encoder on many real datasets.","Foundation models have achieved remarkable empirical success in recent years. Their success largely results from the scaling law -- increasing the model size leads to better performance. However, two questions have not been answered to a satisfactory extent. First, what representations do foundation models learn, and why are these representations useful for a variety of downstream tasks? Second, can increasing the model size always improve the performance?We develop the contexture theory, which shows that foundation models learn representations from the association between the input X and a context variable A. Specifically, they aim to extract the top-d eigenspace of a specific operator called the expectation operator induced by the joint distribution of X and A. Such a representation is useful for a downstream task if the task is compatible with the context. This theory implies that increasing the model size brings the representation closer to the top-d eigenspace, and when they are close enough, further scaling has little benefit.Hence, creating better contexts is essential for further improving pretraining. To this end, we study how to evaluate the usefulness of a context. We propose a metric that quantitatively measures context usefulness. The metric only depends on the spectrum of the expectation operator, and does not need any knowledge of the downstream task. We show that this metric correlates well with the actual error of the pretrained encoder."
Poster,Continual Generalized Category Discovery: Learning and Forgetting from a Bayesian Perspective,https://ICML.cc//virtual/2025/poster/45679,"Hao Dai, Jagmohan Chauhan","Continual Generalized Category Discovery (C-GCD) faces a critical challenge: incrementally learning new classes from unlabeled data streams while preserving knowledge of old classes.     Existing methods struggle with catastrophic forgetting, especially when unlabeled data mixes known and novel categories.     We address this by analyzing C-GCD’s forgetting dynamics through a Bayesian lens, revealing that covariance misalignment between old and new classes drives performance degradation.     Building on this insight, we propose Variational Bayes C-GCD (VB-CGCD), a novel framework that integrates variational inference with covariance-aware nearest-class-mean classification.     VB-CGCD adaptively aligns class distributions while suppressing pseudo-label noise via stochastic variational updates.     Experiments show VB-CGCD surpasses prior art by +15.21% with the overall accuracy in the final session on standard benchmarks.     We also introduce a new challenging benchmark with only 10% labeled data and extended online phases—VB-CGCD achieves a 67.86% final accuracy, significantly higher than state-of-the-art (38.55%), demonstrating its robust applicability across diverse scenarios. Code is available at: https://github.com/daihao42/VB-CGCD","Continual Generalized Category Discovery (C‑GCD) tackles a key problem in machine learning: how to teach a computer to recognize brand‑new categories without forgetting the ones it already knows, all while seeing only unlabeled data over time. Most existing approaches struggle because mixing old and new examples causes the system to “forget” earlier categories—a phenomenon called catastrophic forgetting.We took a fresh look at this issue through a Bayesian lens, discovering that the culprit behind forgetting is when the computer’s internal idea of how old and new categories vary (their “covariances”) gets out of sync. To fix this, we created a new method called Variational Bayes C‑GCD (VB‑CGCD), which uses probabilistic tools to align old and new category patterns.In tests on standard benchmarks, VB-CGCD improved the final accuracy by over 15 percent compared to the previous best. We also designed a tougher challenge—only 10 percent of the data came with labels, and VB‑CGCD achieved nearly 68 percent accuracy, showing it works reliably across varied real‑world scenarios."
Poster,Continual Reinforcement Learning by Planning with Online World Models,https://ICML.cc//virtual/2025/poster/44151,"Zichen Liu, Guoji Fu, Chao Du, Wee Sun Lee, Min Lin","Continual reinforcement learning (CRL) refers to a naturalistic setting where an agent needs to endlessly evolve, by trial and error, to solve multiple tasks that are presented sequentially. One of the largest obstacles to CRL is that the agent may forget how to solve previous tasks when learning a new task, known as catastrophic forgetting. In this paper, we propose to address this challenge by planning with online world models. Specifically, we learn a Follow-The-Leader shallow model online to capture the world dynamics, in which we plan using model predictive control to solve a set of tasks specified by any reward functions. The online world model is immune to forgetting by construction with a proven regret bound of $\mathcal{O}(\sqrt{K^2D\log(T)})$ under mild assumptions. The planner searches actions solely based on the latest online model, thus forming a FTL Online Agent (OA) that updates incrementally. To assess OA, we further design Continual Bench, a dedicated environment for CRL, and compare with several strong baselines under the same model-planning algorithmic framework. The empirical results show that OA learns continuously to solve new tasks while not forgetting old skills, outperforming agents built on deep world models with various continual learning techniques.","(1) Make AI agents learn from experience online is a promising path towards AGI. (2) We attempt to build online world models incrementally and use them to simulate the future events, so that the agent can make informed decisions."
Poster,Continuous Bayesian Model Selection for Multivariate Causal Discovery,https://ICML.cc//virtual/2025/poster/43443,"Anish Dhir, Ruby Sedgwick, Avinash Kori, Ben Glocker, Mark van der Wilk","Current causal discovery approaches require restrictive model assumptions in the absence of interventional data to ensure structure identifiability. These assumptions often do not hold in real-world applications leading to a loss of guarantees and poor performance in practice. Recent work has shown that, in the bivariate case, Bayesian model selection can greatly improve performance by exchanging restrictive modelling for more flexible assumptions, at the cost of a small probability of making an error. Our work shows that this approach is useful in the important multivariate case as well. We propose a scalable algorithm leveraging a continuous relaxation of the discrete model selection problem. Specifically, we employ the Causal Gaussian Process Conditional Density Estimator (CGP-CDE) as a Bayesian non-parametric model, using its hyperparameters to construct an adjacency matrix. This matrix is then optimised using the marginal likelihood and an acyclicity regulariser, giving the maximum a posteriori causal graph. We demonstrate the competitiveness of our approach, showing it is advantageous to perform multivariate causal discovery without infeasible assumptions using Bayesian model selection.","Scientists often want to understand cause-and-effect relationships from data, like determining whether smoking causes cancer or if education leads to higher income. Current methods for discovering these relationships from observational data require very strict assumptions that rarely hold true in real-world situations, leading to unreliable results. We developed a new approach that uses Bayesian statistics to be more flexible about these assumptions while still providing reliable answers. Our method uses advanced machine learning techniques to model the relationships between multiple variables simultaneously, then finds the most likely cause-and-effect structure. Our technique outperforms existing methods where their strict assumptions don't hold. This makes causal discovery more reliable and accessible for scientists studying complex systems with multiple interacting factors, from medical research to economics."
Poster,Continuously Updating Digital Twins using Large Language Models,https://ICML.cc//virtual/2025/poster/44291,"Harry Amad, Nicolás Astorga, Mihaela van der Schaar","Digital twins are models of real-world systems that can simulate their dynamics in response to potential actions. In complex settings, the state and action variables, and available data and knowledge relevant to a system can constantly change, requiring digital twins to continuously update with these changes to remain relevant. Current approaches struggle in this regard, as they require fixed, well-defined modelling environments, and they cannot adapt to novel variables without re-designs, or incorporate new information without re-training. To address this, we frame digital twinning as an in-context learning problem using large language models, enabling seamless updates to the twin at inference time. We develop CALM-DT, a Context-Adaptive Language Model-based Digital Twin that can accurately simulate across diverse state-action spaces using in-context learning alone by utilising fine-tuned encoders for sample retrieval. We empirically demonstrate CALM-DT's competitive performance with existing digital twin approaches, and its unique ability to adapt to changes in its modelling environment without parameter updates.","We tackle a problem with ""digital twins"" – which are computational models of real-world systems (e.g., a cell, a medical patient, a city) that can be used to simulate different scenarios for decision making purposes. Current digital twins lose relevance to their counterpart physical system when real-world conditions change, like when a new medical treatment becomes available, or when new, informative data is released about patients with a certain disease, and they can require extensive re-designs and re-training to get up to date again. We show how large language models (LLMs) can act as accurate digital twins that overcome this limitation, as an LLM-based twin can easily  incorporate new variables or information on the fly using purely natural language prompting. Our method, called CALM-DT, uses neural network encoders to select the data most relevant to the target system that we want to twin, before prompting an LLM to simulate the target system forward in time, using insights derived from the provided relevant data. We show that CALM-DT matches or beats existing digital twin approaches in terms of simulation accuracy, while being much easier to adapt when changes occur to the real-world system. This promises to increase the feasibiliy of digital twin deployment in complex environments, where changes can frequently occur."
Poster,Continuous Semi-Implicit Models,https://ICML.cc//virtual/2025/poster/43572,"Longlin Yu, Jiajun Zha, Tong Yang, Tianyu Xie, Xiangyu Zhang, Gary Chan, Cheng Zhang","Semi-implicit distributions have shown great promise in variational inference and generative modeling.    Hierarchical semi-implicit models, which stack multiple semi-implicit layers, enhance the expressiveness of semi-implicit distributions and can be used to accelerate diffusion models given pretrained score networks.     However, their sequential training often suffers from slow convergence.    In this paper, we introduce CoSIM, a continuous semi-implicit model that extends hierarchical semi-implicit models into a continuous framework.    By incorporating a continuous transition kernel, CoSIM enables efficient, simulation-free training.    Furthermore, we show that CoSIM achieves consistency with a carefully designed transition kernel, offering a novel approach for multistep distillation of generative models at the distributional level.    Extensive experiments on image generation demonstrate that CoSIM performs on par or better than existing diffusion model acceleration methods, achieving superior performance on FD-DINOv2.","Multi-step generative models improve image quality and training efficiency, but distilling them into faster models still requires significant computational cost.To address this, we propose CoSIM, a scalable training method that avoids slow step-by-step simulations. CoSIM unifies two advanced techniques — Hierarchical Semi-implicit Models for multi-step distillation and Score Identity Distillation for one-step distillation — within a continuous framework.By incorporating a continuous transition kernel, CoSIM enables efficient, simulation-free training. Its training objective alternates between refining the image generator and updating an auxiliary score network, using a scaled Fisher divergence and an additional regularization term to improve multi-step generation quality.In experiments on challenging image generation tasks, CoSIM matches or outperforms state-of-the-art diffusion model acceleration methods, achieving particularly strong results on FD-DINOv2. We hope this approach helps make high-quality generative models more efficient, scalable, and practical."
Poster,Continuous-Time Analysis of Heavy Ball Momentum in Min-Max Games,https://ICML.cc//virtual/2025/poster/46302,"Yi Feng, Kaito Fujii, EFSTRATIOS PANTELEIMON SKOULAKIS, Xiao Wang, Volkan Cevher","Since Polyak's pioneering work, heavy ball (HB) momentum has been widely studied in minimization. However, its role in min-max games remains largely unexplored. As a key component of practical min-max algorithms like Adam, this gap limits their effectiveness. In this paper, we present a continuous-time analysis for HB with simultaneous and alternating update schemes in min-max games. Locally, we prove *smaller* momentum enhances algorithmic stability by enabling local convergence across a wider range of step sizes, with alternating updates generally converging faster. Globally, we study the implicit regularization of HB, and find *smaller* momentum guides algorithms trajectories towards shallower slope regions of the loss landscapes, with alternating updates amplifying this effect. Surprisingly, all these phenomena differ from those observed in minimization, where *larger* momentum yields similar effects. Our results reveal fundamental differences between HB in min-max games and minimization, and numerical experiments further validate our theoretical results.","This paper presents a continuous-time analysis of the Heavy Ball momentum method in the context of min-max games, which are optimization problems involving two players with opposing objectives, such as in GANs or adversarial training. The authors aim to bridge the gap in understanding HB momentum, a common component in algorithms like Adam, for min-max games, which has been less explored compared to its application in minimization tasks."
Poster,Continuous Visual Autoregressive Generation via Score Maximization,https://ICML.cc//virtual/2025/poster/44770,"Chenze Shao, Fandong Meng, Jie Zhou","Conventional wisdom suggests that autoregressive models are used to process discrete data. When applied to continuous modalities such as visual data, Visual AutoRegressive modeling (VAR) typically resorts to quantization-based approaches to cast the data into a discrete space, which can introduce significant information loss. To tackle this issue, we introduce a Continuous VAR framework that enables direct visual autoregressive generation without vector quantization. The underlying theoretical foundation is strictly proper scoring rules, which provide powerful statistical tools capable of evaluating how well a generative model approximates the true distribution. Within this framework, all we need is to select a strictly proper score and set it as the training objective to optimize. We primarily explore a class of training objectives based on the energy score, which is likelihood-free and thus overcomes the difficulty of making probabilistic predictions in the continuous space. Previous efforts on continuous autoregressive generation, such as GIVT and diffusion loss, can also be derived from our framework using other strictly proper scores. Source code: \url{https://github.com/shaochenze/EAR}.","This paper introduces a principled framework for continuous visual autoregressive generation, theoretically grounded in strictly proper scoring rules. Within this framework, we primarily explore a class of training objectives based on the energy score, which is likelihood-free and thus overcomes the difficulty of making probabilistic predictions in the continuous space. Previous efforts on continuous autoregressive generation, such as GIVT and diffusion loss, can also be derived from our framework using other strictly proper scores."
