type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,A Closer Look at Generalized BH Algorithm for Out-of-Distribution Detection,https://ICML.cc//virtual/2025/poster/45401,"Xinsong Ma, Jie Wu, Weiwei Liu","Out-of-distribution (OOD) detection is a crucial task in reliable and safety-critical applications. Previous studies primarily focus on developing score functions while neglecting the design of decision rules based on these scores. A recent work (Ma et al., 2024)  is the first to highlight this issue and proposes the generalized BH (g-BH) algorithm to address it. The g-BH algorithm relies on empirical p-values, with the calibrated set playing a central role in their computation. However, the impact of calibrated set on the performance of  g-BH algorithm has not been thoroughly investigated. This paper aims to uncover the underlying mechanisms between them. Theoretically, we demonstrate that conditional expectation of true positive rate (TPR) on calibrated set for the g-BH algorithm follows a beta distribution, which depends on the prescribed level and  size of calibrated set. This indicates that a small calibrated set tends to degrade the performance of g-BH algorithm. To address the limitation of g-BH algorithm on small calibrated set, we propose a novel ensemble g-BH (eg-BH) algorithm which integrates various empirical p-values for making decisions. Finally, extensive experimental results validate the effectiveness of our theoretical findings and demonstrate the superiority of our method over g-BH algorithm on small calibrated set.",This paper focuses on studying the impact of calibrated set on the g-BH algorithm and proposes a novel eg-BH algorithm to tackle the problem caused by the small calibrated set.
Poster,A Closer Look at Multimodal Representation Collapse,https://ICML.cc//virtual/2025/poster/45060,"Abhra Chaudhuri, Anjan Dutta, Tu Bui, Serban Georgescu","We aim to develop a fundamental understanding of modality collapse, a recently observed empirical phenomenon wherein models trained for multimodal fusion tend to rely only on a subset of the modalities, ignoring the rest. We show that modality collapse happens when noisy features from one modality are entangled, via a shared set of neurons in the fusion head, with predictive features from another, effectively masking out positive contributions from the predictive features of the former modality and leading to its collapse. We further prove that cross-modal knowledge distillation implicitly disentangles such representations by freeing up rank bottlenecks in the student encoder, denoising the fusion-head outputs without negatively impacting the predictive features from either modality. Based on the above findings, we propose an algorithm that prevents modality collapse through explicit basis reallocation, with applications in dealing with missing modalities. Extensive experiments on multiple multimodal benchmarks validate our theoretical claims. Project page: https://abhrac.github.io/mmcollapse/.","Even though multimodal models may be fed with inputs from various data sources (modalities), it has recently been observed that they might not actually be utilizing all of them, leading to a phenomenon called modality collapse. This is wasteful in several ways - unused data, unused model parameters, redundant computation, and much more, leading to high overall costs for little to no return. It thus becomes important to understand the root causes of modality collapse, so that we may find ways to mitigate it.We show that modality collapse happens when noisy features from one modality get jointly encoded with predictive features from another, through a shared set of neurons. It's like cooking a soup where some ingredients are fresh, while the others have gone bad. Putting them all together in the same bowl makes the whole bowl of soup inedible! We show that knowledge distillation implicitly separates out those bad ingredients (noisy features) by utilizing previously empty, unused bowls from the cupboard (freeing up rank bottlenecks), prior to putting the soup mix together (multimodal fusion). Based on this, we propose a technique called Explicit Basis Reallocation, which lays the empty bowls (unused dimensions in the representation space) out in the kitchen table, so that the cook (SGD) does not have to look for them in the cupboard while cooking (optimization). With this, we were successfully able to mitigate modality collapse, which led to significant performance improvements in scenarios where certain modalities could randomly go missing during inference."
Poster,A Closer Look at Transformers for Time Series Forecasting: Understanding Why They Work and Where They Struggle,https://ICML.cc//virtual/2025/poster/44262,"Yu Chen, Nathalia Céspedes, Payam Barnaghi","Time-series forecasting is crucial across various domains, including finance, healthcare, and energy. Transformer models, originally developed for natural language processing, have demonstrated significant potential in addressing challenges associated with time-series data. These models utilize different tokenization strategies, point-wise, patch-wise, and variate-wise, to represent time-series data, each resulting in different scope of attention maps. Despite the emergence of sophisticated architectures, simpler transformers  consistently outperform their more complex counterparts in widely used benchmarks. This study examines why point-wise transformers are generally less effective, why intra- and inter-variate attention mechanisms yield similar outcomes, and which architectural components drive the success of simpler models. By analyzing mutual information and evaluating models on synthetic datasets, we demonstrate that intra-variate dependencies are the primary contributors to prediction performance on benchmarks, while inter-variate dependencies have a minor impact. Additionally, techniques such as Z-score normalization and skip connections are also crucial. However, these results are largely influenced by the self-dependent and stationary nature of benchmark datasets. By validating our findings on real-world healthcare data, we provide insights for designing more effective transformers for practical applications.","Accurately predicting future trends from time-based data, such as patient health, stock prices, or energy use, is essential in many fields. Transformer models, originally developed for language processing, have shown promise for this task. These models present time-based data in different ways, but interestingly, simpler transformer designs often outperform more complex ones.This study explores why simpler transformer architects work better in forecasting, and how different ways of representing time-series data affect performance. We find that most useful information comes from tracking patterns within individual variables over time, rather than between variables. Techniques like data normalization and skip connections also contribute significantly to forecasting performance.However, we show that many commonly used datasets are easier to predict than real-world data, which can mislead model design. By testing on real healthcare data, we highlight what matters most when building effective transformer models for practical applications."
Poster,A Cognac Shot To Forget Bad Memories: Corrective Unlearning for Graph Neural Networks,https://ICML.cc//virtual/2025/poster/44563,"Varshita Kolipaka, Akshit Sinha, Debangan Mishra, Sumit Kumar, Arvindh Arun, Shashwat Goel, Ponnurangam Kumaraguru","Graph Neural Networks (GNNs) are increasingly being used for a variety of ML applications on graph data. Because graph data does not follow the independently and identically distributed *i.i.d.* assumption, adversarial manipulations or incorrect data can propagate to other data points through message passing, which deteriorates the model's performance. To allow model developers to remove the adverse effects of manipulated entities from a trained GNN, we study the recently formulated problem of *Corrective Unlearning*. We find that current graph unlearning methods fail to unlearn the effect of manipulations even when the whole manipulated set is known. We introduce a new graph unlearning method,**Cognac**, which can unlearn the effect of the manipulation set even when only $5$% of it is identified. It recovers most of the performance of a strong oracle with fully corrected training data, even beating retraining from scratch without the deletion set, and is $8$x more efficient while also scaling to large datasets. We hope our work assists GNN developers in mitigating harmful effects caused by issues in real-world data, post-training.","Graph Neural Networks (GNNs) are a class of machine learning models designed to learn from structured, interconnected data, such as social networks or molecular structures. A significant challenge arises with graph data—as the data points are not independent, erroneous or manipulated entries can propagate their negative effects throughout the network, degrading the model's overall performance. To add to the problems, we can never be sure if we have identified all erroneous data points.We study—Is there an efficient way to remove the harmful effects of such samples when we only know a handful of them? To tackle this problem, we introduce _Cognac_. Our method is intuitive—we push the internal representations of manipulated nodes away from those of their neighbors to reduce the influence of the manipulation. At the same time, we ensure that the model maintains performance on the rest of the dataset._Cognac_ can restore a model's performance even when only a small fraction, as little as 5%, of the problematic data is identified. It is highly effective, recovering performance to a level comparable to a model trained on fully corrected data. Furthermore, _Cognac_ is approximately 8 times more efficient than the standard approach of completely retraining the system. This work provides a valuable tool for developers to mitigate the adverse effects of imperfect, real-world data in trained GNNs."
Poster,A Comprehensive Framework for Analyzing the Convergence of Adam: Bridging the Gap with SGD,https://ICML.cc//virtual/2025/poster/46043,"Ruinan Jin, Xiao Li, Yaoliang Yu, Baoxiang Wang","Adaptive moment estimation (Adam) is a cornerstone optimization algorithm in deep learning, widely recognized for its flexibility with adaptive learning rates and efficiency in handling large-scale data. However, despite its practical success, the theoretical understanding of Adam's convergence has been constrained by stringent assumptions, such as almost surely bounded stochastic gradients or uniformly bounded gradients, which are more restrictive than those typically required for analyzing stochastic gradient descent (SGD).In this paper, we introduce a novel and comprehensive framework for analyzing the convergence properties of Adam. This framework offers a versatile approach to establishing Adam's convergence. Specifically, we prove that Adam achieves asymptotic (last iterate sense) convergence in both the almost sure sense and the \(L_1\) sense under the relaxed assumptions typically used for SGD, namely \(L\)-smoothness and the ABC inequality. Meanwhile, under the same assumptions, we show that Adam attains non-asymptotic sample complexity bounds similar to those of SGD.","Adam is one of the most popular optimization methods used to train deep learning models. It works well in practice because it can automatically adjust how fast it learns during training. However, until now, understanding exactly when and why Adam works has required very strong and often unrealistic mathematical assumptions. In this paper, we present a new theoretical framework that shows Adam can succeed under much more relaxed and practical conditions—similar to those needed to analyze the more basic algorithm SGD (stochastic gradient descent). Our results show that Adam not only performs well in practice but also has strong theoretical guarantees, helping bridge the gap between its empirical success and formal understanding. This work may also help researchers analyze other similar optimization methods more easily."
Poster,A Computationally Efficient Algorithm for Infinite-Horizon Average-Reward Linear MDPs,https://ICML.cc//virtual/2025/poster/44695,"Kihyuk Hong, Ambuj Tewari","We study reinforcement learning in infinite-horizon average-reward settings with linear MDPs. Previous work addresses this problem by approximating the average-reward setting by discounted setting and employing a value iteration-based algorithm that uses clipping to constrain the span of the value function for improved statistical efficiency. However, the clipping procedure requires computing the minimum of the value function over the entire state space, which is prohibitive since the state space in linear MDP setting can be large or even infinite. In this paper, we introduce a value iteration method with efficient clipping operation that only requires computing the minimum of value functions over the set of states visited by the algorithm. Our algorithm enjoys the same regret bound as the previous work while being computationally efficient, with computational complexity that is independent of the size of the state space.","We study reinforcement learning in the infinite-horizon setting, where the agent interacts with the environment indefinitely, and the objective is to maximize the long-term average reward. We focus on the linear MDP setting, where the state space can be extremely large but is equipped with a low-dimensional feature representation. Prior work approximates the average-reward objective using a discounted formulation, enabling the use of value iteration-based algorithms. However, these methods suffer from computational inefficiency, as they require computing the minimum of a value function over the entire state space, a task that becomes intractable in large or infinite spaces. In this paper, we propose new algorithmic techniques that overcome this limitation, resulting in a computationally efficient algorithm that retains the same performance guarantees as existing approaches."
Poster,A Cross Modal Knowledge Distillation & Data Augmentation Recipe for Improving Transcriptomics Representations through Morphological Features,https://ICML.cc//virtual/2025/poster/43637,"Ihab Bendidi, Yassir El Mesbahi, Alisandra Denton, Karush Suri, Kian Kenyon-Dean, Auguste Genovesio, Emmanuel Noutahi","Understanding cellular responses to stimuli is crucial for biological discovery and drug development. Transcriptomics provides interpretable, gene-level insights, while microscopy imaging offers rich predictive features but is harder to interpret. Weakly paired datasets, where samples share biological states, enable multimodal learning but are scarce, limiting their utility for training and multimodal inference. We propose a framework to enhance transcriptomics by distilling knowledge from microscopy images. Using weakly paired data, our method aligns and binds modalities, enriching gene expression representations with morphological information. To address data scarcity, we introduce (1) *Semi-Clipped*, an adaptation of CLIP for cross-modal distillation using pretrained foundation models, achieving state-of-the-art results, and (2) *PEA* (**P**erturbation **E**mbedding **A**ugmentation), a novel augmentation technique that enhances transcriptomics data while preserving inherent biological information. These strategies improve the predictive power and retain the interpretability of transcriptomics, enabling rich unimodal representations for complex biological tasks.","To better understand how cells respond to their environment, important for science and medicine, scientists often look at two types of data: gene activity (transcriptomics) and cell images (microscopy). Gene data is easy to interpret but may miss some details, while images show rich detail but are harder to understand. It’s rare to have both types of data for the same samples, which limits their combined use. This research introduces a new way to make gene data more informative by ""borrowing"" insights from images. Even when the two types of data aren't perfectly matched, the method learns to connect them. It does this in two key ways: first, by adapting a popular AI technique (like CLIP) to combine these data types and achieve top results, and second, by creating a new method to expand gene data without losing important biological meaning. The result is gene data that stays clear and understandable but also gains the rich detail typically only found in images."
Poster,Action-Constrained Imitation Learning,https://ICML.cc//virtual/2025/poster/45492,"Chia-Han Yeh, Tse-Sheng Nan, Risto Vuorio, Wei Hung, Hung-Yen Wu, Shao-Hua Sun, Ping-Chun Hsieh","Policy learning under action constraints plays a central role in ensuring safe behaviors in various robot control and resource allocation applications.In this paper, we study a new problem setting termed Action-Constrained Imitation Learning (ACIL), where an action-constrained imitator aims to learn from a demonstrative expert with larger action space.The fundamental challenge of ACIL lies in the unavoidable mismatch of occupancy measure between the expert and the imitator caused by the action constraints. We tackle this mismatch through trajectory alignment and propose DTWIL, which replaces the original expert demonstrations with a surrogate dataset that follows similar state trajectories while adhering to the action constraints. Specifically, we recast trajectory alignment as a planning problem and solve it via Model Predictive Control, which aligns the surrogate trajectories with the expert trajectories based on the Dynamic Time Warping (DTW) distance. Through extensive experiments, we demonstrate that learning from the dataset generated by DTWIL significantly enhances performance across multiple robot control tasks and outperforms various benchmark imitation learning algorithms in terms of sample efficiency.","Robots often need to learn from expert demonstrations, and in many real-world situations, they must operate under strict constraints—for example, avoiding certain actions for safety. This creates a challenge when the expert has more flexibility than the learning robot: the robot cannot simply copy the expert’s behavior. Our research addresses this issue in a setting we call Action-Constrained Imitation Learning (ACIL).We propose a method called DTWIL. Instead of using the expert data directly, we generate new “surrogate” trajectories that follow similar paths but respect the robot’s constraints. We do this by framing the alignment as a planning problem and solving it with Model Predictive Control, using Dynamic Time Warping to match the expert’s trajectory.Experiments show that learning from these aligned trajectories leads to better performance and sample efficiency across various robotic control tasks, enabling safer learning in action-constrained environments."
Poster,Action-Dependent Optimality-Preserving Reward Shaping,https://ICML.cc//virtual/2025/poster/43789,"Grant Forbes, Jianxun Wang, Leonardo Villalobos-Arias, Arnav Jhala, David Roberts","Recent RL research has utilized reward shaping--particularly complex shaping rewards such as intrinsic motivation (IM)--to encourage agent exploration in sparse-reward environments. While often effective, ``reward hacking'' can lead to the shaping reward being optimized at the expense of the extrinsic reward, resulting in a suboptimal policy. Potential-Based Reward Shaping (PBRS) techniques such as Generalized Reward Matching (GRM) and Policy-Invariant Explicit Shaping (PIES) have mitigated this. These methods allow for implementing IM without altering optimal policies. In this work we show that they are effectively unsuitable for complex, exploration-heavy environments with long-duration episodes. To remedy this, we introduce Action-Dependent Optimality Preserving Shaping (ADOPS), a method of converting intrinsic rewards to an optimality-preserving form that allows agents to utilize IM more effectively in the extremely sparse environment of Montezuma's Revenge. We also prove ADOPS accommodates reward shaping functions that cannot be written in a potential-based form: while PBRS-based methods require the cumulative discounted intrinsic return be independent of actions, ADOPS allows for intrinsic cumulative returns to be dependent on agents' actions while still preserving the optimal policy set. We show how action-dependence enables ADOPS's to preserve optimality while learning in complex, sparse-reward environments where other methods struggle.","A lot of reinforcement learning problems are either very difficult or impossible to learn without giving the agent ""hints"" of some kind, to help it know what sorts of actions to try. A lot of the time though, the agent can learn to ""hack"" these hints that we give it, and optimize for them at the expense of whatever task we $\textit{actually}$ want it to accomplish. There are some prior mathematical tricks for taking a set of hints that might be ""hackable"" and converting them to a form that we can guarantee isn't hackable. However, these previous methods haven't yet been tested in really hard-to-learn environments. We test them in a really hard-to-learn environment, and find that, even though they technically keep the hints from being hackable, they also make the hints worse at guiding the agent, to the extent that it fails to learn well at all. To remedy this, we develop a provably more general method of converting hints to a form that we can show mathematically can't be hacked. We also demonstrate empirically that our method helps the agent learn a better policy faster, in this same difficult environment where prior methods fail."
Poster,Action Dubber: Timing Audible Actions via Inflectional Flow,https://ICML.cc//virtual/2025/poster/46228,"Wenlong Wan, Weiying Zheng, Tianyi Xiang, Guiqing Li, Shengfeng He","We introduce the task of Audible Action Temporal Localization, which aims to identify the spatio-temporal coordinates of audible movements. Unlike conventional tasks such as action recognition and temporal action localization, which broadly analyze video content, our task focuses on the distinct kinematic dynamics of audible actions. It is based on the premise that key actions are driven by inflectional movements; for example, collisions that produce sound often involve abrupt changes in motion. To capture this, we propose $TA^{2}Net$, a novel architecture that estimates inflectional flow using the second derivative of motion to determine collision timings without relying on audio input. $TA^{2}Net$ also integrates a self-supervised spatial localization strategy during training, combining contrastive learning with spatial analysis. This dual design improves temporal localization accuracy and simultaneously identifies sound sources within video frames. To support this task, we introduce a new benchmark dataset, $Audible623$, derived from Kinetics and UCF101 by removing non-essential vocalization subsets. Extensive experiments confirm the effectiveness of our approach on $Audible623$ and show strong generalizability to other domains, such as repetitive counting and sound source localization. Code and dataset are available at https://github.com/WenlongWan01/Audible623.","This work focuses on accurately identifying the exact moments in a video when a visible action is likely to produce a sound, such as an object hitting the ground, without relying on audio. The task is called Audible Action Temporal Localization. We introduce a model named $TA^{2}Net$ that captures sudden visual changes often linked to sound. To support this task, we create a new dataset called $Audible623$ by removing non-essential vocal parts from existing videos. The approach reduces manual effort in video dubbing and also generalizes well to tasks like counting repeated actions."
