type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,FOUNDER: Grounding Foundation Models in World Models for Open-Ended Embodied Decision Making,https://ICML.cc//virtual/2025/poster/45117,"Yucen Wang, Rui Yu, Shenghua Wan, Le Gan, De-Chuan Zhan","Foundation Models (FMs) and World Models (WMs) offer complementary strengths in task generalization at different levels. In this work, we propose FOUNDER, a framework that integrates the generalizable knowledge embedded in FMs with the dynamic modeling capabilities of WMs to enable open-ended task solving in embodied environments in a reward-free manner. We learn a mapping function that grounds FM representations in the WM state space, effectively inferring the agent's physical states in the world simulator from external observations. This mapping enables the learning of a goal-conditioned policy through imagination during behavior learning, with the mapped task serving as the goal state. Our method leverages the predicted temporal distance to the goal state as an informative reward signal. FOUNDER demonstrates superior performance on various multi-task offline visual control benchmarks, excelling in capturing the deep-level semantics of tasks specified by text or videos, particularly in scenarios involving complex observations or domain gaps where prior methods struggle. The consistency of our learned reward function with the ground-truth reward is also empirically validated. Our project website is https://sites.google.com/view/founder-rl.","Imagine trying to get a robot to understand and perform all sorts of tasks just like we do, say, by telling it ""go get an apple from the kitchen"" or showing it a quick video. This is actually very hard! Current AI is often either like a knowledgeable ""scholar"" (Foundation Models) that understands many concepts but doesn't quite know how to ""act"" in the physical world, or like a skilled ""artisan"" (World Models) that can simulate physical interactions and learn specific actions but struggles with broad, open-ended instructions.Our research is like building a vital bridge between this ""scholar"" and ""artisan,"" enabling them to collaborate effectively. We introduce FOUNDER, a new method that cleverly translates the ""scholar's"" understanding of a task (for instance, ""getting an apple"" means the apple ultimately rests in the robot's hand) into a concrete ""target snapshot"" or goal state within the ""artisan's"" simulated practice arena. Once this target is clear, the robot can teach itself how to reach it by imagining and rehearsing within its own ""mental mini-world"" (the World Model), all without us needing to painstakingly define complex reward rules for every single task.This technology means future robots and AI agents could more easily interpret and execute a wide variety of open-ended instructions we provide, whether through natural language or by watching a video. This could be for exploring in a game or performing complex manipulations in the real world, opening new doors to creating more versatile and intelligent robotic assistants that seamlessly integrate into our lives and work."
Poster,FourierMamba: Fourier Learning Integration with State Space Models for Image Deraining,https://ICML.cc//virtual/2025/poster/43723,"Dong Li, Yidi Liu, Xueyang Fu, Jie Huang, Senyan Xu, Qi Zhu, Zheng-Jun Zha","Image deraining aims to remove rain streaks from rainy images and restore clear backgrounds. Currently, some research that employs the Fourier transform has proved to be effective for image deraining, due to it acting as an effective frequency prior for capturing rain streaks. However, despite there exists dependency of low frequency and high frequency in images, these Fourier-based methods rarely exploit the correlation of different frequencies for conjuncting their learning procedures, limiting the full utilization of frequency information for image deraining. Alternatively, the recently emerged Mamba technique depicts its effectiveness and efficiency for modeling correlation in various domains (e.g., spatial, temporal), and we argue that introducing Mamba into its unexplored Fourier spaces to correlate different frequencies would help improve image deraining. This motivates us to propose a new framework termed FourierMamba, which performs image deraining with Mamba in the Fourier space. Owing to the unique arrangement of frequency orders in Fourier space, the core of FourierMamba lies in the scanning encoding of different frequencies, where the low-high frequency order formats exhibit differently in the spatial dimension  (unarranged in axis) and channel dimension (arranged in axis). Therefore, we design FourierMamba that correlates Fourier space information in the spatial and channel dimensions with distinct designs. Specifically, in the spatial dimension Fourier space, we introduce the zigzag coding to scan the frequencies to rearrange the orders from low to high frequencies,  thereby orderly correlating the connections between frequencies; in the channel dimension  Fourier space with arranged orders of frequencies in axis, we can directly use Mamba to perform frequency correlation and improve the channel information representation. Extensive experiments reveal that our method outperforms state-of-the-art methods both qualitatively and quantitatively.","Rain in photos can seriously degrade image quality, which creates challenges for applications like autonomous driving or outdoor surveillance. Traditional computer vision methods try to clean these images by analyzing them in either the pixel space (what we directly see) or the frequency space (a mathematical way of looking at how fast things change in an image). Recent research shows that using the frequency space helps remove rain better, since rain streaks have special frequency patterns. But current methods often ignore the relationships between different types of frequencies — like low (broad shapes) and high (fine details).In our research, we apply a powerful new machine learning tool called Mamba to connect these frequencies more effectively. Our method, called FourierMamba, explores two different ways of organizing and scanning the frequencies, depending on how they appear in the image. This allows the model to better learn how different frequency patterns relate to rain.The result? Our approach produces cleaner images than existing methods — potentially making rainy-day vision systems smarter and safer."
Poster,Fourier Position Embedding: Enhancing Attention’s Periodic Extension for Length Generalization,https://ICML.cc//virtual/2025/poster/44838,"Ermo Hua, Che Jiang, Xingtai Lv, Kaiyan Zhang, Youbang Sun, Yuchen Fan, Xuekai Zhu, Biqing Qi, Ning Ding, Bowen Zhou","Extending the context length of Language Models (LMs) by improving Rotary Position Embedding (RoPE) has become a trend.While prior works mainly address RoPE's limitations within attention, this paper uncovers the adverse effects on length generalization from nearly all parts of LMs.Using *Discrete Signal Processing* theory, we show that RoPE enables periodic attention by implicitly achieving *Non-Uniform Discrete Fourier Transform*.However, this periodicity is undermined by the spectrum damage caused by: 1) linear layers and activation functions outside of attention; 2) insufficiently trained frequency components brought by time-domain truncation. Building on our observations, we propose ***Fourier Position Embedding (FoPE)***, which enhances attention's frequency-domain properties to improve both its periodic extension and length generalization. FoPE constructs *Fourier Series* and zero-outs the destructive frequency components, increasing model robustness against the spectrum damage.Experiments across various model scales and benchmarks show that, within varying context windows, FoPE maintains a more stable performance compared to other baselines.Several analyses and ablations bring further support to our method and theoretical modeling.","This paper tackles a key challenge in making language models (like ChatGPT) better at understanding and working with long pieces of text. Most current models struggle when they need to remember and process information that is far apart in the text — for example, something mentioned in the first paragraph and then referred to much later.By borrowing ideas from signal processing (the science behind how we analyze sound waves or radio signals), the authors explain how RoPE works a bit like a radio signal — repeating patterns that help the model stay ""in tune"" with long text. But other parts of the model can damage this signal, making it harder for the model to perform well on long texts.To fix this, they propose a new method called ***Fourier Position Embedding (FoPE)***. Think of it like giving the model a clearer and more stable rhythm or signal to follow, by removing parts that cause noise or confusion. This helps the model stay better at understanding connections across long stretches of text."
Poster,Fragments to Facts: Partial-Information Fragment Inference from LLMs,https://ICML.cc//virtual/2025/poster/45801,"Lucas Rosenblatt, Bin Han, Robert Wolfe, Bill Howe","Large language models (LLMs) can leak sensitive training data through memorization and membership inference attacks. Prior work has primarily focused on strong adversarial assumptions, including attacker access to entire samples or long, ordered prefixes, leaving open the question of how vulnerable LLMs are when adversaries have only partial, unordered sample information. For example, if an attacker knows a patient has ""hypertension,"" under what conditions can they query a model fine-tuned on patient data to learn the patient also has ""osteoarthritis?"" In this paper, we introduce a more general threat model under this weaker assumption and show that fine-tuned LLMs are susceptible to these fragment-specific extraction attacks. To systematically investigate these attacks, we propose two data-blind methods: (1) a likelihood ratio attack inspired by methods from membership inference, and (2) a novel approach, PRISM, which regularizes the ratio by leveraging an external prior. Using examples from medical and legal settings, we show that both methods are competitive with a data-aware baseline classifier that assumes access to labeled in-distribution data, underscoring their robustness.","Imagine a chatbot has been trained on private medical or legal notes. Even if an adversarial individual (hacker, etc.) only knows a few scattered facts -- say that a patient has ""hypertension"" and takes ""beta-blockers"" -- our study shows that this person can still prod the chatbot to reveal other hidden details, such as additional illnesses. We introduce a new way of thinking about this risk and design two attack methods that work without any insider knowledge of the training data. In tests on real medical summaries, these ""fragment attacks"" succeeded often enough to raise serious privacy alarms. Our results suggest that simply scrubbing verbatim text or checking for wholesale memorization is not enough: developers need stronger defenses before deploying fine-tuned language models in sensitive domains."
Poster,FrameBridge: Improving Image-to-Video Generation with Bridge Models,https://ICML.cc//virtual/2025/poster/44351,"Yuji Wang, Zehua Chen, Chen Xiaoyu, Yixiang Wei, Jun Zhu, Jianfei Chen","Diffusion models have achieved remarkable progress on image-to-video (I2V) generation, while their noise-to-data generation process is inherently mismatched with this task, which may lead to suboptimal synthesis quality. In this work, we present FrameBridge. By modeling the frame-to-frames generation process with a bridge model based data-to-data generative process, we are able to fully exploit the information contained in the given image and improve the consistency between the generation process and I2V task.Moreover, we propose two novel techniques toward the two popular settings of training I2V models, respectively. Firstly, we propose SNR-Aligned Fine-tuning (SAF), making the first attempt to fine-tune a diffusion model to a bridge model and, therefore, allowing us to utilize the pre-trained diffusion-based text-to-video (T2V) models. Secondly, we propose neural prior, further improving the synthesis quality of FrameBridge when training from scratch. Experiments conducted on WebVid-2M and UCF-101 demonstrate the superior quality of FrameBridge in comparison with the diffusion counterpart (zero-shot FVD 95 vs. 192 on MSR-VTT and non-zero-shot FVD 122 vs. 171 on UCF-101), and the advantages of our proposed SAF and neural prior for bridge-based I2V models. The project page: https://framebridge-icml.github.io/","We propose FrameBridge, an image-to-video (I2V) model which can generate videos with consistent content of a given image. Different from previous diffusion-based methods, which start the generation process with uninformative Gaussian noise, FrameBridge is a bridge-based model and the sampling process can be started from the given image which has provided structural prior information. Our model can be either fine-tuned from a pre-trained video diffusion model to save computational resources or trained from scratch, and we propose techniques (namely SNR-Aligned Fine-tuning and neural prior) to further enhance the performance in these two scenarios."
Poster,Fraud-Proof Revenue Division on Subscription Platforms,https://ICML.cc//virtual/2025/poster/44347,"Abheek Ghosh, Tzeh Yuan Neoh, Nicholas Teh, Giannis Tyrovolas","We study a model of subscription-based platforms where users pay a fixed fee for unlimited access to content, and creators receive a share of the revenue. Existing approaches to detecting fraud predominantly rely on machine learning methods, engaging in an ongoing arms race with bad actors. We explore revenue division mechanisms that inherently disincentivize manipulation. We formalize three types of manipulation-resistance axioms and examine which existing rules satisfy these. We show that a mechanism widely used by streaming platforms, not only fails to prevent fraud, but also makes detecting manipulation computationally intractable. We also introduce a novel rule, ScaledUserProp, that satisfies all three manipulation-resistance axioms. Finally, experiments with both real-world and synthetic streaming data support ScaledUserProp as a fairer alternative compared to existing rules.","Online streaming platforms such as Spotify or Netflix collect monthly fees from users and distribute revenue to content creators—like musicians or filmmakers—based on user activity. But this setup is vulnerable: some content creators can try to game the system to unfairly earn more money, for example by using bots or fake accounts. Current methods to detect such fraudulent behavior rely heavily on machine learning, which often turns into a cat-and-mouse game with bad actors. Our research asks a different question: can we design payment rules that make cheating unprofitable in the first place?We propose three principles (or “axioms”) that any fair and manipulation-resistant revenue distribution system should follow. We then study which current methods meet these standards—and find that some commonly used approaches not only fail to prevent fraud, but also make it extremely hard to detect. To address this, we introduce a new method called ScaledUserProp, which discourages manipulation by design. We test our method using both synthetically-generated and real data from streaming platforms. The results show that ScaledUserProp distributes money more fairly and resists fraud better than existing systems."
Poster,FreeMesh: Boosting Mesh Generation with Coordinates Merging,https://ICML.cc//virtual/2025/poster/45605,"Jian Liu, Haohan Weng, Biwen Lei, Xianghui Yang, Zibo Zhao, Zhuo Chen, Song Guo, Tao Han, Chunchao Guo","The next-coordinate prediction paradigm has emerged as the de facto standard in current auto-regressive mesh generation methods.Despite their effectiveness, there is no efficient measurement for the various tokenizers that serialize meshes into sequences. In this paper, we introduce a new metric Per-Token-Mesh-Entropy (PTME) to evaluate the existing mesh tokenizers theoretically without any training.Building upon PTME, we propose a plug-and-play tokenization technique called coordinate merging.It further improves the compression ratios of existing tokenizers by rearranging and merging the most frequent patterns of coordinates.Through experiments on various tokenization methods like MeshXL, MeshAnything V2, and Edgerunner, we further validate the performance of our method.We hope that the proposed PTME and coordinate merging can enhance the existing mesh tokenizers and guide the further development of native mesh generation.","AI models generate 3D meshes by first converting them into sequences of tokens. A major challenge is efficiently evaluating how well these mesh tokenizers work, as it usually requires training the full AI model. We introduce a new, training-free metric called Per-Token-Mesh-Entropy (PTME) that quickly measures how effectively geometric information is packed into the mesh sequence tokens. Using PTME, we also propose a method to improve existing tokenizers by rearranging and merging frequent patterns within the mesh sequence, creating a more compressed representation. Our PTME metric and the mesh sequence merging technique enable researchers to rapidly evaluate and enhance mesh tokenization methods, helping AI models generate more detailed and higher-quality meshes for applications in computer graphics and design."
Poster,Free Process Rewards without Process Labels,https://ICML.cc//virtual/2025/poster/46278,"Lifan Yuan, Wendi Li, Huayu Chen, Ganqu Cui, Ning Ding, Kaiyan Zhang, Bowen Zhou, Zhiyuan Liu, Hao Peng","Different from its counterpart outcome reward models (ORMs), which evaluate the entire responses, a process reward model (PRM) scores a reasoning trajectory step by step, providing denser and more fine-grained rewards. However, training a PRM requires labels annotated at every intermediate step, presenting significant challenges for both manual and automatic data collection. This paper aims to address this challenge. Both theoretically and empirically, we show that an implicit PRM can be obtained at no additional cost, by simply training an ORM on the cheaper response-level labels. The only assumption is to parameterize the outcome reward as the log-likelihood ratios of the policy and reference models rϕ(y) = β log πϕ(y) πref(y) , which can be optimized regardless of the specific choice of loss objectives. In experiments, we instantiate our implicit PRMs with various objectives and evaluate their performance on MATH. We show that our implicit PRM outperforms a strong MCTS-based baseline á la Math-Shepherd (Wang et al., 2023) using less than 1/38 of the training data. Its performance can be further improved with majority voting. We further find that scaling up instructions and responses benefits our implicit PRM, and the latter brings a larger gain. Particularly, we find that our implicit PRM, when instantiated with the cross-entropy (CE) loss, is more data-efficient and can keep improving generation models even when trained with only one response per instruction, the setup that suffers from extreme data scarcity and imbalance. Further, instructions should be relevant to downstream tasks while the diversity of responses does not bring gains. Surprisingly, training on extra Math-Shepherd step labels brings no further improvements to our implicit PRM trained on only outcome data. We hope that our work will encourage a rethinking of PRM training approaches and contribute to making training PRMs more accessible.","Different from its counterpart outcome reward models (ORMs), which evaluate the entire responses, a process reward model (PRM) scores a reasoning trajectory step by step, providing denser and more fine-grained rewards. However, training a PRM requires labels annotated at every intermediate step, presenting significant challenges for both manual and automatic data collection. This paper aims to address this challenge. Both theoretically and empirically, we show that an implicit PRM can be obtained at no additional cost, by simply training an ORM on the cheaper response-level labels. The only assumption is to parameterize the outcome reward as the log-likelihood ratios of the policy and reference models, which can be optimized regardless of the specific choice of loss objectives. We hope that our work will encourage a rethinking of PRM training approaches and contribute to making training PRMs more accessible."
Poster,Freeze-Omni: A Smart and Low Latency Speech-to-speech Dialogue Model with Frozen LLM,https://ICML.cc//virtual/2025/poster/43854,"Xiong Wang, Yangze Li, Chaoyou Fu, Yike Zhang, Yunhang Shen, Lei Xie, Ke Li, Xing Sun, Long Ma","The GPT-4o's excellent duplex speech interaction ability has given users an impressive experience. Researchers have recently proposed several multimodal LLMs to achieve user-agent speech-to-speech conversations. In this paper, we propose a novel speech-text multimodal LLM architecture called Freeze-Omni, and our main contribution is that the speech input and output modalities can be easily connected to a textual LLM while keeping the LLM's parameters frozen throughout the training process. We effectively ensure that the intelligence of the Freeze-Omni in the speech modality is at the same level as that in the text modality of its backbone LLM while achieving low latency in the end-to-end spoken response. In addition, we also designed a method to achieve duplex dialogue ability through multitask training, giving Freeze-Omni a more natural style of dialogue ability between users and agents. In summary, Freeze-Omni holds great potential to conduct speech-to-speech dialogue based on a multimodal LLM under the condition of a frozen LLM, avoiding the catastrophic forgetting problem caused by limited data and training resources.","Building AI systems that can have natural, real-time voice conversations like humans requires connecting speech inputs to powerful language models. However, retraining these models for speech often demands massive resources and risks degrading their existing text-based intelligence.We designed Freeze-Omni, a system that adds speech interaction to large language models (LLMs) without altering their core knowledge. Imagine plugging a microphone and speaker into a frozen AI brain—our method trains only the speech components while keeping the LLM’s original skills intact. We also taught the system to handle smooth back-and-forth dialogue, mimicking natural human conversation.Freeze-Omni enables voice assistants to respond as intelligently in speech as they do in text, with minimal delay. This approach reduces training costs, avoids ""forgetting"" previous knowledge, and paves the way for more accessible, human-like AI communication tools—even for teams with limited data or computing power."
Poster,From Black Boxes to Transparent Minds: Evaluating and Enhancing the Theory of Mind in Multimodal Large Language Models,https://ICML.cc//virtual/2025/poster/46073,"Xinyang Li, Siqi Liu, Bochao Zou, Jiansheng Chen, Huimin Ma","As large language models evolve, there is growing anticipation that they will emulate human-like Theory of Mind (ToM) to assist with routine tasks. However, existing methods for evaluating machine ToM focus primarily on unimodal models and largely treat these models as black boxes, lacking an interpretative exploration of their internal mechanisms. In response, this study adopts an approach based on internal mechanisms to provide an interpretability-driven assessment of ToM in multimodal large language models (MLLMs). Specifically, we first construct a multimodal ToM test dataset, GridToM, which incorporates diverse belief testing tasks and perceptual information from multiple perspectives. Next, our analysis shows that attention heads in multimodal large models can distinguish cognitive information across perspectives, providing evidence of ToM capabilities. Furthermore, we present a lightweight, training-free approach that significantly enhances the model’s exhibited ToM by adjusting in the direction of the attention head.","Artificial-intelligence helpers will be far safer and more useful if they can reason about what different people have seen or know—a skill psychologists call Theory of Mind. Existing computer tests for this skill treat AI models like sealed black boxes and work, so they miss how modern systems combine language with images. We created GridToM, a new set of puzzles that mix pictures and words and ask models to predict what each observer would believe. Instead of just scoring answers, we also opened the model’s “mind”: we tracked the internal attention heads that decide where the model looks, and found distinct patterns for each observer’s point of view. That tells us the model is genuinely separating perspectives, not just guessing. Finally, we show a simple, training-free tweak—nudging the model along the relevant attention direction—that makes it even better at these social-reasoning tasks. Our approach offers both a sharper yardstick and a clearer window into how future multimodal AI can understand us."
