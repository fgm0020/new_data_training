type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Towards Attributions of Input Variables in a Coalition,https://ICML.cc//virtual/2025/poster/44434,"Xinhao Zheng, Huiqi Deng, Quanshi Zhang","This paper focuses on the fundamental challenge of partitioning input variables in attribution methods for Explainable AI, particularly in Shapley value-based approaches. Previous methods always compute attributions given a predefined partition but lack theoretical guidance on how to form meaningful variable partitions. We identify that attribution conflicts arise when the attribution of a coalition differs from the sum of its individual variables' attributions. To address this, we analyze the numerical effects of AND-OR interactions in AI models and extend the Shapley value to a new attribution metric for variable coalitions. Our theoretical findings reveal that specific interactions cause attribution conflicts, and we propose three metrics to evaluate coalition faithfulness. Experiments on synthetic data, NLP, image classification, and the game of Go validate our approach, demonstrating consistency with human intuition and practical applicability.","We want to make AI models easier to understand by explaining why they make certain decisions — for example, why a model thinks a photo shows a dog rather than a cat. One popular method is to see how much each part of the input (like each word or pixel) contributes to the final decision. But there's a problem: when we group inputs together, the total contribution often doesn't match what you'd expect from the individual parts, which leads to confusion.In this work, we explore why this mismatch happens and how different kinds of logic inside AI models affect it. We build on a well-known method called the Shapley value and create a new way to fairly measure how groups of inputs (called coalitions) contribute to an outcome. We also introduce three ways to check whether these group contributions make sense.We tested our ideas on examples ranging from simple simulations to language tasks, image recognition, and even the game of Go. Our method gave results that aligned better with human intuition, and it could help researchers and developers build more trustworthy and interpretable AI systems."
Poster,Towards a Unified Framework of Clustering-based Anomaly Detection,https://ICML.cc//virtual/2025/poster/46624,"Zeyu Fang, Ming Gu, Sheng Zhou, Jiawei Chen, Qiaoyu Tan, Haishuai Wang, Jiajun Bu","Unsupervised Anomaly Detection (UAD) plays a crucial role in identifying abnormal patterns within data without labeled examples, holding significant practical implications across various domains. Although the individual contributions of representation learning and clustering to anomaly detection are well-established, their interdependencies remain under-explored due to the absence of a unified theoretical framework. Consequently, their collective potential to enhance anomaly detection performance remains largely untapped. To bridge this gap, in this paper, we propose a novel probabilistic mixture model for anomaly detection to establish a theoretical connection among representation learning, clustering, and anomaly detection. By maximizing a novel anomaly-aware data likelihood, representation learning and clustering can effectively reduce the adverse impact of anomalous data and collaboratively benefit anomaly detection. Meanwhile, a theoretically substantiated anomaly score is naturally derived from this framework. Lastly, drawing inspiration from gravitational analysis in physics, we have devised an improved anomaly score that more effectively harnesses the combined power of representation learning and clustering. Extensive experiments, involving 17 baseline methods across 30 diverse datasets, validate the effectiveness and generalization capability of the proposed method, surpassing state-of-the-art methods.","In many real-world applications like detecting financial fraud or identifying unusual medical conditions, we need computers to automatically spot abnormal patterns in data—but often we don't have examples of what ""abnormal"" looks like to teach them.We developed a new mathematical framework that helps computers detect these anomalies by combining three key abilities: understanding data patterns, grouping similar things together, and identifying outliers—all working in harmony rather than separately.   Our approach is inspired by how gravity works in physics, where objects influence each other based on their mass and distance.This unified method significantly improves the accuracy of anomaly detection across 30 different datasets, outperforming existing approaches.   This matters because better anomaly detection can help prevent credit card fraud, catch manufacturing defects early, identify potential health issues before they become serious, and protect computer systems from cyberattacks."
Poster,Towards Better-than-2 Approximation for Constrained Correlation Clustering,https://ICML.cc//virtual/2025/poster/45533,"Andreas Kalavas, Evangelos Kipouridis, Nithin Varma","In the Correlation Clustering problem, we are given an undirected graph and are tasked with computing a clustering (partition of the nodes) that minimizes the sum of the number of edges across different clusters and the number of non-edges within clusters. In the constrained version of this problem, the goal is to compute a clustering that satisfies additional hard constraints mandating certain pairs to be in the same cluster and certain pairs to be in different clusters. Constrained Correlation Clustering is APX-Hard, and the best known approximation factor is 3 (van Zuylen et al. [SODA '07]). In this work, we show that in order to obtain a better-than-2 approximation, solving the (exponentially large) Constrained Cluster LP would be sufficient.[The peer-reviewed version of this article claimed an efficient algorithm for solving the Constrained Cluster LP. An error in the proof, that the authors discovered after the review process, led them to revise the results to be conditional on the existence of a valid LP solution.]","When teaching machines to learn from data without explicit supervision—a setting known as unsupervised learning—a central objective is to group data into clusters based on inherent similarities. In many practical scenarios, however, incorporating expert knowledge can significantly improve clustering quality, giving rise to semi-supervised learning.This paper addresses a semi-supervised learning problem known as Constrained Correlation Clustering. The setting involves a set of elements, along with expert-provided similarity judgments for certain pairs—these are considered reliable. For the remaining pairs, we have less reliable estimates of similarity.The goal is to cluster the elements such that:- Pairs deemed dissimilar by the expert lie in different clusters (cannot-link),- Pairs deemed similar by the expert do not end up in different clusters (must-link),- The number of violated similarity estimates is minimized.In this paper, we draw connections between two fundamental techniques from the literature, paving the way for improved and conceptually simple algorithms."
Poster,Towards Black-Box Membership Inference Attack for Diffusion Models,https://ICML.cc//virtual/2025/poster/45100,"Jingwei Li, Jing Dong, Tianxing He, Jingzhao Zhang","Given the rising popularity of AI-generated art and the associated copyright concerns, identifying whether an artwork was used to train a diffusion model is an important research topic. The work approaches this problem from the membership inference attack (MIA) perspective. We first identify the limitation of applying existing MIA methods for proprietary diffusion models: the required access of internal U-nets.To address the above problem, we introduce a novel membership inference attack method that uses only the image-to-image variation API and operates without access to the model's internal U-net. Our method is based on the intuition that the model can more easily obtain an unbiased noise prediction estimate for images from the training set. By applying the API multiple times to the target image, averaging the outputs, and comparing the result to the original image, our approach can classify whether a sample was part of the training set. We validate our method using DDIM and Stable Diffusion setups and further extend both our approach and existing algorithms to the Diffusion Transformer architecture. Our experimental results consistently outperform previous methods.","AI image generators often train on artists’ works without consent, raising copyright concerns. We introduce a way to detect if a specific image was used in training, even when the model is a black box. Our method repeatedly applies the model’s image-editing tool to the same image and averages the outputs. If the model has seen the image before, the outputs tend to look more consistent. This pattern helps us identify training images without needing access to the model’s internal code, offering a new way to protect creators’ rights."
Poster,Towards characterizing the value of edge embeddings in Graph Neural Networks,https://ICML.cc//virtual/2025/poster/46181,"Dhruv Rohatgi, Tanya Marwah, Zachary Lipton, Jianfeng Lu, Ankur Moitra, Andrej Risteski","Graph neural networks (GNNs) are the dominant approach to solving machine learning problems defined over graphs. Despite much theoretical and empirical work in recent years, our understanding of finer-grained aspects of architectural design for GNNs remains impoverished. In this paper, we consider the benefits of architectures that maintain and update edge embeddings. On the theoretical front, under a suitable computational abstraction for a layer in the model, as well as memory constraints on the embeddings, we show that there are natural tasks on graphical models for which architectures leveraging edge embeddings can be much shallower. Our techniques are inspired by results on time-space tradeoffs in theoretical computer science.  Empirically, we show architectures that maintain edge embeddings almost always improve on their node-based counterparts---frequently significantly so in topologies that have ""hub"" nodes.","Graphs are a useful way of encoding ""similarity"" structure in data: for example, chemical bonds in molecules, or friendships in social networks. Graph Neural Networks (GNNs) learn to predict properties of graph-structured data -- such as chemical properties of a given molecule. Typically, they do this by associating some numerical features to each node of the graph, and then iteratively updating these features based on the features of neighboring nodes. However, a different paradigm is to associate features with *edges* of the graph. When might this lead to more accurate or faster prediction?In this paper, we study this question by looking at how many iterations GNNs need, and how much numerical information they need to ""remember"" at each node or edge, in order to compute a given graph property. We show that when edge-based GNNs and node-based GNNs are constrained to the same amount of memory, the edge-based GNNs can compute some graph properties with much fewer iterations than node-based GNNs. Intuitively, node-based GNNs are bottlenecked by ""hub nodes"" that need to pass lots of information to many neighboring nodes, whereas edge-based GNNs are not. We find similar results in our experiments on both artificial graphs and real-world benchmarks from chemistry and computer vision.Our results suggest a fundamental benefit of edge-based GNNs, but they also have downsides (particularly on graphs with far more edges than nodes). A key direction for future research is to get the ""best of both worlds"" between the edge-based and node-based paradigms."
Poster,Towards Cost-Effective Reward Guided Text Generation,https://ICML.cc//virtual/2025/poster/44130,"Ahmad Rashid, Ruotian Wu, Rongqi Fan, Hongliang Li, Agustinus Kristiadi, Pascal Poupart","Reward-guided text generation (RGTG) has emerged as a viable alternative to offline reinforcement learning from human feedback (RLHF). RGTG methods can align baseline language models to human preferences without further training as in standard RLHF methods. However, they rely on a reward model to score each candidate token generated by the language model at inference, incurring significant test-time overhead. Additionally, the reward model is usually only trained to score full sequences, which can lead to sub-optimal choices for partial sequences. In this work, we present a novel reward model architecture that is trained, using a Bradley-Terry loss, to prefer the optimal expansion of a sequence with just a single call to the reward model at each step of the generation process.  That is, a score for all possible candidate tokens is generated simultaneously, leading to efficient inference. We theoretically analyze various RGTG reward models and demonstrate that prior techniques prefer sub-optimal sequences compared to our method during inference. Empirically, our reward model leads to significantly faster inference than other RGTG methods. It requires fewer calls to the reward model and performs competitively compared to previous RGTG and offline RLHF methods.","Can language models improve with the help of human feedback without re-training ? Re-training is expensive as it requires computational resources and electricity consumption, and contributes to carbon emissions. Prior work has shown that it is indeed possible to do so, but comes at the cost of longer response times from the language model, when answering a query. We present a method , FaRMA, that can significantly reduce this response time while still avoid re-training. Moreover, we demonstrate scenarios where the prior methods fail to provide good responses and show that FaRMA is not vulnerable to these."
Poster,Towards Efficient Online Tuning of VLM Agents via Counterfactual Soft Reinforcement Learning,https://ICML.cc//virtual/2025/poster/45797,"Lang Feng, Weihao Tan, Zhiyi Lyu, Longtao Zheng, Haiyang Xu, Ming Yan, Fei Huang, Bo An","Online fine-tuning vision-language model (VLM) agents with reinforcement learning (RL) has shown promise for equipping agents with multi-step, goal-oriented capabilities in dynamic environments. However, their open-ended textual action space and non-end-to-end nature of action generation present significant challenges to effective online exploration in RL, e.g., explosion of the exploration space. We propose a novel online fine-tuning method, Counterfactual Soft Reinforcement Learning (CoSo), better suited to the textual output space of VLM agents. Compared to prior methods that assign uniform uncertainty to all tokens, CoSo leverages counterfactual reasoning to dynamically assess the causal influence of individual tokens on post-processed actions. By prioritizing the exploration of action-critical tokens while reducing the impact of semantically redundant or low-impact tokens, CoSo enables a more targeted and efficient online rollout process. We provide theoretical analysis proving CoSo's convergence and policy improvement guarantees, and extensive empirical evaluations supporting CoSo's effectiveness. Our results across a diverse set of agent tasks, including Android device control, card gaming, and embodied AI, highlight its remarkable ability to enhance exploration efficiency and deliver consistent performance gains. The code is available at https://github.com/langfengQ/CoSo.","Large vision-language model (VLM) agents can already read screens and describe what to do, but teaching them to take useful actions in the real world—like operating a smartphone, playing a game, or controlling a robot—is still a major challenge. One key reason is that their decisions are made in text, which is far more complex than simple numeric commands. Much of the trial-and-error ends up exploring meaningless parts of the text that don’t affect the actual action. To solve this, we developed a new method called Counterfactual Soft Reinforcement Learning (CoSo). It figures out which tokens in the generated text actually influence the agent’s action, and focuses learning on just those important tokens. This allows the system to learn much faster and make smarter decisions with less guesswork. We tested CoSo on tasks like controlling Android devices, playing card games, and navigating virtual environments. In all cases, it made the agents more effective and efficient compared to older training methods."
Poster,Towards Escaping from Class Dependency Modeling for Multi-Dimensional Classification,https://ICML.cc//virtual/2025/poster/44993,"Teng Huang, Bin-Bin Jia, Min-Ling Zhang","In multi-dimensional classification (MDC), the semantics of objects are characterized by multiple class variables from different dimensions. Existing MDC approaches focus on designing effective class dependency modeling strategies to enhance classification performance. However, the intercoupling of multiple class variables poses a significant challenge to the precise modeling of class dependencies.  In this paper, we make the first attempt towards escaping from class dependency modeling for addressing MDC problems. Accordingly, a novel MDC approach named DCOM is proposed by decoupling the interactions of different dimensions in MDC. Specifically, DCOM endeavors to identify a latent factor that encapsulates the most salient and critical feature information. This factor will facilitate partial conditional independence among class variables conditioned on both the original feature vector and the learned latent embedding. Once the conditional independence is established, classification models can be readily induced by employing simple neural networks on each dimension. Extensive experiments conducted on benchmark data sets demonstrate that DCOM outperforms other state-of-the-art MDC approaches.","In real-world scenarios, objects usually need labels across multiple dimensions. For example, a landscape picture can be labeled from *time* dimension (with possible labels ""morning"", ""afternoon"", and ""night"", etc.), from *weather* dimension (with possible labels ""sunny"", ""rainy"", ""cloudy"", etc.), and from *scene* dimension (with possible labels ""desert"",  ""mountain"",  ""grass"", etc.).These labels can interact in complex ways --- label ""sunny"" in *weather* dimension can not occur with label ""night"" in *time* dimension while label ""dessert"" in *scene* dimension is often accompanied by ""sunny"".Such intricate dependencies make Multi-Dimensional Classification (MDC), a task requiring predictions across multiple class spaces particularly challenging. This paper introduces a groundbreaking approach called DCOM, which bypasses the need to directly analyze class dependencies.Instead, DCOM learns a latent factor to capture the most essential and critical feature information to naturally untangles the chaos caused by interrelated dimensions. This allows simple, independent models to handle each dimension efficiently, like using basic neural networks for separate tasks.As a first attempt towards escaping from class dependency modeling in MDC, DCOM achieves state-of-the-art performance while marking a paradigm shift in handling complex class interactions."
Poster,Towards flexible perception with visual memory,https://ICML.cc//virtual/2025/poster/44639,"Robert Geirhos, Priyank Jaini, Austin Stone, Sourabh Medapati, Xi Yi, George Toderici, Abhijit Ogale, Jonathon Shlens","Training a neural network is a monolithic endeavor, akin to carving knowledge into stone: once the process is completed, editing the knowledge in a network is nearly impossible, since all information is distributed across the network's weights. We here explore a simple, compelling alternative by marrying the representational power of deep neural networks with the flexibility of a database. Decomposing the task of image classification into image similarity (from a pre-trained embedding) and search (via fast nearest neighbor retrieval from a knowledge database), we build a simple and flexible visual memory that has the following key capabilities: (1.) The ability to flexibly add data across scales: from individual samples all the way to entire classes and billion-scale data; (2.) The ability to remove data through unlearning and memory pruning; (3.) An interpretable decision-mechanism on which we can intervene to control its behavior. Taken together, these capabilities comprehensively demonstrate the benefits of an explicit visual memory. We hope that it might contribute to a conversation on how knowledge should be represented in deep vision models---beyond carving it in ""stone"" weights.","Training a neural network is a monolithic endeavor, akin to carving knowledge into stone: once the process is completed, editing the knowledge in a network is nearly impossible, since all information is distributed across the network's weights. We here explore a simple, compelling alternative by marrying the representational power of deep neural networks with the flexibility of a database. Decomposing the task of image classification into image similarity (from a pre-trained embedding) and search (via fast nearest neighbor retrieval from a knowledge database), we build a simple and flexible visual memory that has the following key capabilities: (1.) The ability to flexibly add data across scales: from individual samples all the way to entire classes and billion-scale data; (2.) The ability to remove data through unlearning and memory pruning; (3.) An interpretable decision-mechanism on which we can intervene to control its behavior. Taken together, these capabilities comprehensively demonstrate the benefits of an explicit visual memory. We hope that it might contribute to a conversation on how knowledge should be represented in deep vision models---beyond carving it in ""stone"" weights."
Poster,Towards Global-level Mechanistic Interpretability: A Perspective of Modular Circuits of Large Language Models,https://ICML.cc//virtual/2025/poster/44616,"Yinhan He, Wendy Zheng, Yushun Dong, Yaochen Zhu, Chen Chen, Jundong Li","Mechanistic interpretability (MI) research aims to understand large language models (LLMs) by identifying computational circuits, subgraphs of model components with associated functional interpretations, that explain specific behaviors. Current MI approaches focus on discovering task-specific circuits, which has two key limitations: (1) poor generalizability across different language tasks, and (2) high costs associated with requiring human or advanced LLM interpretation of each computational node. To address these challenges, we propose developing a ``modular circuit (MC) vocabulary'' consisting of task-agnostic functional units. Each unit consists of a small computational subgraph with its interpretation. This approach enables global interpretability by allowing different language tasks to share common MCs, while reducing costs by reusing established interpretations for new tasks. We establish five criteria for characterizing the MC vocabulary and present ModCirc, a novel global-level mechanistic interpretability framework for discovering MC vocabularies in LLMs. We demonstrate ModCirc's effectiveness by showing that it can identify modular circuits that perform well on various metrics.","How do powerful AI language models like ChatGPT actually work inside? Current methods for understanding these systems analyze each task separately and require expensive human interpretation of every component, making comprehensive analysis impractical as AI systems grow larger. We developed a new approach called ModCirc that identifies reusable ""building blocks"" within AI models that perform similar functions across different tasks. Think of these like specialized tools in a workshop that can be used for multiple projects rather than creating new tools from scratch each time. For example, we found components in a medical AI that consistently identify patient symptoms whether the task involves diagnosis, treatment recommendations, or medical summarization. Our method creates a vocabulary of these reusable components with pre-established interpretations, dramatically reducing the cost of understanding new AI behaviors. When analyzing a new task, researchers can match components against this existing vocabulary instead of starting interpretation from zero. Testing on both general and domain-specific tasks, we successfully identified some important components and demonstrated clear patterns of reuse across different applications. This approach can make AI systems more interpretable in a more affordable and scalable manner."
