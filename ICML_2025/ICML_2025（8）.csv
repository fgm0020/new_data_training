type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Adaptive Partitioning Schemes for Optimistic Optimization,https://ICML.cc//virtual/2025/poster/43904,"Raja Sunkara, Ardhendu Tripathy","Applications such as engineering design often require us to optimize a black-box function, i.e., a system whose inner processing is not analytically known and whose gradients are not available. Practitioners often have a fixed budget for the number of function evaluations and the performance of an optimization algorithm is measured by its simple regret. In this paper, we study the class of ``Optimistic Optimization'' algorithms for black-box optimization that use a partitioning scheme for the domain. We develop algorithms that learn a good partitioning scheme and use flexible surrogate models such as neural networks in the optimization procedure. For multi-index functions on an $m$-dimensional subspace within $d$ dimensions, our algorithm attains $\tilde{O}(n^{-\beta / d})$ regret, where $\beta = 1 + \frac{d-m}{2m-1}$, as opposed to $\tilde{O}(n^{-1/d})$ for SequOOL, a state-of-the-art optimistic optimization algorithm. Our approach is competitive across a wide range of numerical benchmarks. Additionally, we introduce weight quantization in a large language model as a novel task for black-box optimization. Our approach improves the quality of Activation-aware Weight Quantization (AWQ) of the OPT-1.3B model, achieving an approximate 10\% improvement in performance relative to the best possible unquantized model.","Engineers often want to find the best solution to complex problems that take time to experiment with, like finding new drug molecules or designing aircraft wings. This becomes extremely challenging when many factors are involved, making traditional search methods slow and inefficient. This paper develops a new approach that uses neural networks to identify which factors matter most, then focuses the search on those key areas rather than exploring everything blindly. When tested on standard problems and applied to making AI language models more efficient, this method found better solutions faster than existing techniques. This research matters because it could help solve complex optimization problems more quickly in various fields, from engineering design to making AI systems run on everyday devices."
Poster,Adaptive Sample Sharing for Multi Agent Linear Bandits,https://ICML.cc//virtual/2025/poster/43940,"Hamza Cherkaoui, Merwan Barlier, Igor Colin","The multi-agent linear bandit setting is a well-known setting for which designing efficient collaboration between agents remains challenging. This paper studies the impact of data sharing among agents on regret minimization. Unlike most existing approaches, our contribution does not rely on any assumptions on the bandit parameters structure. Our main result formalizes the trade-off between the bias and uncertainty of the bandit parameter estimation for efficient collaboration. This result is the cornerstone of the Bandit Adaptive Sample Sharing (BASS) algorithm, whose efficiency over the current state-of-the-art is validated through both theoretical analysis and empirical evaluations on both synthetic and real-world datasets. Furthermore, we demonstrate that, when agents' parameters display a cluster structure, our algorithm accurately recovers them.","Recommendation algorithms—like those used on video platforms—often serve users with similar tastes. While a recommendation system could benefit from sharing what it has learned about one user, doing so effectively requires identifying when user preferences overlap. This motivated us to explore how such systems can collaborate to accelerate learning.We developed BASS, a method that enables algorithms to decide when and with whom to share information. It uses observed behavior to detect when recommendation systems are learning from similar user groups and shares information only when it improves performance. Notably, BASS requires no prior knowledge about which systems are related.This approach makes collaboration between learning systems more efficient and impactful. Whether applied to apps, devices, or content platforms, BASS helps them learn faster by leveraging shared patterns across users. Experiments on both synthetic and real-world data show that BASS consistently outperforms existing methods."
Poster,Adaptive Self-improvement LLM Agentic System for ML Library Development,https://ICML.cc//virtual/2025/poster/44464,"Genghan Zhang, Weixin Liang, Olivia Hsu, Kunle Olukotun","ML libraries, often written in architecture-specific programming languages (ASPLs) that target domain-specific architectures, are key to efficient ML systems. However, writing these high-performance ML libraries is challenging because it requires expert knowledge of both ML algorithms and the ASPL. Large language models (LLMs), on the other hand, have shown general coding capabilities. However, challenges remain when using LLMs for generating ML libraries using ASPLs because 1) this task is complicated even for human experts and 2) there are limited code examples due to the esoteric and evolving nature of ASPLs. We present an adaptive self-improvement agentic system that enables LLMs to perform such complex reasoning under limited data by iteratively improving their capability through self-generated experience. In order to evaluate the effectiveness of our system, we construct a benchmark of a typical ML library and generate ASPL code with both open and closed-source LLMs on this benchmark. Our results show improvements of up to $3.9\times$ over a baseline single LLM.","This paper presents a new system that helps artificial intelligence (AI) models improve themselves over time, specifically for writing the code needed to run machine learning (ML) programs on specialized hardware. Creating this code is usually a difficult and time-consuming task, even for experts, because it requires deep knowledge of both ML techniques and the hardware-specific programming languages. The authors show how large language models can be turned into a team of AI agents that learn from their own past successes and mistakes. This self-improvement process allows them to write better code without needing thousands of examples. They tested their system on a new, cutting-edge programming language and showed it could solve nearly all the critical tasks and be up to four times better than using one AI model alone. This approach could make it much easier and faster to build high-performance ML systems in the future."
Poster,Adaptive Sensitivity Analysis for Robust Augmentation against Natural Corruptions in Image Segmentation,https://ICML.cc//virtual/2025/poster/43645,"Laura Zheng, Wenjie Wei, Tony Wu, Jacob Clements, Shreelekha Revankar, Andre Harrison, Yu Shen, Ming Lin","Achieving robustness in image segmentation models is challenging due to the fine-grained nature of pixel-level classification. These models, which are crucial for many real-time perception applications, particularly struggle when faced with natural corruptions in the wild for autonomous systems. While sensitivity analysis can help us understand how input variables influence model outputs, its application to natural and uncontrollable corruptions in training data is computationally expensive. In this work, we present an adaptive, sensitivity-guided augmentation method to enhance robustness against natural corruptions. Our sensitivity analysis on average runs 10 times faster and requires about 200 times less storage than previous sensitivity analysis, enabling practical, on-the-fly estimation during training for a model-free augmentation policy. With minimal fine-tuning, our sensitivity-guided augmentation method achieves improved robustness on both real-world and synthetic datasets compared to state-of-the-art data augmentation techniques in image segmentation.","Edge cases like adverse weather are difficult to account for in perception tasks like segmentation, especially in real-time applications like robotics. We propose a solution via data augmentation, where we sample ""evenly difficult"" synthetic perturbation intensities with respect to model performance. Our approach is similar to how students may choose to practice on more difficult practice questions and less on easier questions across different sections, relative to their current knowledge. Our approach helps improve convergence and generalization of segmentation models, especially in unseen real world scenarios."
Poster,AdaptiveStep: Automatically Dividing Reasoning Step through Model Confidence,https://ICML.cc//virtual/2025/poster/45053,"Yuliang Liu, Junjie Lu, Chaofeng Qu, Zhaoling Chen, Zefan Cai, Jason Liu, Chonghan Liu, Yunhui Xia, Li Zhao, Jiang Bian, Chuheng Zhang, Wei Shen, Zhouhan Lin","Current approaches for training Process Reward Models (PRMs) often involve deconposing responses into multiple reasoning steps using rule-based techniques, such as using predefined placeholder tokens or setting the reasoning step's length to a fixed size.These approaches overlook the fact that certain words don't usually indicate true decision points. To address this, we propose AdaptiveStep, a method that divides reasoning steps based on the model's confidence in predicting the next word, offering more information on decision-making at each step, improving downstream tasks like reward model training. Moreover, our method requires no manual annotation. Experiments with AdaptiveStep-trained PRMs in mathematical reasoning and code generation show that the outcome PRM achieves state-of-the-art Best-of-N performance, surpassing greedy search strategy with token-level value-guided decoding, while also reducing construction costs by over 30% compared to existing open-source PRMs. We also provide a thorough analysis and case study on its performance, transferability, and generalization capabilities. We provide our code on https://github.com/Lux0926/ASPRM.","Training AI systems to evaluate the quality of multi-step reasoning in process — like intermediate process of solving math problems or writing code — is difficult. Current methods often break down answers into fixed-size chunks or use rule-based markers, which don’t always reflect how real decisions are made during reasoning.We introduce AdaptiveStep, a new method that automatically decides where to split reasoning steps based on the AI model’s confidence in predicting the next word. This leads to more meaningful and informative decision points without needing any manual labeling.Using AdaptiveStep, we train Process Reward Models that better understand complex tasks. These models not only outperform existing methods in math and code tasks but also cost significantly less to train. Our research offers a scalable and effective way to improve how AI learns to evaluate step-by-step reasoning — a key challenge for more reliable AI."
Poster,AdaPTS: Adapting Univariate Foundation Models to Probabilistic Multivariate Time Series Forecasting,https://ICML.cc//virtual/2025/poster/43518,"Abdelhakim Benechehab, Vasilii Feofanov, Giuseppe Paolo, Albert Thomas, Maurizio Filippone, Balázs Kégl","Pre-trained foundation models (FMs) have shown exceptional performance in univariate time series forecasting tasks. However, several practical challenges persist, including managing intricate dependencies among features and quantifying uncertainty in predictions. This study aims to tackle these critical limitations by introducing **adapters**—feature-space transformations that facilitate the effective use of pre-trained univariate time series FMs for multivariate tasks. Adapters operate by projecting multivariate inputs into a suitable latent space and applying the FM independently to each dimension. Inspired by the literature on representation learning and partially stochastic Bayesian neural networks, we present a range of adapters and optimization/inference strategies. Experiments conducted on both synthetic and real-world datasets confirm the efficacy of adapters, demonstrating substantial enhancements in forecasting accuracy and uncertainty quantification compared to baseline methods. Our framework, **AdaPTS**, positions adapters as a modular, scalable, and effective solution for leveraging time series FMs in multivariate contexts, thereby promoting their wider adoption in real-world applications. We release the code at https://github.com/abenechehab/AdaPTS.","While powerful AI models called foundation models have revolutionized forecasting for single time series (like predicting one stock price), they struggle with real-world scenarios involving multiple interconnected variables (like predicting temperature, humidity, and wind speed simultaneously), as these models can't handle the complex relationships between different variables and don't tell us how confident they are in their predictions—both critical issues for practical applications. To address this challenge, we developed AdaPTS, a framework that uses ""adapters""—smart translation layers that help existing single-variable forecasting models work with multiple variables by acting as interpreters that take complex multi-dimensional data, transform it into a format the pre-trained model understands, then let the model make predictions for each dimension separately. We designed several types of adapters inspired by advanced machine learning techniques that not only improve accuracy but also provide uncertainty estimates."
Poster,AdaSplash: Adaptive Sparse Flash Attention,https://ICML.cc//virtual/2025/poster/45440,"Nuno Gonçalves, Marcos V. Treviso, Andre Martins","The computational cost of softmax-based attention in transformers limits their applicability to long-context tasks. Adaptive sparsity, of which $\alpha$-entmax attention is an example, offers a flexible data-dependent alternative, but existing implementations are inefficient and do not leverage the sparsity to obtain runtime and memory gains. In this work, we propose AdaSplash, which combines the efficiency of GPU-optimized algorithms with the sparsity benefits of $\alpha$-entmax. We first introduce a hybrid Halley-bisection algorithm, resulting in a 7-fold reduction in the number of iterations needed to compute the $\alpha$-entmax transformation. Then, we implement custom Triton kernels to efficiently handle adaptive sparsity. Experiments with RoBERTa and ModernBERT for text classification and single-vector retrieval, along with GPT-2 for language modeling, show that our method achieves substantial improvements in runtime and memory efficiency compared to existing $\alpha$-entmax implementations. It approaches---and in some cases surpasses---the efficiency of highly optimized softmax implementations like FlashAttention-2, enabling long-context training while maintaining strong task performance.","Transformers, the backbone of modern language models, use softmax attention to decide how much focus each token (e.g. word) gives to others. While effective, softmax always assigns some importance to all tokens, even irrelevant ones, making it harder for models to focus sharply on important tokens. A promising alternative is adaptively sparse $\alpha$-entmax attention, which learns to ignore irrelevant words by assigning them exactly zero weight, allowing models to focus more selectively. However, prior implementations of $\alpha$-entmax have been slow and memory-intensive for practical use. To solve this, we introduce AdaSplash, a fast and GPU-friendly implementation of $\alpha$-entmax attention. With this, we significantly cut down both computation and required memory usage compared to previous methods, and as a result, AdaSplash closes the longstanding gap between the theoretical appeal of $\alpha$-entmax attention and its practical usability in large-scale, long-context applications. All code is open-source to support broader adoption and further research."
Poster,AdaWorld: Learning Adaptable World Models with Latent Actions,https://ICML.cc//virtual/2025/poster/45343,"Shenyuan Gao, Siyuan Zhou, Yilun Du, Jun Zhang, Chuang Gan","World models aim to learn action-controlled future prediction and have proven essential for the development of intelligent agents. However, most existing world models rely heavily on substantial action-labeled data and costly training, making it challenging to adapt to novel environments with heterogeneous actions through limited interactions. This limitation can hinder their applicability across broader domains. To overcome this limitation, we propose AdaWorld, an innovative world model learning approach that enables efficient adaptation. The key idea is to incorporate action information during the pretraining of world models. This is achieved by extracting latent actions from videos in a self-supervised manner, capturing the most critical transitions between frames. We then develop an autoregressive world model that conditions on these latent actions. This learning paradigm enables highly adaptable world models, facilitating efficient transfer and learning of new actions even with limited interactions and finetuning. Our comprehensive experiments across multiple environments demonstrate that AdaWorld achieves superior performance in both simulation quality and visual planning.","How to achieve human-alike adaptability in unseen environments with new action controls? In this paper, we answer this by pretraining AdaWorld with continuous latent actions from thousands of environments. It enables zero-shot action transfer, fast adaptation, and effective planning with minimal finetuning."
Poster,ADDQ: Adaptive distributional double Q-learning,https://ICML.cc//virtual/2025/poster/46093,"Leif Döring, Benedikt Wille, Maximilian Birr, Mihail Bîrsan, Martin Slowik","Bias problems in the estimation of Q-values are a well-known obstacle that slows down convergence of Q-learning and actor-critic methods. One of the reasons of the success of modern RL algorithms is partially a direct or indirect overestimation reduction mechanism. We introduce an easy to implement method built on top of distributional reinforcement learning (DRL) algorithms to deal with the  overestimation in a locally adaptive way. Our framework ADDQ is simple to implement, existing DRL implementations can be improved with a few lines of code. We provide theoretical backup and experimental results in tabular, Atari, and MuJoCo environments, comparisons with state-of-the-art methods, and a proof of convergence in the tabular case.","Scientists working on computers that learn by trial and error (reinforcement learning) have long noticed that the computer sometimes estimates the value of actions incorrectly. This mistake—overestimating what an action might earn—can slow down the learning process. Many modern methods already include tricks to reduce these mistakes. The new method proposed builds on an approach called distributional reinforcement learning. In simple terms, this method looks at the range of possible outcomes rather than just one average value. By doing so, it can adjust the predictions more accurately in different situations. The cool part is that this new method is easy to add to existing code implementations—just a few lines of code are needed! We back our idea with theoretical analysis and demonstrate how to integrate it using another technique known as double Q-learning. We tested the approach in various scenarios, including simple, grid-like problems, video games (like Atari), and even in simulated robotics (MuJoCo).In summary, this new method helps computer learning systems make better predictions about the value of their actions, leading to quicker and more reliable learning."
Poster,Addressing Concept Mislabeling in Concept Bottleneck Models Through Preference Optimization,https://ICML.cc//virtual/2025/poster/43840,"Emiliano Penaloza, Tianyue Zhang, Laurent Charlin, Mateo Espinosa Zarlenga","Concept Bottleneck Models (CBMs) propose toenhance the trustworthiness of AI systems byconstraining their decisions on a set of humanunderstandable concepts. However, CBMs typically rely on datasets with assumedly accurateconcept labels—an assumption often violated inpractice which we show can significantly degradeperformance. To address this, we introduce theConcept Preference Optimization (CPO) objective, a new loss function based on Direct Preference Optimization, which effectively mitigatesthe negative impact of concept mislabeling onCBM performance. We provide an analysis onsome key properties of the CPO objective showing it directly optimizes for the concept’s posteriordistribution, and contrast it against Binary CrossEntropy (BCE) where we show CPO is inherentlyless sensitive to concept noise. We empiricallyconfirm our analysis finding that CPO consistentlyoutperforms BCE in three real-world datasets withand without added label noise","Concept Bottleneck Models (CBMs) are a type of machine learning model that first predict human-understandable concepts — like “has a beak” or “is smiling” — and then use those concepts to make a final decision. This design makes the model’s reasoning easier to inspect and, importantly, allows users to intervene by correcting mispredicted concepts.Unfortunately, like many machine learning models, CBMs assume all concept labels are accurate — which isn’t realistic. Real-world data is often contaminated with labeling errors due to subjectivity, labeler fatigue, or even standard training tricks like cropping images that can accidentally hide important features. Our work introduces a new training method called Concept Preference Optimization (CPO) that makes CBMs more reliable when labels aren’t perfect.Instead of treating every label as correct, CPO compares pairs of labels during training and teaches the model to favor those that seem more trustworthy. We show that CPO improves CBM performance even when many concept labels are wrong. It also helps the model better recognize when it’s unsure — a critical ability in high-stakes fields like healthcare or law enforcement."
