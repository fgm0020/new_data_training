type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,CSTrack: Enhancing RGB-X Tracking via Compact Spatiotemporal Features,https://ICML.cc//virtual/2025/poster/45687,"xiaokun Feng, Dailing Zhang, Shiyu Hu, Xuchen Li, Meiqi Wu, Jing Zhang, Xiaotang Chen, Kaiqi Huang","Effectively modeling and utilizing spatiotemporal features from RGB and other modalities (e.g., depth, thermal, and event data, denoted as X) is the core of RGB-X tracker design. Existing methods often employ two parallel branches to separately process the RGB and X input streams, requiring the model to simultaneously handle two dispersed feature spaces, which complicates both the model structure and computation process. More critically, intra-modality spatial modeling within each dispersed space incurs substantial computational overhead, limiting resources for inter-modality spatial modeling and temporal modeling.To address this, we propose a novel tracker, CSTrack, which focuses on modeling Compact Spatiotemporal features to achieve simple yet effective tracking.Specifically, we first introduce an innovative Spatial Compact Module that integrates the RGB-X dual input streams into a compact spatial feature, enabling thorough intra- and inter-modality spatial modeling. Additionally, we design an efficient Temporal Compact Module that compactly represents temporal features by constructing the refined target distribution heatmap. Extensive experiments validate the effectiveness of our compact spatiotemporal modeling method, with CSTrack achieving new SOTA results on mainstream RGB-X benchmarks.  The code and models will be released at: https://github.com/XiaokunFeng/CSTrack.","When tracking objects using different types of data like regular images (RGB), depth, thermal, and event data, it's crucial to efficiently merge and analyze these sources. Current tracking methods often process regular images and additional data streams separately, which leads to complicated models and increased computational demands. This complexity hinders the ability to effectively merge spatial data from different sources and track changes over time.To tackle these challenges, we introduce CSTrack, a new tracking method that focuses on simplifying and enhancing the way data is combined and analyzed. CSTrack employs a unique Spatial Compact Module to merge image and additional data streams into a unified spatial feature. This integration allows for effective modeling across different types of data. Moreover, CSTrack uses a Temporal Compact Module to represent changes over time efficiently, refining how moving objects are tracked.Our approach has been validated through extensive experiments, demonstrating that CSTrack sets new standards in tracking accuracy on RGB-X benchmarks, showcasing its simple yet powerful method for object tracking."
Poster,CSV-Occ: Fusing Multi-frame Alignment for Occupancy Prediction with Temporal Cross State Space Model and Central Voting Mechanism,https://ICML.cc//virtual/2025/poster/46333,"Ziming Zhu, Yu Zhu, Jiahao Chen, Xiaofeng Ling, Huanlei Chen, Lihua Sun","Recently, image-based 3D semantic occupancy prediction has become a hot topic in 3D scene understanding for autonomous driving. Compared with the bounding box form of 3D object detection, the ability to describe the fine-grained contours of any obstacles in the scene is the key insight of voxel occupancy representation, which facilitates subsequent tasks of autonomous driving. In this work, we propose CSV-Occ to address the following two challenges: (1) Existing methods fuse temporal information based on the attention mechanism, but are limited by high complexity. We extend the state space model to support multi-input sequence interaction and conduct temporal modeling in a cascaded architecture, thereby reducing the computational complexity from quadratic to linear. (2) Existing methods are limited by semantic ambiguity, resulting in the centers of foreground objects often being predicted as empty voxels. We enable the model to explicitly vote for the instance center to which the voxels belong and spontaneously learn to utilize the other voxel features of the same instance to update the semantics of the internal vacancies of the objects from coarse to fine. Experiments on the Occ3D-nuScenes dataset show that our method achieves state-of-the-art in camera-based 3D semantic occupancy prediction and also performs well on lidar point cloud semantic segmentation on the nuScenes dataset. Therefore, we believe that CSV-Occ is beneficial to the community and industry of autonomous vehicles.","Recently, predicting 3D semantic occupancy from images has become popular in self-driving 3D scene understanding. Voxel occupancy can describe fine-grained obstacle contours better than 3D object detection's bounding boxes, helping self-driving tasks. Our CSV-Occ method meets two challenges. First, we simplify temporal information fusion by extending the state space model, cutting computational complexity. Second, we help the model accurately vote for voxel-belonging instance centers to fix semantic ambiguity. Tests on Occ3D-nuScenes and nuScenes lidar data show our method excels in camera-based 3D occupancy prediction and lidar semantic segmentation. We think CSV-Occ benefits the self-driving community and industry."
Poster,CTBench: A Library and Benchmark for Certified Training,https://ICML.cc//virtual/2025/poster/46137,"Yuhao Mao, Stefan Balauca, Martin Vechev","Training certifiably robust neural networks is an important but challenging task. While many algorithms for (deterministic) certified training have been proposed, they are often evaluated on different training schedules, certification methods, and systematically under-tuned hyperparameters, making it difficult to compare their performance. To address this challenge, we introduce CTBench, a unified library and a high-quality benchmark for certified training that evaluates all algorithms under fair settings and systematically tuned hyperparameters. We show that (1) almost all algorithms in CTBench surpass the corresponding reported performance in literature in the magnitude of algorithmic improvements, thus establishing new state-of-the-art, and (2) the claimed advantage of recent algorithms drops significantly when we enhance the outdated baselines with a fair training schedule, a fair certification method and well-tuned hyperparameters. Based on CTBench, we provide new insights into the current state of certified training, including (1) certified models have less fragmented loss surface, (2) certified models share many mistakes, (3) certified models have more sparse activations, (4) reducing regularization cleverly is crucial for certified training especially for large radii and (5) certified training has the potential to improve out-of-distribution generalization. We are confident that CTBench will serve as a benchmark and testbed for future research in certified training.","Neural networks are powerful tools used in everything from medical diagnostics to self-driving cars, but they can be easily fooled by small changes to their inputs—like altering just a few pixels in an image—raising concerns about their reliability. To make these systems more trustworthy, researchers have developed techniques that train models to be provably robust against such changes. However, because different methods were developed independently, past comparisons have often been inconsistent—especially when newer approaches were evaluated more favorably than older ones due to differences in testing conditions or tuning.In this paper, we introduce CTBench, the first unified framework that enables fair and thorough comparisons of leading robust training methods. By evaluating all methods under the same conditions and carefully tuning each one, we find that many older techniques perform much better than previously reported, narrowing the apparent advantage of newer state-of-the-art methods.Beyond comparison, CTBench also helps us better understand how robust models behave—for example, they tend to make similar mistakes and use their internal components more selectively. Finally, CTBench provides a simple, modular codebase that makes it easier to design and evaluate future robust training methods. We hope CTBench will serve as a strong foundation for future research, helping to build AI systems that are not only powerful, but also reliably safe and robust."
Poster,CtrlSynth: Controllable Image Text Synthesis for Data-Efficient Multimodal Learning,https://ICML.cc//virtual/2025/poster/43494,"Qingqing Cao, Mahyar Najibi, Sachin Mehta","Pretraining robust vision or multimodal foundation models (e.g., CLIP) relies on large-scale datasets that may be noisy, potentially misaligned, and have long-tail distributions. Previous works have shown promising results in augmenting datasets by generating synthetic samples. However, they only support domain-specific ad hoc use cases (e.g., either image or text only, but not both), and are limited in data diversity due to a lack of fine-grained control over the synthesis process. In this paper, we design a controllable image-text synthesis pipeline, CtrlSynth, for data-efficient and robust multimodal learning. The key idea is to decompose the visual semantics of an image into basic elements, apply user-specified control policies (e.g., remove, add, or replace operations), and recompose them to synthesize images or texts. The decompose and recompose feature in CtrlSynth allows users to control data synthesis in a fine-grained manner by defining customized control policies to manipulate the basic elements. CtrlSynth leverages the capabilities of pretrained foundation models such as large language models or diffusion models to reason and recompose basic elements such that synthetic samples are natural and composed in diverse ways. CtrlSynth is a closed-loop, training-free, and modular framework, making it easy to support different pretrained models. With extensive experiments on 31 datasets spanning different vision and vision-language tasks, we show that CtrlSynth substantially improves zero-shot classification, image-text retrieval, and compositional reasoning performance of CLIP models.","Training robust vision-language AI models like CLIP requires massive datasets that are often noisy, misaligned, and lack diversity, while existing synthetic data generation methods only work for single modalities and offer limited control. We developed CtrlSynth, a controllable pipeline that decomposes visual content into basic elements, applies user-defined policies to manipulate these elements, and reassembles them using pretrained AI models to generate diverse, natural image-text pairs. Testing on 31 datasets showed CtrlSynth significantly improves AI performance on classification, retrieval, and reasoning tasks, offering a training-free solution that makes models more robust while requiring less real-world data."
Poster,CUPS: Improving Human Pose-Shape Estimators with Conformalized Deep Uncertainty,https://ICML.cc//virtual/2025/poster/43692,"Harry Zhang, Luca Carlone","We introduce CUPS, a novel method for learning sequence-to-sequence 3D human shapes and poses from RGB videos with uncertainty quantification. To improve on top of prior work, we develop a method to {generate and score multiple hypotheses during training}, effectively integrating uncertainty quantification into the learning process. This process results in a deep uncertainty function that is trained end-to-end with the 3D pose estimator. Post-training, the learned deep uncertainty model is used as the conformity score, which can be used to calibrate a conformal predictor in order to {assess} the quality of the output prediction. Since the data in human pose-shape learning is not fully exchangeable, we also {present} two practical bounds for the coverage gap in conformal prediction, developing theoretical backing for the uncertainty bound of our model. Our results indicate thatby taking advantage of deep uncertainty with conformal prediction, our method achieves state-of-the-art performance across variousmetrics and datasets while inheriting the probabilistic guarantees of conformal prediction. Interactive 3D visualization, code, and data will be available at https://sites.google.com/view/champpp.",Improving human pose-shape estimation with uncertainty quantification.
Poster,Curriculum Learning for Biological Sequence Prediction: The Case of De Novo Peptide Sequencing,https://ICML.cc//virtual/2025/poster/45008,"Xiang Zhang, Jiaqi Wei, Zijie Qiu, Sheng Xu, Nanqing Dong, ZhiQiang Gao, Siqi Sun","Peptide sequencing—the process of identifying amino acid sequences from mass spectrometry data—is a fundamental task in proteomics. Non-Autoregressive Transformers (NATs) have proven highly effective for this task, outperforming traditional methods. Unlike autoregressive models, which generate tokens sequentially, NATs predict all positions simultaneously, leveraging bidirectional context through unmasked self-attention.However, existing NAT approaches often rely on Connectionist Temporal Classification (CTC) loss, which presents significant optimization challenges due to CTC's complexity and increases the risk of training failures. To address these issues, we propose an improved non-autoregressive peptide sequencing model that incorporates a structured protein sequence curriculum learning strategy. This approach adjusts protein's learning difficulty based on the model’s estimated protein generational capabilities through a sampling process, progressively learning peptide generation from simple to complex sequences. Additionally, we introduce a self-refining inference-time module that iteratively enhances predictions using learned NAT token embeddings, improving sequence accuracy at a fine-grained level. Our curriculum learning strategy reduces NAT training failures frequency by more than 90% based on sampled training over various data distributions. Evaluations on nine benchmark species demonstrate that our approach outperforms all previous methods across multiple metrics and species. Model and source code are available at https://github.com/BEAM-Labs/denovo.","Proteins are essential to life, and understanding their structure is critical for advances in medicine, biology, and drug discovery. One common technique to study proteins is peptide sequencing, which tries to figure out the building blocks (amino acids) of a protein using data from mass spectrometry, a tool that measures molecules by their mass. However, current methods often struggle with accuracy or efficiency, especially when trying to predict entire sequences all at once.In this work, we improve a type of AI model called a non-autoregressive Transformer, which predicts all parts of a sequence in parallel instead of one by one. These models are faster but hard to train. To solve this, we introduce a new curriculum learning approach, inspired by how humans learn — starting with simpler sequences and gradually tackling harder ones. We also add a second step where the model refines its own guesses to make them more accurate.Our method makes the model much more stable during training and significantly more accurate when predicting protein sequences. It outperforms all existing methods across multiple species, making it a promising tool for scientific research and future medical breakthroughs."
Poster,Curse of High Dimensionality Issue in Transformer for Long Context Modeling,https://ICML.cc//virtual/2025/poster/46056,"Shuhai Zhang, Zeng You, Yaofo Chen, Zhiquan Wen, Qianyue Wang, Zhijie Qiu, Yuanqing Li, Mingkui Tan","Transformer-based large language models (LLMs) excel in natural language processing tasks by capturing long-range dependencies through self-attention mechanisms. However, long-context modeling faces significant computational inefficiencies due to redundant attention computations: while attention weights are often sparse, all tokens consume equal computational resources. In this paper, we reformulate traditional probabilistic sequence modeling as a supervised learning task, enabling the separation of relevant and irrelevant tokens and providing a clearer understanding of redundancy. Based on this reformulation, we theoretically analyze attention sparsity, revealing that only a few tokens significantly contribute to predictions. Building on this, we formulate attention optimization as a linear coding problem and propose a group coding strategy, theoretically showing its ability to improve robustness against random noise and enhance learning efficiency. Motivated by this, we propose Dynamic Group Attention (DGA), which leverages the group coding to explicitly reduce redundancy by aggregating less important tokens during attention computation. Empirical results show that our DGA significantly reduces computational costs while maintaining competitive performance.","Modern large language models often struggle to efficiently process long texts since these models treat each word as equally important, even though many words, like repeated phrases or filler text, contribute little to the final result. This inefficiency wastes computational resources, slows down tasks, and limits real-world applications in areas where long-text analysis is critical.  This work theoretically discovers that only a few key words actually influence the final understanding. To address this, we propose Dynamic Group Attention (DGA), which dynamically identifies and prioritizes the most important words while grouping less critical ones. DGA method reduces computational costs while maintaining accuracy, making it feasible to deploy powerful language tools in resource-limited settings like small labs or rural healthcare systems."
Poster,CursorCore: Assist Programming through Aligning Anything,https://ICML.cc//virtual/2025/poster/44883,"Hao Jiang, Qi Liu, Rui Li, Shengyu Ye, Shijin Wang","Large language models have been successfully applied to programming assistance tasks, such as code completion, code insertion, and instructional code editing. However, these applications remain insufficiently automated and struggle to effectively integrate various types of information during the programming process, including coding history, code context, and user instructions. In this work, we propose a new framework that comprehensively integrates these information sources, collect data to train our models and evaluate their performance. Firstly, to thoroughly evaluate how well models align with different types of information and the quality of their outputs, we introduce a new benchmark, APEval (Assist Programming Eval), to comprehensively assess the performance of models in programming assistance tasks. Then, for data collection, we develop a data generation pipeline, Programming-Instruct, which synthesizes training data from diverse sources, such as GitHub and online judge platforms. This pipeline can automatically generate various types of messages throughout the programming process. Finally, using this pipeline, we generate 219K samples, fine-tune multiple models, and develop the CursorCore series. We show that CursorCore outperforms other models of comparable size. This framework unifies applications such as inline chat and automated editing, contributes to the advancement of coding assistants.","Modern code assistants act like short-term memory. They only see the line you are typing and miss everything that led up to it. We give them a longer memory, letting an AI read three things at once: the edits you have already made, the code you are working on now, and any notes you leave for it. To teach this skill, we build a new test called APEval to check whether an AI has really learned this, and collect examples from diverse sources to train the AI, resulting in the CursorCore series, which solve programming tasks more accurately than other AIs of the same size. Our system is open-source — anyone can build on it — paving the way for coding assistants that fix bugs, add features, and answer questions with far fewer operations from developers. It turns AI from a one-off code suggester into a collaborative partner that remembers what you have already done."
Poster,Curvature-aware Graph Attention for PDEs on Manifolds,https://ICML.cc//virtual/2025/poster/43668,"Yunfeng Liao, Jiawen Guan, Xiucheng Li","Deep models have recently achieved remarkable performances in solving partial differential equations (PDEs). The previous methods are mostly focused on PDEs arising in Euclidean spaces with less emphasis on the general manifolds with rich geometry. Several proposals attempt to account for the geometry by exploiting the spatial coordinates but overlook the underlying intrinsic geometry of manifolds. In this paper, we propose a Curvature-aware Graph Attention for PDEs on manifolds by exploring the important intrinsic geometric quantities such as curvature and discrete gradient operator. It is realized via parallel transport and tensor field on manifolds. To accelerate computation, we present three curvature-oriented graph embedding approaches and derive closed-form parallel transport equations, and a subtree partition method is also developed to promote parameter-sharing. Our proposed curvature-aware attention can be used as a replacement for vanilla attention, and experiments show that it significantly improves the performance of the existing methods for solving PDEs on manifolds. Our code is available at https://github.com/Supradax/CurvGT.","We use graph neural networks (GNNs) to solve partial differential equations (PDEs) on surfaces. Currently proposed methods only focus on PDEs in Euclidean spaces. PDEs defined on curved spaces also matter in many regions. It is expected that the introduction of surface geometry to neural networks can enhance their performance. To this end, we observe that the message passing on GNN can be naturally extended to be tensor operations, a generalization of matrix operations. This is because tensors are naturally defined on surfaces. But there is also a gap between discretized surface meshes and smooth surfaces. We further propose a fast computation method by locally embedding the surface onto constant curvature surfaces. As the parameters and feature vectors vary according to the curvature there, our proposed GNN can thereby be aware of the curvature geometry."
Poster,Curvature Enhanced Data Augmentation for Regression,https://ICML.cc//virtual/2025/poster/44222,"Ilya Kaufman, Omri Azencot","Deep learning models with a large number of parameters, often referred to as over-parameterized models, have achieved exceptional performance across various tasks. Despite concerns about overfitting, these models frequently generalize well to unseen data, thanks to effective regularization techniques, with data augmentation being among the most widely used. While data augmentation has shown great success in classification tasks using label-preserving transformations, its application in regression problems has received less attention. Recently, a novel manifold learning approach for generating synthetic data was proposed, utilizing a first-order approximation of the data manifold. Building on this foundation, we present a theoretical framework and practical tools for approximating and sampling general data manifolds. Furthermore, we introduce the Curvature-Enhanced Manifold Sampling (CEMS) method for regression tasks. CEMS leverages a second-order representation of the data manifold to enable efficient sampling and reconstruction of new data points. Extensive evaluations across multiple datasets and comparisons with state-of-the-art methods demonstrate that CEMS delivers superior performance in both in-distribution and out-of-distribution scenarios, while introducing only minimal computational overhead. Code is available at https://github.com/azencot-group/CEMS.","Artificial intelligence systems have revolutionized fields from vision to language, but they usually require huge datasets to avoid memorizing instead of learning. One common approach data augmentation generates extra synthetic examples to show the AI system more varied scenarios. While this works well for categorizing tasks (like distinguishing between cats and dogs), it's harder when the system needs to predict continuous values, such as temperatures or stock prices. In our work, we introduce a new method to produce realistic synthetic data for these continuous prediction problems by carefully analyzing how the original data naturally varies. By capturing these natural patterns, we create additional examples that accurately reflect real-world situations. We show that this makes predictions more reliable and accurate across multiple fields, such as environmental monitoring and financial forecasting, without significantly increasing computing resources."
