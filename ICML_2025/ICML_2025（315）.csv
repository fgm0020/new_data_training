type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,UDora: A Unified Red Teaming Framework against LLM Agents by Dynamically Hijacking Their Own Reasoning,https://ICML.cc//virtual/2025/poster/44008,"Jiawei Zhang, Shuang Yang, Bo Li","Large Language Model (LLM) agents equipped with external tools have become increasingly powerful for complex tasks such as web shopping, automated email replies, and financial trading. However, these advancements amplify the risks of adversarial attacks, especially when agents can access sensitive external functionalities. Nevertheless, manipulating LLM agents into performing targeted malicious actions or invoking specific tools remains challenging, as these agents extensively reason or plan before executing final actions. In this work, we present UDora, a unified red teaming framework designed for LLM agents that dynamically hijacks the agent's reasoning processes to compel malicious behavior. Specifically, UDora first generates the model’s reasoning trace for the given task, then automatically identifies optimal points within this trace to insert targeted perturbations. The resulting perturbed reasoning is then used as a surrogate response for optimization. By iteratively applying this process, the LLM agent will then be induced to undertake designated malicious actions or to invoke specific malicious tools. Our approach demonstrates superior effectiveness compared to existing methods across three LLM agent datasets. The code is available at https://github.com/AI-secure/UDora.","Large Language Model (LLM) agents are powerful AI systems capable of executing real-world tasks, such as online shopping, automated email replies, and financial transactions. However, their advanced capabilities also expose them to greater risks from adversarial attacks, which aim to exploit the model’s reasoning to trigger malicious actions.In this work, we introduce a new framework called UDora designed specifically to test and identify vulnerabilities in these AI agents. Unlike previous methods that rely on fixed instructions or simple prompts, UDora dynamically leverages the agent's internal reasoning process. It first captures how the agent reasons through tasks, identifies strategic points within that reasoning to introduce subtle manipulations, and then optimizes these manipulations iteratively. By carefully inserting these targeted perturbations, UDora guides the agent towards performing unintended and potentially harmful actions, such as unauthorized email forwarding or inappropriate financial transactions.We demonstrate UDora's effectiveness across multiple realistic scenarios and datasets, achieving higher success rates than existing methods. Importantly, our approach highlights critical vulnerabilities in real-world AI systems and underscores the need for robust safeguards to ensure the secure and trustworthy deployment of powerful AI agents."
Poster,UGPhysics: A Comprehensive Benchmark for Undergraduate Physics Reasoning with Large Language Models,https://ICML.cc//virtual/2025/poster/45927,"Xin Xu, Qiyun Xu, Tong Xiao, Tianhao Chen, Yuchen Yan, Jiaxin ZHANG, Shizhe Diao, Can Yang, Yang Wang","Large language models (LLMs) have demonstrated remarkable capabilities in solving complex reasoning tasks, particularly in mathematics. However, the domain of physics reasoning presents unique challenges that have received significantly less attention. Existing benchmarks often fall short in evaluating LLMs’ abilities on the breadth and depth of undergraduate-level physics, underscoring the need for a comprehensive evaluation. To fill this gap, we introduce UGPhysics, a large-scale and diverse benchmark specifically designed to evaluate **U**nder**G**raduate-level **Physics** (**UGPhysics**) reasoning with LLMs. UGPhysics includes 5,520 undergraduate-level physics problems in both English and Chinese across 13 subjects with seven different answer types and four distinct physics reasoning skills, all rigorously screened for data leakage. Additionally, we develop a Model-Assistant Rule-based Judgment (**MARJ**) pipeline specifically tailored for assessing physics problems, ensuring accurate evaluation. Our evaluation of 31 leading LLMs shows that the highest overall accuracy, 49.8% (achieved by OpenAI-o1-mini), emphasizes the need for models with stronger physics reasoning skills, beyond math abilities. We hope UGPhysics, along with MARJ, will drive future advancements in AI for physics reasoning. Codes and data are available at \href{https://github.com/YangLabHKUST/UGPhysics}{https://github.com/YangLabHKUST/UGPhysics}.","Large language models (LLMs) like ChatGPT have shown impressive reasoning abilities, especially in solving math problems. But physics, a subject that combines math with a deep understanding of the physical world, is a tougher challenge. To see how well LLMs handle this, we created **UGPhysics**, a large and diverse set of over 5,500 carefully crafted undergraduate-level physics questions written in English and Chinese.These questions span 13 physics subjects and test different skills, from understanding concepts to applying formulas.To fairly evaluate model responses, the researchers also built a specialized grading system called **MARJ** that blends human-like judgment with automated rules.When testing 31 top-performing language models, the highest score was just under 50%, showing that current models have much room to improve in physics reasoning: they often struggle even if they do well in math.The UGPhysics dataset and MARJ evaluation system are now released, helping researchers develop AI that can better understand and solve physics problems — a key step toward more capable AI."
Poster,UI-Vision: A Desktop-centric GUI Benchmark for Visual Perception and Interaction,https://ICML.cc//virtual/2025/poster/46427,"Perampalli Shravan Nayak, Xiangru Jian, Kevin Qinghong Lin, Juan A. Rodriguez, Montek Kalsi, Nicolas Chapados, M. Özsu, Aishwarya Agrawal, David Vazquez, Christopher Pal, Perouz Taslakian, Spandana Gella, Sai Rajeswar Mudumba","Autonomous agents that navigate Graphical User Interfaces (GUIs) to automate tasks like document editing and file management can greatly enhance computer workflows. While existing research focuses on online settings, desktop environments, critical for many professional and everyday tasks, remain underexplored due to data collection challenges and licensing issues. We introduce UI-Vision, the first comprehensive, license-permissive benchmark for offline, fine-grained evaluation of computer use agents in real-world desktop environments. Unlike online benchmarks, UI-Vision provides: (i) dense, high-quality annotations of human demonstrations, including bounding boxes, UI labels, and action trajectories (clicks, drags, and keyboard inputs) across 83 software applications, and (ii) three fine-to-coarse grained tasks—Element Grounding, Layout Grounding, and Action Prediction—with well-defined metrics to rigorously evaluate agents' performance in desktop environments. Our evaluation reveals critical limitations in state-of-the-art models like UI-TARS-72B, including issues with understanding professional software, spatial reasoning, and complex actions like drag-and-drop. These findings highlight the challenges in developing fully autonomous computer-use agents. With UI-Vision, we aim to advance the development of more capable agents for real-world desktop tasks.","Desktop graphical interfaces (GUIs)—like those used for software applications—are central to how we perform daily tasks such as editing documents or managing files. Yet, automating these desktop tasks with artificial intelligence remains difficult, mainly due to challenges in understanding complex visual information and interactions that users regularly navigate. To address this, we developed UI-Vision, a large-scale dataset that captures detailed interactions with 83 popular desktop software applications. It includes thousands of carefully annotated examples showing how humans interact with these interfaces, such as clicking, dragging, and typing. Our dataset provides benchmarks to assess how well AI models understand and interact with desktop GUIs. Evaluations using UI-Vision reveal significant limitations in existing state-of-the-art AI models, particularly when tasks require understanding professional software tools or performing complex actions like dragging and dropping. By clearly identifying these challenges, UI-Vision helps guide future improvements in AI systems designed to automate and enhance everyday computer use."
Poster,Ultra Lowrate Image Compression with Semantic Residual Coding and Compression-aware Diffusion,https://ICML.cc//virtual/2025/poster/43570,"Anle Ke, Xu Zhang, Tong Chen, Ming Lu, Chao Zhou, Jiawen Gu, Zhan Ma","Existing multimodal large model-based image compression frameworks often rely on a fragmented integration of semantic retrieval, latent compression, and generative models, resulting in suboptimal performance in both reconstruction fidelity and coding efficiency. To address these challenges, we propose a residual-guided ultra lowrate image compression named ResULIC, which incorporates residual signals into both semantic retrieval and the diffusion-based generation process. Specifically, we introduce Semantic Residual Coding (SRC) to capture the semantic disparity between the original image and its compressed latent representation. A perceptual fidelity optimizer is further applied for superior reconstruction quality. Additionally, we present the Compression-aware Diffusion Model (CDM), which establishes an optimal alignment between bitrates and diffusion time steps, improving compression-reconstruction synergy. Extensive experiments demonstrate the effectiveness of ResULIC, achieving superior objective and subjective performance compared to state-of-the-art diffusion-based methods with -80.7\%, -66.3\% BD-rate saving in terms of LPIPS and FID.","Our research addresses a critical challenge in image compression: avoiding incorrect textures (e.g., wrong colors or shapes) when using AI to reconstruct images from tiny files.Our solution combines two strategies:1.**Semantic Residual Coding**: AI compares the original and compressed images to identify and restore lost semantic details.2.**Compression-Aware Diffusion Models**: The AI’s image-generation process is dynamically adjusted based on compression levels, ensuring sharp, realistic results even at minimal file sizes.These advancements are particularly vital for bandwidth-constrained applications—such as emergency communications or satellite imaging—where both accuracy and efficiency are paramount. By combining these strategies, our work bridges the gap between extreme compression and faithful visual reconstruction, delivering a robust solution for resource-limited scenarios."
Poster,Ultra-Resolution Adaptation with Ease,https://ICML.cc//virtual/2025/poster/46464,"Ruonan Yu, Songhua Liu, Zhenxiong Tan, Xinchao Wang","Text-to-image diffusion models have achieved remarkable progress in recent years. However, training models for high-resolution image generation remains challenging, particularly when training data and computational resources are limited. In this paper, we explore this practical problem from two key perspectives: data and parameter efficiency, and propose a set of key guidelines for ultra-resolution adaptation termed URAE. For data efficiency, we theoretically and empirically demonstrate that synthetic data generated by some teacher models can significantly promote training convergence. For parameter efficiency, we find that tuning minor components of the weight matrices outperforms widely-used low-rank adapters when synthetic data are unavailable, offering substantial performance gains while maintaining efficiency. Additionally, for models leveraging guidance distillation, such as FLUX, we show that disabling classifier-free guidance, i.e., setting the guidance scale to 1 during adaptation, is crucial for satisfactory performance. Extensive experiments validate that URAE achieves comparable 2K-generation performance to state-of-the-art closed-source models like FLUX1.1 [Pro] Ultra with only 3K samples and 2K iterations, while setting new benchmarks for 4K-resolution generation. Codes are available [here](https://github.com/Huage001/URAE).","Text-to-image diffusion models have improved rapidly, but training them to generate high-resolution images remains challenging, especially when data and computational resources are limited. Our work addresses this problem by focusing on data efficiency and parameter-efficient fine-tuning, leading to several practical insights. Based on our findings, we provide guidelines for training high-performing models under resource constraints. Especially, we show that synthetic data generated by teacher models can significantly accelerate training process and enhance stability. When synthetic data is not available, we find that tuning minor parts of model leads to better performance than widely-used low-rank adaptation methods, while still maintaining efficiency. Finally, for advanced models that incorporate additional guidance from a more powerful teacher model, such as FLUX, we demonstrate that turning off classifier-free guidance is crucial for achieving satisfactory results. In summary, our proposed guidelines lowers the barrier for developing state-of-the-art text-to-image models, making advanced image generation accessible across a wider range of practical settings."
Poster,UltraTWD: Optimizing Ultrametric Trees for Tree-Wasserstein Distance,https://ICML.cc//virtual/2025/poster/44185,"Fangchen Yu, Yanzhen Chen, Jiaxing Wei, Jianfeng Mao, Wenye Li, Qiang Sun","The Wasserstein distance is a widely used metric for measuring differences between distributions, but its super-cubic time complexity introduces substantial computational burdens. To mitigate this, the tree-Wasserstein distance (TWD) offers a linear-time approximation by leveraging a tree structure; however, existing TWD methods often compromise accuracy due to suboptimal tree structures and edge weights. To address it, we introduce UltraTWD, a novel unsupervised framework that simultaneously optimizes both ultrametric tree structures and edge weights to more faithfully approximate the cost matrix. Specifically, we develop algorithms based on minimum spanning trees, iterative projection, and gradient descent to efficiently learn high-quality ultrametric trees. Empirical results across document retrieval, ranking, and classification tasks demonstrate that UltraTWD achieves superior approximation accuracy and competitive downstream performance. Code is available at: https://github.com/NeXAIS/UltraTWD.","Understanding how similar two distributions are — like two documents — is a fundamental problem in machine learning. A powerful tool for this is the “Wasserstein distance,” which measures how much effort it takes to transform one distribution into another. However, calculating this exactly is often slow and impractical for large datasets.Our method, called UltraTWD, offers a much faster way to approximate the Wasserstein distance on a tree. It does this by learning a special type of tree structure, called an “ultrametric tree,” that simplifies the calculation while preserving neighbor relationships between data points. Unlike earlier methods, UltraTWD can simultaneously learn both the tree structure and edge weights in a scalable and unsupervised way.This makes our approach both accurate and computationally efficient, enabling its application to large-scale problems involving Wasserstein distances. By accelerating a core machine learning tool, UltraTWD paves the way for more practical and scalable AI systems."
Poster,Unbiased Evaluation of Large Language Models from a Causal Perspective,https://ICML.cc//virtual/2025/poster/45947,"Meilin Chen, Jian Tian, Liang Ma, Di Xie, Weijie Chen, Jiang Zhu","Benchmark contamination has become a significant concern in the LLM evaluation community. Previous Agents-as-an-Evaluator address this issue by involving agents in the generation of questions. Despite their success, the biases in Agents-as-an-Evaluator methods remain largely unexplored. In this paper, we present a theoretical formulation of evaluation bias, providing valuable insights into designing unbiased evaluation protocols. Furthermore, we identify two type of bias in Agents-as-an-Evaluator through carefully designed probing tasks on a minimal Agents-as-an-Evaluator setup. To address these issues, we propose the Unbiased Evaluator, an evaluation protocol that delivers a more comprehensive, unbiased, and interpretable assessment of LLMs. Extensive experiments reveal significant room for improvement in current LLMs. Additionally, we demonstrate that the Unbiased Evaluator not only offers strong evidence of benchmark contamination but also provides interpretable evaluation results.","As AI language models like ChatGPT get more powerful, it's important to test them in a fair and accurate way. But many of the tests used today may be ""contaminated""—meaning the AI might have already seen some of the test questions during its training. This gives it an unfair head start and can make it seem smarter than it really is. In our research, we explain what these hidden biases are and why they matter. We then design simple experiments to reveal two common types of bias in current evaluation methods. To solve this problem, we introduce a new system called the Unbiased Evaluator. It checks whether a model truly understands a piece of knowledge by asking the same question in different ways. Just like a child is considered to know something only if they can answer all related questions correctly, our method ensures that the AI really ""gets it"" and isn't just guessing or remembering. Our results show that even today’s top AI models still have a lot of room to grow. We also demonstrate that our approach is better at spotting both hidden advantages and the true language understanding of these models."
Poster,Unbiased Recommender Learning from Implicit Feedback via Weakly Supervised Learning,https://ICML.cc//virtual/2025/poster/46694,"Eric Wang, Zhichao Chen, Haotian Wang, Yanchao Tan, Licheng Pan, Tianqiao Liu, Xu Chen, Haoxuan Li, Zhouchen Lin","Implicit feedback recommendation is challenged by the missing negative feedback essential for effective model training. Existing methods often resort to negative sampling, a technique that assumes unlabeled interactions as negative samples. This assumption risks misclassifying potential positive samples within the unlabeled data, thereby undermining model performance. To address this issue, we introduce PURL, a model-agnostic framework that reframes implicit feedback recommendation as a weakly supervised learning task, eliminating the need for negative samples. However, its unbiasedness hinges on the accurate estimation of the class prior. To address this challenge, we propose Progressive Proximal Transport (PPT), which estimates the class prior by minimizing the proximal transport cost between positive and unlabeled samples. Experiments on three real-world datasets validate the efficacy of PURL in terms of improved recommendation quality.  Code is available at https://github.com/HowardZJU/weakrec.","This paper formulates implicit feedback recommendation as a weakly supervised learning problem, obtaining an unbiased positive-negative recommender without the need of negative feedback."
Poster,UncertainSAM: Fast and Efficient Uncertainty Quantification of the Segment Anything Model,https://ICML.cc//virtual/2025/poster/45857,"Timo Kaiser, Thomas Norrenbrock, Bodo Rosenhahn","The introduction of the Segment Anything Model (SAM) has paved the way for numerous semantic segmentation applications. For several tasks, quantifying the uncertainty of SAM is of particular interest. However, the ambiguous nature of the class-agnostic foundation model SAM challenges current uncertainty quantification (UQ) approaches. This paper presents a theoretically motivated uncertainty quantification model based on a Bayesian entropy formulation jointly respecting aleatoric, epistemic, and the newly introduced task uncertainty. We use this formulation to train USAM, a lightweight post-hoc UQ method. Our model traces the root of uncertainty back to under-parameterised models, insufficient prompts or image ambiguities. Our proposed deterministic USAM demonstrates superior predictive capabilities on the SA-V, MOSE, ADE20k, DAVIS, and COCO datasets, offering a computationally cheap and easy-to-use UQ alternative that can support user-prompting, enhance semi-supervised pipelines, or balance the tradeoff between accuracy and cost efficiency.","Artificial intelligence leads to strong results in various domains such as detecting and segmenting objects in images. For example, the famous Segment Anything Model (SAM) is able to segment arbitrary objects by clicking on a distinct point in the image. Unfortunately, humans cannot trust algorithms like SAM without further validations. Some predictions of SAM are possibly wrong because the choosen SAM model is not suitable to the image, the image contains ambiguous segments, or the prompt is badly choosen. To improve the validation process and to indicate how the prediction can be optimized, we introduce UncertainSAM, a simple method to estimate the uncertainty of SAM. Without much overhead, our method creates a few single valued indicators which estimate if a better model could improve the prediction, better prompts are necessary, or multiple valid results are existing in the image. Using our method, semi-automated pipelines can be improved by asking for user feedback in uncertain situations. We evaluate the method on various datasets and settings and provide easy-to-use code."
Poster,Uncertainty-Based Extensible Codebook for Discrete Federated Learning in Heterogeneous Data Silos,https://ICML.cc//virtual/2025/poster/45945,"Tianyi Zhang, Yu Cao, Dianbo Liu","Federated learning (FL), aimed at leveraging vast distributed datasets, confronts a crucial challenge: the heterogeneity of data across different silos. While previous studies have explored discrete representations to enhance model generalization across minor distributional shifts, these approaches often struggle to adapt to new data silos with significantly divergent distributions. In response, we have identified that models derived from FL exhibit markedly increased uncertainty when applied to data silos with unfamiliar distributions. Consequently, we propose an innovative yet straightforward iterative framework, termed \emph{Uncertainty-Based Extensible-Codebook Federated Learning (UEFL)}. This framework dynamically maps latent features to trainable discrete vectors, assesses the uncertainty, and specifically extends the discretization dictionary or codebook for silos exhibiting high uncertainty. Our approach aims to simultaneously enhance accuracy and reduce uncertainty by explicitly addressing the diversity of data distributions, all while maintaining minimal computational overhead in environments characterized by heterogeneous data silos. Extensive experiments across multiple datasets demonstrate that UEFL outperforms state-of-the-art methods, achieving significant improvements in accuracy (by 3\%--22.1\%) and uncertainty reduction (by 38.83\%--96.24\%).The source code is available at https://github.com/destiny301/uefl.","Modern machine learning often relies on federated learning (FL) to train models using data from many different sources—like phones or hospitals—without sharing private information. But this approach struggles when each source (or ""silo"") has very different types of data. In these cases, combining updates from different silos leads to poor accuracy and inconsistent predictions.To fix this, we developed a new method called Uncertainty-Based Extensible-codebook Federated Learning (UEFL). UEFL converts features into simplified representations and dynamically adds new ones when the model is unsure. This allows the model to learn from each silo more effectively, even when the data is very different.Our experiments show that UEFL improves accuracy by up to 22% and reduces uncertainty by as much as 96%, all with little added computation. It also works well when tested on completely new types of data. This makes UEFL a practical solution for real-world FL systems—like mobile apps or healthcare platforms—where data differences are the norm."
