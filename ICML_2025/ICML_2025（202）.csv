type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Of Mice and Machines: A Comparison of Learning Between Real World Mice and RL Agents,https://ICML.cc//virtual/2025/poster/43969,"Shuo Han, German Espinosa, Junda Huang, Daniel A. Dombeck, Malcolm MacIver, Bradly Stadie","Recent advances in reinforcement learning (RL) have demonstrated impressive capabilities in complex decision-making tasks. This progress raises a natural question: how do these artificial systems compare to biological agents, which have been shaped by millions of years of evolution? To help answer this question, we undertake a comparative study of biological mice and RL agents in a predator-avoidance maze environment. Through this analysis, we identify a striking disparity: RL agents consistently demonstrate a lack of self-preservation instinct, readily risking ``death'' for marginal efficiency gains. These risk-taking strategies are in contrast to biological agents, which exhibit sophisticated risk-assessment and avoidance behaviors. Towards bridging this gap between the biological and artificial, we propose two novel mechanisms that encourage more naturalistic risk-avoidance behaviors in RL agents. Our approach leads to the emergence of naturalistic behaviors, including strategic environment assessment, cautious path planning, and predator avoidance patterns that closely mirror those observed in biological systems.","Imagine you're playing a game where you need to reach your goal while avoiding a dangerous robot. How would you play compared to a real mouse in the same situation? This research reveals a fascinating difference: while computer programs (artificial intelligence) often take risky shortcuts to complete tasks faster, real animals like mice are much more cautious and safety-focused.This highlights a crucial gap between artificial and biological intelligence. AI systems excel at optimizing for specific objectives but lack the self-preservation instincts that evolution has built into living creatures.Although our experiment focuses on a specific scenario, predator-prey interactions are well-studied and complex situations in biology. We developed two new techniques that help AI agents learn to be more cautious, leading our AI agents to behave much more like real mice—taking safer paths and spending more time assessing their environment.This work contributes to understanding mouse behavior and bridging the gap between artificial and biological decision-making."
Poster,Olica: Efficient Structured Pruning of Large Language Models without Retraining,https://ICML.cc//virtual/2025/poster/44400,"Jiujun He, Huazhen Lin","Most existing structured pruning methods for  Large Language Models (LLMs) require substantial computational  and data resources for retraining to reestablish the corrupted correlations, making them prohibitively expensive. To address this, we propose an efficient pruning framework for LLMs called Orthogonal Neuron Decomposition and Linear Calibration  (Olica),  which eliminates the need for retraining.  A key observation is that the multi-head attention (MHA) layer depends on two types of matrix products (i.e., ${\rm W}_q{\rm W}^{\top}_k$ and ${\rm W}_v{\rm W}^{\top}_o$). By treating these matrix products as unified entities and applying principal component analysis (PCA), we extract the most important information to compress LLMs without sacrificing accuracy or disrupting their original structure. Consequently, retraining becomes unnecessary. Moreover, a fast decomposition method is  devised, reducing the  complexity of PCA by a factor of the square of the number of attention heads. Additionally,  to mitigate error accumulation problem caused by pruning the feed-forward network (FFN) layer, we introduce a linear calibration  method to reconstruct the residual errors of a pruned layer using two low-rank matrices. By leveraging singular value decomposition (SVD) on the solution of the least-squares problem, these matrices are obtained without requiring  retraining.  Extensive experiments show that the proposed Olica is efficient in terms of data usage, GPU memory, and running time, while delivering superior performance across multiple benchmarks.","Network pruning is a pivotal technique for reducing the complexity and accelerating the inference time of large language models (LLMs) by removing redundant components (e.g., neurons), but conventional methods require substantial computational and data resources for retraining to restore the corrupted correlations. We propose an efficient pruning framework for LLMs that employs orthogonal neuron decomposition and linear calibration, applied to the multi-head attention (MHA) layer and the feed-forward network (FFN) layer of the transformer, respectively.  By developing a fast decomposition method and leveraging the closed-form solution of the least-squares problem, our method is efficient in terms of data usage, GPU memory consumption, and runing time. This enables pruning of models with 70B parameters on a single NVIDIA GeForce RTX 4090 GPU with less than an hour of runtime."
Poster,O-MAPL: Offline Multi-agent Preference Learning,https://ICML.cc//virtual/2025/poster/45881,"The Viet Bui, Tien Mai, Thanh Nguyen","Inferring reward functions from demonstrations is a key challenge in reinforcement learning (RL), particularly in multi-agent RL (MARL). The large joint state-action spaces and intricate inter-agent interactions in MARL make inferring the joint reward function especially challenging. While prior studies in single-agent settings have explored ways to recover reward functions and expert policies from human preference feedback, such studies in MARL remain limited. Existing methods typically combine two separate stages, supervised reward learning, and standard MARL algorithms, leading to unstable training processes. In this work, we exploit the inherent connection between reward functions and Q functions in cooperative MARL to introduce a novel end-to-end preference-based learning framework.Our framework is supported by a carefully designed multi-agent value decomposition strategy that enhances training efficiency. Extensive experiments on two state-of-the-art benchmarks, SMAC and MAMuJoCo, using preference data generated by both rule-based and large language model approaches demonstrate that our algorithm consistently outperforms existing methods across various tasks.","Teaching AI teams to cooperate is hard if we can't perfectly define a scoring system for ""good"" behavior. An alternative is ""preference learning"": simply showing the AI two attempts and indicating which was better. Our new method, O-MAPL, enables AI teams to learn directly from a pre-existing dataset of such ""better/worse"" examples.Unlike many previous approaches that first try to build a scoring system from these preferences before training the team, O-MAPL skips this potentially unstable intermediate step. This direct approach leads to more stable and efficient learning, and includes a specialized technique for managing team coordination. When tested in complex game simulations (like StarCraft and robotics), O-MAPL helped AI teams learn to cooperate and perform more successfully than other methods."
Poster,OmiAD: One-Step Adaptive Masked Diffusion Model for Multi-class Anomaly Detection via Adversarial Distillation,https://ICML.cc//virtual/2025/poster/46291,"Yaoxuan Feng, Wenchao Chen, yuxin li, Bo Chen, Yubiao Wang, Zixuan Zhao, Hongwei Liu, Mingyuan Zhou","Diffusion models have demonstrated outstanding performance in industrial anomaly detection. However, their iterative denoising nature results in slow inference speed, limiting their practicality for real-time industrial deployment. To address this challenge, we propose OmiAD, a one-step masked diffusion model for multi-class anomaly detection, derived from a well-designed multi-step  **A**daptive  **M**asked  **D**iffusion  **M**odel (AMDM) and compressed using  **A**dversarial  **S**core  **D**istillation (ASD). OmiAD first introduces AMDM, equipped with an adaptive masking strategy that dynamically adjusts masking patterns based on noise levels and encourages the model to reconstruct anomalies as normal counterparts by leveraging broader context, to reduce the pixel-level shortcut reliance. Then, ASD  is developed to compress the multi-step diffusion process into a single-step generator by score distillation and incorporating a shared-weight discriminator effectively reusing parameters while significantly improving both inference efficiency and detection performance. The effectiveness of OmiAD is validated on four diverse datasets, achieving state-of-the-art performance across seven metrics while delivering a remarkable inference speedup.","Detecting unusual patterns or defects in images—like scratches on a smartphone screen or flaws in manufactured goods—is important in many real-world applications. Our work introduces a new method called OmiAD that helps computers find such defects faster and more accurately. OmiAD teaches a small, fast model to behave like a larger, more accurate one, using a process inspired by how humans learn from teachers. This makes it possible to spot problems in real time, which is especially useful in industrial settings like factories. Our method works well across different types of defects and offers a practical solution for automated quality inspection."
Poster,Omni-Angle Assault: An Invisible and Powerful Physical Adversarial Attack on Face Recognition,https://ICML.cc//virtual/2025/poster/46320,"Shuai Yuan, Hongwei Li, Rui Zhang, Hangcheng Cao, Wenbo Jiang, Tao Ni, Wenshu Fan, Qingchuan Zhao, Guowen Xu","Deep learning models employed in face recognition (FR) systems have been shown to be vulnerable to physical adversarial attacks through various modalities, including patches, projections, and infrared radiation. However, existing adversarial examples targeting FR systems often suffer from issues such as conspicuousness, limited effectiveness, and insufficient robustness. To address these challenges, we propose a novel approach for adversarial face generation, UVHat, which utilizes ultraviolet (UV) emitters mounted on a hat to enable invisible and potent attacks in black-box settings. Specifically, UVHat simulates UV light sources via video interpolation and models the positions of these light sources on a curved surface, specifically the human head in our study. To optimize attack performance, UVHat integrates a reinforcement learning-based optimization strategy, which explores a vast parameter search space, encompassing factors such as shooting distance, power, and wavelength. Extensive experimental evaluations validate that UVHat substantially improves the attack success rate in black-box settings, enabling adversarial attacks from multiple angles with enhanced robustness.","Face recognition systems are now part of everyday life, from unlocking phones to checking airport passports. But how safe are they? Our research shows that these systems can be fooled using ultraviolet light, which is invisible to human eyes. A person can look completely normal but still avoid being recognized by the camera. We used artificial intelligence to search for the most effective way to set up the UV light, including its brightness and position. This technique works in real-world settings and does not need access to the internal system. Our findings reveal that current face recognition systems are more vulnerable than people might expect, especially in real-world situations. By showing this hidden risk, we hope to raise awareness and encourage the development of more secure and reliable face recognition technology. As these systems spread, protecting them from invisible attacks becomes more important than ever."
Poster,OmniArch: Building Foundation Model for Scientific Computing,https://ICML.cc//virtual/2025/poster/45099,"Tianyu Chen, Haoyi Zhou, Ying Li, Hao Wang, Chonghan Gao, Rongye Shi, Shanghang Zhang, Jianxin Li","Foundation models have revolutionized language modeling, while whether this success is replicated in scientific computing remains unexplored. We present OmniArch, the first prototype aiming at solving multi-scale and multi-physics scientific computing problems with physical alignment. We addressed all three challenges with one unified architecture. Its pre-training stage contains a Fourier Encoder-decoder fading out the disharmony across separated dimensions and a Transformer backbone integrating quantities through temporal dynamics, and the novel PDE-Aligner performs physics-informed fine-tuning under flexible conditions. As far as we know, we first conduct 1D-2D-3D united pre-training on the PDEBench, and it sets not only new performance benchmarks for 1D, 2D, and 3D PDEs but also demonstrates exceptional adaptability to new physics via in-context and zero-shot learning approaches, which supports realistic engineering applications and foresight physics discovery.","Scientific simulations power everything from weather forecasting to aircraft design, but traditional methods require specialized coding and supercomputers. We present OmniArch, the first AI foundation model that can solve diverse physics problems across 1D, 2D, and 3D simulations using a single system—like how language models understand diverse texts.Our key innovation is teaching AI the ""language of physics"" through frequency-based learning (like musical notes for equations) and a special Physics-Aligner that ensures predictions obey real-world laws. Trained on 11 types of physics problems, OmniArch outperforms specialized AI tools while showing human-like adaptability—it can solve new physics problems with minimal examples (in-context learning) or even zero examples (zero-shot learning).This breakthrough could democratize scientific computing, allowing engineers to simulate complex systems faster while maintaining accuracy. Future applications may accelerate climate modeling, energy research, and materials discovery."
Poster,OmniAudio: Generating Spatial Audio from 360-Degree Video,https://ICML.cc//virtual/2025/poster/43952,"Huadai Liu, Tianyi Luo, Kaicheng Luo, Qikai Jiang, Peiwen Sun, Jialei Wang, Rongjie Huang, Qian Chen, Wen Wang, Xiangtai Li, ShiLiang Zhang, Zhijie Yan, Zhou Zhao, Wei Xue","Traditional video-to-audio generation techniques primarily focus on perspective video and non-spatial audio, often missing the spatial cues necessary for accurately representing sound sources in 3D environments. To address this limitation, we introduce a novel task, \textbf{360V2SA}, to generate spatial audio from 360-degree videos, specifically producing First-order Ambisonics (FOA) audio - a standard format for representing 3D spatial audio that captures sound directionality and enables realistic 3D audio reproduction. We first create \textbf{Sphere360}, a novel dataset tailored for this task that is curated from real-world data. We also design an efficient semi-automated pipeline for collecting and cleaning paired video-audio data. To generate spatial audio from 360-degree video, we propose a novel framework \textbf{OmniAudio}, which leverages self-supervised pre-training using both spatial audio data (in FOA format) and large-scale non-spatial data. Furthermore, OmniAudio features a dual-branch framework that utilizes both panoramic and perspective video inputs to capture comprehensive local and global information from 360-degree videos. Experimental results demonstrate that OmniAudio achieves state-of-the-art performance across both objective and subjective metrics on Sphere360. Code and datasets are available at~\href{https://github.com/liuhuadai/OmniAudio}{\texttt{github.com/liuhuadai/OmniAudio}}. The project website is available at \href{https://OmniAudio-360V2SA.github.io}{\texttt{OmniAudio-360V2SA.github.io}}.","Imagine watching a video where you can hear sounds coming from all around you, just like in real life. This is called spatial audio, and it makes videos feel more immersive and realistic. Our research focuses on creating this type of audio for 360-degree videos, which let you look in any direction.We've developed a new method called OmniAudio that can generate spatial audio from 360-degree videos. This means that when you watch a 360-degree video with the audio our system creates, you'll hear sounds as if they're coming from their actual locations in the video scene.To make this possible, we first created a large collection of 360-degree videos with matching spatial audio, called Sphere360. We then designed OmniAudio, a smart computer system that learns to understand both the full 360-degree view and a focused front view of the video. By combining these two perspectives, OmniAudio can accurately place sounds in the right locations.Our tests show that OmniAudio performs better than existing methods, creating more realistic and accurate spatial audio for 360-degree videos. This technology could enhance various applications, from virtual reality experiences to more immersive video content, making viewers feel like they're truly part of the scene they're watching."
Poster,OmniBal: Towards Fast Instruction-Tuning for Vision-Language Models via  Omniverse Computation Balance,https://ICML.cc//virtual/2025/poster/43963,"Yongqiang Yao, Jingru Tan, Feizhao Zhang, Jiahao Hu, Yazhe Niu, JinXin, Bo Li, Pengfei Liu, Ruihao Gong, Dahua Lin, Ningyi Xu","Vision-language instruction-tuning models have recently achieved significant performance improvements. In this work, we discover that large-scale 3D parallel training on those models leads to an imbalanced computation load across different devices. The vision and language parts are inherently heterogeneous:  their data distribution and model architecture differ significantly, which affects distributed training efficiency. To address this issue, we rebalance the computational load from data, model, and memory perspectives, achieving more balanced computation across devices.  Specifically, for the data, instances are grouped into new balanced mini-batches within and across devices. A search-based method is employed for the model to achieve a more balanced partitioning. For memory optimization, we adaptively adjust the re-computation strategy for each partition to utilize the available memory fully. These three perspectives are not independent but are closely connected, forming an omniverse balanced training framework. Extensive experiments are conducted to validate the effectiveness of our method. Compared with the open-source training code of InternVL-Chat, training time is reduced greatly, achieving about 1.8$\times$ speed-up. Our method's efficacy and generalizability are further validated across various models and datasets. Codes will be released at https://github.com/ModelTC/OmniBal.","Vision-language models, which understand both images and text, are becoming more powerful—but training them is slow and inefficient on large computer clusters. We found that this happens because the image and text parts of the model are very different, leading to an uneven workload across devices.To fix this, we created OmniBal, a new training method that balances the work more fairly. It does this in three ways: by grouping training data more evenly, splitting the model into better-balanced parts, and managing memory more efficiently during training.These improvements work together to make training faster and more stable. In our tests, OmniBal sped up training by about 1.8× compared to current methods. It also works well on different models and datasets.This research matters because it helps developers train large, multi-modal models more efficiently—saving time, energy, and computing resources."
Poster,On-Device Collaborative Language Modeling via a Mixture of Generalists and Specialists,https://ICML.cc//virtual/2025/poster/45925,"Dongyang Fan, Bettina Messmer, Nikita Doikov, Martin Jaggi","On-device LLMs have gained increasing attention for their ability to enhance privacy and provide a personalized user experience. To facilitate private learning with scarce data, Federated Learning has become a standard approach. However, it faces challenges such as computational resource heterogeneity and data heterogeneity among end users. We propose CoMiGS ($\textbf{Co}$llaborative learning  with a $\textbf{Mi}$xture of $\textbf{G}$eneralists and $\textbf{S}$pecialists), the first approach to address both challenges. A key innovation of our method is the bi-level optimization formulation of the Mixture-of-Experts learning objective, where the router is optimized using a separate validation set to ensure alignment with the target distribution. We solve our objective with alternating minimization, for which we provide a theoretical analysis. Our method shares generalist experts across users while localizing a varying number of specialist experts, thereby adapting to users’ computational resources and preserving privacy. Through extensive experiments, we show CoMiGS effectively balances general and personalized knowledge for each token generation. We demonstrate that CoMiGS remains robust against overfitting—due to the generalists' regularizing effect—while adapting to local data through specialist expertise. We open source our codebase for collaborative LLMs.","Modern language models are increasingly deployed on personal devices to preserve user privacy and improve personalization. However, this approach faces two major challenges: devices differ in computational power (model heterogeneity), and users have unique data and language habits (data heterogeneity). Traditional methods cannot effectively address both at once.We introduce CoMiGS, a collaborative learning framework that blends shared ""generalist"" knowledge with user-specific ""specialist"" insights. It dynamically routes each word prediction to the most suitable expert using a novel bi-level optimization algorithm that separates training and validation phases.CoMiGS enables efficient, privacy-preserving language model customization on devices with varying capabilities. It reduces communication costs by 50%, minimizes risk of overfitting, and delivers consistent performance across users. This makes it a practical foundation for smarter, more adaptive AI on mobile and edge devices."
Poster,On Differential Privacy for Adaptively Solving Search Problems via Sketching,https://ICML.cc//virtual/2025/poster/44265,"Shiyuan Feng, Ying Feng, George Li, Zhao Song, David Woodruff, Lichen Zhang","Recently differential privacy has been used for a number of streaming, data structure, and dynamic graph problems as a means of hiding the internal randomness of the data structure, so that multiple possibly adaptive queries can be made without sacrificing the correctness of the responses. Although these works use differential privacy to show that for some problems it is possible to tolerate $T$ queries using $\widetilde{O}(\sqrt{T})$ copies of a data structure, such results only apply to {\it numerical estimation problems}, and only return the {\it cost} of an optimization problem rather than the solution itself. In this paper we investigate the use of differential privacy for adaptive queries to {\it search} problems, which are significantly more challenging since the responses to queries can reveal much more about the internal randomness than a single numerical query. We focus on two classical search problems: nearest neighbor queries and regression with arbitrary turnstile updates. We identify key parameters to these problems, such as the number of $c$-approximate near neighbors and the matrix condition number, and use different differential privacy techniques to design algorithms returning the solution point or solution vector with memory and time depending on these parameters. We give algorithms for each of these problems that achieve similar tradeoffs.","A significant challenge to many modern day AI systems is the presence of malicious attackers. For example, a malicious attacker to chatGPT might try to generate prompts that misguide the model and let it mistakenly leak crucial and private information. This type of attack can happen at various aspects of the AI systems, especially many tools used by chatGPT-like large language models. One such tool they use follows from a simple idea: when user inputs a prompt, they invoke tools to search in a database for similar prompts, and use themselves to generate responses given the new information. This powerful search functionality significantly improves the answers generated by these models, however, they also contain a lot of important private information that could be compromised by an attacker. In this work, we develop database search tools that under some mild conditions, any malicious attacker could not learn any information from our database by only observing the result returned from the search. For some other important AI problems, such as fitting a line to learn the relationship between cancers and patient symptoms, we also develop very efficient approaches that can estimate this fitting line quickly and protect the privacy of patients."
