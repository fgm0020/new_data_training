type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Testing the Limits of Fine-Tuning for Improving Visual Cognition in Vision Language Models,https://ICML.cc//virtual/2025/poster/44300,"Luca M. Schulze Buschoff, Konstantinos Voudouris, Elif Akata, Matthias Bethge, Josh Tenenbaum, Eric Schulz","Pre-trained vision language models still fall short of human visual cognition. In an effort to improve visual cognition and align models with human behavior, we introduce visual stimuli and human judgments on visual cognition tasks, allowing us to systematically evaluate performance across cognitive domains under a consistent environment. We fine-tune models on ground truth data for intuitive physics and causal reasoning and find that this improves model performance in the respective fine-tuning domain. Furthermore, it can improve model alignment with human behavior. However, we find that task-specific fine-tuning does not contribute to robust human-like generalization to data with other visual characteristics or to tasks in other cognitive domains.","Modern large machine learning models can perform remarkable feats. However, they still struggle on visual tasks that are relatively easy for human observers. To make them better at these tasks, and to ideally make models behave more like humans, we train models on selected tasks from the psychology literature. We find that this makes models better on the task they are trained on, but that they can not transfer what they have learned to other related tasks."
Poster,Test-Time Adaptation for Online Vision-Language Navigation with Feedback-based Reinforcement Learning,https://ICML.cc//virtual/2025/poster/45655,"Sung June Kim, Gyeongrok Oh, Heeju Ko, Daehyun Ji, Dongwook Lee, Byung-Jun Lee, Sujin Jang, Sangpil Kim","Navigating in an unfamiliar environment during deployment poses a critical challenge for a vision-language navigation (VLN) agent. Yet, test-time adaptation (TTA) remains relatively underexplored in robotic navigation, leading us to the fundamental question: what are the key properties of TTA for online VLN? In our view, effective adaptation requires three qualities: 1) flexibility in handling different navigation outcomes, 2) interactivity with external environment, and 3) maintaining a harmony between plasticity and stability. To address this, we introduce FeedTTA, a novel TTA framework for online VLN utilizing feedback-based reinforcement learning. Specifically, FeedTTA learns by maximizing binary episodic feedback, a practical setup in which the agent receives a binary scalar after each episode that indicates the success or failure of the navigation. Additionally, we propose a gradient regularization technique that leverages the binary structure of FeedTTA to achieve a balance between plasticity and stability during adaptation. Our extensive experiments on challenging VLN benchmarks demonstrate the superior adaptability of FeedTTA, even outperforming the state-of-the-art offline training methods in REVERIE benchmark with a single stream of learning.","Imagine a robot trying to find its way around a new place based on spoken instructions, like ""go to the red couch."" This is called Vision-Language Navigation (VLN). Our research started because these robots often struggle in environments they haven't seen before. While we train them beforehand, adapting on the fly in a new setting hasn't been explored much. We asked: what's crucial for a robot to learn and adjust as it navigates in real-time?To solve this, we created \textsc{FeedTTA}, a new way for robots to learn while they navigate. Our method uses simple feedback – a ""yes"" or ""no"" at the end of each attempt, telling the robot if it succeeded. We also developed a special technique to help the robot learn quickly without forgetting what it already knows, balancing being adaptable and stable.Our work matters because it shows a more effective way for navigation robots to handle unfamiliar situations. Our approach outperforms even the best pre-trained methods on a challenging task, meaning robots could become much better at following instructions in the real world, even in places they've never seen before."
Poster,Test-time Adaptation on Graphs via Adaptive Subgraph-based Selection and Regularized Prototypes,https://ICML.cc//virtual/2025/poster/44212,"Ming Zhang, Qixin Zhang, Xiao Luo, Junyu Luo, Wei Ju, Zhiping Xiao, Ming Zhang","Test-time adaptation aims to adapt a well-trained model using test data only, without accessing training data. It is a crucial topic in machine learning, enabling a wide range of applications in the real world, especially when it comes to data privacy. While existing works on test-time adaptation primarily focus on Euclidean data, research on non-Euclidean graph data remains scarce. Prevalent graph neural network methods could encounter serious performance degradation in the face of test-time domain shifts. In this work, we propose a novel method named Adaptive Subgraph-based Selection and Regularized Prototype Supervision (ASSESS) for reliable test-time adaptation on graphs. Specifically, to achieve flexible selection of reliable test graphs, ASSESS adopts an adaptive selection strategy based on fine-grained individual-level subgraph mutual information. Moreover, to utilize the information from both training and test graphs, ASSESS constructs semantic prototypes from the well-trained model as prior knowledge from the unknown training graphs and optimizes the posterior given the unlabeled test graphs. We also provide a theoretical analysis of the proposed algorithm. Extensive experiments verify the effectiveness of ASSESS against various baselines.","Artificial intelligence can be used to predict the properties of graph-structured data, like proteins or small molecules. However, when AI faces proteins or molecules significantly different from what it saw before, it may fail to predict their properties correctly. We design a machine learning algorithm that helps AI perform better in this scenario. This enhances the AI's ability to handle more cases in graph-structured data, like proteins or small molecules."
Poster,Test-Time Adaptation with Binary Feedback,https://ICML.cc//virtual/2025/poster/46190,"Taeckyung Lee, Sorn Chottananurak, Junsu Kim, Jinwoo Shin, Taesik Gong, Sung-Ju Lee","Deep learning models perform poorly when domain shifts exist between training and test data. Test-time adaptation (TTA) is a paradigm to mitigate this issue by adapting pre-trained models using only unlabeled test samples. However, existing TTA methods can fail under severe domain shifts, while recent active TTA approaches requiring full-class labels are impractical due to high labeling costs. To address this issue, we introduce a new setting of TTA with binary feedback, which uses a few binary feedbacks from annotators to indicate whether model predictions are correct, thereby significantly reducing the labeling burden of annotators. Under the setting, we propose BiTTA, a novel dual-path optimization framework that leverages reinforcement learning to balance binary feedback-guided adaptation on uncertain samples with agreement-based self-adaptation on confident predictions. Experiments show BiTTA achieves substantial accuracy improvements over state-of-the-art baselines, demonstrating its effectiveness in handling severe distribution shifts with minimal labeling effort.","AI models often make more mistakes when they see new types of data that are different from what they were trained on - this is called a distribution shift. A common way to fix this is through test-time adaptation (TTA), where the model updates itself while making predictions, using only the test data. But most TTA methods either fail in hard situations or need too much human help. This paper introduces a simple and smart solution: instead of asking people for full labels, the model only asks if its answers are right or wrong - a quick yes or no. The authors propose BiTTA, a method that learns from these yes/no answers on tricky cases and also improves itself using its own confident guesses. BiTTA works better than previous methods and even beats models that use full answers, making TTA both cheaper and more effective in the real world."
Poster,Test-time Adapted Reinforcement Learning with Action Entropy Regularization,https://ICML.cc//virtual/2025/poster/44941,"Shoukai Xu, ZihaoLian, Mingkui Tan, Liu Liu, Zhong Zhang, Peilin Zhao","Offline reinforcement learning is widely applied in multiple fields due to its advantages in efficiency and risk control. However, a major problem it faces is the distribution shift between offline datasets and online environments. This mismatch leads to out-of-distribution (OOD) state-action pairs that fall outside the scope of the training data. Therefore, existing conservative training policies may not provide reliable decisions when the test environment deviates greatly from the offline dataset. In this paper, we propose Test-time Adapted Reinforcement Learning (TARL) to address this problem. TARL constructs unsupervised test-time optimization objectives for discrete and continuous control tasks, using test data without depending on environmental rewards. In discrete control tasks, it minimizes the entropy of predicted action probabilities to decrease uncertainty and avoid OOD state-action pairs. For continuous control tasks, it represents and minimizes action uncertainty based on the normal distribution of policy network outputs. Moreover, to prevent model bias caused by overfitting and error accumulation during the test-time update process, TARL enforces a KL divergence constraint between the fine-tuned policy and the original policy. For efficiency, TARL only updates the layer normalization layer parameters during testing. Extensive experiments on popular Atari game benchmarks and the D4RL dataset demonstrate the superiority of our method. Our method achieved a significant improvement over CQL, with a 13.6% episode return relative increase on the hopper-expert-v2 task.","Offline reinforcement learning helps AI systems learn from pre-collected datasets (like past robot movements or game strategies) safely and efficiently. But when the real-world environment changes — like a robot encountering new obstacles or a game adding unexpected rules — the AI often struggles because it hasn’t seen these scenarios before. This mismatch can lead to unreliable or unsafe decisions.We designed a method called Test-time Adapted Reinforcement Learning (TARL) that lets the AI adjust itself during real-world use without needing explicit feedback. For tasks with clear choices (e.g., game controls), it reduces confusion by picking the most confident action. For complex tasks (e.g., robotic arm movements), it avoids risky moves by narrowing down possible actions. To prevent overcorrection, TARL limits how much the AI can deviate from its original safe training. Crucially, these updates happen efficiently — only tweaking a tiny part of the AI’s ""brain"" during testing.TARL improved performance over prior methods in robot tasks and video game benchmarks. By enabling safer and more flexible AI adaptation, it bridges the gap between offline training and real-world challenges without costly retraining."
Poster,Test-Time Canonicalization by Foundation Models for Robust Perception,https://ICML.cc//virtual/2025/poster/45699,"Utkarsh Singhal, Ryan Feng, Stella Yu, Atul Prakash","Real-world visual perception requires invariance to diverse transformations, yet current methods rely heavily on specialized architectures or training on predefined augmentations, limiting generalization. We propose FoCal, a test-time, data-driven framework that achieves robust perception by leveraging internet-scale visual priors from foundation models. By generating and optimizing candidate transformations toward visually typical, ""canonical"" views, FoCal enhances robustness without retraining or architectural changes. Experiments demonstrate improved robustness of CLIP and SAM across challenging transformations, including 2D/3D rotations, illumination shifts (contrast and color), and day-night variations. We also highlight potential applications in active vision. Our approach challenges the assumption that transform-specific training is necessary, instead offering a scalable path to invariance. Our code is available at: https://github.com/sutkarsh/focal.","Current AI vision systems struggle with everyday transformations that humans handle effortlessly. Show a robot an upside-down chair or a strangely lit room, and it might fail completely. That's because these systems are trained on near-perfect internet photos, not the messy reality they encounter in the real world. Re-training the entire system with each new messy example would be expensive and impractical.The key insight: AI models trained on billions of internet images already know what objects typically look like. We tap into this knowledge by testing different versions of an image (rotating it, adjusting lighting, changing viewpoints) and picking the one that big models like CLIP and Stable Diffusion find most familiar. It's like how you'd mentally rotate an upside-down photo to understand it.This method works remarkably well, even for complex real-world transformations that have been very challenging for previous approaches (like viewpoint changes, day-night changes, and more). As a bonus, FoCal doesn't require re-training and works with any existing vision system. Our work is a step towards making vision systems reliable in real-world conditions, crucial for applications like home robots and self-driving cars."
Poster,Test-time Correlation Alignment,https://ICML.cc//virtual/2025/poster/46675,"Linjing You, Jiabao Lu, Xiayuan Huang","Deep neural networks often degrade under distribution shifts. Although domain adaptation offers a solution, privacy constraints often prevent access to source data, making Test-Time Adaptation (TTA)—which adapts using only unlabeled test data—increasingly attractive. However, current TTA methods still face practical challenges: (1) a primary focus on instance-wise alignment, overlooking CORrelation ALignment (CORAL) due to missing source correlations; (2) complex backpropagation operations for model updating, resulting in overhead computation and (3) domain forgetting. To address these challenges, we provide a theoretical analysis to investigate the feasibility of **T**est-time **C**orrelation **A**lignment (**TCA**), demonstrating that correlation alignment between high-certainty instances and test instances can enhance test performances with a theoretical guarantee. Based on this, we propose two simple yet effective algorithms: LinearTCA and LinearTCA+. LinearTCA applies a simple linear transformation to achieve both instance and correlation alignment without additional model updates, while LinearTCA+ serves as a plug-and-play module that can easily boost existing TTA methods. Extensive experiments validate our theoretical insights and show that TCA methods significantly outperforms baselines across various tasks, benchmarks and backbones. Notably, LinearTCA achieves higher accuracy with only 4\% GPU memory and 0.6\% computation time compared to the best TTA baseline. It also outperforms existing methods on CLIP over 1.86\%. Code: https://github.com/youlj109/TCA","In this work, we propose Test-time Correlation Alignment (TCA), a theoretically grounded and efficient approach to Test-Time Adaptation (TTA) that aligns feature correlations between high-confidence test samples and the test domain—without requiring access to source data.TCA addresses several key challenges in existing TTA methods:(1) the neglect of correlation alignment due to missing source statistics,(2) high computational overhead caused by backpropagation-based updates, and(3) domain forgetting during adaptation.We begin by exploring the feasibility of TCA through two central questions:(1) Can we construct a pseudo-source correlation that approximates the true source correlation?(2) Can this enable effective adaptation at test time?To answer these, we present a theoretical analysis showing that aligning correlations between high-certainty and test instances can provably improve test-time performance.Based on this insight, we propose two simple yet effective methods: LinearTCA and LinearTCA⁺. - LinearTCA performs both instance-and correlation-level alignment via a lightweight linear transformation, without modifying model parameters. - LinearTCA⁺ serves as a plug-and-play module that enhances existing TTA methods with minimal effort.Experimental results demonstrate that LinearTCA achieves strong standalone performance, while LinearTCA⁺ consistently boosts other TTA approaches across diverse settings.Further analysis provides insights into the applicability and limitations of LinearTCA, offering valuable guidance for future research."
Poster,Test-Time Graph Neural Dataset Search With Generative Projection,https://ICML.cc//virtual/2025/poster/46295,"Xin Zheng, Wei Huang, Chuan Zhou, Ming Li, Shirui Pan","In this work, we address the test-time adaptation challenge in graph neural networks (GNNs), focusing on overcoming the limitations in flexibility and generalization inherent in existing data-centric approaches. To this end, we propose a novel research problem, test-time graph neural dataset search, which seeks to learn a parameterized test-time graph distribution to enhance the inference performance of unseen test graphs on well-trained GNNs. Specifically, we propose a generative Projection based test-time Graph Neural Dataset Search method, named PGNDS, which maps the unseen test graph distribution back to the known training distribution through a generation process guided by well-trained GNNs. The proposed PGNDS framework consists of three key modules: (1) dual conditional diffusion for GNN-guided generative projection through test-back-to-training distribution mapping; (2) dynamic search from the generative sampling space to select the most expressive test graphs; (3) ensemble inference to aggregate information from original and adapted test graphs. Extensive experiments on real-world graphs demonstrate the superior ability of our proposed PGNDS for improved test-time GNN inference.","Graph neural networks (GNNs) often struggle to perform well when applied to new, unseen graphs due to distribution shifts in the data. Our paper introduces PGNDS, a new method that adapts GNNs at test time without modifying the model. Rather than fine-tuning the model, PGNDS automatically transforms new graphs to resemble the training data, enabling better performance on shifted distributions. This improves prediction accuracy across tasks and provides a practical, data-centric solution for deploying GNNs in dynamic, real-world scenarios."
Poster,Test-Time Learning for Large Language Models,https://ICML.cc//virtual/2025/poster/44367,"Jinwu Hu, Zitian Zhang, Guohao Chen, Xutao Wen, Chao Shuai, Wei Luo, Bin Xiao, Yuanqing Li, Mingkui Tan","While Large Language Models (LLMs) have exhibited remarkable emergent capabilities through extensive pre-training,  they still face critical limitations in generalizing to specialized domains and handling diverse linguistic variations, known as distribution shifts. In this paper, we propose a Test-Time Learning (TTL) paradigm for LLMs, namely TLM, which dynamically adapts LLMs to target domains using only unlabeled test data during testing. Specifically, we first provide empirical evidence and theoretical insights to reveal that more accurate predictions from LLMs can be achieved by minimizing the input perplexity of the unlabeled test data. Based on this insight, we formulate the Test-Time Learning process of LLMs as input perplexity minimization, enabling self-supervised enhancement of LLM performance. Furthermore, we observe that high-perplexity samples tend to be more informative for model optimization. Accordingly, we introduce a Sample Efficient Learning Strategy that actively selects and emphasizes these high-perplexity samples for test-time updates. Lastly, to mitigate catastrophic forgetting and ensure adaptation stability, we adopt Low-Rank Adaptation (LoRA) instead of full-parameter optimization, which allows lightweight model updates while preserving more original knowledge from the model. We introduce the AdaptEval benchmark for TTL and demonstrate through experiments that TLM improves performance by at least 20% compared to original LLMs on domain knowledge adaptation.","While Large Language Models (LLMs) have exhibited remarkable emergent capabilities through extensive pre-training,  they still face critical limitations in generalizing to specialized domains and handling diverse linguistic variations, known as distribution shifts. In this paper, we propose a Test-Time Learning (TTL) paradigm for LLMs, namely TLM, which dynamically adapts LLMs to target domains using only unlabeled test data during testing.  Experiments demonstrate that TLM improves performance by at least 20% compared to original LLMs on domain knowledge adaptation."
Poster,Test-Time Multimodal Backdoor Detection by Contrastive Prompting,https://ICML.cc//virtual/2025/poster/46621,"Yuwei Niu, Shuo He, Qi Wei, Zongyu Wu, Feng Liu, Lei Feng","While multimodal contrastive learning methods (e.g., CLIP) can achieve impressive zero-shot classification performance, recent research has revealed that these methods are vulnerable to backdoor attacks. To defend against backdoor attacks on CLIP, existing defense methods focus on either the pre-training stage or the fine-tuning stage, which would unfortunately cause high computational costs due to numerous parameter updates and are not applicable in black-box settings. In this paper, we provide the first attempt at a computationally efficient backdoor detection method to defend against backdoored CLIP in the inference stage. We empirically find that the visual representations of backdoored images are insensitive to benign and malignant changes in class description texts. Motivated by this observation, we propose BDetCLIP, a novel test-time backdoor detection method based on contrastive prompting. Specifically, we first prompt a language model (e.g., GPT-4) to produce class-related description texts (benign) and class-perturbed random texts (malignant) by specially designed instructions. Then, the distribution difference in cosine similarity between images and the two types of class description texts can be used as the criterion to detect backdoor samples. Extensive experiments validate that our proposed BDetCLIP is superior to state-of-the-art backdoor detection methods, in terms of both effectiveness and efficiency.","As multimodal models like CLIP have become essential for tasks such as image classification and text-to-image generation, they have also become vulnerable to backdoor attacks. These attacks involve manipulating models to classify certain inputs in a harmful way, which could pose serious security risks. Current defense methods are computationally expensive or impractical in real-world scenarios where access to the model is limited.We propose a novel, computationally efficient method called BDetCLIP to detect backdoor samples during the inference stage, without the need for modifying model parameters. By using contrastive prompting, we prompt GPT-4 to generate benign and malignant class descriptions. We then analyze the cosine similarity between image representations and these texts to identify backdoored images based on how the visual representation aligns with the class descriptions.Our method, BDetCLIP, is not only highly effective but also more efficient than existing solutions. It outperforms state-of-the-art detection techniques on various datasets under multiple backdoor attack scenarios with impressive speed. This work is crucial for enhancing the security of multimodal AI systems, providing a lightweight defense strategy for real-world applications, especially in settings where models are accessed as black-boxes."
