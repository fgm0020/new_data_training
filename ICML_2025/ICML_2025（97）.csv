type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,EPIC: Efficient Position-Independent Caching for Serving Large Language Models,https://ICML.cc//virtual/2025/poster/43926,"JUNHAO HU, Wenrui Huang, Weidong Wang, Haoyi Wang, tiancheng hu, zhang qin, Hao Feng, Xusheng Chen, Yizhou Shan, Tao Xie","Large Language Models (LLMs) show great capabilities in a wide range of applications, but serving them efficiently becomes increasingly challenging as requests (prompts) become more complex. Context caching improves serving performance by reusing Key-Value (KV) vectors, the intermediate representations of tokens that are repeated across requests. However, existing context caching requires exact prefix matches across requests, limiting reuse cases in settings such as few-shot learning and retrieval-augmented generation, where immutable content (e.g., documents) remains unchanged across requests but is preceded by varying prefixes. Position-IndependentCaching (PIC) addresses this issue by enabling modular reuse of the KV vectors regardless of prefixes. We formalize PIC and advance prior work by introducing EPIC, a serving system incorporating our new LegoLink algorithm, which mitigates the inappropriate “attention sink” effect at every document beginning, to maintain accuracy with minimal computation. Experiments show that EPIC achieves up to 8× improvements in Time-To-First-Token (TTFT) and 7× throughput gains over existing systems, with negligible or no accuracy loss.","Large Language Models (LLMs) demonstrate strong capabilities across a wide range of applications; however, efficiently serving them becomes increasingly challenging as user requests (prompts) grow in complexity.In this work, we formalize Position-Independent Caching (PIC), an approach designed to substantially accelerate LLM inference by enabling modular reuse of intermediate representations. Building upon prior PIC efforts, we present EPIC, a serving system that incorporates a novel algorithm, LegoLink, which preserves model accuracy while minimizing computational overhead.Empirical results show that EPIC yields substantial performance gains, particularly in scenarios such as few-shot learning and retrieval-augmented generation, achieving significant improvements in both latency and throughput with minimal or no loss in accuracy."
Poster,EpiCoder: Encompassing Diversity and Complexity in Code Generation,https://ICML.cc//virtual/2025/poster/45292,"Yaoxiang Wang, Haoling Li, Xin Zhang, Jie Wu, Xiao Liu, Wenxiang Hu, Zhongxin Guo, Yangyu Huang, Ying Xin, Yujiu Yang, Jinsong Su, Qi Chen, Scarlett Li","Existing methods for code generation use code snippets as seed data, restricting the complexity and diversity of the synthesized data. In this paper,  we introduce a novel feature tree-based synthesis framework, which revolves around hierarchical code features derived from high-level abstractions of code. The feature tree is constructed from raw data and refined iteratively to increase the quantity and diversity of the extracted features, which captures and recognizes more complex patterns and relationships within the code. By adjusting the depth and breadth of the sampled subtrees, our framework provides precise control over the complexity of the generated code, enabling functionalities that range from function-level operations to multi-file scenarios. We fine-tuned widely-used base models to obtain EpiCoder series, achieving state-of-the-art performance on multiple benchmarks at both the function and file levels. In particular, empirical evidence indicates that our approach shows significant potential in the synthesizing of repository-level code data. Our code and data are publicly available.","AI models can generate computer code, but they often rely on small pieces of existing code to learn from, which limits how complex or realistic the generated code can be. Our research introduces a new approach that learns from the structure and patterns of code in a more organized way—like building a tree of features that represent how code works at different levels. This ""feature tree"" helps the AI understand both simple and complex parts of programming, and lets us control how detailed or large the generated code should be—ranging from a single function to entire software projects. We also created a series of improved AI models, called EpiCoder, which outperform existing tools on standard tests. Our results suggest that this method could help generate high-quality code, potentially benefiting developers, educators, and AI models."
Poster,Epsilon-VAE: Denoising as Visual Decoding,https://ICML.cc//virtual/2025/poster/44068,"Long Zhao, Sanghyun Woo, Ziyu Wan, Yandong li, Han Zhang, Boqing Gong, Hartwig Adam, Xuhui Jia, Ting Liu","In generative modeling, tokenization simplifies complex data into compact, structured representations, creating a more efficient, learnable space. For high-dimensional visual data, it reduces redundancy and emphasizes key features for high-quality generation. Current visual tokenization methods rely on a traditional autoencoder framework, where the encoder compresses data into latent representations, and the decoder reconstructs the original input. In this work, we offer a new perspective by proposing denoising as decoding, shifting from single-step reconstruction to iterative refinement. Specifically, we replace the decoder with a diffusion process that iteratively refines noise to recover the original image, guided by the latents provided by the encoder. We evaluate our approach by assessing both reconstruction (rFID) and generation quality (FID), comparing it to state-of-the-art autoencoding approaches. By adopting iterative reconstruction through diffusion, our autoencoder, namely Epsilon-VAE, achieves high reconstruction quality, which in turn enhances downstream generation quality by 22% at the same compression rates or provides 2.3x inference speedup through increasing compression rates. We hope this work offers new insights into integrating iterative generation and autoencoding for improved compression and generation.","Creating high-quality digital images with AI often starts by simplifying complex visual information into compact representations, a process called visual tokenization. Current methods usually reconstruct images from these simplified forms in a single step, which can limit the final quality. This paper introduces Epsilon-VAE, a new approach that reimagines this reconstruction. Instead of a one-shot process, Epsilon-VAE decodes images by treating it as an iterative denoising task: it starts with an initial noisy state and progressively refines it over a few steps to build back the detailed image, guided by the compact representation from an encoder. This method of iterative refinement leads to significantly better image reconstruction quality, especially when information is highly compressed. As a result, AI systems using Epsilon-VAE can generate entirely new images with up to 22% improved visual quality or achieve more than a twofold speed-up in generating images by using more compressed data without sacrificing quality."
Poster,Equivalence is All: A Unified View for Self-supervised Graph Learning,https://ICML.cc//virtual/2025/poster/44874,"Yejiang Wang, Yuhai Zhao, Zhengkui Wang, Ling Li, Jiapu Wang, Fangting Li, Miaomiao Huang, Shirui Pan, Xingwei Wang","Node equivalence is common in graphs, such as computing networks, encompassing automorphic equivalence (preserving adjacency under node permutations) and attribute equivalence (nodes with identical attributes). Despite their importance for learning node representations, these equivalences are largely ignored by existing graph models. To bridge this gap, we propose a GrAph self-supervised Learning framework with Equivalence (GALE) and analyze its connections to existing techniques. Specifically, we: 1) unify automorphic and attribute equivalence into a single equivalence class; 2) enforce the equivalence principle to make representations within the same class more similar while separating those across classes; 3) introduce approximate equivalence classes with linear time complexity to address the NP-hardness of exact automorphism detection and handle node-feature variation; 4) analyze existing graph encoders, noting limitations in message passing neural networks and graph transformers regarding equivalence constraints; 5) show that graph contrastive learning are a degenerate form of equivalence constraint; and 6) demonstrate that GALE achieves superior performance over baselines.","In many networks, like social circles, some ""nodes"" (or points) are essentially interchangeable. They might have identical connection patterns to their neighbors or share the same characteristics. However, current AI methods for learning from these networks often overlook these crucial similarities, treating most distinct nodes as entirely different, even if they play very similar roles. This is like not recognizing that two identical tools should be treated similarly just because they are separate objects.We've developed a new AI learning approach called GALE that embraces this idea of ""node equivalence."" GALE first identifies groups of nodes that are effectively the same, considering both their structural position in the network and their individual features. To handle real-world complexities where perfect sameness is rare or hard to find, it cleverly uses efficient approximations. GALE then teaches the AI that nodes within the same ""equivalence group"" should be understood as being very similar, while nodes in different groups should remain distinct.This approach allows AI to learn more accurate and meaningful information from network data. By recognizing and using these fundamental equivalences, GALE helps AI understand the underlying structure and function of networks much better, outperforming existing methods in our tests."
Poster,EquivaMap: Leveraging LLMs for Automatic Equivalence Checking of Optimization Formulations,https://ICML.cc//virtual/2025/poster/44297,"Haotian Zhai, Connor Lawless, Ellen Vitercik, Liu Leqi","A fundamental problem in combinatorial optimization is identifying equivalent formulations. Despite the growing need for automated equivalence checks---driven, for example, by *optimization copilots*, which generate problem formulations from natural language descriptions---current approaches rely on simple heuristics that fail to reliably check formulation equivalence.Inspired by Karp reductions, in this workwe introduce *Quasi-Karp equivalence*, a formal criterion for determining when two optimization formulations are equivalentbased on the existence of a mapping between their decision variables. We propose *EquivaMap*, a framework that leverages large language models to automatically discover such mappings for scalable, reliable equivalence checking, with a verification stage that ensures mapped solutions preserve feasibility and optimality without additional solver calls. To evaluate our approach, we construct *EquivaFormulation*, the first open-source dataset of equivalent optimization formulations, generatedby applying transformations such as adding slack variables or valid inequalitiesto existing formulations.Empirically, *EquivaMap*significantly outperforms existing methods, achieving substantial improvements in correctly identifying formulation equivalence.","Optimization problems are often expressed in many different but equivalent ways. For example, the same scheduling or routing problem can be written using different variables or constraints. However, automatically determining whether two such formulations are truly equivalent—meaning they represent the same problem and have the same solutions—is a challenging and important task.In this work, we introduce a new formal notion called Quasi-Karp equivalence to rigorously define when two optimization problems are equivalent through efficient transformations between their variables. To detect this equivalence automatically, we develop EquivaMap, a novel framework that leverages large language models (LLMs) to discover mappings between variables of two problem formulations.We create the first dataset of equivalent optimization problems by applying common transformations, and show that EquivaMap significantly outperforms existing heuristic methods in identifying equivalences, even under complex changes like variable rescaling.Our approach enables reliable verification of AI-generated optimization models, improving trust and interoperability in automated decision-making systems."
Poster,Equivariant Neural Tangent Kernels,https://ICML.cc//virtual/2025/poster/44041,"Philipp Misof, Pan Kessel, Jan Gerken","Little is known about the training dynamics of equivariant neural networks, in particular how it compares to data augmented training of their non-equivariant counterparts. Recently, neural tangent kernels (NTKs) have emerged as a powerful tool to analytically study the training dynamics of wide neural networks. In this work, we take an important step towards a theoretical understanding of training dynamics of equivariant models by deriving neural tangent kernels for a broad class of equivariant architectures based on group convolutions. As a demonstration of the capabilities of our framework, we show an interesting relationship between data augmentation and group convolutional networks. Specifically, we prove that they share the same expected prediction over initializations at all training times and even off the data manifold. In this sense, they have the same training dynamics. We demonstrate in numerical experiments that this still holds approximately for finite-width ensembles. By implementing equivariant NTKs for roto-translations in the plane ($G=C_{n}\ltimes\mathbb{R}^{2}$) and 3d rotations ($G=\mathrm{SO}(3)$), we show that equivariant NTKs outperform their non-equivariant counterparts as kernel predictors for histological image classification and quantum mechanical property prediction.","A significant proportion of machine learning problems are subject to inherent symmetries, e.g. translation or rotation symmetry in image classification. This underlying property can either be learned by means of data augmentation or enforced through the model structure itself, so-called equivariant networks. However, the training dynamics of the latter are not understood well, rendering a systematic comparison between those approaches difficult.In this work, we extend a mathematical tool, called the neural tangent kernel (NTK) to equivariant networks. In the regime of wide hidden layers, it allows for an analytic solution of the training dynamics and has already been applied with great success on simpler models. We use our extension to find an explicit connection between data augmentation and equivariance: For a particular class of conventional networks trained with data augmentation, we find corresponding equivariant networks that share the same expected training dynamics in the limit of infinitely wide hidden layers. We further implement the general analytic relations we found for rotation and translation symmetries.The presented framework and its implications contribute to the ongoing debate on whether symmetry should be enforced by construction or learned from data by finding an explicit correspondence between those two approaches."
Poster,Equivariant Polynomial Functional Networks,https://ICML.cc//virtual/2025/poster/44584,"Thieu Vo, Viet Hoang Tran, Tho Tran Huu, An Nguyen The, Thanh Tran, Minh-Khoi Nguyen-Nhat, Duy-Tung Pham, Tan Nguyen","A neural functional network (NFN) is a specialized type of neural network designed to process and learn from entire neural networks as input data.  Recent NFNs have been proposed with permutation and scaling equivariance based on either graph-based message-passing mechanisms or parameter-sharing mechanisms. Compared to graph-based models, parameter-sharing-based NFNs built upon equivariant linear layers exhibit lower memory consumption and faster running time. However, their expressivity is limited due to the large size of the symmetric group of the input neural networks. The challenge of designing a permutation and scaling equivariant NFN that maintains low memory consumption and running time while preserving expressivity remains unresolved. In this paper, we propose a novel solution with the development of MAGEP-NFN (**M**onomial m**A**trix **G**roup **E**quivariant **P**olynomial **NFN**). Our approach follows the parameter-sharing mechanism but differs from previous works by constructing a nonlinear equivariant layer represented as a polynomial in the input weights. This polynomial formulation enables us to incorporate additional relationships between weights from different input hidden layers, enhancing the model's expressivity while keeping memory consumption and running time low, thereby addressing the aforementioned challenge. We provide empirical evidence demonstrating that MAGEP-NFN achieves competitive performance and efficiency compared to existing baselines.","A Neural Functional Network (NFN) learns from entire neural networks as input. While efficient NFNs use shared parameters to handle permutations and scaling, they often lack expressivity due to symmetry constraints. We propose MAGEP-NFN, which introduces a nonlinear, polynomial-based layer to capture richer relationships between weights. This approach maintains low memory and fast runtime while improving expressivity, achieving strong performance in practice."
Poster,EQ-VAE: Equivariance Regularized Latent Space for Improved Generative Image Modeling,https://ICML.cc//virtual/2025/poster/45112,"Theodoros Kouzelis, Ioannis Kakogeorgiou, Spyros Gidaris, Nikos Komodakis","Latent generative models have emerged as a leading approach for high-quality image synthesis. These models rely on an autoencoder to compress images into a latent space, followed by a generative model to learn the latent distribution. We identify that existing autoencoders lack equivariance to semantic-preserving transformations like scaling and rotation, resulting in complex latent spaces that hinder generative performance. To address this, we propose EQ-VAE, a simple regularization approach that enforces equivariance in the latent space, reducing its complexity without degrading reconstruction quality. By finetuning pre-trained autoencoders with EQ-VAE, we enhance the performance of several state-of-the-art generative models, including DiT, SiT, REPA and MaskGIT, achieving a ×7 speedup on DiT-XL/2 with only five epochs of SD-VAE fine-tuning. EQ-VAE is compatible with both continuous and discrete autoencoders, thus offering a versatile enhancement for a wide range of latent generative models.","Latent generative models are widely used for high-quality image synthesis but face challenges due to the complexity of the latent space created by existing autoencoders. We find that state-of-the-art autoencoders lack equivariance to simple transformations like scaling and rotation, resulting in complex latent spaces that hinder generative performance.We introduced EQ-VAE, a new method that enforces equivariance in the latent space of autoencoders. This ensures that simple transformations of the image result in corresponding simple transformations of the latent representation. This is achieved with a simple regularization loss that is compatible with both discrete and continuous autoencoders.By fine-tuning pre-trained autoencoders with EQ-VAE, we significantly improved the performance of various generative models, including Latent Diffusion Models such as DiT, SiT, and REPA, and Masked Generative Models such as MaskGIT. For example, with EQ-VAE, DiT achieves up to 7 times faster training time without compromising reconstruction quality."
Poster,EraseAnything: Enabling Concept Erasure in Rectified Flow Transformers,https://ICML.cc//virtual/2025/poster/43648,"Daiheng Gao, Shilin Lu, Wenbo Zhou, Jiaming Chu, Jie Zhang, Mengxi Jia, Bang Zhang, Zhaoxin Fan, Weiming Zhang","Removing unwanted concepts from large-scale text-to-image (T2I) diffusion models while maintaining their overall generative quality remains an open challenge. This difficulty is especially pronounced in emerging paradigms, such as Stable Diffusion (SD) v3 and Flux, which incorporate flow matching and transformer-based architectures. These advancements limit the transferability of existing concept-erasure techniques that were originally designed for the previous T2I paradigm (e.g., SD v1.4). In this work, we introduce EraseAnything, the first method specifically developed to address concept erasure within the latest flow-based T2I framework. We formulate concept erasure as a bi-level optimization problem, employing LoRA-based parameter tuning and an attention map regularizer to selectively suppress undesirable activations. Furthermore, we propose a self-contrastive learning strategy to ensure that removing unwanted concepts does not inadvertently harm performance on unrelated ones. Experimental results demonstrate that EraseAnything successfully fills the research gap left by earlier methods in this new T2I paradigm, achieving state-of-the-art performance across a wide range of concept erasure tasks.","This paper introduces a new method called EraseAnything. It's the first tool specifically designed to tackle this problem in these latest text-to-image models. EraseAnything works by carefully adjusting the model's internal settings using LoRA, and by guiding the model's ""attention"" to suppress the unwanted concept. It also has a clever strategy that makes sure that when it removes an unwanted concept, it doesn't accidentally make the model worse at generating other, unrelated things."
Poster,Ergodic Generative Flows,https://ICML.cc//virtual/2025/poster/45840,"Leo Brunswic, Mateo Clémente, Rui Heng Yang, Adam Sigal, Amir Rasouli, Yinchuan Li","Generative Flow Networks (GFNs) were initially introduced on directed non-acyclic graphs to sample from an unnormalized distribution density. Recent works have extended the theoretical framework for generative methods allowing more flexibility and enhancing application range. However, many challenges remain in training GFNs in continuous settings and for imitation learning (IL), including intractability of flow-matching loss, limited tests of non-acyclic training, and the need for a separate reward model in imitation learning. The present work proposes a family of generative flows called Ergodic Generative Flows (EGFs) which are used to address the aforementioned issues. First, we leverage ergodicity to build simple generative flows with finitely many globally defined transformations (diffeomorphisms) with universality guarantees and tractable flow-matching loss (FM loss). Second, we introduce a new loss involving cross-entropy coupled to weak flow-matching control, coined KL-weakFM loss. It is designed for IL training without a separate reward model. We evaluate IL-EGFs on toy 2D tasks and real-world datasets from NASA on the sphere, using the KL-weakFM loss.  Additionally, we conduct toy 2D reinforcement learning experiments with a target reward, using the FM loss.","At the most abstract level, the generative models belong to a family (GANs, Diffusion models, GFlowNets,...) which specifies how the neural net is trained and how the computations it carries out are used. GFlowNet applies transformations iteratively to modify a sample until it is satisfactory; the key part of the training is to build a heuristic that guides the choice of transformation at each step. Our work introduces Ergodic Generative Flows (EGFs), a new kind of GFN that simplifies training while preserving flexibility. EGFs rely on a small set of well-chosen transformations that can reach any part of the space through mixing, ensuring both expressiveness and mathematical tractability. This approach allows the use of GFlowNets for Generative modeling in a more direct fashion. More generally, our approach opens up a new way of building expressive generative models with large-step mixing transformations in small numbers, rather than small-step transformations in large numbers."
