type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Temperature-Annealed Boltzmann Generators,https://ICML.cc//virtual/2025/poster/45260,"Henrik Schopmans, Pascal Friederich","Efficient sampling of unnormalized probability densities such as theBoltzmann distribution of molecular systems is a longstanding challenge.Next to conventional approaches like molecular dynamics or Markov chainMonte Carlo, variational approaches, such as training normalizing flows withthe reverse Kullback-Leibler divergence, have been introduced. However, suchmethods are prone to mode collapse and often do not learn to sample the fullconfigurational space. Here, we present temperature-annealed Boltzmanngenerators (TA-BG) to address this challenge. First, we demonstrate thattraining a normalizing flow with the reverse Kullback-Leibler divergence athigh temperatures is possible without mode collapse. Furthermore, weintroduce a reweighting-based training objective to anneal the distribution to lower target temperatures.We apply this methodology to three molecular systems of increasing complexity and, compared to the baseline, achieve better results in almost all metrics while requiring up to three times fewer target energy evaluations. For the largest system, our approach is the only method that accurately resolves the metastable states of the system.","Understanding how molecules behave and interact is key to breakthroughs in areas like drug discovery. Computer simulations of physical systems are like virtual microscopes that offer insights into a system's behavior without requiring expensive lab experiments. However, to cover all relevant interactions and processes, the movement of the atoms in a system typically has to be simulated for a very long time, requiring large amounts of computational resources.Instead of simulating the system over time, variational sampling methods train generative machine learning models to directly match the probability distribution of the physical system. This is a promising approach to make computer simulations more efficient. However, such variational methods often show a problem called mode collapse, where only a small fraction of the system's behavior is learned by the machine learning model.Our work presents a simple and effective fix: we start training the model under easier conditions, simulating a higher-temperature environment where the mode collapse problem disappears. Then, we gradually ""cool"" the system down, guiding the model toward realistic behaviors at the target temperature. This approach allows efficient exploration of the atomistic behavior of molecular systems, without mode collapse."
Poster,Temporal Difference Flows,https://ICML.cc//virtual/2025/poster/44320,"Jesse Farebrother, Matteo Pirotta, Andrea Tirinzoni, REMI MUNOS, Alessandro Lazaric, Ahmed Touati","Predictive models of the future are fundamental for an agent's ability to reason and plan. A common strategy learns a world model and unrolls it step-by-step at inference, where small errors can rapidly compound. Geometric Horizon Models (GHMs) offer a compelling alternative by directly making predictions of future states, avoiding cumulative inference errors. While GHMs can be conveniently learned by a generative analog to temporal difference (TD) learning, existing methods are negatively affected by bootstrapping predictions at train time and struggle to generate high-quality predictions at long horizons. This paper introduces Temporal Difference Flows (TD-Flow), which leverages the structure of a novel Bellman equation on probability paths alongside flow-matching techniques to learn accurate GHMs at over 5x the horizon length of prior methods. Theoretically, we establish a new convergence result and primarily attribute TD-Flow's efficacy to reduced gradient variance during training. We further show that similar arguments can be extended to diffusion-based methods.  Empirically, we validate TD-Flow across a diverse set of domains on both generative metrics and downstream tasks, including policy evaluation. Moreover, integrating TD-Flow with recent behavior foundation models for planning over policies demonstrates substantial performance gains, underscoring its promise for long-horizon decision-making.","Predicting future events accurately is crucial for intelligent systems that plan and make decisions over long periods. Typically, systems predict the future by repeatedly predicting one step at a time, but even tiny errors at each step can snowball into big mistakes, making long-term predictions very unreliable. To address this issue, we developed Temporal Difference Flows (TD-Flow), a method that directly predicts future states over extended horizons, avoiding the buildup of small errors. TD-Flow combines a new theoretical insight with advanced techniques from generative modeling, which allows it to predict accurately over much longer time horizons—up to five times longer than existing methods. We demonstrated, both theoretically and experimentally, that TD-Flow enables stable and accurate long-term predictions. When tested in different scenarios, TD-Flow consistently outperformed previous methods, improving not only prediction accuracy but also how effectively agents can assess and decide on what behaviours to commit to for extended periods of time. Ultimately, TD-Flow holds great promise for enhancing long-term decision-making capabilities across various complex systems."
Poster,Temporal Distance-aware Transition Augmentation for Offline Model-based Reinforcement Learning,https://ICML.cc//virtual/2025/poster/44612,"Dongsu Lee, Minhae Kwon","The goal of offline reinforcement learning (RL) is to extract the best possible policy from the previously collected dataset considering the *out-of-distribution* (OOD) sample issue. Offline model-based RL (MBRL) is a captivating solution capable of alleviating such issues through a \textit{state-action transition augmentation} with a learned dynamic model. Unfortunately, offline MBRL methods have been observed to fail in sparse rewarded and long-horizon environments for a long time. In this work, we propose a novel MBRL method, dubbed Temporal Distance-Aware Transition Augmentation (TempDATA), that generates additional transitions in a geometrically structured representation space, instead of state space. For comprehending long-horizon behaviors efficiently, our main idea is to learn state abstraction, which captures a *temporal distance* from both *trajectory and transition levels* of state space. Our experiments empirically confirm that TempDATA outperforms previous offline MBRL methods and achieves matching or surpassing the performance of diffusion-based trajectory augmentation and goal-conditioned RL on the D4RL AntMaze, FrankaKitchen, CALVIN, and pixel-based FrankaKitchen.","Until now, offline model-based reinforcement learning (MBRL) has struggled with long-horizon tasks where rewards are sparse, because naively augmenting data in the raw state space often produces unrealistic transitions and fails to connect distant start and goal states within limited datasets.Our approach, Temporal Distance-Aware Transition Augmentation (TempDATA), first learns a compact latent representation that captures true temporal distances between states, then generates new transitions in this space and decodes them back into realistic trajectories, ensuring augmented data respects the multi-step structure needed to reach far-away goals.By focusing on time-aware augmentation, TempDATA not only enhances offline MBRL but can be seamlessly integrated into policy-only (model-free) methods, skill or hierarchical RL, and goal-conditioned RL; it likewise complements both model-based and model-free learning pipelines, broadening its applicability across diverse reinforcement learning paradigms."
Poster,Temporal Misalignment in ANN-SNN Conversion and its Mitigation via Probabilistic Spiking Neurons,https://ICML.cc//virtual/2025/poster/45627,"Velibor Bojkovic, Xiaofeng Wu, Bin Gu","Spiking Neural Networks (SNNs) offer a more energy-efficient alternative to Artificial Neural Networks (ANNs) by mimicking biological neural principles, establishing them as a promising approach to mitigate the increasing energy demands of large-scale neural models. However, fully harnessing the capabilities of SNNs remains challenging due to their discrete signal processing and temporal dynamics. ANN-SNN conversion has emerged as a practical approach, enabling SNNs to achieve competitive performance on complex machine learning tasks. In this work, we identify a phenomenon in the ANN-SNN conversion framework, termed *temporal misalignment*, in which random spike rearrangement across SNN layers leads to performance improvements. Based on this observation, we introduce biologically plausible two-phase probabilistic (TPP) spiking neurons, further enhancing the conversion process. We demonstrate the advantages of our proposed method both theoretically and empirically through comprehensive experiments on CIFAR-10/100, CIFAR10-DVS, and ImageNet across a variety of architectures, achieving state-of-the-art results.","Spiking neural networks (SNNs) are designed to mimic biological functioning of biological neurons. In this work we discover and study a seemingly counterintuitive phenomenon in ANN-to-SNN conversion (a way to train SNNs via pretrained Artificial Neural Networks), which we term Temporal Misalignment. Namely, we find that random permutations of spike trains after spiking layers significantly boost model performance.We dive deeper into explaining what is actually happening and we introduce the Two-Phase Probabilistic (TPP) Spiking Neuron—a novel, biologically plausible, and hardware-friendly neuron model. Mitigating Temporal Misalignment, our TPP neuron enables SNNs to closely match ANN accuracy with just a few time steps."
Poster,Temporal Query Network for Efficient Multivariate Time Series Forecasting,https://ICML.cc//virtual/2025/poster/44603,"Shengsheng Lin, Haojun Chen, Haijie Wu, Chunyun Qiu, Weiwei Lin","Sufficiently modeling the correlations among variables (aka channels) is crucial for achieving accurate multivariate time series forecasting (MTSF). In this paper, we propose a novel technique called Temporal Query (TQ) to more effectively capture multivariate correlations, thereby improving model performance in MTSF tasks. Technically, the TQ technique employs periodically shifted learnable vectors as queries in the attention mechanism to capture global inter-variable patterns, while the keys and values are derived from the raw input data to encode local, sample-level correlations. Building upon the TQ technique, we develop a simple yet efficient model named Temporal Query Network (TQNet), which employs only a single-layer attention mechanism and a lightweight multi-layer perceptron (MLP). Extensive experiments demonstrate that TQNet learns more robust multivariate correlations, achieving state-of-the-art forecasting accuracy across 12 challenging real-world datasets. Furthermore, TQNet achieves high efficiency comparable to linear-based methods even on high-dimensional datasets, balancing performance and computational cost. The code is available at: https://github.com/ACAT-SCUT/TQNet.","Predicting what will happen in the future based on patterns from the past (known as time series forecasting) is important in many areas like weather prediction, traffic control, and energy management. These tasks often involve many related measurements (such as temperatures at different locations or traffic at different intersections), and understanding how these measurements influence each other is key to making accurate predictions. In this paper, we introduce a new method called Temporal Query (TQ) that helps computers better understand the relationships between different measurements over time. TQ works by learning to focus on long-term patterns across variables, even when individual data points might be noisy or incomplete. Based on this method, we build a lightweight model named TQNet, which is simple but surprisingly powerful. TQNet outperforms many existing forecasting models on 12 real-world datasets while staying fast and efficient, even when working with large and complex data. This makes it a practical and effective tool for a wide range of forecasting applications."
Poster,Tensor Decomposition Based Memory-Efficient Incremental Learning,https://ICML.cc//virtual/2025/poster/44196,"Yuhang Li, Guoxu Zhou, Zhenhao Huang, Xinqi Chen, Yuning Qiu, Qibin Zhao","Class-Incremental Learning (CIL) has gained considerable attention due to its capacity to accommodate new classes during learning. Replay-based methods demonstrate state-of-the-art performance in CIL but suffer from high memory consumption to save a set of old exemplars for revisiting. To address this challenge, many memory-efficient replay methods have been developed by exploiting image compression techniques. However, the gains are often bittersweet when pixel-level compression methods are used. Here, we present a simple yet efficient approach that employs tensor decomposition to address these limitations. This method fully exploits the low intrinsic dimensionality and pixel correlation of images to achieve high compression efficiency while preserving sufficient discriminative information, significantly enhancing performance. We also introduce a hybrid exemplar selection strategy to improve the representativeness and diversity of stored exemplars. Extensive experiments across datasets with varying resolutions consistently demonstrate that our approach substantially boosts the performance of baseline methods, showcasing strong generalization and robustness.","Incremental learning aims to enable our AI systems to learn new knowledge from dynamic data streams, but this often leads to them severely forgetting past knowledge. Inspired by the human learning process, researchers retain a portion of the old knowledge for the system to ‘review’ when learning new knowledge. However, strict memory limits often cripple such replay methods. We propose a memory-efficient replay approach based on tensor decomposition: instead of storing full images, we decompose each into a set of small factors via CP decomposition, drastically reducing storage needs while preserving reconstruction quality.  We further introduce a two-stage exemplar selection strategy—first, choosing representative raw examples, then augmenting them with well-reconstructed compressed ones—to ensure both coverage and fidelity.  Integrated into class-incremental learning frameworks, our method significantly boosts their performance, especially under tight memory constraints. These results hold across various image resolutions and tasks. This plug-and-play solution makes continual learning practical for real-world systems, enabling them to learn robustly and efficiently with far less memory overhead."
Poster,Tensorized Multi-View Multi-Label Classification via Laplace Tensor Rank,https://ICML.cc//virtual/2025/poster/44133,"Qiyu Zhong, Yi Shan, Haobo Wang, Zhen Yang, Gengyu Lyu","In multi-view multi-label classification (MVML), each object has multiple heterogeneous views and is annotated with multiple labels. The key to deal with such problem lies in how to capture cross-view consistent correlations while excavate multi-label semantic relationships. Existing MVML methods usually employ two independent components to address them separately, and ignores their potential interaction relationships. To address this issue, we propose a novel Tensorized MVML method named TMvML, which formulates an MVML tensor classifier to excavate comprehensive cross-view feature correlations while characterize complete multi-label semantic relationships. Specifically, we first reconstruct the MVML mapping matrices as an MVML tensor classifier. Then, we rotate the tensor classifier and introduce a low-rank tensor constraint to ensure view-level feature consistency and label-level semantic co-occurrence simultaneously. To better characterize the low-rank tensor structure, we design a new Laplace Tensor Rank (LTR), which serves as a tighter surrogate of tensor rank to capture high-order fiber correlations within the tensor space. By conducting the above operations, our method can easily address the two key challenges in MVML via a concise LTR tensor classifier and achieve the extraction of both cross-view consistent correlations and multi-label semantic relationships simultaneously. Extensive experiments demonstrate that TMvML significantly outperforms state-of-the-art methods.","Modern data, like news webpage data, often comes in multiple forms—such as text, images, and videos—and can belong to multiple categories at once. Existing methods struggle to analyze these complex relationships effectively because they treat different data types and labels separately. Our work introduces a new approach called TMvML, which combines multi-view and multi-label learning into a unified framework using tensor-based techniques. Whatsmore, we develop a novel Laplace Tensor Rank (LTR) that better identifies meaningful patterns while filtering out noise. Experiments on real-world datasets show that TMvML achieves higher accuracy than current state-of-the-art methods, making it a practical solution for tasks like music or biological classification where multi-modal data and multiple labels are common. By capturing interactions between different data types and their labels in a single model, TMvML provides a more efficient and interpretable way to handle complex classification problems."
Poster,Tensor Product Neural Networks for Functional ANOVA Model,https://ICML.cc//virtual/2025/poster/46044,"Seokhun Park, Insung Kong, yongchan Choi, Chanmoo Park, Yongdai Kim","Interpretability for machine learning models is becoming more and more important as machine learning models become more complex. The functional ANOVA model, which decomposes a high-dimensional function into a sum of lower dimensional functions (commonly referred to as components), is one of the most popular tools for interpretable AI, and recently, various neural networks have been developed for estimating each component in the functional ANOVA model. However, such neural networks are highly unstable when estimating each component since the components themselves are not uniquely defined. That is, there are multiple functional ANOVA decompositions for a given function. In this paper, we propose a novel neural network which guarantees a unique functional ANOVA decomposition and thus is able to estimate each component stably. We call our proposed neural network ANOVA Tensor Product Neural Network (ANOVA-TPNN) sinceit is motivated by the tensor product basis expansion.Theoretically, we prove that ANOVA-TPNN can approximate any smooth function well.Empirically, we show that ANOVA-TPNN provide much more stable estimation of each component and thus much more stable interpretation when training data and initial values of the model parameters vary than existing neural networks do.Our source code is released at https://github.com/ParkSeokhun/ANOVA-TPNN","As machine learning models become more complex, it is becoming increasingly important to understand how they work.One common approach to making these models more interpretable is to break them down into smaller, more understandable parts.A widely used method for doing this is called functional ANOVA, which analyzes the effect of each interaction separately by decomposing the model into components.However, existing AI models that implement this method often produce unstable and inconsistent results.This is because there are many ways to perform such a decomposition, and traditional models cannot guarantee a unique or consistent breakdown of the model.To address this issue, we developed a new AI model called ANOVA-TPNN.This model ensures the uniqueness of decomposition, so that the effect of each component can be reliably understood.We have proven mathematically that ANOVA-TPNN can represent a wide range of smooth functions, and our experiments show that it provides much more stable and trustworthy results compared to existing models."
Poster,Tensor-Var: Efficient Four-Dimensional Variational Data Assimilation,https://ICML.cc//virtual/2025/poster/44739,"Yiming Yang, Xiaoyuan Cheng, Daniel Giles, Sibo Cheng, Yi He, Xiao Xue, Boli Chen, Yukun Hu","Variational data assimilation estimates the dynamical system states by minimizing a cost function that fits the numerical models with the observational data. Although four-dimensional variational assimilation (4D-Var) is widely used, it faces high computational costs in complex nonlinear systems and depends on imperfect state-observation mappings. Deep learning (DL) offers more expressive approximators, while integrating DL models into 4D-Var is challenging due to their nonlinearities and lack of theoretical guarantees in assimilation results. In this paper, we propose \textit{Tensor-Var}, a novel framework that integrates kernel conditional mean embedding (CME) with 4D-Var to linearize nonlinear dynamics, achieving convex optimization in a learned feature space. Moreover, our method provides a new perspective for solving 4D-Var in a linear way, offering theoretical guarantees of consistent assimilation results between the original and feature spaces. To handle large-scale problems, we propose a method to learn deep features (DFs) using neural networks within the Tensor-Var framework. Experiments on chaotic systems and global weather prediction with real-time observations show that Tensor-Var outperforms conventional and DL hybrid 4D-Var baselines in accuracy while achieving a 10- to 20-fold speed improvement.","Data assimilation plays a key role in predicting the evolution of dynamical systems across a wide variety of engineering and scientific domains. It involves combining computer simulations with real-world observations to improve forecasting performance. One popular method, 4D-Var, is effective but can be computationally slow and has known difficulties when dealing with complex chaotic systems such as weather prediction.We present a novel framework called Tensor-Var, which provides performance gains in relation to computational time and accuracy. Rather than relying directly on deep learning models—which can be challenging to understand and control—Tensor-Var simplifies the problem by transforming complex dynamics into a simple linear form that allows for faster, more reliable optimization. This is achieved by embedding the dynamics in a feature space using kernel embedding methods. We also integrate deep neural networks to learn scalable representations for large-scale problems. In tests on both chaotic systems and real weather data, Tensor-Var not only produced more accurate results but also ran up to 20 times faster than traditional methods. Our work paves the way to faster, more reliable assimilation and forecasts in science and engineering by combining machine learning, physical models, and observational data in a principled way."
Poster,Testing Conditional Mean Independence Using Generative Neural Networks,https://ICML.cc//virtual/2025/poster/44626,"Yi Zhang, Linjun Huang, Yun Yang, Xiaofeng Shao","Conditional mean independence (CMI) testing is crucial for statistical tasks including model determination and variable importance evaluation. In this work, we introduce a novel population CMI measure and a bootstrap-based testing procedure that utilizes deep generative neural networks to estimate the conditional mean functions involved in the population measure. The test statistic is thoughtfully constructed to ensure that even slowly decaying nonparametric estimation errors do not affect the asymptotic accuracy of the test. Our approach demonstrates strong empirical performance in scenarios with high-dimensional covariates and response variable, can handle multivariate responses, and maintains nontrivial power against local alternatives outside an $n^{-1/2}$ neighborhood of the null hypothesis. We also use numerical simulations and real-world imaging data applications to highlight the efficacy and versatility of our testing procedure.","Conditional mean independence (CMI) testing is a fundamental tool for model simplification and assessing variable importance. However, existing test procedures suffer from severe performance deterioration in high dimensional setting. We propose a new test procedure, basing on a novel CMI measure and neural networks, that has strong empirical performance in scenarios with high-dimensional covariates and response variable. Our test can help in improving model efficiency, accuracy, and interpretability for many machine learning applications."
