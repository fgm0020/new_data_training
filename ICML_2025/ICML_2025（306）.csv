type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Tokenized Bandit for LLM Decoding and Alignment,https://ICML.cc//virtual/2025/poster/45185,"Suho Shin, Chenghao Yang, Haifeng Xu, MohammadTaghi Hajiaghayi","We introduce the tokenized linear bandit (TLB) and multi-armed bandit (TMAB), variants of linear and stochastic multi-armed bandit problems inspired by LLM decoding and alignment. In these problems, at each round $t \in [T]$, a user submits a query (context), and the decision maker (DM) sequentially selects a token irrevocably from a token set. Once the sequence is complete, the DM observes a random utility from the user, whose expectation is presented by a sequence function mapping the chosen token sequence to a nonnegative real value that depends on the query.In both problems, we first show that learning is impossible without any structure on the sequence function.We introduce a natural assumption, diminishing distance with more commons (DDMC), and propose algorithms with regret $\tilde{O}(L\sqrt{T})$ and $\tilde{O}(L\sqrt{T^{2/3}})$ for TLB and TMAB, respectively.As a side product, we obtain an (almost) optimality of the greedy decoding for LLM decoding algorithm under DDMC, which justifies the unresaonable effectiveness of greedy decoding in several tasks.This also has an immediate application to decoding-time LLM alignment, when the misaligned utility can be represented as the frozen LLM's utility and a linearly realizable latent function.We finally validate our algorithm's performance empirically as well as verify our assumptions using synthetic and real-world datasets.","Large language models (LLMs) like ChatGPT generate responses one word (or token) at a time. But how should they choose the next word in a way that aligns best with what the user wants? This paper introduces a new mathematical framework to study this problem using ideas from a field called multi-armed bandits, which is often used to model decision-making under uncertainty.In our problem setting, a user submits a question, and the system chooses one word at a time to form a complete response. After the response is finished, the system receives feedback — a score measuring how good the response was. The challenge is to learn how to pick better responses over time.We show that without any structure, learning is hopeless. But with a natural assumption (that similar tokens lead to similar outcomes), they develop new algorithms that learn effectively and provide strong performance guarantees. Surprisingly, our results also explain why simple decoding methods like greedy generation (choosing the best word at each step) often work well in practice. Our findings are supported with experiments using both synthetic and real-world data."
Poster,Token Signature: Predicting Chain-of-Thought Gains with Token Decoding Feature in Large Language Models,https://ICML.cc//virtual/2025/poster/45104,"peijie liu, Fengli Xu, Yong Li","Chain-of-Thought (CoT) technique has proven effective in improving the performance of large language models (LLMs) on complex reasoning tasks. However, the performance gains are inconsistent across different tasks, and the underlying mechanism remains a long-standing research question. In this work, we make a preliminary observation that the monotonicity of token probability distributions may be correlated with the gains achieved through CoT reasoning. Leveraging this insight, we propose two indicators based on the token probability distribution to assess CoT effectiveness across different tasks. By combining instance-level indicators with logistic regression model, we introduce Dynamic CoT, a method that dynamically select between CoT and direct answer. Furthermore, we extend Dynamic CoT to closed-source models by transferring decision strategies learned from open-source models. Our indicators for assessing CoT effectiveness achieve an accuracy of 89.2\%, and Dynamic CoT reduces token consumption by more than 35\% while maintaining high accuracy. Overall, our work offers a novel perspective on the underlying mechanisms of CoT reasoning and provides a framework for its more efficient deployment.","Large language models (LLMs) can solve complex problems, but their ability to reason through difficult tasks isn’t always consistent. One popular technique, called Chain-of-Thought (CoT), helps improve reasoning by encouraging the model to break down its answers step by step. However, the success of this method varies across different tasks, and it's not entirely clear why it works well in some cases but not in others.In our work, we make an interesting observation: the way the model’s predictions change over time could explain when CoT is more effective. Based on this, we develop two indicators to assess how well CoT works for different tasks. To make things more efficient, we introduce a method called Dynamic CoT, which automatically chooses between using CoT or direct answer based on the task at hand.This method not only improves the model’s accuracy but also reduces its computational costs by more than 35%. Our work provides new insights into why CoT reasoning works and offers a more efficient way to apply it, helping to improve the performance of LLMs across various tasks."
Poster,TokenSwift: Lossless Acceleration of Ultra Long Sequence Generation,https://ICML.cc//virtual/2025/poster/44173,"Tong Wu, Junzhe Shen, Zixia Jia, Yuxuan Wang, Zilong Zheng","Generating ultra-long sequences with large language models (LLMs) has become increasingly crucial but remains a highly time-intensive task, particularly for sequences up to 100K tokens. While traditional speculative decoding methods exist, simply extending their generation limits fails to accelerate the process and can be detrimental. Through an in-depth analysis, we identify three major challenges hindering efficient generation: frequent model reloading, dynamic key-value (KV) management and repetitive generation. To address these issues, we introduce TokenSwift, a novel framework designed to substantially accelerate the generation process of ultra-long sequences while maintaining the target model’s inherent quality. Experimental results demonstrate that TokenSwift achieves over $3 \times$ speedup across models of varying scales (1.5B, 7B, 8B, 14B) and architectures (MHA, GQA). This acceleration translates to hours of time savings for ultra-long sequence generation, establishing TokenSwift as a scalable and effective solution at unprecedented lengths.","Generating very long outputs (up to 100K tokens) from large language models is painfully slow because current approaches frequently reload the model, inefficiently manage the growing key–value cache, and often re-compute tokens. To tackle these bottlenecks, we developed TokenSwift, a framework that keeps the model in memory, dynamically updates its key–value cache, and skips redundant token computations. By combining these optimizations, TokenSwift accelerates ultra-long sequence generation without changing the model’s predictions. In tests on models ranging from 1.5 B to 14 B parameters—including both standard multi-head attention and grouped-query attention architectures—TokenSwift consistently achieved over $3 \times$ speedups. This speed boost translates into saving hours of runtime on demanding tasks, making it practical to generate unprecedentedly long sequences in research and real-world applications."
Poster,ToMA: Token Merge with Attention for Diffusion Models,https://ICML.cc//virtual/2025/poster/46449,"Wenbo Lu, Shaoyi Zheng, Yuxuan Xia, Shenji Wan","Diffusion models excel in high-fidelity image generation but face scalability limits due to transformers’ quadratic attention complexity. Plug-and-play token reduction methods like ToMeSD and ToFu reduce FLOPs by merging redundant tokens in generated images but rely on GPU-inefficient operations (e.g., sorting, scattered writes), introducing overheads that negate theoretical speedups when paired with optimized attention implementations (e.g., FlashAttention). To bridge this gap, we propose **To**ken **M**erge with **A**ttention (ToMA), an off-the-shelf method that redesigns token reduction for GPU-aligned efficiency, with three key contributions: 1) a reformulation of token merging as a submodular optimization problem to select diverse tokens; 2) merge/unmerge as an attention-like linear transformation via GPU-friendly matrix operations; and 3) exploiting latent locality and sequential redundancy (pattern reuse) to minimize overhead. ToMA reduces SDXL/Flux generation latency by 24%/23% (DINO $\Delta <$ 0.07), outperforming prior methods. This work bridges the gap between theoretical and practical efficiency for transformers in diffusion.","AI image generators such as Stable Diffusion paint stunning pictures, but they must process thousands of tiny image pieces—called tokens—at every step. Shuffling so many tokens makes creation slow and energy-hungry. Earlier shortcuts tried to merge similar tokens, yet the extra bookkeeping erased most of the speed gains.Our work presents ToMA (Token Merge with Attention), a plug-in that lets the model spot and temporarily group tokens that carry nearly the same information. We choose these groups with a fast, easy-to-compute rule that picks a small, diverse set of “representative” tokens, then use the same GPU-friendly math the model already employs for its internal reasoning. After the heavy thinking is done, ToMA cleanly spreads the results back to every original token, so image quality stays intact.In practice, ToMA cuts the time to create a high-resolution image by roughly one-quarter on today’s hardware while keeping visual scores nearly unchanged . Faster generation means lower energy use, smoother creative workflows, and wider public access to top-tier generative art tools."
Poster,Tool Unlearning for Tool-Augmented LLMs,https://ICML.cc//virtual/2025/poster/46311,"Jiali Cheng, Hadi Amiri","Tool-augmented large language models (LLMs) may need to forget learned tools due to security concerns, privacy restrictions, or deprecated tools. However, ``tool unlearning'' has not been investigated in machine unlearning literature. We introduce this novel task, which requires addressing distinct challenges compared to traditional unlearning: knowledge removal rather than forgetting individual samples, the high cost of optimizing LLMs, and the need for principled evaluation metrics. To bridge these gaps, we propose ToolDelete , the first approach for unlearning tools from tool-augmented LLMs which implements three properties for effective tool unlearning, and a new membership inference attack (MIA) model for evaluation. Experiments on three tool learning datasets and tool-augmented LLMs show that ToolDelete effectively unlearns both randomly selected and category-specific tools, while preserving the LLM's knowledge on non-deleted tools and maintaining performance on general tasks.",We study the problem of forgetting non-trustworthy tools from LLMs that know how to use tools. We propose an effective method and compare to baselines on three benchmarks.
Poster,TopInG: Topologically Interpretable Graph Learning via Persistent Rationale Filtration,https://ICML.cc//virtual/2025/poster/43748,"Cheng Xin, Fan Xu, Xin Ding, Jie Gao, Jiaxin Ding","Graph Neural Networks (GNNs) have shown remarkable success across various scientific fields,yet their adoption in critical decision-making is often hindered by a lack of interpretability. Recently,intrinsic interpretable GNNs have been studied to provide insights into model predictions by identifying rationale substructures in graphs. However, existing methods face challenges when the underlying rationale subgraphs are complex and varied. In this work, we propose TopInG: Topologically Interpretable Graph Learning, a novel topological framework that leverages persistent homology to identify persistent rationale subgraphs. TopInG employs a rationale filtration learning approach to model an autoregressive generating process of rationale subgraphs, and introduces a self-adjusted topological constraint, termed topological discrepancy, to enforce a persistent topological distinction between rationale subgraphs and irrelevant counterparts. We provide theoretical guarantees that our loss function is uniquely optimized by the ground truth under specific conditions. Extensive experiments demonstrate TopInG's effectiveness in tackling key challenges, such as handling variform rationale subgraphs, balancing predictive performance with interpretability, and mitigating spurious correlations. Results show that our approach improves upon state-of-the-artmethods on both predictive accuracy and interpretation quality.","Powerful AI models known as Graph Neural Networks (GNNs) are increasingly used in science, but their ""black box"" nature can make them difficult to trust for critical decisions. A key challenge is explaining why a GNN makes a certain prediction, especially when the underlying reasons can have many different shapes and structures. For instance, in biology, different molecules might cause the same effect through entirely different structural components. Our work, TopInG, addresses this by teaching the AI to focus on the fundamental shape and structure of the data using a mathematical field called topology. The method learns to identify and prioritize the most important parts of a data structure, separating them from less relevant components. This process creates a clear structural gap, allowing the model to reliably distinguish between the essential ""rationale"" for a decision and the background noise.This approach leads to more trustworthy and transparent AI, allowing scientists to understand the ""why"" behind a prediction, not just the ""what"". Our experiments show that TopInG is more effective than previous methods at identifying the correct explanation, especially when dealing with complex and diverse data. This helps build more reliable AI tools for scientific discovery."
Poster,TOPLOC: A Locality Sensitive Hashing Scheme for Trustless Verifiable Inference,https://ICML.cc//virtual/2025/poster/46281,"Jack Min Ong, Matthew Di Ferrante, Aaron Pazdera, Ryan Garner, Sami Jaghouar, Manveer Basra, Max Ryabinin, Johannes Hagemann","Large language models (LLMs) have proven to be very capable, but access to frontier models currently relies on inference providers.This introduces trust challenges: how can we be sure that the provider is using the model configuration they claim?We propose TOPLOC, a novel method for verifiable inference that addresses this problem.TOPLOC leverages a compact locality-sensitive hashing mechanism for intermediate activations, which can detect unauthorized modifications to models, prompts, or precision with 100\% accuracy, achieving no false positives or negatives in our empirical evaluations.Our approach is robust across diverse hardware configurations, GPU types, and algebraic reorderings, which allows for validation speeds significantly faster than the original inference.By introducing a polynomial encoding scheme, TOPLOC minimizes the memory overhead of the generated proofs by $1000\times$, requiring only 258 bytes of storage per 32 new tokens, compared to the 262 KB requirement of storing the token embeddings directly for Llama 3.1-8B-Instruct.Our method empowers users to verify LLM inference computations efficiently, fostering greater trust and transparency in open ecosystems and laying a foundation for decentralized, verifiable and trustless AI services.","Large language models now power many chatbots and writing tools, but these models are resource intensive and are usually run by companies that can benefit from scale. This creates a basic trust problem: how can we be sure that the company used the exact model and settings they claim?Our work introduces TopLoc, an add-on to the model execution that can give users that proof.  As the model generates text, TopLoc records tiny “digital fingerprints” of its internal calculations. These fingerprints can later be verified by other providers to identify if the model or prompt has been altered. This verification can be done at a fraction of the cost of the original computation. Because the fingerprints are compact they’re also easy to share and store. With TopLoc, people and companies can trust outsourced AI services without having to take the provider’s word for it, paving the way for open, provably honest language‑model ecosystems."
Poster,Topological Signatures of Adversaries in Multimodal Alignments,https://ICML.cc//virtual/2025/poster/46109,"Minh Vu, Geigh Zollicoffer, Huy Mai, Ben Nebgen, Boian S Alexandrov, Manish Bhattarai","Multimodal Machine Learning systems, particularly those aligning text and image data like CLIP/BLIP models, have become increasingly prevalent, yet remain susceptible to adversarial attacks. While substantial research has addressed adversarial robustness in unimodal contexts, defense strategies for multimodal systems are underexplored. This work investigates the topological signatures that arise between image and text embeddings and shows how adversarial attacks disrupt their alignment, introducing distinctive signatures. We specifically leverage persistent homology and introduce two novel Topological-Contrastive losses based on Total Persistence and Multi-scale kernel methods to analyze the topological signatures introduced by adversarial perturbations. We observe a pattern of monotonic changes in the proposed topological losses emerging in a wide range of attacks on image-text alignments, as more adversarial samples are introduced in the data. By designing an algorithm to back-propagate these signatures to input samples, we are able to integrate these signatures into Maximum Mean Discrepancy tests, creating a novel class of tests that leverage topological signatures for better adversarial detection.","Multimodal machine learning systems—such as those that combine text and images (like CLIP or BLIP)—are becoming popular but remain vulnerable to deceptive (adversarial) attacks. While many studies have addressed attacks on single-mode systems (only images or only text), defending multimodal systems is less understood. This paper explores how adversarial attacks alter the relationships between image and text representations, leaving unique patterns called ""topological signatures."" Using a mathematical technique called persistent homology, we introduce new methods, based on our proposed Topological-Contrastive losses, that measure these distinctive patterns. We found that adversarial attacks consistently cause predictable changes in these topological patterns. Additionally, by tracking these signatures back to the original input data, we developed a new approach to detect adversarial samples in batch."
Poster,Topology-Aware Dynamic Reweighting for Distribution Shifts on Graph,https://ICML.cc//virtual/2025/poster/46500,"Weihuang Zheng, Jiashuo Liu, Jiaxing Li, Jiayun Wu, Peng Cui, Youyong Kong","Graph Neural Networks (GNNs) are widely used for node classification tasks but often fail to generalize when training and test nodes come from different distributions, limiting their practicality. To address this challenge, recent approaches have adopted invariant learning and sample reweighting techniques from the out-of-distribution (OOD) generalization field. However, invariant learning-based methods face difficulties when applied to graph data, as they rely on the impractical assumption of obtaining real environment labels and strict invariance, which may not hold in real-world graph structures. Moreover, current sample reweighting methods tend to overlook topological information, potentially leading to suboptimal results. In this work, we introduce the Topology-Aware Dynamic Reweighting (TAR) framework to address distribution shifts by leveraging the inherent graph structure. TAR dynamically adjusts sample weights through gradient flow on the graph edges during training. Instead of relying on strict invariance assumptions, we theoretically prove that our method is able to provide distributional robustness, thereby enhancing the out-of-distribution generalization performance on graph data. Our framework's superiority is demonstrated through standard testing on extensive node classification OOD datasets, exhibiting marked improvements over existing methods.","GNNs struggle in real-world situations because they assume the training and testing data are similar, which isn’t always true. Some existing solutions either make unrealistic assumptions about the data or ignore the graph’s structure, leading to poor performance. In this work, we proposed a Topology-Aware Dynamic Reweighting (TAR) framework, whichtackles this by focusing on the graph’s natural connections. It adjusts the importance of different data points during training by looking at how they’re linked, making the model more adaptable to changes in data patterns."
Poster,Topology-aware Neural Flux Prediction Guided by Physics,https://ICML.cc//virtual/2025/poster/46276,"Haoyang Jiang, Jindong Wang, Xingquan Zhu, Yi He","Graph Neural Networks (GNNs) often struggle in preserving high-frequency components of nodal signals when dealing with directed graphs. Such components are crucial for modeling flow dynamics, without which a traditional GNN tends to treat a graph with forward and reverse topologies equal. To make GNNs sensitive to those high-frequency components thereby being capable to capture detailed topological differences, this paper proposes a novel framework that combines 1) explicit difference matrices that model directional gradients and 2) implicit physical constraints that enforce messages passing within GNNs to be consistent with natural laws. Evaluations on two real-world directed graph data, namely, water flux network and urban traffic flow network, demonstrate the effectiveness of our proposal.","Predicting how physical quantities like energy or material flow (a.k.a. flux) behave in complex systems is critical in fields such as environmental science, fluid dynamics, and ecological engineering. Physics-based simulators, while built upon first principles, can be computationally expensive and difficult to scale or adapt to dynamic, real-time scenarios. In contrast, data-driven approaches like machine learning offer flexibility and efficiency, yet they often ignore physical constraints and may yield predictions that violate fundamental laws of physics -- for instance, erroneously predicting flux propagation from downstream to upstream, which contradicts the natural water flow direction.This paper presents a physics-guided framework that integrates graph neural networks (GNNs) with governing physical laws to improve neural flux prediction. Rather than treating GNNs as black boxes, our method encodes conservation laws directly into the message-passing process, ensuring that learned representations are physically consistent. The resultant model PhyNFP enhances directional distinguishability, exhibits robustness to abrupt perturbations, and yields physically interpretable outputs. These merits collectively lend PhyNFP a reliable and trustworthy tool for real-time forecasting and decision-making in high-stakes settings such as flood forecasting and environmental risk management."
