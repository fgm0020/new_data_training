type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,The Value of Prediction in Identifying the Worst-Off,https://ICML.cc//virtual/2025/poster/46605,"Unai Fischer Abaigar, Christoph Kern, Juan Perdomo","Machine learning is increasingly used in government programs to identify and support the most vulnerable individuals, prioritizing assistance for those at greatest risk over optimizing aggregate outcomes. This paper examines the welfare impacts of prediction in equity-driven contexts, and how they compare to other policy levers, such as expanding bureaucratic capacity. Through mathematical models and a real-world case study on long-term unemployment amongst German residents, we develop a comprehensive understanding of the relative effectiveness of prediction in surfacing the worst-off. Our findings provide clear analytical frameworks and practical, data-driven tools that empower policymakers to make principled decisions when designing these systems.","Governments are increasingly using machine learning to help people in need, for example, by predicting who is most at risk of long-term unemployment and offering them early support. But how effective are these prediction tools compared to other options, like hiring more caseworkers?In our research, we explore how well prediction-based systems actually identify and support the worst-off individuals, those who are struggling the most, rather than just improving overall program performance. We combine mathematical modeling with a real-world case study in Germany to evaluate when and how prediction can make the biggest difference.Our work shows that while machine learning can potentially help target support more effectively, its benefits depend on how it’s used and what tradeoffs are involved. In some cases, such as when resources are very limited or the prediction is already decently accurate, expanding institutional capacity may matter more. We provide clear guidelines and tools that help policymakers think through these choices and design more equitable support systems."
Poster,Thickness-aware E(3)-Equivariant 3D Mesh Neural Networks,https://ICML.cc//virtual/2025/poster/44903,"Sungwon Kim, Namkyeong Lee, Yunyoung Doh, Seungmin Shin, Guimok Cho, Seung-Won Jeon, Sangkook Kim, Chanyoung Park","Mesh-based 3D static analysis methods have recently emerged as efficient alternatives to traditional computational numerical solvers, significantly reducing computational costs and runtime for various physics-based analyses. However, these methods primarily focus on surface topology and geometry, often overlooking the inherent thickness of real-world 3D objects, which exhibits high correlations and similar behavior between opposing surfaces. This limitation arises from the disconnected nature of these surfaces and the absence of internal edge connections within the mesh.  In this work, we propose a novel framework, the Thickness-aware E(3)-Equivariant 3D Mesh Neural Network (T-EMNN), that effectively integrates the thickness of 3D objects while maintaining the computational efficiency of surface meshes. Additionally, we introduce data-driven coordinates that encode spatial information while preserving E(3)-equivariance or invariance properties, ensuring consistent and robust analysis. Evaluations on a real-world industrial dataset demonstrate the superior performance of T-EMNN in accurately predicting node-level 3D deformations, effectively capturing thickness effects while maintaining computational efficiency.","Many AI models that try to predict how 3D objects bend or change shape only focus on the surface, ignoring the object’s thickness. However, in the real world, thickness plays a major role—especially when the front and back surfaces of an object are closely related, like in plastic or metal parts. Ignoring this can lead to inaccurate predictions.We developed a new AI method that not only takes thickness into account but also follows a basic rule of geometry: if you move or rotate an object, its behavior should stay the same. This property, called equivariance, helps the AI make predictions that are more consistent and physically meaningful.Our approach runs much faster than traditional simulation tools and can still give highly accurate results. This makes it useful for industries like manufacturing, where engineers need quick and reliable ways to predict how products will perform before they are built."
Poster,Thinking LLMs: General Instruction Following with Thought Generation,https://ICML.cc//virtual/2025/poster/43495,"Tianhao Wu, Janice Lan, Weizhe Yuan, Jiantao Jiao, JASON WESTON, Sainbayar Sukhbaatar","LLMs are typically trained to answer user questions or follow instructions similarly to how human experts respond. However, in the standard alignment framework they lack the basic ability of explicit thinking before answering. Thinking is important for complex questions that require reasoning and planning -- but can be applied to *any* task. We propose a training method for equipping existing LLMs with such thinking abilities for general instruction following without use of additional human data. We achieve this by an iterative search and optimization procedure that explores the space of possible thought generations, allowing the model to learn how to think without direct supervision. For each instruction, the thought candidates are scored using a judge model to evaluate their responses only, and then optimized via preference optimization. We show that this procedure leads to superior performance on AlpacaEval and Arena-Hard, and  shows gains from thinking on  non-reasoning categories such as marketing, health and general knowledge, in addition to more traditional reasoning & problem-solving tasks.","Imagine a super-smart computer program that answers your questions, like a highly knowledgeable expert. Usually, these programs just give you an answer directly. But what if they could ""think"" things through, just like we do when faced with a tricky problem? Our research introduces a new way to teach these programs to think step-by-step before answering, even for everyday tasks, not just complex ones. We do this without needing more human help. It's like the program learns to brainstorm and refine its own ideas until it comes up with the best response. This ""thinking"" ability makes these programs much better at understanding and following instructions, leading to more accurate and helpful answers across a wide range of topics, from marketing advice to health questions and tricky puzzles."
Poster,Think Smarter not Harder: Adaptive Reasoning with Inference Aware Optimization,https://ICML.cc//virtual/2025/poster/46693,"Zishun Yu, Tengyu Xu, Di Jin, Karthik Abinav Sankararaman, Yun He, Wenxuan Zhou, Zhouhao Zeng, Eryk Helenowski, Chen Zhu, Sinong Wang, Hao Ma, Han Fang","Solving mathematics problems has been an intriguing capability of large language models, and many efforts have been made to improve reasoning by extending reasoning length, such as through self-correction and extensive long chain-of-thoughts. While promising in problem-solving, advanced long reasoning chain models exhibit an undesired single-modal behavior, where trivial questions require unnecessarily tedious long chains of thought. In this work, we propose a way to allow models to be aware of inference budgets by formulating it as utility maximization with respect to an inference budget constraint, hence naming our algorithm Inference Budget-Constrained Policy Optimization (IBPO). In a nutshell, models fine-tuned through IBPO learn to ``understand'' the difficulty of queries and allocate inference budgets to harder ones. With different inference budgets, our best models are able to have a $4.14$\% and $5.74$\% absolute improvement ($8.08$\% and $11.2$\% relative improvement) on MATH500 using $2.16$x and $4.32$x inference budgets respectively, relative to LLaMA3.1 8B Instruct. These improvements are approximately $2$x those of self-consistency under the same budgets.","Solving mathematics problems has been an intriguing capability of large language models, and many efforts have been made to improve reasoning by extending reasoning length, such as through self-correction and extensive long chain-of-thoughts. While promising in problem-solving, advanced long reasoning chain models exhibit an undesired single-modal behavior, where trivial questions require unnecessarily tedious long chains of thought. In this work, we propose a way to allow models to be aware of inference budgets by formulating it as utility maximization with respect to an inference budget constraint, hence naming our algorithm Inference Budget-Constrained Policy Optimization (IBPO). In a nutshell, models fine-tuned through IBPO learn to ``understand'' the difficulty of queries and allocate inference budgets to harder ones. With different inference budgets, our best models are able to have a $4.14$\% and $5.74$\% absolute improvement ($8.08$\% and $11.2$\% relative improvement) on MATH500 using $2.16$x and $4.32$x inference budgets respectively, relative to LLaMA3.1 8B Instruct. These improvements are approximately $2$x those of self-consistency under the same budgets."
Poster,"Think Twice, Act Once: A Co-Evolution Framework of LLM and RL for Large-Scale Decision Making",https://ICML.cc//virtual/2025/poster/43534,"Xu Wan, Wenyue Xu, Chao Yang, Mingyang Sun","Recent advancements in Large Language Models (LLMs) and Reinforcement Learning (RL) have shown significant promise in decision-making tasks. Nevertheless, for large-scale industrial decision problems, both approaches face distinct challenges: LLMs lack real-time long-sequence decision-making capabilities, while RL struggles with sample efficiency in vast action spaces. To bridge this gap, we propose **A**gents **C**o-**E**volution (ACE), a synergistic framework between LLMs and RL agent for large-scale decision-making scenarios. ACE introduces a dual-role trajectory refinement mechanism where LLMs act as both Policy Actor and Value Critic during RL's training: the Actor refines suboptimal actions via multi-step reasoning and environment validation, while the Critic performs temporal credit assignment through trajectory-level reward shaping. Concurrently, RL agent enhance LLMs' task-specific decision-making via prioritized experience replay.Through extensive experiments across multiple power grid operation challenges with action spaces exceeding 60K discrete actions, ACE demonstrates superior performance over existing RL methods and LLM-based methods.",We present a co-evolution framework where large language models and reinforcement learning agents enhance each other's capabilities to achieve efficient learning and rapid execution in large-scale decision-making.
Poster,Three-Dimensional Trajectory Prediction with 3DMoTraj Dataset,https://ICML.cc//virtual/2025/poster/44289,"Hao Zhou, Xu Yang, Mingyu Fan, Lu Qi, Xiangtai Li, Ming-Hsuan Yang, Fei Luo","With the growing interest in embodied and spatial intelligence, accurately predicting trajectories in 3D environments has become increasingly critical. However, no datasets have been explicitly designed to study 3D trajectory prediction. To this end, we contribute a 3D motion trajectory (3DMoTraj) dataset collected from unmanned underwater vehicles (UUVs) operating in oceanic environments. Mathematically, trajectory prediction becomes significantly more complex when transitioning from 2D to 3D. To tackle this challenge, we analyze the prediction complexity of 3D trajectories and propose a new method consisting of two key components: decoupled trajectory prediction and correlated trajectory refinement. The former decouples inter-axis correlations, thereby reducing prediction complexity and generating coarse predictions. The latter refines the coarse predictions by modeling their inter-axis correlations. Extensive experiments show that our method significantly improves 3D trajectory prediction accuracy and outperforms state-of-the-art methods. Both the 3DMoTraj dataset and the method are available at https://github.com/zhouhao94/3DMoTraj.","Predicting how things move in three dimensions, like underwater vehicles or aerial drones, is becoming increasingly important in fields like robotics and autonomous navigation. However, most existing research only handles 2D movement because there aren’t any public datasets specifically built for 3D trajectory prediction. To address this, we introduce a new dataset called 3DMoTraj, which captures 3D motion patterns from underwater vehicles in complex ocean environments. Predicting 3D trajectories is mathematically much harder than 2D, so we also design a new method to make it easier: first, we simplify the problem by predicting each axis (x-axis, y-axis, and z-axis) separately, and then we refine the results by considering how those axes influence each other. Our experiments show that this method outperforms existing approaches and offers a strong baseline for future research."
Poster,Tight and Fast Bounds for Multi-Label Learning,https://ICML.cc//virtual/2025/poster/43880,"Yi-Fan Zhang, Min-Ling Zhang","Commonly used evaluation metrics in multi-label learning all involve base loss functions, and the theoretical guarantees of multi-label learning often rely on the properties of base loss functions. Some recent theoretical works have used the Lipschitz continuity of base loss functions to prove the generalization bounds for multi-label learning, but the impact of the smoothness of base loss functions on the generalization bounds is completely unknown. In an attempt to make up for this gap in the generalization theory of multi-label learning, we develop some novel vector-contraction inequalities for smooth base loss functions and derive tight generalization bounds with no dependency on the number of labels, up to logarithmic terms. We then exploit local Rademacher complexity to develop some novel local vector-contraction inequalities for smooth base loss functions, which induce generalization bounds with a tighter dependency on the number of labels and a faster convergence rate with respect to the number of examples. In addition, we derive tight generalization bounds with no dependency on the number of labels, up to logarithmic terms, for Macro-Averaged AUC by exploiting the Lipschitz continuity and smoothness of base loss functions, respectively. Our state-of-the-art theoretical results provide general theoretical guarantees for the generalization of multi-label learning.","Multi-label learning is one of the most studied and important machine learning paradigms in practice, in which each object is represented by a single instance while being associated with a set of labels. Some recent theoretical works have made preliminary explorations into the generalization of multi-label learning, however, the establishment of faster convergence rates with respect to the number of examples of the generalization bounds and the impact of the smoothness of base losses on the generalization bounds remain unexplored. We deeply explore the smoothness property of base losses, and develop novel vector-contraction inequalities to induce tight bounds with no dependency on the number of labels. We further exploit local Rademacher complexity and develop novel local vector-contraction inequalities to induce bounds with no dependency on the number of labels and a faster rate with respect to the number of examples. In addition, we derive tight bounds with no dependency on the number of labels for Macro-Averaged AUC with both Lipschitz and smooth base losses. Our theoretical analysis induces tighter and faster bounds and reveals the impact of smooth base losses on the generalization."
Poster,Tightening Causal Bounds via Covariate-Aware Optimal Transport,https://ICML.cc//virtual/2025/poster/45194,"Sirui Lin, Zijun Gao, Jose Blanchet, Peter Glynn","Causal estimands can vary significantly depending on the relationship between outcomes in treatment and control groups, leading to wide partial identification (PI) intervals that impede decision making. Incorporating covariates can substantially tighten these bounds, but requires determining the range of PI over probability models consistent with the joint distributions of observed covariates and outcomes in treatment and control groups. This problem is known to be equivalent to a conditional optimal transport (COT) optimization task, which is more challenging than standard optimal transport (OT) due to the additional conditioning constraints. In this work, we study a tight relaxation of COT that effectively reduces it to standard OT, leveraging its well-established computational and theoretical foundations. Our relaxation incorporates covariate information and ensures narrower PI intervals for any value of the penalty parameter, while becoming asymptotically exact as a penalty increases to infinity. This approach preserves the benefits of covariate adjustment in PI and results in a data-driven estimator for the PI set that is easy to implement using existing OT packages. We analyze the convergence rate of our estimator and demonstrate the effectiveness of our approach through extensive simulations, highlighting its practical use and superior performance compared to existing methods.","Causal conclusions can vary a lot depending on how outcomes from treated and untreated groups relate to each other. This uncertainty results in wide ranges—called partial identification (PI) intervals—that make it hard to draw firm conclusions. However, by taking into account additional information about individuals, known as covariates, we can significantly narrow these ranges and improve the reliability of decisions.Using covariates in a statistically sound way is not straightforward. The problem turns into a complex mathematical task known as conditional optimal transport (COT), which is much harder to solve than the standard tools researchers typically use.In this work, we introduce a simpler and more practical method that approximates this difficult problem using well-known tools from optimal transport. Our method still uses covariate information, provides tighter and more useful results, and becomes nearly exact as a tuning parameter increases. It’s also easy to apply using existing software. We prove that our method works well in theory and show through simulations that it outperforms current approaches."
Poster,Tilted Sharpness-Aware Minimization,https://ICML.cc//virtual/2025/poster/44711,"Tian Li, Tianyi Zhou, Jeff Bilmes","Sharpness-Aware Minimization (SAM) has been demonstrated to improve the generalization performance of overparameterized models by seeking flat minima on the loss landscape through optimizing model parameters that incur the largest loss within a neighborhood. Nevertheless, such min-max formulations are computationally challenging especially when the problem is highly non-convex. Additionally, focusing only on the worst-case local solution while ignoring potentially many other local solutions may be suboptimal when searching for flat minima. In this work, we propose Tilted SAM (TSAM), a smoothed generalization of SAM inspired by exponential tilting that effectively assigns higher priority to local solutions that incur larger losses. TSAM is parameterized by a tilt hyperparameter $t$ and reduces to SAM as $t$ approaches infinity. We show that TSAM is smoother than SAM and thus easier to optimize, and it explicitly favors flatter minima. We develop algorithms motivated by the discretization of Hamiltonian dynamics to solve TSAM. Empirically, TSAM arrives at flatter local minima and results in superior test performance than the baselines of SAM and ERM across a range of image and text tasks.","Sharpness-Aware Minimization (SAM) is a technique that improves the performance of deep learning models by finding ""flat"" areas on the loss landscape---regions where small changes to the model parameters don't dramatically increase the loss. However, SAM can be computationally challenging because it focuses only on the worst-case scenarios in a small neighborhood of parameters, making optimization difficult, especially when the model's loss landscape is complex.We introduce a new approach called Tilted SAM (TSAM), inspired by a method called ""exponential tilting."" TSAM smooths out the optimization by assigning greater importance to areas with higher losses, rather than just focusing on the absolute worst-case. This makes it easier to find flatter minima, potentially improving model performance and making optimization smoother and less challenging. We develop new algorithms to efficiently solve TSAM and demonstrate that it achieves better results than standard SAM and its variants in various image and text tasks."
Poster,Time-Aware World Model for Adaptive Prediction and Control,https://ICML.cc//virtual/2025/poster/44469,"Anh Nhu, Sanghyun Son, Ming Lin","In this work, we introduce the Time-Aware World Model (TAWM), a model-based approach that explicitly incorporates temporal dynamics. By conditioning on the time-step size, $\Delta t$, and training over a diverse range of $\Delta t$ values – rather than sampling at a fixed time-step – TAWM learns both high- and low-frequency task dynamics across diverse control problems. Grounded in the information-theoretic insight that the optimal sampling rate depends on a system’s underlying dynamics, this time-aware formulation improves both performance and data efficiency. Empirical evaluations show that TAWM consistently outperforms conventional models across varying observation rates in a variety of control tasks, using the same number of training samples and iterations. Our code can be found online at: github.com/anh-nn01/Time-Aware-World-Model.","“World models” are an emerging class of machine learning algorithms that learn how the world changes over time, essentially modeling how actions lead to different outcomes. They serve as an internal simulation of the world, enabling AI systems to plan and solve complex tasks, much like how humans rely on physical intuition and experience to drive, cook, or navigate.To learn world models, AI systems collect observations from the surrounding environment, similar to how we humans learn from experience. However, current methods typically train these models using a single, fixed observation rate, learning how things evolve at only a single, small time scale. It’s like trying to predict the road ahead every second during a calm drive: when little changes, this becomes redundant and inefficient.We rethink how to train world models: instead of using one fixed observation rate, we train them across a wide range of observation rates, which we call Time-Aware World Models (TAWM). This simple change allows the model to learn both fast and slow dynamics more effectively in a single training run. With our time-aware approach, AI systems learn how the world evolves across multiple time scales, boosting success rates and performance on various complex control tasks — all without requiring additional data or resources. As a result, our method enables more efficient training, reduces energy and computing costs, and supports greener AI. Our findings can enable more robust, efficient AI systems across different domains, from simulation and physical AI research to autonomous driving and industrial autonomous systems."
