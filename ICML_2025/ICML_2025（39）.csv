type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Bongard in Wonderland: Visual Puzzles that Still Make AI Go Mad?,https://ICML.cc//virtual/2025/poster/45299,"Antonia Wüst, Tim Woydt, Lukas Helff, Inga Ibs, Wolfgang Stammer, Devendra Dhami, Constantin Rothkopf, Kristian Kersting","Recently, newly developed Vision-Language Models (VLMs), such as OpenAI's o1, have emerged, seemingly demonstrating advanced reasoning capabilities across text and image modalities. However, the depth of these advances in language-guided perception and abstract reasoning remains underexplored, and it is unclear whether these models can truly live up to their ambitious promises. To assess the progress and identify shortcomings, we enter the wonderland of Bongard problems, a set of classic visual reasoning puzzles that require human-like abilities of pattern recognition and abstract reasoning. With our extensive evaluation setup, we show that while VLMs occasionally succeed in identifying discriminative concepts and solving some of the problems, they frequently falter. Surprisingly, even elementary concepts that may seem trivial to humans, such as simple spirals, pose significant challenges. Moreover, when explicitly asked to recognize ground truth concepts, they continue to falter, suggesting not only a lack of understanding of these elementary visual concepts but also an inability to generalize to unseen concepts. We compare the results of VLMs to human performance and observe that a significant gap remains between human visual reasoning capabilities and machine cognition.","New AI systems called Vision-Language Models (VLMs), like OpenAI’s o1, are designed to understand and reason about both pictures and text. These models are impressive on the surface, but it's still unclear how well they truly ""understand"" what they see.To test their abilities, we used a set of tricky visual puzzles known as Bongard problems. These puzzles challenge the kind of pattern recognition and abstract thinking that humans are naturally good at.Our tests revealed that while these AI models can sometimes spot key patterns and solve a few puzzles, they often struggle, especially with concepts that seem simple to people, like recognizing a spiral. Even when we clearly told the models what they were supposed to look for, they still had trouble.We also compared their performance to how humans do on the same tasks. The results showed a big gap: human thinking and visual understanding are still far ahead of what these AI systems can do."
Poster,BOOD: Boundary-based Out-Of-Distribution Data Generation,https://ICML.cc//virtual/2025/poster/44166,"Qilin Liao, Shuo Yang, Bo Zhao, Ping Luo, Hengshuang Zhao","Harnessing the power of diffusion models to synthesize auxiliary training data based on latent space features has proven effective in enhancing out-of-distribution (OOD) detection performance. However, extracting effective features outside the in-distribution (ID) boundary in latent space remains challenging due to the difficulty of identifying decision boundaries between classes. This paper proposes a novel framework called Boundary-based Out-Of-Distribution data generation (BOOD), which synthesizes high-quality OOD features and generates human-compatible outlier images using diffusion models. BOOD first learns a text-conditioned latent feature space from the ID dataset, selects ID features closest to the decision boundary, and perturbs them to cross the decision boundary to form OOD features. These synthetic OOD features are then decoded into images in pixel space by a diffusion model. Compared to previous works, BOOD provides a more training efficient strategy for synthesizing informative OOD features, facilitating clearer distinctions between ID and OOD data. Extensive experimental results on common benchmarks demonstrate that BOOD surpasses the state-of-the-art method significantly, achieving a 29.64\% decrease in average FPR95 (40.31\% vs. 10.67\%) and a 7.27\% improvement in average AUROC (90.15\% vs. 97.42\%) on the Cifar-100 dataset.","In real-world scenarios, machine learning models often encounter unfamiliar inputs — things they weren’t trained to recognize — which can lead to incorrect or untrustworthy predictions. Identifying these unfamiliar inputs, known as Out-Of-Distribution (OOD) data, is essential for building reliable AI systems.Our work introduces a new method called BOOD that uses advanced image generation tools, known as diffusion models, to create realistic examples of unfamiliar data. These examples are carefully designed to distributed just outside the boundary of original input training data, helping the system learn to spot the difference between known and unknown inputs more effectively.By generating helpful OOD examples and training with them, our approach significantly improves the model’s ability to detect unusual or harmful inputs, while still maintaining strong performance on familiar tasks. Tests on widely used datasets show that BOOD outperforms existing methods by a large margin."
Poster,Boost-and-Skip: A Simple Guidance-Free Diffusion for Minority Generation,https://ICML.cc//virtual/2025/poster/45743,"Soobin Um, Beomsu Kim, Jong Chul YE","Minority samples are underrepresented instances located in low-density regions of a data manifold, and are valuable in many generative AI applications, such as data augmentation, creative content generation, etc. Unfortunately, existing diffusion-based minority generators often rely on computationally expensive guidance dedicated for minority generation. To address this, here we present a simple yet powerful guidance-free approach called *Boost-and-Skip* for generating minority samples using diffusion models. The key advantage of our framework requires only two minimal changes to standard generative processes: (i) variance-boosted initialization and (ii) timestep skipping. We highlight that these seemingly-trivial modifications are supported by solid theoretical and empirical evidence, thereby effectively promoting emergence of underrepresented minority features. Our comprehensive experiments demonstrate that Boost-and-Skip greatly enhances the capability of generating minority samples, even rivaling guidance-based state-of-the-art approaches while requiring significantly fewer computations. Code is available at https://github.com/soobin-um/BnS.","In many AI applications—like creating new content or improving data variety—it’s important to generate rare or unusual examples, also called minority samples. These are hard to find because they don’t appear often in training data. Current methods that generate these rare samples using AI (specifically, a type called diffusion models) usually need a lot of extra computing power.This research introduces a new and much simpler way to generate these rare examples, called Boost-and-Skip. The method only needs two small tweaks to the usual process:- Start with more randomness (variance) to explore a wider range of possibilities.- Skip some steps in the generation process to speed things up and better capture rare features.Even though these changes sound small, they are backed by strong evidence and work surprisingly well. Experiments show that Boost-and-Skip can generate rare samples just as well as more complex and resource-heavy methods, but with much less computing power."
Poster,Boosting Adversarial Robustness with CLAT: Criticality Leveraged Adversarial Training,https://ICML.cc//virtual/2025/poster/44154,"Bhavna Gopal, Huanrui Yang, Jingyang Zhang, Mark Horton, Yiran Chen","Adversarial training (AT) enhances neural network robustness. Typically, AT updates all trainable parameters, but can lead to overfitting and increased errors on clean data. Research suggests that fine-tuning specific parameters may be more effective; however, methods for identifying these essential parameters and establishing effective optimization objectives remain inadequately addressed. We present CLAT, an innovative adversarial fine-tuning algorithm that mitigates adversarial overfitting by integrating ""criticality"" into the training process. Instead of tuning the entire model, CLAT identifies and fine-tunes fewer parameters in robustness-critical layers—those predominantly learning non-robust features—while keeping the rest of the model fixed. Additionally, CLAT employs a dynamic layer selection process that adapts to changes in layer criticality during training. Empirical results demonstrate that CLAT can be seamlessly integrated with existing adversarial training methods, enhancing clean accuracy and adversarial robustness by over 2% compared to baseline approaches.","(1) AI models that recognize images can be fooled by small changes that are imperceptible to the human eye—known as adversarial attacks—which cause them to make incorrect predictions. Vision Transformers (models for vision classification tasks), are especially vulnerable to these attacks. (2) We developed a method that strengthens these models by training only the parts that matter most, making them harder to fool while keeping their performance high. (3) This will help improve the reliability of AI vision systems by making them more resilient to attacks, enabling safer deployment in real-world settings."
Poster,Boosting Masked ECG-Text Auto-Encoders as Discriminative Learners,https://ICML.cc//virtual/2025/poster/44157,"Hung Manh Pham, Aaqib Saeed, Dong Ma","The accurate interpretation of Electrocardiogram (ECG) signals is pivotal for diagnosing cardiovascular diseases. Integrating ECG signals with accompanying textual reports further holds immense potential to enhance clinical diagnostics by combining physiological data and qualitative insights. However, this integration faces significant challenges due to inherent modality disparities and the scarcity of labeled data for robust cross-modal learning. To address these obstacles, we propose D-BETA, a novel framework that pre-trains ECG and text data using a contrastive masked auto-encoder architecture, uniquely combining generative and boosted discriminative capabilities for robust cross-modal representations. This is accomplished through masked modality modeling, specialized loss functions, and an improved negative sampling strategy tailored for cross-modal alignment. Extensive experiments on five public datasets across diverse downstream tasks demonstrate that D-BETA significantly outperforms existing methods, achieving an average AUC improvement of 15% in linear probing with only one percent of training data and 2% in zero-shot performance without requiring training data over state-of-the-art models. These results highlight the effectiveness of D-BETA, underscoring its potential to advance automated clinical diagnostics through multi-modal representations.","What about an ECG signal foundation model?Cardiovascular diseases are the leading cause of death worldwide, accounting for an estimated 17.9 million deaths annually, which is about 32% of all global deaths. Electrocardiograms (ECGs) play a crucial role in diagnosing these conditions, with over 300 million ECGs performed each year globally.Despite the widespread use of ECGs, there's a lack of general-purpose models that can effectively interpret ECG data across diverse populations and conditions. Our work presents D-BETA, a novel approach that learns directly from both ECG signals and their corresponding textual reports simultaneously, without requiring exact manual labels. D-BETA not only captures subtle details in each type of data but also learns how they connect, helping it make a better foundation model with more accurate decisions. Across comprehensive evaluation, D-BETA consistently outperforms strong baselines on 100+ cardiac conditions, offering a scalable, self-supervised path toward accurate, label-efficient heart health AI worldwide."
Poster,Boosting Multi-Domain Fine-Tuning of Large Language Models through Evolving Interactions between Samples,https://ICML.cc//virtual/2025/poster/45212,"Xize Liang, Lin Yang, Jie Wang, Yiyang Lu, Runyu Wu, Hanzhu Chen, Jianye Hao","The multi-domain fine-tuning of large language models (LLMs) confronts a notorious trade-off among abilities across domains. Existing studies attribute this trade-off to the conflicts between samples rooted in inherent semantics. Recent approaches attempt to mitigate these conflicts through the empirical investigation or heuristic strategies. However, without a fundamental understanding of interactions between samples, they yield only marginal improvements, while incurring substantial trial-and-error costs. To address this challenge, we move beyond empirical studies by modeling interactions between samples as their influence on each other's loss, estimated using gradients. Intriguingly, we find that these interactions **evolve throughout training** rather than being purely determined by inherent semantics. Building on this insight, we propose **EV**olving **I**nteraction-guided **C**urriculum (**EVIC**), which iteratively selects samples that positively influence the overall dataset for training. By dynamically adapting the training curriculum to prioritize samples that contribute the most to the model training, EVIC effectively mitigates conflicts and improves the sample efficiency. Extensive experiments on a mixed dataset covering coding, math, and general tasks with several model architectures show that EVIC significantly outperforms all baselines across diverse capabilities.","Training large language models (LLMs) on multiple domains—like math, coding, and general language—often causes a trade-off: improving in one domain can degrade performance in another. This challenge is commonly blamed on inherent semantic conflicts between training samples from different domains. Prior methods have tried to resolve this through empirical tuning or heuristics, but these strategies offer limited gains and require extensive trial-and-error. Our research introduces a new perspective by analyzing how training samples influence each other using gradient-based measurements. Surprisingly, we find that sample conflicts are not fixed by their content alone—they change over time as training progresses. Based on this insight, we propose EVIC, a method that dynamically adjusts the training process by selecting samples that are most helpful to overall model performance. This curriculum-style approach reduces harmful interference between domains and helps the model learn more effectively. Our experiments on mixed-domain datasets show that EVIC improves performance across all tasks and domains, while also requiring fewer training steps. This makes it a promising step toward more balanced and efficient multi-domain LLM training."
Poster,Boosting Protein Graph Representations through Static-Dynamic Fusion,https://ICML.cc//virtual/2025/poster/45332,"Pengkang Guo, Bruno Correia, Pierre Vandergheynst, Daniel Probst","Machine learning for protein modeling faces significant challenges due to proteins' inherently dynamic nature, yet most graph-based machine learning methods rely solely on static structural information. Recently, the growing availability of molecular dynamics trajectories provides new opportunities for understanding the dynamic behavior of proteins; however, computational methods for utilizing this dynamic information remain limited. We propose a novel graph representation that integrates both static structural information and dynamic correlations from molecular dynamics trajectories, enabling more comprehensive modeling of proteins. By applying relational graph neural networks (RGNNs) to process this heterogeneous representation, we demonstrate significant improvements over structure-based approaches across three distinct tasks: atomic adaptability prediction, binding site detection, and binding affinity prediction. Our results validate that combining static and dynamic information provides complementary signals for understanding protein-ligand interactions, offering new possibilities for drug design and structural biology applications.","Proteins are essential molecules in living organisms that constantly move and often change shape to perform their functions, like enzymes breaking down food or motor proteins moving materials within cells. Most current artificial intelligence methods for studying proteins only look at their static 3D structures — like taking a single photograph of a dancer instead of watching the entire performance.We developed a new framework that combines both the static structure of proteins with information about how they move over time, captured through computer simulations called molecular dynamics. Think of it as creating a movie of protein motion rather than just a snapshot. Our approach creates a new way to represent this combined information, then uses specialized AI models called relational graph neural networks to process it.We tested our framework on three important tasks: predicting how flexible different parts of proteins are, identifying where drugs might bind, and estimating how strongly drugs stick to proteins. Consistently, our method that combines structural and motion information significantly outperformed approaches using structure alone.This advance could accelerate drug discovery by helping scientists better understand how proteins work and how to design medicines that interact with them more effectively."
Poster,"Boosting Virtual Agent Learning and Reasoning: A Step-Wise, Multi-Dimensional, and Generalist Reward Model with Benchmark",https://ICML.cc//virtual/2025/poster/45451,"Bingchen Miao, Yang Wu, Minghe Gao, Qifan Yu, Wendong Bu, Wenqiao Zhang, liyunfei, Siliang Tang, Tat-Seng Chua, Juncheng Li","The development of Generalist Virtual Agents (GVAs) has shown significant promise in autonomous task execution. However, current training paradigms face critical limitations, including reliance on outcome supervision and labor-intensive human annotations. To address these challenges, we propose **Similar**, a **s**tep-w**i**se **m**ult**i**-dimensiona**l** gener**a**list **r**eward model, which offers fine-grained signals for agent training and can choose better actions for inference-time scaling. Specifically, we begin by systematically defining five dimensions for evaluating agent actions. Building on this framework, we design an MCTS-P algorithm to automatically collect and annotate step-wise, five-dimensional agent execution data. Using this data, we train **Similar** with our crafted Triple-M strategy. Furthermore, we introduce the first benchmark in the virtual agent domain for step-wise, multi-dimensional reward model training and evaluation, named ***SRM***. This benchmark consists of two components: ***SRMTrain***, which serves as the training set for **Similar**, and ***SRMEval***, a manually selected test set for evaluating the reward model. Experimental results demonstrate that **Similar**, through its step-wise, multi-dimensional assessment and synergistic gain, provides GVAs with effective intermediate signals during both training and inference-time scaling. The code is available at [https://github.com/antgroup/Similar](https://github.com/antgroup/Similar).","Teaching AI assistants to perform digital tasks—like using websites or apps—is challenging because current methods only tell them whether they ultimately succeed or fail. This is inefficient, as assistants receive no feedback on *individual actions* (e.g., clicking a button or typing text). Without knowing *why* an action helps or hinders progress, learning becomes slow and struggles with complex tasks.To solve this, we built ""Similar"": an AI system that automatically evaluates every step an assistant takes using five intuitive criteria—whether the action **helps** complete the task, **is likely to succeed**, **saves time**, **relates to the goal**, and **makes logical sense**. We designed a smart algorithm (MCTS-P) to generate this feedback across web/mobile/desktop environments, avoiding costly human labeling. Surprisingly, this granular guidance boosts task success rates by up to 29.9% during training and 25.9% during real-world use.We further created the first benchmark (SRM) to evaluate such feedback systems. Our approach enables more reliable AI assistants that better understand complex digital tasks—paving the way for smarter tools that navigate computers as humans do."
Poster,Bootstrapping Self-Improvement of Language Model Programs for Zero-Shot Schema Matching,https://ICML.cc//virtual/2025/poster/44668,"Nabeel Seedat, Mihaela van der Schaar","Schema matching -- the task of finding matches between attributes across disparate data sources with different tables and hierarchies -- is critical for creating interoperable machine learning (ML)-ready data. Addressing this fundamental data-centric problem has wide implications, especially in domains like healthcare, finance and e-commerce --- but also has the potential to benefit ML models more generally, by increasing the data available for ML model training. However, schema matching is a challenging ML task due to structural/hierarchical and semantic heterogeneity between different schemas. Previous ML approaches to automate schema matching have either required significant labeled data for model training, which is often unrealistic or suffer from poor zero-shot performance. To this end, we propose Matchmaker -  a compositional language model program for schema matching, comprised of candidate generation, refinement and confidence scoring. Matchmaker also self-improves in a zero-shot manner without the need for labeled demonstrations via a novel optimization approach, which constructs synthetic in-context demonstrations to guide the language model's reasoning process.  Empirically, we demonstrate on real-world medical schema matching benchmarks that Matchmaker outperforms previous ML-based approaches, highlighting its potential to accelerate data integration and interoperability of ML-ready data.","Machine learning models need large, unified datasets to work well, but in reality, data often comes from many different sources with incompatible formats. This leads to a fundamental data interoperability challenge. This data mismatch forces researchers to either manually connect these data pieces (which took experts 500 hours for just one medical database) or use smaller, incomplete datasets that limit their models' potential. We propose Matchmaker, a self-improving LLM system that automatically finds these connections between different data formats. Unlike previous approaches that simply compare names for similarity, Matchmaker uses a multi-step reasoning process: it generates potential matches using both semantic similarity and logical reasoning, refines these candidates, and assigns confidence scores to each match. Crucially, it can also recognize when no good match exists. The system even improves itself by learning from its own successful examples, without needing human-labeled training data. When tested on complex medical databases, Matchmaker outperformed existing methods by 20%, making it significantly faster and more accurate to combine data from different sources. This could accelerate medical research, business analytics, and any field where combining diverse datasets is essential for building better AI systems."
Poster,BOPO: Neural Combinatorial Optimization via Best-anchored and Objective-guided Preference Optimization,https://ICML.cc//virtual/2025/poster/45892,"Zijun Liao, Jinbiao Chen, Debing Wang, Zizhen Zhang, Jiahai Wang","Neural Combinatorial Optimization (NCO) has emerged as a promising approach for NP-hard problems. However, prevailing RL-based methods suffer from low sample efficiency due to sparse rewards and underused solutions. We propose *Best-anchored and Objective-guided Preference Optimization (BOPO)*, a training paradigm that leverages solution preferences via objective values. It introduces: (1) a best-anchored preference pair construction for better explore and exploit solutions, and (2) an objective-guided pairwise loss function that adaptively scales gradients via objective differences, removing reliance on reward models or reference policies. Experiments on Job-shop Scheduling Problem (JSP), Traveling Salesman Problem (TSP), and Flexible Job-shop Scheduling Problem (FJSP) show BOPO outperforms state-of-the-art neural methods, reducing optimality gaps impressively with efficient inference. BOPO is architecture-agnostic, enabling seamless integration with existing NCO models, and establishes preference optimization as a principled framework for combinatorial optimization.","Complex planning tasks, like scheduling factory machines or mapping delivery routes, are incredibly hard and often take too long to solve perfectly. These challenges slow down businesses and waste resources. We created a new method called BOPO to tackle this. It teaches computers to compare different plans, learn from the best ones, and fine-tune solutions based on how good they are. Unlike older methods, BOPO works efficiently without needing extra complex systems. Our approach delivers faster, better plans for tasks like factory scheduling or city-to-city travel, outperforming other advanced tools. By sharing BOPO, we’re helping businesses save time and resources while making planning easier and more effective."
