type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Improving Compositional Generation with Diffusion Models Using Lift Scores,https://ICML.cc//virtual/2025/poster/44926,"Chenning Yu, Sicun Gao","We introduce a novel resampling criterion using lift scores, for improving compositional generation in diffusion models. By leveraging the lift scores, we evaluate whether generated samples align with each single condition and then compose the results to determine whether the composed prompt is satisfied. Our key insight is that lift scores can be efficiently approximated using only the original diffusion model, requiring no additional training or external modules. We develop an optimized variant that achieves relatively lower computational overhead during inference while maintaining effectiveness. Through extensive experiments, we demonstrate that lift scores significantly improved the condition alignment for compositional generation across 2D synthetic data, CLEVR position tasks, and text-to-image synthesis. Our code is available at github.com/rainorangelemon/complift.","Modern AI image generation tools can create pictures based on written prompts like “an elephant with glasses.” But when these prompts include multiple conditions — especially when combining them — the results often miss important details.We developed a method to better check whether each part of a prompt is actually being followed. Think of it like a checklist that evaluates if the final image matches each condition before saying the whole prompt is satisfied. Our method uses a simple trick called “lift scores” that can work directly with existing models — no retraining or extra tools needed.We also made an efficient version that works faster without losing accuracy. In experiments ranging from simple shapes to complex scenes and real images, our method showed clear improvements in following the prompt correctly.This could help make AI-generated content more accurate, controllable, and reliable — especially when combining multiple ideas into one request."
Poster,Improving Consistency Models with Generator-Augmented Flows,https://ICML.cc//virtual/2025/poster/45833,"Thibaut Issenhuth, Sangchul Lee, Ludovic Dos Santos, Jean-Yves Franceschi, Chansoo Kim, alain rakotomamonjy","Consistency models imitate the multi-step sampling of score-based diffusion in a single forward pass of a neural network.They can be learned in two ways: consistency distillation and consistency training. The former relies on the true velocity field of the corresponding differential equation, approximated by a pre-trained neural network.In contrast, the latter uses a single-sample Monte Carlo estimate of this velocity field.The related estimation error induces a discrepancy between consistency distillation and training that, we show, still holds in the continuous-time limit.To alleviate this issue, we propose a novel flow that transports noisy data towards their corresponding outputs derived from a consistency model.We prove that this flow reduces the previously identified discrepancy and the noise-data transport cost.Consequently, our method not only accelerates consistency training convergence but also enhances its overall performance. The code is available at https://github.com/thibautissenhuth/consistency_GC.","Most image generation models work by gradually turning random noise into a clear image, a process that can be slow and resource-intensive. To speed this up, methods like Consistency Models (CMs) have been developed. These neural network-based models can generate images in just one step instead of many. There are two ways to train CMs: (i) by imitating an already trained diffusion model, or (ii) by training from scratch without using such a pre-trained model. The second method is attractive because it doesn’t require an existing model. The question we address is whether these two training methods are equivalent, and we provide a negative answer. Indeed, when a CM is trained from scratch, we prove mathematically that an extra term affects the model, making it different from the first method. To alleviate the effect of this term, we introduce a simple solution called Generator-Augmented Flows. This method feeds the model’s own predictions back into its training process.As a result, Generator-Augmented Flows help the model learn faster while generating better images. These findings show how important it is to design training methods that reduce randomness during the training of CMs."
Poster,Improving Continual Learning Performance and Efficiency with Auxiliary Classifiers,https://ICML.cc//virtual/2025/poster/43813,"Filip Szatkowski, Yaoyue Zheng, Fei Yang, Tomasz Trzcinski, Bartłomiej Twardowski, Joost van de Weijer","Continual learning is crucial for applying machine learning in challenging, dynamic, and often resource-constrained environments. However, catastrophic forgetting — overwriting previously learned knowledge when new information is acquired — remains a major challenge. In this work, we examine the intermediate representations in neural network layers during continual learning and find that such representations are less prone to forgetting, highlighting their potential to accelerate computation. Motivated by these findings, we propose to use auxiliary classifiers~(ACs) to enhance performance and demonstrate that integrating ACs into various continual learning methods consistently improves accuracy across diverse evaluation settings, yielding an average 10\% relative gain. We also leverage the ACs to reduce the average cost of the inference by 10-60\% without compromising accuracy, enabling the model to return the predictions before computing all the layers. Our approach provides a scalable and efficient solution for continual learning.","Standard machine learning models often suffer from *catastrophic forgetting*, where learning new data causes them to forget what they’ve previously learned. Continual learning aims to address this by enabling models to learn incrementally, without retraining from scratch.In this work, we propose a simple and effective way to improve continual learning by adding small *auxiliary classifiers*~(ACs) to intermediate layers of the network. These classifiers operate on earlier features, which we demonstrate are more stable and less prone to forgetting.Integrating ACs improves accuracy across a broad range of continual learning methods, yielding an average 10% relative gain. Surprisingly, on older data, intermediate classifiers often outperform the final classifier. They also enable early exits, allowing the model to make predictions without using all the layers, which can reduce the inference costs by up to 60% without compromising the accuracy.Our approach is architecture-agnostic, easy to implement, and improves both performance and efficiency, making continual learning more practical and reliable in real-world settings"
Poster,"Improving Diversity in Language Models: When Temperature Fails, Change the Loss",https://ICML.cc//virtual/2025/poster/45259,"Alexandre Verine, Florian Le Bronnec, Kunhao Zheng, Alexandre Allauzen, yann CHEVALEYRE, benjamin negrevergne","Increasing diversity in language models is a challenging yet essential objective. A common approach is to raise the decoding temperature. In this work, we investigate this approach through a simplistic yet common case to provide insights into why decreasing temperature can improve quality (Precision), while increasing it often fails to boost coverage (Recall). Our analysis reveals that for a model to be effectively tunable through temperature adjustments, it must be trained toward coverage. To address this, we propose rethinking loss functions in language models by leveraging the Precision-Recall framework. Our results demonstrate that this approach achieves a substantially better trade-off between Precision and Recall than merely combining negative log-likelihood training with temperature scaling. These findings offer a pathway toward more versatile and robust language modeling techniques.","Making language models more diverse in what they generate is important but not easy. A popular way to do this is by increasing the “temperature” during decoding, which is meant to make outputs more varied. In this study, we look closely at this method using a simple example to understand why lowering the temperature can improve output quality, but raising it often doesn’t help with generating more diverse content. We find that for temperature changes to work well, the model must first be trained to focus on covering a wide range of possibilities. To do this, we suggest a new way to train language models using a framework that balances quality and coverage. Our experiments show that this new approach works better than the usual method of just adjusting temperature after training. This could help build language models that are both more accurate and more flexible."
Poster,Improving Flow Matching by Aligning Flow Divergence,https://ICML.cc//virtual/2025/poster/45878,"Yuhao Huang, Taos Transue, Shih-Hsin Wang, William Feldman, Hong Zhang, Bao Wang","Conditional flow matching (CFM) stands out as an efficient, simulation-free approach for training flow-based generative models, achieving remarkable performance for data generation. However, CFM is insufficient to ensure accuracy in learning probability paths. In this paper, we introduce a new partial differential equation characterization for the error between the learned and exact probability paths, along with its solution. We show that the total variation between probability paths is bounded above by a combination of the CFM loss and an associated divergence loss. This theoretical insight leads to the design of a new objective function that simultaneously matches the flow and its divergence. Our new approach improves the performance of the flow-based generative model by a noticeable margin without significantly raising the computational cost. We showcase the advantages of this enhanced training approach over CFM on several important benchmark tasks, including generative modeling for dynamical systems, DNA sequences, and videos.","Flow-based generative models are powerful tools for producing complex data such as images, DNA sequences, and videos. A recent method called Conditional Flow Matching (CFM) has improved training efficiency by directly matching learned and exact vector fields, avoiding costly simulations. However, CFM alone can struggle to accurately capture how probabilities evolve over time, which can reduce the reliability of the generated results.In our research, we developed a new mathematical framework that precisely characterizes the error between the learned and true probability flows. We showed that this error depends not only on the original CFM loss but also on a previously overlooked factor: a mismatch in the divergence of the flow fields.Motivated by this insight, we designed a new training objective that matches both the flow and its divergence. This simple yet impactful modification leads to significantly better performance across several challenging tasks, including modeling dynamical systems, DNA sequences, and videos.Our approach retains the speed and scalability of CFM while improving accuracy and reliability, making it a practical and effective upgrade for real-world generative modeling applications."
Poster,Improving Generalization in Federated Learning with Highly Heterogeneous Data via Momentum-Based Stochastic Controlled Weight Averaging,https://ICML.cc//virtual/2025/poster/45760,"Junkang Liu, Yuanyuan Liu, Fanhua Shang, Hongying Liu, Jin Liu, Wei Feng","For federated learning (FL) algorithms such as FedSAM, their generalization capability is crucial for real-word applications. In this paper, we revisit the generalization problem in FL and investigate the impact of data heterogeneity on FL generalization. We find that FedSAM usually performs worse than FedAvg in the case of highly heterogeneous data, and thus propose a novel and effective federated learning algorithm with Stochastic Weight Averaging (called \texttt{FedSWA}), which aims to find flatter minima in the setting of highly heterogeneous data. Moreover, we introduce a new momentum-based stochastic controlled weight averaging FL algorithm (\texttt{FedMoSWA}), which is designed to better align local and global models.  Theoretically, we provide both convergence analysis and generalization bounds for \texttt{FedSWA} and \texttt{FedMoSWA}. We also prove that the optimization and generalization errors of \texttt{FedMoSWA} are smaller than those of their counterparts, including FedSAM and its variants. Empirically, experimental results on CIFAR10/100 and Tiny ImageNet demonstrate the superiority of the proposed algorithms compared to their counterparts.","(1) Problem: Federated learning (FL) is a powerful method for training machine learning models across multiple devices without sharing data, but it struggles with data heterogeneity, leading to poor generalization.(2) Solution: We propose two new algorithms, FedSWA and FedMoSWA, which use Stochastic Weight Averaging and momentum-based techniques to find flatter minima in the loss landscape, improving generalization in highly heterogeneous data settings.(3) Impact: Our methods enhance the practical applicability of FL by improving model performance and reducing the impact of data heterogeneity, making federated learning more effective in real-world applications like healthcare and finance."
Poster,Improving Generalization with Flat Hilbert Bayesian Inference,https://ICML.cc//virtual/2025/poster/43972,"Tuan Truong, Quyen Tran, Ngoc Quan Pham, Nhat Ho, Dinh Phung, Trung Le","We introduce Flat Hilbert Bayesian Inference (FHBI), an algorithm designed to enhance generalization in Bayesian inference. Our approach involves an iterative two-step procedure with an adversarial functional perturbation step and a functional descent step within the reproducing kernel Hilbert spaces. This methodology is supported by a theoretical analysis that extends previous findings on generalization ability from finite-dimensional Euclidean spaces to infinite-dimensional functional spaces. To evaluate the effectiveness of FHBI, we conduct comprehensive comparisons against nine baseline methods on the VTAB-1K benchmark, which encompasses 19 diverse datasets across various domains with diverse semantics. Empirical results demonstrate that FHBI consistently outperforms the baselines by notable margins, highlighting its practical efficacy.","Approximate Bayesian Inference techniques have been known to be effective for machine learning models to deal with uncertainty by approximating an unknown target distribution. In our research, we explore ways to improve the generalization ability of the Bayesian Inference models. To achieve this, we incorporate a technique called sharpness-aware minimization (SAM) into Bayesian Inference. SAM focuses on finding model settings that are less sensitive to small changes, leading to more reliable predictions. However, applying SAM directly to each model particle didn't yield significant improvements for the ensemble.To address this, we developed a novel theoretical framework that formulates the *sharpness on the functional spaces*. Then, we applied this framework to monitor the sharpness of the *transportation functions* which govern the motion of the model particles. By monitoring and controlling this sharpness of the movements, we not only improved each model's ability to generalize but also enhanced the diversity of the model particles, hence yielding a better approximation of the target distribution and enhancing the generalization ability of the final ensemble.We tested our approach on the VTAB-1K benchmark, which includes 19 diverse datasets from various fields like natural images, medical imaging, and simulated environments. Our method showed both theoretical and practical improvements, indicating its potential for enhancing machine learning predictions across different domains."
Poster,Improving LLM Safety Alignment with Dual-Objective Optimization,https://ICML.cc//virtual/2025/poster/45626,"Xuandong Zhao, Will Cai, Tianneng Shi, David Huang, Licong Lin, Song Mei, Dawn Song","Existing training-time safety alignment techniques for large language models (LLMs) remain vulnerable to jailbreak attacks. Direct preference optimization (DPO), a widely deployed alignment method, exhibits limitations in both experimental and theoretical contexts as its loss function proves suboptimal for refusal learning. Through gradient-based analysis, we identify these shortcomings and propose an improved safety alignment that disentangles DPO objectives into two components: (1) robust refusal training, which encourages refusal even when partial unsafe generations are produced, and (2) targeted unlearning of harmful knowledge. This approach significantly increases LLM robustness against a wide range of jailbreak attacks, including prefilling, suffix, and multi-turn attacks across both in-distribution and out-of-distribution scenarios. Furthermore, we introduce a method to emphasize critical refusal tokens by incorporating a reward-based token-level weighting mechanism for refusal learning, which further improves the robustness against adversarial exploits. Our research also suggests that robustness to jailbreak attacks is correlated with token distribution shifts in the training process and internal representations of refusal and harmful tokens, offering valuable directions for future research in LLM safety alignment. The code is available at https://github.com/wicai24/DOOR-Alignment.","Large language models (LLMs) can be tricked into generating harmful content through ""jailbreak"" attacks, and current safety methods aren't always effective. This research introduces a new training technique called Dual-Objective Optimization for Refusal (DOOR). DOOR improves LLM safety by focusing on two key areas:* **Robust Refusal Training**: Teaching the model to consistently refuse unsafe requests, even if it initially starts generating problematic content. * **Targeted Unlearning**: Actively removing or suppressing harmful knowledge within the model. An enhanced version, W-DOOR, further refines this by emphasizing critical ""refusal"" words (like ""Sorry"") during training, making the model quicker to identify and reject harmful prompts. Experiments show that DOOR and W-DOOR significantly boost an LLM's defenses against various jailbreak attacks. [cite: 4, 26, 27] This is achieved while maintaining the model's general usefulness and without causing it to refuse safe requests too often. [cite: 200] The findings aim to help develop safer and more trustworthy AI systems."
Poster,Improving LLMs for Recommendation with Out-Of-Vocabulary Tokens,https://ICML.cc//virtual/2025/poster/44677,"Ting-Ji Huang, Jia-Qi Yang, Chunxu Shen, Kai-Qi Liu, De-Chuan Zhan, Han-Jia Ye","Characterizing users and items through vector representations is crucial for various tasks in recommender systems. Recent approaches attempt to apply Large Language Models (LLMs) in recommendation through a question\&answer format, where real items (eg, Item No.2024) are represented with compound words formed from in-vocabulary tokens (eg, ``item``, ``20``, ``24``). However, these tokens are not suitable for representing items, as their meanings are shaped by pre-training on natural language tasks, limiting the model's ability to capture user-item relationships effectively. In this paper, we explore how to effectively characterize users and items in LLM-based recommender systems from the token construction view. We demonstrate the necessity of using out-of-vocabulary (OOV) tokens for the characterization of items and users, and propose a well-constructed way of these OOV tokens. By clustering the learned representations from historical user-item interactions, we make the representations of user/item combinations share the same OOV tokens if they have similar properties. This construction allows us to capture user/item relationships well (memorization) and preserve the diversity of descriptions of users and items (diversity). Furthermore, integrating these OOV tokens into the LLM’s vocabulary allows for better distinction between users and items and enhanced capture of user-item relationships during fine-tuning on downstream tasks. Our proposed framework outperforms existing state-of-the-art methods across various downstream recommendation tasks.","Recommender systems — like those behind Netflix suggestions or Amazon product recommendations — rely on understanding both users and items in a meaningful way. A recent trend is to use powerful language models (similar to ChatGPT) for these systems. However, these models are trained on regular language and don’t naturally understand things like “Item 2024” in the way a recommender system needs.This paper addresses that challenge by rethinking how users and items are represented inside language models. Instead of forcing items into combinations of existing words (like breaking “Item 2024” into “item”, “20”, and “24”),  we introduce custom tokens — called out-of-vocabulary (OOV) tokens — to better represent users and items. By carefully designing and adding these new tokens into the model’s vocabulary, the system becomes better at understanding the relationships between users and items."
Poster,Improving LLM Video Understanding with 16 Frames Per Second,https://ICML.cc//virtual/2025/poster/46540,"Yixuan Li, Changli Tang, Jimin Zhuang, Yudong Yang, Guangzhi Sun, Wei Li, Zejun MA, Chao Zhang","Human vision is dynamic and continuous. However, in video understanding with multimodal large language models (LLMs), existing methods primarily rely on static features extracted from images sampled at a fixed low frame rate of frame-per-second (FPS) $\leqslant$2, leading to critical visual information loss. In this paper, we introduce F-16, the first multimodal LLM designed for high-frame-rate video understanding. By increasing the frame rate to 16 FPS and compressing visual tokens within each 1-second clip, F-16 efficiently captures dynamic visual features while preserving key semantic information.Experimental results demonstrate that higher frame rates considerably enhance video understanding across multiple benchmarks, providing a new approach to improving video LLMs beyond scaling model size or training data. F-16 achieves state-of-the-art performance among 7-billion-parameter video LLMs on both general and fine-grained video understanding benchmarks, such as Video-MME and TemporalBench. Furthermore, F-16 excels in complex spatiotemporal tasks, including high-speed sports analysis (*e.g.*, basketball, football, gymnastics, and diving), outperforming SOTA proprietary visual models like GPT-4o and Gemini-1.5-pro.Additionally, we introduce a novel decoding method for F-16 that enables highly efficient low-frame-rate inference without requiring model retraining. We will release the source code, model checkpoints, and data at [https://github.com/bytedance/F-16](https://github.com/bytedance/F-16).","Human vision naturally processes continuous motion, but most AI video models only analyze a few still frames per second, missing important visual details. To address this, we developed F-16, a new AI model that can understand videos at a much higher frame rate—16 frames per second. F-16 compresses visual information from each second of video, allowing it to capture motion and key details more effectively without needing much more computing power. Tests show that F-16 performs better than previous models on various video understanding tasks, including general and detailed benchmarks, as well as complex activities like sports. It even beats leading commercial models like GPT-4o and Gemini 1.5 Pro in analyzing fast-paced sports like basketball and diving."
