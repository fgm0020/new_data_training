type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,High Dynamic Range Novel View Synthesis with Single Exposure,https://ICML.cc//virtual/2025/poster/44362,"Kaixuan Zhang, HuWang, Minxian Li, Mingwu Ren, Mao Ye, Xiatian Zhu","High Dynamic Range Novel View Synthesis (HDR-NVS) aims to establish a 3D scene HDR model from Low Dynamic Range (LDR) imagery. Typically, multiple-exposure LDR images are employed to capture a wider range of brightness levels in a scene, as a single LDR image cannot represent both the brightest and darkest regions simultaneously. While effective, this multiple-exposure HDR-NVS approach has significant limitations, including susceptibility to motion artifacts (e.g., ghosting and blurring), high capture and storage costs.To overcome these challenges, we introduce, for the first time, the  single-exposure HDR-NVS problem, where only single exposure LDR images are available during training. We further introduce a novel approach, Mono-HDR-3D, featuring two dedicated modules formulated by the LDR image formation principles, one for converting LDR colors to HDR counterparts, and the other for transforming HDR images to LDR format so that unsupervised learning is enabled in a closed loop. Designed as a meta-algorithm, our approach can be seamlessly integrated with existing NVS models. Extensive experiments show that Mono-HDR-3D significantly outperforms previous methods.Source code is released at https://github.com/prinasi/Mono-HDR-3D.","This paper introduces a new way to create high-quality 3D images with rich lighting details using ordinary photographs. Traditional methods require taking multiple photos of the same scene at different brightness levels (like adjusting your phone camera’s settings for dark and bright areas) to capture both shadows and highlights. However, this approach often leads to blurry or ghost-like artifacts when objects move between shots, and it demands more storage and effort.Our solution, called Mono-HDR-3D, eliminates these issues by working with just a single photo per viewpoint. Imagine taking one snapshot in a dimly lit room and still capturing all the details—from the glowing lamp to the darkest corners—without any extra steps. We achieve this through two smart tools: one enhances colors to mimic high-dynamic-range effects, while the other cross-checks results by converting them back to normal photo quality. This self-correcting loop ensures accuracy without needing special equipment.Unlike previous techniques, our method integrates seamlessly with existing 3D reconstruction methods and produces sharper, more realistic results. Experiments show it outperforms existing approaches, making advanced 3D imaging more accessible for applications like virtual reality, robotics, or even everyday photography where lighting conditions are challenging."
Poster,High-Fidelity Simultaneous Speech-To-Speech Translation,https://ICML.cc//virtual/2025/poster/44512,"Tom Labiausse, Laurent Mazaré, Edouard Grave, Alexandre Défossez, Neil Zeghidour","We introduce Hibiki, a decoder-only model for simultaneous speech translation. Hibiki leverages a multistream language model to synchronously process source and target speech, and jointly produces text and audio tokens to perform speech-to-text and speech-to-speech translation. We furthermore address the fundamental challenge of simultaneous interpretation, which unlike its consecutive counterpart --where one waits for the end of the source utterance to start translating-- adapts its flow to accumulate just enough context to produce a correct translation in real-time, chunk by chunk. To do so, we introduce a weakly-supervised method that leverages the perplexity of an off-the-shelf text translation system to identify optimal delays on a per-word basis and create aligned synthetic data. After supervised training, Hibiki performs adaptive, simultaneous speech translation with vanilla temperature sampling. On a French-English simultaneous speech translation task, Hibiki demonstrates state-of-the-art performance in translation quality, speaker fidelity and naturalness. Moreover, the simplicity of its inference process makes it compatible with batched translation and even real-time on-device deployment. We provide examples on *huggingface.co/spaces/kyutai/hibiki-samples* as well as models and inference code at *github.com/kyutai-labs/hibiki*.","Most speech translation systems today work after a person has finished speaking, which is too slow for real-time conversations. Simultaneous translation --where the system starts translating while the speaker is still talking-- is much harder. It requires smart, split-second decisions about when to translate, how much to wait, and how to keep the translated voice natural and expressive. Until now, machines have struggled to match the performance of human interpreters in this setting. We created Hibiki, a powerful yet simple system that can simultaneously listen and speak. It learns to balance waiting and translating in real time and generates both written and spoken translations. We also developed techniques to train it using synthetic data that sounds natural and stays aligned with the original speaker’s voice and rhythm. Hibiki outperforms past systems in accuracy, speaker similarity, and naturalness, and is the first model to come close to professional human interpretation. It makes real-time, human-like translation more accessible as it can even run on a smartphone. We’re sharing our code, models, and a large dataset to help others build on this progress and bring high-fidelity cross-language communication to more people."
Poster,Highly Compressed Tokenizer Can Generate Without Training,https://ICML.cc//virtual/2025/poster/43881,"Lukas Lao Beyer, Tianhong Li, Xinlei Chen, Sertac Karaman, Kaiming He","Commonly used image tokenizers produce a 2D grid of spatially arranged tokens. In contrast, so-called *1D* image tokenizers represent images as highly compressed one-dimensional sequences of as few as 32 discrete tokens. We find that the high degree of compression achieved by a 1D tokenizer with vector quantization enables image editing and generative capabilities through heuristic manipulation of tokens, demonstrating that even very crude manipulations -- such as copying and replacing tokens between latent representations of images -- enable fine-grained image editing by transferring appearance and semantic attributes. Motivated by the expressivity of the 1D tokenizer's latent space, we construct an image generation pipeline leveraging gradient-based test-time optimization of tokens with plug-and-play loss functions such as reconstruction or CLIP similarity. Our approach is demonstrated for inpainting and text-guided image editing use cases, and can generate diverse and realistic samples without requiring training of any generative model.","Generating realistic images with AI is difficult because images contain hundreds of thousands of pixels with complex relationships. To make this easier, the image generation task is typically split into two steps: first ""compress"" the image into a smaller set of meaningful pieces called ""tokens,"" then learn how these tokens relate to each other.Recent advances have created extremely efficient compression methods that can represent an entire image using just 32 small integers. We discovered that these compressed representations actually capture surprisingly rich information about what's in the image that humans can understand.More importantly, we found that you can edit images by simply manipulating these 32 tokens directly -- no complex AI training required. Furthermore, we show that this enables users to define any custom goal or ""objective function"" for how they want their image to look, and our system can achieve it in just a few seconds without needing to train new models. Our examples demonstrate this approach for various image tasks like text-guided editing, filling in missing parts, and generating new images from text descriptions."
Poster,High Probability Bound for Cross-Learning Contextual Bandits with Unknown Context Distributions,https://ICML.cc//virtual/2025/poster/43891,"Ruiyuan Huang, Zengfeng Huang","Motivated by applications in online bidding and sleeping bandits, we examine the problem of contextual bandits with cross learning, where the learner observes the loss associated with the action across all possible contexts, not just the current round’s context. Our focus is on a setting where losses are chosen adversarially, and contexts are sampled i.i.d. from a specific distribution. This problem was first studied by Balseiro et al. (2019), who proposed an algorithm that achieves near-optimal regret under the assumption that the context distribution is known in advance. However, this assumption is often unrealistic. To address this issue, Schneider & Zimmert (2023) recently proposed a new algorithm that achieves nearly optimal expected regret. It is well-known that expected regret can be significantly weaker than high-probability bounds. In this paper, we present a novel, in-depth analysis of their algorithm and demonstrate that it actually achieves near-optimal regret with high probability. There are steps in the original analysis by Schneider & Zimmert (2023) that lead only to an expected bound by nature. In our analysis, we introduce several new insights. Specifically, we make extensive use of the weak dependency structure between different epochs, which was overlooked in previous analyses. Additionally, standard martingale inequalities are not directly applicable, so we refine martingale inequalities to complete our analysis.",Contextual bandits are widely used in today's industry. Assuming we can see the feedback across different contexts introduces new challenges. We analyze an algorithm for this setting and show that its performance has high-probability assurance. High-probability assurance is critical for a robust algorithm.
Poster,Hi-Patch: Hierarchical Patch GNN for Irregular Multivariate Time Series,https://ICML.cc//virtual/2025/poster/44115,"Yicheng Luo, Bowen Zhang, Zhen Liu, Qianli Ma","Multi-scale information is crucial for multivariate time series modeling. However, most existing time series multi-scale analysis methods treat all variables in the same manner, making them unsuitable for Irregular Multivariate Time Series (IMTS), where variables have distinct origin scales/sampling rates. To fill this gap, we propose Hi-Patch, a hierarchical patch graph network. Hi-Patch encodes each observation as a node, represents and captures local temporal and inter-variable dependencies of densely sampled variables through an intra-patch graph layer, and obtains patch-level nodes through aggregation. These nodes are then updated and re-aggregated through a stack of inter-patch graph layers, where several scale-specific graph networks progressively extract more global temporal and inter-variable features of both sparsely and densely sampled variables under specific scales. The output of the last layer is fed into task-specific decoders to adapt to different downstream tasks. Experiments on 8 datasets demonstrate that Hi-Patch outperforms state-of-the-art models in IMTS forecasting and classification tasks.","In many fields like healthcare or environmental monitoring, data is collected over time at different speeds—for example, heart rate every second vs. lab results once a day. Most AI models struggle with this kind of irregular data. We introduce Hi-Patch, a new method that respects these differences. It groups data into small units and uses a layered graph approach to find both local and global patterns, even when variables are sampled unevenly. Hi-Patch outperforms leading models on eight real-world datasets, improving forecasting and classification in complex time-based data."
Poster,HiRemate: Hierarchical Approach for Efficient Re-materialization of Neural Networks,https://ICML.cc//virtual/2025/poster/43866,"Julia Gusak, Xunyi Zhao, Théotime Le Hellard, Zhe LI, Lionel Eyraud-Dubois, Olivier Beaumont","Training deep neural networks (DNNs) on memory-limited GPUs is challenging,  as storing intermediate activations often exceeds available memory. Re-materialization, a technique that preserves exact computations, addresses this by selectively recomputing activations instead of storing them. However, existing methods either fail to scale, lack generality, or introduce excessive execution overhead. We introduce ${\mbox{HiRemate}}$ a ${\textit hierarchical}$ re-materialization framework that recursively partitions  large computation graphs, applies optimized solvers at multiple levels, and merges solutions into a global efficient training schedule. This enables scalability to significantly larger graphs than prior ILP-based methods while keeping runtime overhead low. Designed for single-GPU models and activation re-materialization, HiRemate extends  the feasibility of training networks with thousands of graph nodes, surpassing  prior methods in both efficiency and scalability. Experiments on various types of networks yield up to 50-70%  memory reduction with only 10-15% overhead, closely matching optimal solutions while significantly reducing solver time. Seamlessly integrating with PyTorch Autograd, HiRemate requires almost no  code change to use,  enabling broad adoption in memory-constrained deep learning.","Training deep neural networks requires storing many intermediate results during the forward pass so they can be reused during backpropagation. Although the model’s weights may fit on a single GPU, the total memory needed for training can exceed the device’s capacity, largely due to the size of these intermediate values. One way to reduce memory usage is through re-materialization, which selectively recomputes some of them instead of storing everything. However, for large models, deciding what to recompute is a challenging problem.We introduce HiRemate, a framework that tackles this problem in a hierarchical manner. The computation graph of the neural network is first divided into parts small enough to make the problem easy to solve. Thanks to our algorithm, these partial solutions are then merged—several times if necessary—until we obtain a complete solution for the entire graph. HiRemate is designed for models whose weights fit in GPU memory and focuses on reducing activation memory during training. It also supports re-materialization strategies from the literature, making it easy to combine different methods within a single framework.We tested HiRemate on a range of common neural networks and consistently saw large memory savings with only a small increase in training time. This makes it easier to train modern deep learning models on limited hardware."
Poster,Hi Robot: Open-Ended Instruction Following with Hierarchical Vision-Language-Action Models,https://ICML.cc//virtual/2025/poster/44202,"Lucy Xiaoyang Shi, brian ichter, Michael Equi, Liyiming Ke, Karl Pertsch, Quan Vuong, James Tanner, Anna Walling, Haohuan Wang, Niccolo Fusai, Adrian Li, Danny Driess, Lachy Groom, Sergey Levine, Chelsea Finn","Generalist robots that can perform a range of different tasks in open-world settings must be able to not only reason about the steps needed to accomplish their goals, but also process complex instructions, prompts, and even feedback during task execution. Intricate instructions (e.g., ""Could you make me a vegetarian sandwich?"" or ""I don't like that one"") require not just the ability to physically perform the individual steps, but the ability to situate complex commands and feedback in the physical world. In this work, we describe a system that uses vision-language models in a hierarchical structure, first reasoning over complex prompts and user feedback to deduce the most appropriate next step to fulfill the task, and then performing that step with low-level actions. In contrast to direct instruction following methods that can fulfill simple commands (""pick up the cup""), our system can reason through complex prompts and incorporate situated feedback during task execution (""that's not trash""). We evaluate our system across three robotic platforms, including single-arm, dual-arm, and dual-arm mobile robots, demonstrating its ability to handle tasks such as cleaning messy tables, making sandwiches, and grocery shopping.Videos are available at https://www.pi.website/research/hirobot","Imagine teaching a robot to cook a new dish by having it talk through each step the same way you do with that little voice in your head. Our “Hi Robot” system gives machines two modes: a fast, instinctive layer that handles familiar actions like picking up objects, and a slower, thoughtful layer that breaks complicated requests—like “make me a sandwich without tomatoes” or “only pick up the trash, not the dishes”—into simple steps. The thoughtful layer literally “whispers” instructions to the fast layer, guiding the robot through the task and adapting if you say things like “that’s not trash.” We trained the robot by generating lots of example conversations between people and robots, so it learned to understand and respond to complex prompts and mid-task corrections. On real-world chores—like bussing tables, making sandwiches, and shopping for groceries—Hi Robot followed instructions far more accurately than previous methods, showing that giving robots an inner voice and the ability to think through problems makes them much more flexible and reliable in everyday settings."
Poster,History-Guided Video Diffusion,https://ICML.cc//virtual/2025/poster/44316,"Kiwhan Song, Boyuan Chen, Max Simchowitz, Yilun Du, Russ Tedrake, Vincent Sitzmann","Classifier-free guidance (CFG) is a key technique for improving conditional generation in diffusion models, enabling more accurate control while enhancing sample quality. It is natural to extend this technique to video diffusion, which generates video conditioned on a variable number of context frames,  collectively referred to as history. However, we find two key challenges to guiding with variable-length history: architectures that only support fixed-size conditioning, and the empirical observation that CFG-style history dropout performs poorly.  To address this, we propose the Diffusion Forcing Transformer (DFoT), a video diffusion architecture and theoretically grounded training objective that jointly enable conditioning on a flexible number of history frames. We then introduce History Guidance, a family of guidance methods uniquely enabled by DFoT. We show that its simplest form, vanilla history guidance, already significantly improves video generation quality and temporal consistency. A more advanced method, history guidance across time and frequency further enhances motion dynamics, enables compositional generalization to out-of-distribution history, and can stably roll out extremely long videos. Project website: [https://boyuan.space/history-guidance](https://boyuan.space/history-guidance)","Creating high-quality, long, and realistic videos with AI is an exciting area of research, but current AI models often fall short. They typically generate only short videos and struggle to keep objects and scenes consistent over time.Our paper tackles this challenge by introducing a new approach that enables AI models to better use information from any point in a video’s past, known as its “history.” This improved handling of history brings two main benefits. First, by more effectively remembering past content, our model produces videos that are more realistic, dynamic, and consistent. Second, by continually connecting past frames to newly generated ones, our method can create extremely long videos—something that was not possible with previous techniques.We have open-sourced our method, called the Diffusion Forcing Transformer and History Guidance, making it easy for others to apply it to larger AI models. We hope this will help unlock new applications in areas such as media production and robotics, while also advancing the capabilities of AI video generation."
Poster,Holistic Physics Solver: Learning PDEs in a Unified Spectral-Physical Space,https://ICML.cc//virtual/2025/poster/44074,"Xihang Yue, Yi Yang, Linchao Zhu","Recent advances in operator learning have produced two distinct approaches for solving partial differential equations (PDEs): attention-based methods offering point-level adaptability but lacking spectral constraints, and spectral-based methods providing domain-level continuity priors but limited in local flexibility. This dichotomy has hindered the development of PDE solvers with both strong flexibility and generalization capability. This work introduces Holistic Physics Mixer (HPM), a novel framework that bridges this gap by integrating spectral and physical information in a unified space. HPM unifies both approaches as special cases while enabling more powerful spectral-physical interactions beyond either method alone. This enables HPM to inherit both the strong generalization of spectral methods and the flexibility of attention mechanisms while avoiding their respective limitations. Through extensive experiments across diverse PDE problems, we demonstrate that HPM consistently outperforms state-of-the-art methods in both accuracy and computational efficiency, while maintaining strong generalization capabilities with limited training data and excellent zero-shot performance on unseen resolutions.","Scientists and engineers often need to solve complex equations, known as PDEs, to predict things like fluid flow or structural stress. Current AI methods struggle here: some capture the big picture but miss fine details, while others excel at specifics but aren't always reliable with new scenarios or limited data.We developed the Holistic Physics Mixer (HPM), an AI framework that overcomes this challenge. It learns by processing information in a special ""holistic spectral space,"" where these global and local perspectives are intelligently blended.HPM significantly surpasses existing methods in accuracy and efficiency. It consistently makes accurate predictions even with sparse training data and adapts well to new conditions, such as varying levels of discretization."
Poster,Homophily Enhanced Graph Domain Adaptation,https://ICML.cc//virtual/2025/poster/45180,"Ruiyi Fang, Bingheng Li, Jingyu Zhao, Ruizhi Pu, QIUHAO Zeng, Gezheng Xu, Charles X. Ling, Boyu Wang","Graph Domain Adaptation (GDA) transfers knowledge from labeled source graphs to unlabeled target graphs, addressing the challenge of label scarcity. In this paper, we highlight the significance of graph homophily, a pivotal factor for graph domain alignment, which, however, has long been overlooked in existing approaches. Specifically, our analysis first reveals that homophily discrepancies exist in benchmarks. Moreover, we also show that homophily discrepancies degrade GDA performance from both empirical and theoretical aspects, which further underscores the importance of homophily alignment in GDA. Inspired by this finding, we propose a novel homophily alignment algorithm that employs mixed filters to smooth graph signals, thereby effectively capturing and mitigating homophily discrepancies between graphs. Experimental results on a variety of benchmarks verify the effectiveness of our method.","Graphs are powerful ways to represent complex relationships, like how people interact on social networks or how information flows across the internet. In many real-world situations, useful information (like labels or categories) exists for one graph but not for another. Graph Domain Adaptation (GDA) helps transfer this knowledge from one graph to another, saving time and resources.In our research, we discovered that a key factor called homophily—the tendency for connected nodes to be similar is often different between graphs, and this mismatch can hurt GDA's performance. Surprisingly, this issue has largely been ignored until now.We studied how these differences affect results and found that aligning this similarity across graphs can make a big difference. We developed a new method to smooth out these differences and improve how well knowledge transfers between graphs. Our approach works well across various datasets, showing promise for improving learning from graph data in many applications, from recommendation systems to social networks."
