type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Taming Diffusion for Dataset Distillation with High Representativeness,https://ICML.cc//virtual/2025/poster/45402,"Lin Zhao, Yushu Wu, Xinru Jiang, Jianyang Gu, Yanzhi Wang, Xiaolin Xu, Pu Zhao, Xue Lin","Recent deep learning models demand larger datasets, driving the need for dataset distillation to create compact, cost-efficient datasets while maintaining performance. Due to the powerful image generation capability of diffusion, it has been introduced to this field for generating distilled images. In this paper, we systematically investigate issues present in current diffusion-based dataset distillation methods, including inaccurate distribution matching, distribution deviation with random noise, and separate sampling. Building on this, we propose D$^3$HR, a novel diffusion-based framework to generate distilled datasets with high representativeness. Specifically, we adopt DDIM inversion to map the latents of the full dataset from a low-normality latent domain to a high-normality Gaussian domain, preserving information and ensuring structural consistency to generate representative latents for the distilled dataset. Furthermore, we propose an efficient sampling scheme to better align the representative latents with the high-normality Gaussian distribution. Our comprehensive experiments demonstrate that D$^3$HR can achieve higher accuracy across different model architectures compared with state-of-the-art baselines in dataset distillation. Source code: https://github.com/lin-zhao-resoLve/D3HR.","How can training efficiency, in terms of both time and memory, be improved through data reduction? Many researchers have explored this question by generating a small subset to replace the full training dataset. The key challenge lies in ensuring that this generated subset accurately approximates the distribution of the full dataset.Our paper aims to address this challenge by leveraging the generative capabilities of large models, inspired by several prior works. We conduct a systematic analysis of existing large model based methods and suggest that the key to improving performance lies in finding a simpler distribution for approximation. Motivated by this insight, we propose an efficient method for constructing a simpler distribution that better approximates the original distribution of the full dataset.Our method achieves the best performance across datasets of four different scales. To facilitate future research, we open-source the generated small datasets and code, aiming to support the community in enhancing training efficiency or developing more effective dataset compression methods under this new paradigm."
Poster,Taming Knowledge Conflicts in Language Models,https://ICML.cc//virtual/2025/poster/46677,"Gaotang Li, Yuzhong Chen, Hanghang Tong","Language Models (LMs) often encounter knowledge conflicts when parametric memory contradicts contextual knowledge. Previous works attribute this conflict to the interplay between ""memory heads"" and ""context heads"", attention heads assumed to promote either memory or context exclusively. In this study, we go beyond this fundamental assumption by uncovering a critical phenomenon we term the *superposition of contextual information and parametric memory*, where highly influential attention heads simultaneously contribute to both memory and context. Building upon this insight, we propose Just Run Twice (JuICE), a test-time attention intervention method that steers LMs toward either parametric beliefs or contextual knowledge without requiring fine-tuning. JuICE identifies a set of reliable attention heads and leverages a dual-run approach to mitigate the superposition effects. Extensive experiments across 11 datasets and 6 model architectures demonstrate that JuICE sets the new state-of-the-art performance and robust generalization, achieving significant and consistent improvement across different domains under various conflict types. Finally, we theoretically analyze knowledge conflict and the superposition of contextual information and parametric memory in attention heads, which further elucidates the effectiveness of JuICE in these settings. Our code is available at https://github.com/GaotangLi/JUICE.","Language models frequently encounter ""knowledge conflicts,"" where their pre-trained knowledge contradicts the information provided by specific contexts. These conflicts often arise in context-dependent systems, such as retrieval-augmented generation and tools integrated with language models. But what exactly happens inside the model during these conflicts? Can we find solutions by examining the model’s internal mechanisms?Our research uncovers an unexpected phenomenon called superposition of contextual information and parametric memory, where critical components (attention heads specifically) simultaneously influence both stored knowledge and contextual information, without clearly favoring one over the other. Through rigorous empirical and theoretical studies, using carefully designed synthetic datasets, we validate the presence and implications of this superposition phenomenon. Building upon these findings, we introduce a lightweight training-free method to reliably steer language models toward using either their pre-existing knowledge or context-specific information, depending on what is required. Our detailed analysis approach provides a rigorous and unified framework for future research on knowledge conflicts. Furthermore, our insights relate to many concurrent works supporting superposition and offer an effective and practical intervention method against superposition, which could potentially benefit other tasks and help overcome a significant obstacle in the interpretability community."
Poster,Taming Rectified Flow for Inversion and Editing,https://ICML.cc//virtual/2025/poster/43737,"Jiangshan Wang, Junfu Pu, Zhongang Qi, Jiayi Guo, Yue Ma, Nisha Huang, Yuxin Chen, Xiu Li, Ying Shan","Rectified-flow-based diffusion transformers like FLUX and OpenSora have demonstrated outstanding performance in the field of image and video generation. Despite their robust generative capabilities, these models often struggle with inversion inaccuracies, which could further limit their effectiveness in downstream tasks such as image and video editing. To address this issue, we propose RF-Solver, a novel training-free sampler that effectively enhances inversion precision by mitigating the errors in the ODE-solving process of rectified flow. Specifically, we derive the exact formulation of the rectified flow ODE and apply the high-order Taylor expansion to estimate its nonlinear components, significantly enhancing the precision of ODE solutions at each timestep. Building upon RF-Solver, we further propose RF-Edit, a general feature-sharing-based framework for image and video editing. By incorporating self-attention features from the inversion process into the editing process, RF-Edit effectively preserves the structural information of the source image or video while achieving high-quality editing results. Our approach is compatible with any pre-trained rectified-flow-based models for image and video tasks, requiring no additional training or optimization. Extensive experiments across generation, inversion, and editing tasks in both image and video modalities demonstrate the superiority and versatility of our method. The source code is available at https://github.com/wangjiangshan0725/RF-Solver-Edit.","Many rectified-flow diffusion transformers can generate realistic images and videos but struggle to convert inputs back into precise latent codes, which limits editing accuracy. RF-Solver tackles this by deriving the exact rectified flow ODE and using high-order Taylor expansions to reduce ODE-solving errors at each timestep without any extra training. RF-Edit then shares self-attention features from the inversion stage into the editing stage to preserve structural details during edits. Extensive tests across generation, inversion, and editing tasks show more faithful inversions and higher-quality edits with no retraining required."
Poster,TANGO: Clustering with Typicality-Aware Nonlocal Mode-Seeking and Graph-Cut Optimization,https://ICML.cc//virtual/2025/poster/43507,"Haowen Ma, Zhiguo Long, Hua Meng","Density-based mode-seeking methods generate a density-ascending dependency from low-density points towards higher-density neighbors.Current mode-seeking methods identify modes by breaking some dependency connections, but relying heavily on local data characteristics, requiring case-by-case threshold settings or human intervention to be effective for different datasets. To address this issue, we introduce a novel concept called typicality, by exploring the locally defined dependency from a global perspective, to quantify how confident a point would be a mode. We devise an algorithm that effectively and efficiently identifies modes with the help of the global-view typicality. To implement and validate our idea, we design a clustering method called TANGO, which not only leverages typicality to detect modes, but also utilizes graph-cut with an improved path-based similarity to aggregate data into the final clusters. Moreover, this paper also provides some theoretical analysis on the proposed algorithm. Experimental results on several synthetic and extensive real-world datasets demonstrate the effectiveness and superiority of TANGO. The code is available at https://github.com/SWJTU-ML/TANGO_code.","When computers partition similar data into groups (like categorizing customer profiles or medical images), current methods can spot these groups by first finding “representatives” of groups and then putting other data into the group where the most similar representative is. They usually require manual adjustments for different data distributions, much like needing to recalibrate a machine for every product, because they only look at small, nearby details.We developed a new concept called ""typicality"" that evaluates how likely a data sample is to be a representative by analyzing both local and global patterns in the dataset. Our TANGO algorithm then uses this insight to automatically identify representatives, followed by a technique called ""graph-cut"" to group these representatives and their affiliated data into final partitions.This eliminates the need for case-by-case calibration and tests on real-world datasets show TANGO outperforms existing methods while being computationally efficient. TANGO makes partitioning data by computers more realistic and reliable for diverse applications - from spotting disease patterns in medical scans to grouping similar products in e-commerce."
Poster,Target Concrete Score Matching: A Holistic Framework for Discrete Diffusion,https://ICML.cc//virtual/2025/poster/44859,"Ruixiang Zhang, Shuangfei Zhai, Yizhe Zhang, James Thornton, Zijing Ou, Joshua M Susskind, Navdeep Jaitly","Discrete diffusion is a promising framework for modeling and generating discrete data.In this work, we present Target Concrete Score Matching (TCSM), a novel and versatile objective for training and fine-tuning discrete diffusion models.TCSM provides a general framework with broad applicability. It supports pre-training discrete diffusion models directly from data samples, and many existing discrete diffusion approaches naturally emerge as special cases of our more general TCSM framework.Furthermore, the same TCSM objective extends to post-training of discrete diffusion models, including fine-tuning using reward functions or preference data, and distillation of knowledge from pre-trained autoregressive models.These new capabilities stem from the core idea of TCSM, estimating the concrete score of the target distribution, which resides in the original (clean) data space. This allows seamless integration with reward functions and pre-trained models, which inherently only operate in the clean data space rather than the noisy intermediate spaces of diffusion processes.Our experiments on language modeling tasks demonstrate that TCSM matches or surpasses current methods. Additionally, TCSM is versatile, applicable to both pre-training and post-training scenarios, offering greater flexibility and sample efficiency.","Discrete diffusion models are a promising approach for generating structured data like text. Our research introduces a new, comprehensive framework called Target Concrete Score Matching (TCSM) for training and adapting these models. The core idea is to train the model by focusing directly on the properties of the final, high-quality data, rather than on the noisy, intermediate steps inherent to the diffusion process. This perspective provides a single, principled objective that unifies various existing methods and, more importantly, can be used for both initial pre-training and subsequent post-training and distillation. Because our method operates in the ""clean"" data space, it allows for the seamless integration of external information, such as reward functions for task optimization or user preferences for alignment—a critical capability that was challenging for previous discrete diffusion methods. Our work establishes a more versatile and efficient foundation for developing these powerful discrete diffusion models."
Poster,Targeted control of fast prototyping through domain-specific interface,https://ICML.cc//virtual/2025/poster/46378,"Yu-Zhe Shi, Mingchen Liu, Hanlu Ma, Qiao Xu, Huamin Qu, Kun He, Lecheng Ruan, Qining Wang","Industrial designers have long sought a natural and intuitive way to achieve the targeted control of prototype models---using simple natural language instructions to configure and adjust the models seamlessly according to their intentions, without relying on complex modeling commands. While Large Language Models have shown promise in this area, their potential for controlling prototype models through language remains partially underutilized. This limitation stems from gaps between designers' languages and modeling languages, including mismatch in abstraction levels, fluctuation in semantic precision, and divergence in lexical scopes. To bridge these gaps, we propose an interface architecture that serves as a medium between the two languages. Grounded in design principles derived from a systematic investigation of fast prototyping practices, we devise the interface's operational mechanism and develop an algorithm for its automated domain specification. Both machine-based evaluations and human studies on fast prototyping across various product design domains demonstrate the interface's potential to function as an auxiliary module for Large Language Models, enabling precise and effective targeted control of prototype models.","Imagine a sculptor working with clay---they can feel, shape, and instantly see their vision come to life. Product designers dream of this same fluid experience when creating digital models on computers. The problem? There's a massive communication gap. The way designers think about products---envisioning curves, textures, and functions---is completely different from the technical language computers need to build digital models. It's like trying to paint a masterpiece while speaking through a translator who only knows engineering terms. Our research tackles this challenge by developing a method that automatically creates digital interfaces acting as translators. These interfaces convert a designer's creative vision directly into the technical instructions computers need to build accurate digital models. Instead of designers struggling with complex software, they can focus on designing. The result? Designs that better capture the original creative vision. Beyond design studios, this approach of bridging communication gaps between creative and technical teams could reshape collaboration in manufacturing."
Poster,Targeted Low-rank Refinement: Enhancing Sparse Language Models with Precision,https://ICML.cc//virtual/2025/poster/45249,"Li Shen, Anke Tang, Yong Luo, Tao Sun, Han Hu, Xiaochun Cao","Pruning is a widely used technique for compressing large neural networks that eliminates weights that have minimal impact on the model's performance. Current pruning methods, exemplified by magnitude pruning, assign an importance score to each weight based on its magnitude and remove weights with scores below a certain threshold. Nonetheless, these methods often create a gap between the original dense and the pruned sparse model, potentially impairing performance. Especially when the sparsity ratio is high, the gap becomes more pronounced. To mitigate this issue, we introduce a method to bridge the gap left by pruning by utilizing a low-rank approximation of the difference between the dense and sparse matrices. Our method entails the iterative refinement of the sparse weight matrix augmented by a low-rank adjustment. This technique captures and retains the essential information often lost during pruning, thereby improving the performance of the pruned model. Furthermore, we offer a comprehensive theoretical analysis of our approach, emphasizing its convergence properties and establishing a solid basis for its efficacy. Experimental results on LLaMa models validate its effectiveness on large language models across various pruning techniques and sparsity levels. Our method shows significant improvements: at 50\% sparsity, it reduces perplexity by 53.9\% compared to conventional magnitude pruning on LLaMa-7B. Furthermore, to achieve a specific performance target, our approach enables an 8.6\% reduction in model parameters while maintaining a sparsity ratio of about 50\%.","Large language models like ChatGPT contain billions of parameters, making them powerful but computationally expensive. Researchers use ""pruning"" to remove less important connections and make models faster, but this often hurts performance significantly.We developed a method to recover the lost performance by identifying what information was removed during pruning and adding back a compressed low-rank component. Our approach works without additional training data and maintains the sparse structure needed for efficient hardware execution."
Poster,Targeted Unlearning with Single Layer Unlearning Gradient,https://ICML.cc//virtual/2025/poster/46379,"Zikui Cai, Yaoteng Tan, M. Salman Asif","Machine unlearning methods aim to remove sensitive or unwanted content from trained models, but typically demand extensive model updates at significant computational cost while potentially degrading model performance on both related and unrelated tasks. We propose Single Layer Unlearning Gradient (SLUG) as an efficient method to unlearn targeted information by updating a single critical layer using a one-time gradient computation. SLUG uses layer importance and gradient alignment metrics to identify the optimal layer for targeted information removal while preserving the model utility. We demonstrate the effectiveness of SLUG for CLIP, Stable Diffusion, and vision-language models (VLMs) in removing concrete (e.g., identities and objects) and abstract concepts (e.g., artistic styles). On the UnlearnCanvas benchmark, SLUG achieves comparable unlearning performance to existing methods while requiring significantly less computational resources. Our proposed approach offers a practical solution for targeted unlearning that is computationally efficient and precise. Our code is available at https://github.com/CSIPlab/SLUG","Modern generative models can create misinformation through celebrity impersonation, unauthorized copying of artwork, or misuse of styles. To tackle this, researchers use machine unlearning—removing certain knowledge while keeping the model's original power. However, existing methods typically need many updates and repeated calculations, which are computationally costly.We propose Single Layer Unlearning Gradient (SLUG), a highly efficient alternative. Instead of retraining the whole model, SLUG finds one key layer of model to update using a smart metric that identifies where the targeted information is stored. With just a single gradient calculation and a one-step update, SLUG removes the unwanted information while preserving the model’s ability to perform other tasks.We show that SLUG works well on popular models like CLIP and Stable Diffusion, effectively forgetting specific identities, objects, or styles with far less effort than traditional methods. Our code is publicly available at https://github.com/CSIPlab/SLUG"
Poster,TAROT: Targeted Data Selection via Optimal Transport,https://ICML.cc//virtual/2025/poster/45916,"Lan Feng, Fan Nie, Yuejiang Liu, Alexandre Alahi","We propose TAROT, a targeted data selection framework grounded in Optimal Transport theory. Previous targeted data selection methods primarily rely on influence-based greedy heuristics to enhance domain-specific performance. While effective on limited, unimodal data (i.e., data following a single pattern), these methods struggle as target data complexity increases. Specifically, in multimodal distributions, such heuristics fail to account for multiple inherent patterns, leading to suboptimal data selection. This work identifies two primary limitations: (i) the disproportionate impact of dominant feature components in high-dimensional influence estimation, and (ii) the restrictive linear additive assumptions in greedy selection strategies. To address these challenges, TAROT incorporates whitened feature distance to mitigate dominant feature bias, offering a more reliable measure of data influence. Building on this, TAROT leverages whitened feature distance to quantify and minimize the optimal transport distance between selected data and target domains. Notably, this minimization also facilitates the estimation of optimal selection ratios. We evaluate TAROT across multiple tasks, including semantic segmentation, motion prediction, and instruction tuning. Results consistently show that TAROT outperforms state-of-the-art methods, demonstrating its versatility across various deep learning tasks. Code is available at: https://github.com/vita-epfl/TAROT.","In today’s world, machine learning models are trained on enormous amounts of data. But not all data is equally useful—some examples are much more important for helping a model learn a specific task well. Our work introduces a new method called TAROT that helps choose the right data to train models more efficiently and effectively.Imagine trying to teach someone to drive in a new city. Instead of showing them every possible street from every city, it’s smarter to show them the most relevant examples that reflect the roads and conditions in that particular city. TAROT does exactly this for machine learning: it selects the most relevant examples from a large pool to match a specific target task or domain.What makes TAROT unique is that it uses a mathematical tool called “optimal transport” to better understand which data examples are most aligned with the target task. This approach avoids common pitfalls of previous methods that often missed important patterns, especially when the target data is complex.We tested TAROT on a variety of problems—from understanding images and predicting vehicle movements to fine-tuning large language models—and found that it not only improved performance but also reduced the amount of data needed. This could make machine learning more efficient, faster, and accessible to those with limited resources."
Poster,Task-Agnostic Pre-training and Task-Guided Fine-tuning for Versatile Diffusion Planner,https://ICML.cc//virtual/2025/poster/43821,"Chenyou Fan, Chenjia Bai, Zhao Shan, Haoran He, Yang Zhang, Zhen Wang","Diffusion models have demonstrated their capabilities in modeling trajectories of multi-tasks. However, existing multi-task planners or policies typically rely on task-specific demonstrations via multi-task imitation, or require task-specific reward labels to facilitate policy optimization via Reinforcement Learning (RL). They are costly due to the substantial human efforts required to collect expert data or design reward functions. To address these challenges, we aim to develop a versatile diffusion planner capable of leveraging large-scale inferior data that contains task-agnostic sub-optimal trajectories, with the ability to fast adapt to specific tasks. In this paper, we propose SODP, a two-stage framework that leverages Sub-Optimal data to learn a Diffusion Planner, which is generalizable for various downstream tasks. Specifically, in the pre-training stage, we train a foundation diffusion planner that extracts general planning capabilities by modeling the versatile distribution of multi-task trajectories, which can be sub-optimal and has wide data coverage. Then for downstream tasks, we adopt RL-based fine-tuning with task-specific rewards to quickly refine the diffusion planner, which aims to generate action sequences with higher task-specific returns. Experimental results from multi-task domains including Meta-World and Adroit demonstrate that SODP outperforms state-of-the-art methods with only a small amount of data for reward-guided fine-tuning.","Learning agents to automatically perform multiple tasks is challenging due to the high cost of collecting human demonstrations for each task or labeling existing data to distinguish between good and bad behaviors. We investigate whether a generalizable agent can be trained using low-quality trajectories without explicit labels, while still retaining the ability to adapt quickly to various downstream tasks.To address this, we develop a versatile agent based on a diffusion model, trained using a proposed two-stage training paradigm. We show that training on low-quality trajectories in the first stage can provide a broad prior over behavior patterns, even in the absence of labels, and facilitates subsequent adaptation to specific tasks in the second stage."
