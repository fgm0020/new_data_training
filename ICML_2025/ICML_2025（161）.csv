type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Learning Classifiers That Induce Markets,https://ICML.cc//virtual/2025/poster/45851,"Yonatan Sommer, Ivri Hikri, lotan amit, Nir Rosenfeld","When learning is used to inform decisions about humans, such as for loans, hiring, or admissions, this can incentivize users to strategically modify their features, at a cost, to obtain positive predictions. The common assumption is that the function governing costs is exogenous, fixed, and predetermined. We challenge this assumption, and assert that costs emerge as a *result* of deploying a classifier. Our idea is simple: when users seek positive predictions, this creates demand for important features; and if features are available for purchase, then a market will form, and competition will give rise to prices. We extend the strategic classification framework to support this notion, and study learning in a setting where a classifier can induce a market for features. We present an analysis of the learning task, devise an algorithm for computing market prices, propose a differentiable learning framework, and conduct experiments to explore our novel setting and approach.","Learning is increasingly being used to inform decisions about people—such as loan approval, hiring, or university admissions. This makes people more likely to modify their profile or update their application in a way which they believe will improve outcomes for them. A key point is that such changes are typically costly, and people will invest the time, effort, and money only if doing so is cost-effective for them. So far the assumption has been that these costs are fixed, predetermined, and known to the designer of the learning algorithm. We challenge this view: rather than assuming costs simply ""exist"", we argue that they arise as a *result* of how the system makes decisions about individuals. When this holds, the choice of decision rule can determine costs; in other words, it will *create a market*. One example is university admissions: if the importance of SAT scores in the decision rule changes (say relative to GPA scores), then this can impact the price of prep courses and private tutoring. Our paper studies learning in a setting where learned decision rules give rise to markets for the attributes that the decision rule uses. We expect prices to be high for attributes that are important, and low for those that are not. This gives the algorithm flexibility in trading-off performance and market behavior. We study such market behavior and how it interacts with learning. We also propose an algorithm for learning in a way that anticipates market formation, and demonstrate our approach on real data with simulated behavior."
Poster,Learning Compact Semantic Information for Incomplete Multi-View Missing Multi-Label Classification,https://ICML.cc//virtual/2025/poster/45273,"Jie Wen, Yadong Liu, Zhanyan Tang, Yuting He, Yulong Chen, Mu Li, Chengliang Liu","Multi-view data involves various data forms, such as multi-feature, multi-sequence and multimodal data, providing rich semantic information for downstream tasks. The inherent challenge of incomplete multi-view missing multi-label learning lies in how to effectively utilize limited supervision and insufficient data to learn discriminative representation. Starting from the sufficiency of multi-view shared information for downstream tasks, we argue that the existing contrastive learning paradigms on missing multi-view data show limited consistency representation learning ability, leading to the bottleneck in extracting multi-view shared information. In response, we propose to minimize task-independent redundant information by pursuing the maximization of cross-view mutual information. Additionally, to alleviate the hindrance caused by missing labels, we develop a dual-branch soft pseudo-label cross-imputation strategy to improve classification performance. Extensive experiments on multiple benchmarks validate our advantages and demonstrate strong compatibility with both missing and complete data.","For the task of incomplete Multi-view Multi-label Classification (iM3C), we propose a strategy to extract multi-view shared semantic information relevant to downstream tasks from multiple views while discarding redundant information. Furthermore, we employ a dual-branch architecture to generate soft pseudo-labels for alternating training, which assists the model in achieving good performance even in the presence of missing labels. Experimental results on multiple datasets demonstrate the effectiveness of the proposed method."
Poster,Learning Condensed Graph via Differentiable Atom Mapping for Reaction Yield Prediction,https://ICML.cc//virtual/2025/poster/43812,"Ankit Ghosh, Gargee Kashyap, Sarthak Mittal, Nupur Jain, Raghavan B Sunoj, Abir De","Yield of chemical reactions generally depends on the activation barrier, i.e., the energy difference between the reactant and the transition state. Computing the transition state from the reactant and product graphs requires prior knowledge of the correct node alignment (i.e., atom mapping), which is not available in yield prediction datasets.  In this work, we propose YieldNet, a neural yield prediction model, which tackles these challenges.  Here, we first  approximate the atom mapping between the reactants and products using a differentiable node alignment network. We then use this approximate atom mapping to obtain a noisy realization of the condensed graph of reaction (CGR),  which is a supergraph encompassing both the reactants and products. This CGR  serves as a surrogate for the transition state graph structure. The CGR embeddings of different steps in a multi-step reaction are then passed into a transformer-guided reaction path encoder.Our experiments  show that YieldNet can predict the yield more accurately than the baselines. Furthermore, the model is trained only under the distant supervision of yield values, without requiring fine-grained supervision of atom mapping.","Predicting the yield of a chemical reaction is a fundamental challenge in chemistry. A key determinant of yield is the transition state, a transient high-energy structure. Existing deep learning models often overlook this critical aspect as real-world datasets typically the any transition state information.To address this, we introduce YIELDNET, a neural network that first approximates atom mapping using a differentiable node alignment module, allowing it to estimate a continuous condensed graph of the reaction as a surrogate transition state. This surrogate graph is then processed by input-differentiable graph neural networks and a transformer-based reaction path encoder to predict yields across multi-step reactions. Crucially, the model is trained solely under the distant supervision of reaction yield values, without requiring ground-truth atom mappings or transition states. This enables end-to-end learning of chemically meaningful inductive bias from data alone. This work bridges a key gap between physical chemistry and machine learning, offering a practical tool for chemists to screen and optimize reactions more effectively. YIELDNET could accelerate discovery in fields ranging from pharmaceuticals to materials science by reducing the need for costly lab experimentation."
Poster,Learning Configurations for Data-Driven Multi-Objective Optimization,https://ICML.cc//virtual/2025/poster/46623,"Zhiyang Chen, Hailong Yao, Xia Yin","Multi-objective optimization problems arise widely in various fields. In practice, multi-objective optimization is generally solved by heuristics with tunable parameters that are highly application-specific. Tuning parameters based on real-world instances (a.k.a. algorithm configuration) are generally empirical without theoretical guarantees. In this work, we establish the theoretical foundation of data-driven multi-objective optimization through the lens of machine learning theory. We provide generalization guarantees on selecting parameters for multi-objective optimization algorithms based on sampled problem instances. Moreover, if the performance metric of the algorithm is the Pareto volume, we can PAC-learn the approximately optimal configuration in polynomial time. We apply our framework to various algorithms, including approximation algorithms, local search, and linear programming. Experiments on multiple problems verify our theoretical findings.","Multi-objective optimization problems arise widely in various fields. In practice, multi-objective optimization is generally solved by heuristics with tunable parameters that are highly application-specific. Tuning parameters based on real-world instances (a.k.a. algorithm configuration) are generally empirical without theoretical guarantees. In this work, we establish the theoretical foundation of data-driven multi-objective optimization through the lens of machine learning theory. We provide generalization guarantees on selecting parameters for multi-objective optimization algorithms based on sampled problem instances. Moreover, if the performance metric of the algorithm is the Pareto volume, we can PAC-learn the approximately optimal configuration in polynomial time. We apply our framework to various algorithms, including approximation algorithms, local search, and linear programming. Experiments on multiple problems verify our theoretical findings."
Poster,Learning Curves of Stochastic Gradient Descent in Kernel Regression,https://ICML.cc//virtual/2025/poster/45142,"Haihan Zhang, Weicheng Lin, Yuanshi Liu, Cong Fang","This paper considers a canonical problem in kernel regression: how good are the model performances when it is trained by the popular online first-order algorithms, compared to the offline ones, such as ridge and ridgeless regression? In this paper, we analyze the foundational single-pass Stochastic Gradient Descent (SGD) in kernel regression under source condition where the optimal predictor can even not belong to the RKHS, i.e. the model is misspecified. Specifically, we focus on the inner product kernel over the sphere and characterize the exact orders of the excess risk curves under different scales of sample sizes $n$ concerning the input dimension $d$. Surprisingly, we show that SGD achieves min-max optimal rates up to constants among all the scales, $without$ suffering the saturation, a prevalent phenomenon observed in (ridge) regression, except when the model is highly misspecified and the learning is in a final stage where $n\gg d^\gamma$ with any constant $\gamma >0$. The main reason for SGD to overcome the curse of saturation is the exponentially decaying step size schedule, a common practice in deep neural network training. As a byproduct, we provide the $first$ provable advantage of the scheme over the iterative averaging method in the common setting.","Modern machine learning often deals with very high-dimensional data—meaning each data point has many features or variables. In such situations stochastic gradient descent (SGD)—a simple yet powerful algorithm—often performs remarkably well. Our work explores a question: how effective is SGD when applied to kernel regression, a classic machine learning method, particularly when both the number of data points and the dimension grow very large? We report a surprising phenomenon: for certain moderately challenging learning problems, stochastic gradient descent (SGD) achieves optimal sample efficiency when the number of data points scales polynomially with the data dimension. Building upon this finding, we further demonstrate that SGD can outperform spectral methods, such as Kernel Ridge Regression (KRR), in simpler problem settings."
Poster,Learning curves theory for hierarchically compositional data with power-law distributed features,https://ICML.cc//virtual/2025/poster/45566,"Francesco Cagnetta, Hyunmo Kang, Matthieu Wyart","Recent theories suggest that Neural Scaling Laws arise whenever the task is linearly decomposed into units that are power-law distributed. Alternatively, scaling laws also emerge when data exhibit a hierarchically compositional structure, as is thought to occur in language and images. To unify these views, we consider classification and next-token prediction tasks based on probabilistic context-free grammars—probabilistic models that generate data via a hierarchy of production rules. For classification, we show that having power-law distributed production rules results in a power-law learning curve with an exponent depending on the rules’ distribution and a large multiplicative constant that depends on the hierarchical structure. By contrast, for next-token prediction, the distribution of production rules controls the fine details of the learning curve, but not the exponent describing the large-scale behaviour.","The performance of neural networks often improves predictably as they are trained on more data, typically following a power-law pattern. This phenomenon, known as neural scaling, has played a key role in recent advances in artificial intelligence. Yet, its underlying cause remains poorly understood.One line of thought attributes neural scaling to the uneven frequency of features in data. For example, in language, some words are far more common than others. Since frequent words appear more often during training, they are learned faster, leading to performance that scales with the distribution of feature frequencies.Another view points to the hierarchical nature of many real-world data sources, like the nested grammatical structure of sentences or the compositional layout of images. According to this view, neural networks improve as they progressively learn to reconstruct deeper levels of this hidden structure.In this paper, we bring these two ideas together using a simple, controlled model of data that mimics both the hierarchical organisation and the broad (Zipf-like) distribution of feature frequencies: Our model generates data through a hierarchy of probabilistic rules, some common, some rare.Our key finding is this: for language modelling tasks such as next-word prediction, it’s the hierarchical structure---not the frequency of individual elements---that governs how learning scales with data. This suggests that the remarkable scaling behaviour observed in large language models may originate not from surface-level statistics like word frequency, but from their ability to uncover and exploit the deep structure of language."
Poster,Learning Distances from Data with Normalizing Flows and Score Matching,https://ICML.cc//virtual/2025/poster/45225,"Peter Sorrenson, Daniel Behrend-Uriarte, Christoph Schnörr, Ullrich Koethe","Density-based distances (DBDs) provide a principled approach to metric learning by defining distances in terms of the underlying data distribution. By employing a Riemannian metric that increases in regions of low probability density, shortest paths naturally follow the data manifold. Fermat distances, a specific type of DBD, have attractive properties, but existing estimators based on nearest neighbor graphs suffer from poor convergence due to inaccurate density estimates. Moreover, graph-based methods scale poorly to high dimensions, as the proposed geodesics are often insufficiently smooth. We address these challenges in two key ways. First, we learn densities using normalizing flows. Second, we refine geodesics through relaxation, guided by a learned score model. Additionally, we introduce a dimension-adapted Fermat distance that scales intuitively to high dimensions and improves numerical stability. Our work paves the way for the practical use of density-based distances, especially in high-dimensional spaces.","One way to measure how far apart two points are is to calculate the straight-line distance between them. For certain applications, e.g., images, just interpolating a straight line between two points doesn't yield realistic results. In these cases, it makes sense to make a lot of small steps, where each step is a realistic interpolation, and stitch them together into a curved trajectory. Then we can compute the length of this trajectory, where we also weight each step by how unlikely it is, to get a realistic idea of the distance between far away points. We improve a method to compute such a distance, called the Fermat distance, by use of machine learning models called normalizing flows and score matching models. We show how we can greatly improve the accuracy of the estimated distance, even in high-dimensional spaces, where the problem becomes more difficult."
Poster,Learning Distribution-wise Control in Representation Space for Language Models,https://ICML.cc//virtual/2025/poster/46193,"Deng, Ruidi Chang, Hanjie Chen","Interventions in language models (LMs) are applied strategically to steer model behavior during the forward pass. Learnable interventions, also known as representation fine-tuning, aim to apply pointwise control within the concept subspace and have proven effective in altering high-level behaviors. In this work, we extend this approach to the distribution level, enabling the model to learn not only pointwise transformations but also the surrounding regions of the concept subspace. We demonstrate that these methods perform effectively in early layers, with larger standard deviations correlating strongly with improved performance. Across eight commonsense reasoning and seven arithmetic reasoning benchmarks, our distribution-wise interventions consistently outperform pointwise interventions in controllability and robustness. These results illustrate that distribution-wise interventions provide a more comprehensive method for steering model behavior and enabling finer-grained control over language models. The code is at: https://github.com/chili-lab/D-Intervention.","- **Problem**: Current methods for controlling AI language models work like adjusting a single point on a dial—they make precise changes but miss the surrounding area where similar beneficial effects might occur. This limits how effectively we can steer these models to behave the way we want them to.- **Solution**: We developed a new approach that works more like adjusting a region rather than a single point. Instead of making one exact change to how the AI processes information, our method learns to make small variations around that change, exploring the ""neighborhood"" of possibilities. Think of it like the difference between hitting one specific note on a piano versus playing a gentle chord that includes nearby harmonious notes.- **Impact**: Our method consistently outperformed existing techniques across 15 different reasoning tasks, showing improvements of 2-4% while using fewer computational resources. More importantly, it made AI models more robust—they maintained better performance even when faced with slightly altered or corrupted inputs. This advancement helps make AI language models more reliable and easier to control, which is crucial as these systems are increasingly used in real-world applications where consistent, predictable behavior matters."
Poster,Learning Dynamics in Continual Pre-Training for Large Language Models,https://ICML.cc//virtual/2025/poster/45051,"Xingjin Wang, Howe Tissue, Lu Wang, Linjing Li, Daniel Zeng","Continual Pre-Training (CPT) has become a popular and effective method to apply strong foundation models to specific downstream tasks. In this work, we explore the **learning dynamics** throughout the CPT process for large language models (LLMs). We specifically focus on how general and downstream domain performance evolves at each training step, with domain performance measured via validation losses. We have observed that the CPT loss curve fundamentally characterizes the transition from one curve to another hidden curve, and could be described by decoupling the effects of distribution shift and learning rate (LR) annealing. We derive a CPT scaling law that combines the two factors, enabling the prediction of loss at any (continual) training steps and across learning rate schedules (LRS) in CPT. Our formulation presents a comprehensive understanding of several critical factors in CPT, including the learning rate, the training steps, and the distribution distance between PT and CPT datasets.Moreover, our approach can be adapted to customize training hyper-parameters to different CPT goals such as balancing general and domain-specific performance.Extensive experiments demonstrate that our scaling law holds across various CPT datasets and training hyper-parameters.","Continual Pre-Training (CPT) of large language models aims to enhance their abilities in specific downstream domains (e.g. coding, finance, math) while mitigating the substantial costs associated with re-training. However, understanding how the training process progresses and how different factors influence performance remains unclear. In this work, we explore the learning dynamics throughout the CPT process. We specifically focus on how general and downstream domain performance evolves at each training step, with domain performance measured via validation losses.We have observed that the CPT loss curve fundamentally characterizes the transition from one curve to another hidden curve, and could be described by decoupling the effects of distribution shift and learning rate (LR) annealing. We propose a CPT scaling law, that captures these effects and predicts model performance at any training step and under different learning rate schedules.Our scaling law presents a comprehensive understanding of several critical factors in CPT and can be adapted to optimize training hyper-parameters for different CPT goals, such as balancing general and domain-specific performance."
Poster,Learning dynamics in linear recurrent neural networks,https://ICML.cc//virtual/2025/poster/45649,"Alexandra Proca, Clémentine Dominé, Murray Shanahan, Pedro Mediano","Recurrent neural networks (RNNs) are powerful models used widely in both machine learning and neuroscience to learn tasks with temporal dependencies and to model neural dynamics. However, despite significant advancements in the theory of RNNs, there is still limited understanding of their learning process and the impact of the temporal structure of data. Here, we bridge this gap by analyzing the learning dynamics of linear RNNs (LRNNs) analytically, enabled by a novel framework that accounts for task dynamics. Our mathematical result reveals four key properties of LRNNs: (1) Learning of data singular values is ordered by both scale and temporal precedence, such that singular values that are larger and occur later are learned faster. (2) Task dynamics impact solution stability and extrapolation ability. (3) The loss function contains an effective regularization term that incentivizes small weights and mediates a tradeoff between recurrent and feedforward computation. (4) Recurrence encourages feature learning, as shown through a novel derivation of the neural tangent kernel for finite-width LRNNs. As a final proof-of-concept, we apply our theoretical framework to explain the behavior of LRNNs performing sensory integration tasks. Our work provides a first analytical treatment of the relationship between the temporal dependencies in tasks and learning dynamics in LRNNs, building a foundation for understanding how complex dynamic behavior emerges in cognitive models.","Neural networks and brains seem to show similar behavior when performing certain tasks involving information that changes over time-- for example, predicting the landing spot of a tennis ball as it moves. How do brains and neural networks learn these tasks, and how do the types of tasks we learn affect them? In this paper, we study learning in neural networks that can solve time-dependent tasks, called recurrent neural networks (RNN).Although RNNs are generally quite complex, with a few assumptions, we derive a simple set of equations that describes the RNN's learning in terms of how well it can perform the task. By studying these equations, we find that tasks that rely on the recent past are learned faster. We can also predict how a RNN will solve a task, how well a RNN will do on a new version of a task, and how a RNN's ""connections"" will look like, depending on what it's initially trained on. Although the RNNs we study are much simpler than the brain, understanding how they learn and work can help us understand more about learning and cognition in general, some of which might apply to more complex systems. This research acts as a first stepping stone towards describing more complex settings, networks, and behavior, related to learning time-dependent tasks."
