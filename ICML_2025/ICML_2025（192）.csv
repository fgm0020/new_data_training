type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Multi-Marginal Stochastic Flow Matching for High-Dimensional Snapshot Data at Irregular Time Points,https://ICML.cc//virtual/2025/poster/44861,"Justin Lee, Behnaz Moradi-Jamei, Heman Shakeri","Modeling the evolution of high-dimensional systems from limited snapshot observations at irregular time points poses a significant challenge in quantitative biology and related fields. Traditional approaches often rely on dimensionality reduction techniques, which can oversimplify the dynamics and fail to capture critical transient behaviors in non-equilibrium systems. We present Multi-Marginal Stochastic Flow Matching (MMSFM), a novel extension of simulation-free score and flow matching methods to the multi-marginal setting, enabling the alignment of high-dimensional data measured at non-equidistant time points without reducing dimensionality. The use of measure-valued splines enhances robustness to irregular snapshot timing, and score matching prevents overfitting in high-dimensional spaces. We validate our framework on several synthetic and benchmark datasets and apply it to single-cell perturbation data from melanoma cell lines and gene expression data collected at uneven time points.","When studying how biological systems like cells respond to treatments, scientists often can only take snapshots at specific time points rather than continuously tracking individual cells. This is like having photos of a crowd at different times without knowing which person is which across photos—we can't see how individuals moved between snapshots.We developed Multi-Marginal Stochastic Flow Matching (MMSFM) to reconstruct likely trajectories from snapshot data taken at irregular time intervals. Our method first uses optimal transport to find the most efficient way to match cells between consecutive snapshots, like pairing dancers between songs. Then, we use overlapping windows of three snapshots at a time to create smooth paths connecting these matched cells, similar to drawing multiple possible routes on a map. This overlapping approach makes our method robust to measurement timing and captures the inherent randomness in biological systems.We successfully applied our method to track how melanoma cells respond to cancer drugs over time, revealing complex cellular dynamics that would otherwise remain hidden. This enables researchers to better understand drug resistance mechanisms and potentially design more effective treatments by observing cellular behavior between measurement points."
Poster,Multimodal Medical Code Tokenizer,https://ICML.cc//virtual/2025/poster/45110,"Xiaorui Su, Shvat Messica, Yepeng Huang, Ruth Johnson, Lukas Fesser, Shanghua Gao, Faryad Sahneh, Marinka Zitnik","Foundation models trained on patient electronic health records (EHRs) require tokenizing medical data into sequences of discrete vocabulary items. Existing tokenizers treat medical codes from EHRs as isolated textual tokens. However, each medical code is defined by its textual description, its position in ontological hierarchies, and its relationships to other codes, such as disease co-occurrences and drug-treatment associations. Medical vocabularies contain more than 600,000 codes with critical information for clinical reasoning.  We introduce MedTok, a multimodal medical code tokenizer that uses the text descriptions and relational context of codes. MedTok processes text using a language model encoder and encodes the relational structure with a graph encoder. It then quantizes both modalities into a unified token space, preserving modality-specific and cross-modality information.  We integrate MedTok into five EHR models and evaluate it on operational and clinical tasks across in-patient and out-patient datasets, including outcome prediction, diagnosis classification, drug recommendation, and risk stratification. Swapping standard EHR tokenizers with MedTok improves AUPRC across all EHR models, by 4.10% on MIMIC-III, 4.78% on MIMIC-IV, and 11.32% on EHRShot, with the largest gains in drug recommendation. Beyond EHR modeling, we demonstrate using MedTok tokenizer with medical QA systems. Our results demonstrate the potential of MedTok as a unified tokenizer for medical codes, improving tokenization for medical foundation models.","Despite advances in medical representation learning, a unified tokenizer that integrates textual and structured relational knowledge across coding systems remains an open challenge. We introduce MedTok , a multimodal medical code tokenizer that integrates textual descriptions and graph-based dependencies from biomedical ontologies, which can be seamlessly integrated into any model or pipeline dealing with medical codes, providing unified medical tokens for downstream tasks."
Poster,Multi-Modal Object Re-identification via Sparse Mixture-of-Experts,https://ICML.cc//virtual/2025/poster/43710,"Yingying Feng, Jie Li, Chi Xie, Lei Tan, Jiayi Ji","We present MFRNet, a novel network for multi-modal object re-identification that integrates multi-modal data features to effectively retrieve specific objects across different modalities. Current methods suffer from two principal limitations: (1) insufficient interaction between pixel-level semantic features across modalities, and (2) difficulty in balancing modality-shared and modality-specific features within a unified architecture. To address these challenges, our network introduces two core components. First, the Feature Fusion Module (FFM) enables fine-grained pixel-level feature generation and flexible cross-modal interaction. Second, the Feature Representation Module (FRM) efficiently extracts and combines modality-specific and modality-shared features, achieving strong discriminative ability with minimal parameter overhead. Extensive experiments on three challenging public datasets (RGBNT201, RGBNT100, and MSVR310) demonstrate the superiority of our approach in terms of both accuracy and efficiency, with 8.4% mAP and 6.9% accuracy improved in RGBNT201 with negligible additional parameters.","We mainly explore how to fully and efficiently utilize multispectral data to search for specific targets. Recent systems struggle because they don’t let the different kinds of pictures interact with each other enough, and they can’t decide which details are common to all images and which belong only to one type. Our new method, called MFRNet, tackles both issues. First, it blends the tiniest visual cues from the different image types so they reinforce one another. Second, it smartly keeps shared clues together while storing unique ones separately, all with almost no extra computing cost. Tests on three public datasets show MFRNet finds the right object far more accurately, up to 8 percentage points better, while staying fast and lightweight."
Poster,Multinoulli Extension: A Lossless Yet Effective Probabilistic Framework for Subset Selection over Partition Constraints,https://ICML.cc//virtual/2025/poster/46369,"Qixin Zhang, Wei Huang, Can Jin, Puning Zhao, Yao Shu, Li Shen, Dacheng Tao","Identifying the most representative subset for a close-to-submodular objective while satisfying the predefined partition constraint is a fundamental task with numerous applications in machine learning.  However, the existing  distorted local-search methods are often hindered by their prohibitive query complexities and the rigid requirement for prior knowledge of difficult-to-obtain structural parameters. To overcome these limitations, we introduce a novel algorithm titled **Multinoulli-SCG**, which not only is parameter-free, but also can achieve the same approximation guarantees as the distorted local-search methods with significantly fewer function evaluations. The core of our **Multinoulli-SCG** algorithm is an innovative continuous-relaxation framework named Multinoulli Extension(***ME***), which can effectively convert the discrete subset selection problem subject to partition constraints into a solvable continuous maximization focused on learning the optimal multinoulli priors across the considered partition. In sharp contrast with the well-established multi-linear extension for submodular subset selection, a notable advantage of our proposed ***ME*** is its intrinsic capacity to provide a lossless rounding scheme for any set function. Finally, we validate the practical efficacy of our proposed algorithms by applying them to video summarization, bayesian A-optimal design and coverage maximization.","Identifying the most representative subset for a close-to-submodular objective while satisfying the predefined partition constraint is a fundamental task with numerous applications in machine learning.  However, the existing  distorted local-search methods are often hindered by their prohibitive query complexities and the rigid requirement for prior knowledge of difficult-to-obtain structural parameters. To overcome these limitations, in this paper, we introduce a novel algorithm titled **Multinoulli-SCG**, which not only is parameter-free, but also can achieve the same approximation guarantees as the distorted local-search methods with significantly fewer function evaluations.  More specifically, when the objective function is monotone $\alpha$-weakly DR-submodular or $(\gamma,\beta)$-weakly submodular, our Multinoulli-SCG algorithm can attain a value of   $(1-e^{-\alpha})\text{OPT}-\epsilon$ or $(\frac{\gamma^{2}(1-e^{-(\beta(1-\gamma)+\gamma^2)})}{\beta(1-\gamma)+\gamma^2})\text{OPT}-\epsilon$ with only  $O(1/\epsilon^{2})$ function evaluations, where OPT denotes  the optimal value."
Poster,Multi-Objective Causal Bayesian Optimization,https://ICML.cc//virtual/2025/poster/43849,"Shriya Bhatija, Paul-David Zuercher, Jakob Thumm, Thomas Bohné","In decision-making problems, the outcome of an intervention often depends on the causal relationships between system components and is highly costly to evaluate. In such settings, causal Bayesian optimization (CBO) exploits the causal relationships between the system variables and sequentially performs interventions to approach the optimum with minimal data. Extending CBO to the multi-outcome setting, we propose *multi-objective Causal Bayesian optimization* (MO-CBO), a paradigm for identifying Pareto-optimal interventions within a known multi-target causal graph. Our methodology first reduces the search space by discarding sub-optimal interventions based on the structure of the given causal graph. We further show that any MO-CBO problem can be decomposed into several traditional multi-objective optimization tasks. Our proposed MO-CBO algorithm is designed to identify Pareto-optimal interventions by iteratively exploring these underlying tasks, guided by relative hypervolume improvement. Experiments on synthetic and real-world causal graphs demonstrate the superiority of our approach over non-causal multi-objective Bayesian optimization in settings where causal information is available.","Many real-world decision problems involve choosing actions that influence multiple outcomes, such as improving health while minimizing cost. However, testing different actions can be expensive, especially when outcomes depend on complex cause-and-effect relationships. This work introduces Multi-Objective Causal Bayesian Optimization (MO-CBO), a method that uses known causal information to more efficiently search for the best interventions. MO-CBO rules out suboptimal interventions based on the system’s causal graph, and breaks the problem into simpler optimization tasks. By guiding exploration with a measure of potential improvement, the method finds high-quality solutions with very few data points needed. Experiments show that MO-CBO outperforms standard approaches that do not use causal information, especially when interventions are costly to perform."
Poster,Multiobjective distribution matching,https://ICML.cc//virtual/2025/poster/45789,"Xiaoyuan Zhang, Peijie Li, Ying Ying YU, Yichi Zhang, Han Zhao, Qingfu Zhang","Distribution matching is a key technique in machine learning, with applications in generative models, domain adaptation, and algorithmic fairness. A related but less explored challenge is generating a distribution that aligns with multiple underlying distributions, often with conflicting objectives, known as a Pareto optimal distribution.In this paper, we develop a general theory based on information geometry to construct the Pareto set and front for the entire exponential family under KL and inverse KL divergences. This formulation allows explicit derivation of the Pareto set and front for multivariate normal distributions, enabling applications like  multiobjective variational autoencoders (MOVAEs) to generate interpolated image distributions.Experimental results on real-world images demonstrate that both algorithms can generate high-quality interpolated images across multiple distributions.","We study how to generate a distribution, which resembles to multiple distributions at the same time in this paper. We formulate this problem as an optimization problem defined in the dually flat manifold. In this way, we could derive the explicit formulation for the PS for the exponational family. Multiobjective distribution matching is a fundamental research problem in machine learning, which is highly related with group DRO, algorithmic fairness, and generative models."
Poster,Multi-objective Linear Reinforcement Learning with Lexicographic Rewards,https://ICML.cc//virtual/2025/poster/45277,"Bo Xue, Dake Bu, Ji Cheng, Yuanyu Wan, Qingfu Zhang","Reinforcement Learning (RL) with linear transition kernels and reward functions has recently attracted growing attention due to its computational efficiency and theoretical advancements. However, prior theoretical research in RL has primarily focused on single-objective problems, resulting in limited theoretical development for multi-objective reinforcement learning (MORL). To bridge this gap, we examine MORL under lexicographic reward structures, where rewards comprise $m$ hierarchically ordered objectives. In this framework, the agent the agent maximizes objectives sequentially, prioritizing the highest-priority objective before considering subsequent ones. We introduce the first MORL algorithm with provable regret guarantees. For any objective $i \in \\{1, 2, \ldots, m\\}$, our algorithm achieves a regret bound of $\widetilde{O}(\Lambda^i(\lambda) \cdot \sqrt{d^2H^4 K})$, where $\Lambda^i(\lambda) = 1 + \lambda + \cdots + \lambda^{i-1}$, $\lambda$ quantifies the trade-off between conflicting objectives, $d$ is the feature dimension, $H$ is the episode length, and $K$ is the number of episodes. Furthermore, our algorithm can be applied in the misspecified setting, where the regret bound for the $i$-th objective becomes $\widetilde{O}(\Lambda^i(\lambda)\cdot(\sqrt{d^2H^4K}+\epsilon dH^2K))$, with $\epsilon$ denoting the degree of misspecification.","Reinforcement learning (RL) works well when an agent optimizes for a single goal, but many real-world problems require balancing multiple, sometimes competing objectives, like maximizing efficiency while minimizing risk. While single-objective RL has strong theoretical foundations, multi-objective RL (MORL) lacks similar guarantees, making it harder to trust in practical applications. To address this, we focus on lexicographic MORL, where objectives are ranked by importance, e.g., safety first, then performance. We develop the first MORL algorithm with mathematically proven regret bounds, meaning we can quantify how well it performs compared to the best possible strategy. Even when the environment is slightly misrepresented, our method remains robust. This research matters because it provides a principled way to handle real-world tasks where trade-offs are unavoidable, from autonomous driving to healthcare. By guaranteeing performance while respecting priorities, our work helps build more reliable and transparent AI systems."
Poster,MultiPDENet: PDE-embedded Learning with Multi-time-stepping for Accelerated Flow Simulation,https://ICML.cc//virtual/2025/poster/46029,"Qi Wang, Yuan Mi, Wang Haoyun, Yi Zhang, Ruizhi Chengze, Hongsheng Liu, Ji-Rong Wen, Hao Sun","Solving partial differential equations (PDEs) by numerical methods meet computational cost challenge for getting the accurate solution since fine grids and small time steps are required. Machine learning can accelerate this process, but struggle with weak generalizability, interpretability, and data dependency, as well as suffer in long-term prediction. To this end, we propose a PDE-embedded network with multiscale time stepping (MultiPDENet), which fuses the scheme of numerical methods and machine learning, for accelerated simulation of  flows. In particular, we design a convolutional filter based on the structure of finite difference stencils with a small number of parameters to optimize, which estimates the equivalent form of spatial derivative on a coarse grid to minimize the equation's residual. A Physics Block with a 4th-order Runge-Kutta integrator at the fine time scale is established that embeds the structure of PDEs to guide the prediction. To alleviate the curse of temporal error accumulation in long-term prediction, we introduce a multiscale time integration approach, where a neural network is used to correct the prediction error at a coarse time scale. Experiments across various PDE systems, including the Navier-Stokes equations, demonstrate that MultiPDENet can accurately predict long-term spatiotemporal dynamics, even given small and incomplete training data, e.g., spatiotemporally down-sampled datasets. MultiPDENet achieves the state-of-the-art performance compared with other neural baseline models, also with clear speedup compared to classical numerical methods","Simulating complex physical systems, like fluid flows, using traditional numerical methods is computationally expensive. These methods require very detailed grids and tiny time steps to be accurate. Machine learning (ML) can speed things up but often struggles with making reliable long-term predictions, explaining how it works, and needing huge amounts of training data.To overcome these challenges, we developed MultiPDENet. This new approach cleverly combines numerical methods with machine learning by embedding the core physics equations (PDEs) directly into the model's design. It uses efficient, physics-inspired filters based on numerical stencils to calculate crucial spatial changes accurately on much coarser grids, significantly reducing computational effort. For time integration, a dedicated ""Physics Block"" employs a precise numerical method at a fine time scale. Crucially, to prevent small errors from accumulating over long predictions, MultiPDENet uses multiscale time stepping: a neural network corrects prediction errors at a significantly coarser time scale.Tested on challenging systems like fluid dynamics, MultiPDENet achieves highly accurate long-term predictions even when trained on very limited or sparse data (e.g., data missing in space or time). It outperforms other ML models in accuracy and provides a clear speedup compared to standard numerical methods, offering a powerful tool for faster scientific simulations."
Poster,Multiple-policy Evaluation via Density Estimation,https://ICML.cc//virtual/2025/poster/46262,"Yilei Chen, Aldo Pacchiano, Ioannis Paschalidis","We study the multiple-policy evaluation problem where we are given a set of $K$ policies and the goal is to evaluate their performance (expected total reward over a fixed horizon) to an accuracy $\epsilon$ with probability at least $1-\delta$. We propose an algorithm named CAESAR for this problem. Our approach is based on computing an approximately optimal sampling distribution and using the data sampled from it to perform the simultaneous estimation of the policy values. CAESAR has two phases. In the first phase, we produce coarse estimates of the visitation distributions of the target policies at a low order sample complexity rate that scales with $\tilde{O}(\frac{1}{\epsilon})$. In the second phase, we approximate the optimal sampling distribution and compute the importance weighting ratios for all target policies by minimizing a step-wise quadratic loss function inspired by the DualDICE objective. Up to low order and logarithmic terms CAESAR achieves a sample complexity $\tilde{O}\left(\frac{H^4}{\epsilon^2}\sum_{h=1}^H\max_{k\in[K]}\sum_{s,a}\frac{(d_h^{\pi^k}(s,a))^2}{\mu^*_h(s,a)}\right)$, where $d^{\pi}$ is the visitation distribution of policy $\pi$, $\mu^*$ is the optimal sampling distribution, and $H$ is the horizon.","We study the problem of evaluating the performance of multiple decision-making strategies (policies), known as multiple-policy evaluation. Evaluating a policy typically requires collecting data that reflects its behavior. A naive approach for multiple-policy evaluation is to evaluate each policy independently, which costs lots of data, as data collected for one policy cannot be reused for others.We propose a new algorithm designed to evaluate multiple policies more efficiently by leveraging the potential similarity between the policies. The algorithm operates in two phases: First, it quickly computes rough estimates of how each policy behaves using a small number of samples. Then, based on the rough estimates, we can compute an optimal strategy to collect data which will be used to evaluate the performance of all policies simultaneously.Our method reduces the data required compared to independent evaluation, especially when the number of policies is large. We provide the rigorous theoretical results for the multiple-policy evaluation problem which may also be of interest in broader contexts. In practice, our method can significantly lower costs in applications like robotics or healthcare where trying out different strategies is expensive."
Poster,Multi-Session Budget Optimization for Forward Auction-based Federated Learning,https://ICML.cc//virtual/2025/poster/44752,"Xiaoli Tang, Han Yu, Zengxiang Li, Xiaoxiao Li","Auction-based Federated Learning (AFL) has emerged as an important research field in recent years. The prevailing strategies for FL data consumers (DCs) assume that the entire team of the required data owners (DOs) for an FL task must be assembled before training can commence. In practice, a DC can trigger the FL training process multiple times. DOs can thus be gradually recruited over multiple FL model training sessions. Existing bidding strategies for AFL DCs are not designed to handle such scenarios. Therefore, the problem of multi-session AFL remains open. To address this problem, we propose the Multi-session Budget Optimization Strategy for forward Auction-based Federated Learning (MBOS-AFL). Based on hierarchical reinforcement learning, MBOS-AFL jointly optimizes intersession budget pacing and intra-session bidding for AFL DCs, with the objective of maximizing the total utility. Extensive experiments on six benchmark datasets show that it significantly outperforms seven state-of-the-art approaches. On average, MBOS-AFL achieves 12.28% higher utility, 14.52% more data acquired through auctions for a given budget, and 1.23% higher test accuracy achieved by the resulting FL model compared to the best baseline. To the best of our knowledge, it is the first budget optimization decision support method with budget pacing capability designed for DCs in multi-session forward AFL.","Auction-based Federated Learning (AFL) has emerged as an important research field in recent years. The prevailing strategies for FL data consumers (DCs) assume that the entire team of the required data owners (DOs) for an FL task must be assembled before training can commence. In practice, a DC can trigger the FL training process multiple times. DOs can thus be gradually recruited over multiple FL model training sessions. Existing bidding strategies for AFL DCs are not designed to handle such scenarios. Therefore, the problem of multi-session AFL remains open. To address this problem, we propose the Multi-session Budget Optimization Strategy for forward Auction-based Federated Learning (MBOS-AFL). Based on hierarchical reinforcement learning, MBOS-AFL jointly optimizes intersession budget pacing and intra-session bidding for AFL DCs, with the objective of maximizing the total utility. Extensive experiments on six benchmark datasets show that it significantly outperforms seven state-of-the-art approaches. On average, MBOS-AFL achieves 12.28% higher utility, 14.52% more data acquired through auctions for a given budget, and 1.23% higher test accuracy achieved by the resulting FL model compared to the best baseline. To the best of our knowledge, it is the first budget optimization decision support method with budget pacing capability designed for DCs in multi-session forward AFL."
