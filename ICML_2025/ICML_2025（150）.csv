type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,IntLoRA: Integral Low-rank Adaptation of Quantized Diffusion Models,https://ICML.cc//virtual/2025/poster/45657,"Hang Guo, Yawei Li, Tao Dai, Shutao Xia, Luca Benini","Fine-tuning pre-trained diffusion models under limited budgets has gained great success. In particular, the recent advances that directly fine-tune the quantized weights using Low-rank Adaptation (LoRA) further reduces training costs. Despite these progress, we point out that existing adaptation recipes are not inference-efficient. Specifically, additional post-training quantization (PTQ) on tuned weights is needed during deployment, which results in noticeable performance drop when the bit-width is low. Based on this observation, we introduce IntLoRA, which adapts quantized diffusion models with integer-type low-rank parameters, to include inference efficiency during tuning. Specifically, IntLoRA enables pre-trained weights to remain quantized during training, facilitating fine-tuning on consumer-level GPUs. During inference, IntLoRA weights can be seamlessly merged into pre-trained weights to directly obtain quantized downstream weights without PTQ. Extensive experiments show our IntLoRA achieves significant speedup on both training and inference without losing performance.","Adapting large AI models to new tasks is often expensive and slow. Our method, IntLoRA, makes this process more efficient by allowing the model to be fine-tuned using compact, low-precision data without sacrificing performance. Unlike existing approaches that require extra steps after training, IntLoRA keeps everything efficient both during and after fine-tuning. This helps reduce the cost of using powerful models on personal devices while maintaining high-quality results."
Poster,Introducing 3D Representation for Dense Volume-to-Volume Translation via Score Fusion,https://ICML.cc//virtual/2025/poster/45130,"Xiyue Zhu, Dou Kwark, Ruike Zhu, Kaiwen Hong, Yiqi Tao, Shirui Luo, Yudu Li, Zhi-Pei Liang, Volodymyr Kindratenko","In volume-to-volume translations in medical images, existing models often struggle to capture the inherent volumetric distribution using 3D voxel-space representations, due to high computational dataset demands. We present Score-Fusion, a novel volumetric translation model that effectively learns 3D representations by ensembling perpendicularly trained 2D diffusion models in score function space. By carefully initializing our model to start with an average of 2D models as in existing models, we reduce 3D training to a fine-tuning process, mitigating computational and data demands. Furthermore, we explicitly design the 3D model's hierarchical layers to learn ensembles of 2D features, further enhancing efficiency and performance. Moreover, Score-Fusion naturally extends to multi-modality settings by fusing diffusion models conditioned on different inputs for flexible, accurate integration. We demonstrate that 3D representation is essential for better performance in downstream recognition tasks, such as tumor segmentation, where most segmentation models are based on 3D representation. Extensive experiments demonstrate that Score-Fusion achieves superior accuracy and volumetric fidelity in 3D medical image super-resolution and modality translation. Additionally, we extend Score-Fusion to video super-resolution by integrating 2D diffusion models on time-space slices with a spatial-temporal video diffusion backbone, highlighting its potential for general-purpose volume translation and providing broader insight into learning-based approaches for score function fusion.","Medical images like MRIs and CT scans are 3D, but most AI tools struggle to fully understand this 3D structure without using massive computing power and large datasets. Traditional methods often simplify the problem by analyzing 2D slices, missing important information that’s only visible in 3D.We introduce Score-Fusion, a new AI method that combines the strengths of multiple 2D image models to build an accurate 3D understanding of medical data. Instead of training a full 3D model from scratch, which is expensive and time-consuming, we fine-tune a model that cleverly merges insights from several 2D perspectives. This makes the process much more efficient. Score-Fusion can even handle multiple types of medical scans at once to give a clearer, more complete picture.Our model improves tasks like tumor detection and medical image enhancement, which rely on understanding 3D details. It even works for video tasks by treating time as another dimension. By learning how to fuse different views smartly, Score-Fusion opens up a more flexible tool for medical imaging and beyond."
Poster,Invariance Makes LLM Unlearning Resilient Even to Unanticipated Downstream Fine-Tuning,https://ICML.cc//virtual/2025/poster/43597,"Changsheng Wang, Yihua Zhang, jinghan jia, Parikshit Ram, Dennis Wei, Yuguang Yao, Soumyadeep Pal, Nathalie Baracaldo, Sijia Liu","Machine unlearning presents a promising approach to mitigating privacy and safety concerns in large language models (LLMs) by enabling the selective removal of targeted data or knowledge while preserving model utility. However, existing unlearning methods remain over-sensitive to downstream fine-tuning, which can rapidly recover what is supposed to be unlearned information even when the fine-tuning task is entirely unrelated to the unlearning objective.To enhance robustness, we introduce the concept of `invariance' into unlearning for the first time from the perspective of invariant risk minimization (IRM), a principle for environment-agnostic training. By leveraging IRM, we develop a new invariance-regularized LLM unlearning framework, termed invariant LLM unlearning (ILU). We show that the proposed invariance regularization, even using only a single fine-tuning dataset during ILU training, can enable unlearning robustness to generalize effectively across diverse and new fine-tuning tasks at test time.A task vector analysis is also provided to further elucidate the rationale behind ILU's effectiveness. Extensive experiments on the WMDP benchmark, which focuses on removing an LLM's hazardous knowledge generation capabilities, reveal that ILU significantly outperforms state-of-the-art unlearning methods, including negative preference optimization (NPO) and representation misdirection for unlearning (RMU). Notably, ILU achieves superior unlearning robustness across diverse downstream fine-tuning scenarios (e.g., math, paraphrase detection, and sentiment analysis) while preserving the fine-tuning performance.","(1) Large language models (LLMs) can memorize sensitive or unsafe information, and safely removing this knowledge—known as machine unlearning—is crucial but difficult, especially when downstream training interferes with forgetting.(2) We introduce a new method called invariant LLM unlearning (ILU), which uses a regularization strategy inspired by invariant risk minimization to make forgetting more reliable and robust, even across unrelated tasks.(3) This approach helps build safer AI systems by ensuring sensitive knowledge is thoroughly removed while preserving the model’s performance on useful tasks."
Poster,Invariant Deep Uplift Modeling for Incentive Assignment in Online Marketing via Probability of Necessity and Sufficiency,https://ICML.cc//virtual/2025/poster/44136,"Zexu Sun, Qiyu Han, Hao Yang, Anpeng Wu, Minqin Zhu, Dugang Liu, Chen Ma, Yunpeng Weng, Xing Tang, xiuqiang He","In online platforms, incentives (\textit{e.g}., discounts, coupons) are used to boost user engagement and revenue. Uplift modeling methods are developed to estimate user responses from observational data, often incorporating distribution balancing to address selection bias. However, these methods are limited by in-distribution testing data, which mirrors the training data distribution. In reality, user features change continuously due to time, geography, and other factors, especially on complex online marketing platforms. Thus, effective uplift modeling method for out-of-distribution data is crucial. To address this, we propose a novel uplift modeling method \textbf{I}nvariant \textbf{D}eep \textbf{U}plift \textbf{M}odeling, namely \textbf{IDUM}, which uses invariant learning to enhance out-of-distribution generalization by identifying causal factors that remain consistent across domains. IDUM further refines these features into necessary and sufficient factors and employs a masking component to reduce computational costs by selecting the most informative invariant features. A balancing discrepancy component is also introduced to mitigate selection bias in observational data. We conduct extensive experiments on public and real-world datasets to demonstrate IDUM's effectiveness in both in-distribution and out-of-distribution scenarios in online marketing. Furthermore, we also provide theoretical analysis and related proofs to support our IDUM's generalizability.","Online platforms leverage incentives (e.g., discounts, coupons) to enhance user engagement and revenue, with uplift modeling methods estimating user responses from observational data through distribution balancing to address selection bias. However, these methods are constrained by in-distribution testing, failing to adapt to real-world scenarios where user features dynamically shift due to time, geography, and platform complexity. To tackle this, we propose \textbf{I}nvariant \textbf{D}eep \textbf{U}plift \textbf{M}odeling (IDUM), which enhances out-of-distribution generalization by identifying domain-invariant causal features. IDUM disentangles these features into necessary (directly influencing behavior) and sufficient (indirectly related) factors, employs a masking mechanism to prioritize informative invariant features for efficiency, and integrates a balancing discrepancy component to mitigate selection bias. Experiments on public and real-world datasets validate IDUM’s effectiveness in both in- and out-of-distribution settings, supported by theoretical analysis on generalization error bounds to ensure robustness."
Poster,Inverse Bridge Matching Distillation,https://ICML.cc//virtual/2025/poster/45134,"Nikita Gushchin, David Li, Daniil Selikhanovych, Evgeny Burnaev, Dmitry Baranchuk, Aleksandr Korotin","Learning diffusion bridge models is easy; making them fast and practical is an art. Diffusion bridge models (DBMs) are a promising extension of diffusion models for applications in image-to-image translation. However, like many modern diffusion and flow models, DBMs suffer from the problem of slow inference. To address it, we propose a novel distillation technique based on the inverse bridge matching formulation and derive the tractable objective to solve it in practice. Unlike previously developed DBM distillation techniques, the proposed method can distill both conditional and unconditional types of DBMs, distill models in a one-step generator, and use only the corrupted images for training. We evaluate our approach for both conditional and unconditional types of bridge matching on a wide set of setups, including super-resolution, JPEG restoration, sketch-to-image, and other tasks, and show that our distillation technique allows us to accelerate the inference of DBMs from 4x to 100x and even provide better generation quality than used teacher model depending on particular setup.","Modern AI systems that transform one image into another — for example, sharpening a blurry photo or turning a sketch into a realistic image — often rely on a class of tools called diffusion models. These models produce high-quality results but are painfully slow, sometimes taking hundreds or even thousands of steps to generate a single image.Our research focuses on a special kind of these models called Diffusion Bridge Models (DBMs), which are well-suited for image-to-image tasks but face the same issue: slow generation speed. We introduce a new technique called Inverse Bridge Matching Distillation (IBMD) that significantly accelerates these models — making them up to 100 times faster — without sacrificing image quality.Unlike earlier methods, our approach works universally for different types of DBMs and can even compress them into a single-step generator. We tested IBMD on a wide range of tasks, like super-resolution, inpainting, and image restoration, and found it not only faster but often better than the original models. This opens the door to making powerful AI-based image editing tools much more practical and accessible in everyday applications."
Poster,Inverse Flow and Consistency Models,https://ICML.cc//virtual/2025/poster/45980,"Yuchen Zhang, Jian Zhou","Inverse generation problems, such as denoising without ground truth observations, is a critical challenge in many scientific inquiries and real-world applications. While recent advances in generative models like diffusion models, conditional flow matching, and consistency models achieved impressive results by casting generation as denoising problems, they cannot be directly used for inverse generation without access to clean data. Here we introduce Inverse Flow (IF), a novel framework that enables using these generative models for inverse generation problems including denoising without ground truth. Inverse Flow can be flexibly applied to nearly any continuous noise distribution and allows complex dependencies. We propose two algorithms for learning Inverse Flows, Inverse Flow Matching (IFM) and Inverse Consistency Model (ICM). Notably, to derive the computationally efficient, simulation-free inverse consistency model objective, we generalized consistency training to any forward diffusion processes or conditional flows, which have applications beyond denoising. We demonstrate the effectiveness of IF on synthetic and real datasets, outperforming prior approaches while enabling noise distributions that previous methods cannot support. Finally, we showcase applications of our techniques to fluorescence microscopy and single-cell genomics data, highlighting IF's utility in scientific problems. Overall, this work expands the applications of powerful generative models to inversion generation problems.","We often get data that’s messy or “noisy”—for example, blurry microscope pictures or shaky readings—without having any perfect examples to learn from. Our new method, called Inverse Flow, treats each noisy example as a step along a path and learns how to go backwards, undoing the noise. Unlike older approaches, it only needs the noisy data itself and doesn’t require any clean reference. We show it can sharpen microscope images and make single-cell gene measurements more accurate, so scientists can uncover hidden details from messy observations in biology, physics, and beyond."
Poster,Inverse Optimization via Learning Feasible Regions,https://ICML.cc//virtual/2025/poster/44209,"Ke Ren, Peyman Mohajerin Esfahani, Angelos Georghiou","We study inverse optimization (IO), where the goal is to use a parametric optimization program as the hypothesis class to infer relationships between input-decision pairs. Most of the literature focuses on learning only the objective function, as learning the constraint function (i.e., feasible regions) leads to nonconvex training programs. Motivated by this, we focus on learning feasible regions for known linear objectives, and introduce two training losses along with a hypothesis class to parameterize the  constraint function. Our hypothesis class surpasses the previous objective-only method by naturally capturing discontinuous behaviors in input-decision pairs. We introduce a customized block coordinate descent algorithm with a smoothing technique to solve the training problems, while for further restricted hypothesis classes, we reformulate the training optimization as a tractable convex program or mixed integer linear program. Synthetic experiments and two power system applications including comparisons with state-of-the-art approaches showcase and validate the proposed approach.","Many real-world systems make complex decisions within strict boundaries, e.g., power grid operators who must balance electricity supply while respecting physical limitations. When experts observe such decisions, they often want to understand what invisible rules or constraints are influencing them. We develop a method to reverse-engineer these hidden constraints from observed decisions, assuming we already know the decision-makers’ goals. Unlike earlier approaches that are dedicated to learn the objectives, our method specifically focuses on learning the constraints that shape feasible decisions. A key innovation of our work is its ability to handle situations where small changes in conditions lead to large shifts in behavior, i.e., the ability to learn a potentially discontinuous behavior. We demonstrate our method's effectiveness through both synthetic experiments and real power system applications, where it outperforms existing approaches and offers valuable insights into complex decision-making processes."
Poster,Inverse Problem Sampling in Latent Space Using Sequential Monte Carlo,https://ICML.cc//virtual/2025/poster/44148,"Idan Achituve, Hai Victor Habi, Amir Rosenfeld, Arnon Netzer, Idit Diamant, Ethan Fetaya","In image processing, solving inverse problems is the task of finding plausible reconstructions of an image that was corrupted by some (usually known) degradation operator. Commonly, this process is done using a generative image model that can guide the reconstruction towards solutions that appear natural. The success of diffusion models over the last few years has made them a leading candidate for this task. However, the sequential nature of diffusion models makes this conditional sampling process challenging. Furthermore, since diffusion models are often defined in the latent space of an autoencoder, the encoder-decoder transformations introduce additional difficulties. To address these challenges, we suggest a novel sampling method based on sequential Monte Carlo (SMC) in the latent space of diffusion models. We name our method LD-SMC. We define a generative model for the data using additional auxiliary observations and perform posterior inference with SMC sampling based on a backward diffusion process. Empirical evaluations on ImageNet and FFHQ show the benefits of LD-SMC over competing methods in various inverse problem tasks and especially in challenging inpainting tasks.","It is often the case that an image we witness has undergone some kind of loss or damage. Figuring out what the original image might have looked like before that happened is termed inverse problem. The goal of our paper is to propose a method for recovering or ""guessing"" the original, high-quality image from a damaged, incomplete, or low-quality version of it. Common examples are (1) Deblurring, where we are given a blurry photo (maybe from a shaky camera) and the goal is to recover the sharp, original image; and (2) Inpainting, where an image has missing or damaged parts (like holes, scratches, or objects removed) and the goal is to fill in the missing parts in a natural, realistic way. Recently generative models (e.g., diffusion models) have been proposed to help solve this task by guiding towards more probable image reconstructions. Most inverse problem methods were developed for generative models that operate in the original pixel space. However, state-of-the-art image generative models are designed to work in some latent, low-dimensional, space. In our paper, we bridge that gap. We developed a method for solving inverse problems that leverage diffusion models operating in a latent space. We propose to generate auxiliary images based on the distorted image which are then used to guide the diffusion process to generate a clean version of it. The injection of this information along the sampling process of diffusion models allows us to remain faithful to the information in the distorted image while making the resulting image look more natural. We ground our method using a well-established technique in the literature called sequential Monte Carlo which enjoys theoretical guarantees. Empirically our method generates plausible and natural image reconstructions in various inverse problem tasks."
Poster,Inverse problems with experiment-guided AlphaFold,https://ICML.cc//virtual/2025/poster/43912,"Sai Advaith Maddipatla, Nadav Bojan, Meital Bojan, Sanketh Vedula, Paul Schanda, Ailie Marx, Alexander Bronstein","Proteins exist as a dynamic ensemble of multiple conformations, and these motions are often crucial for their functions. However, current structure prediction methods predominantly yield a single  conformation, overlooking the conformational heterogeneity revealed by diverse experimental modalities. Here, we present a framework for building experiment-grounded protein structure generative models that infer conformational ensembles consistent with measured experimental data. The key idea is to treat state-of-the-art protein structure predictors (e.g., AlphaFold3) as sequence-conditioned structural priors, and cast ensemble modeling as posterior inference of protein structures given experimental measurements. Through extensive real-data experiments, we demonstrate the generality of our method to incorporate a variety of experimental measurements. In particular, our framework uncovers previously unmodeled conformational heterogeneity from crystallographic densities, generates high-accuracy NMR ensembles orders of magnitude faster than status quo, and incorporates pairwise cross-link constraints. Notably, we demonstrate that our ensembles outperform AlphaFold3 and sometimes better fit experimental data than publicly deposited structures to the protein database (PDB). We believe that this approach will unlock building predictive models that fully embrace experimentally observed conformational diversity.",AlphaFold is a groundbreaking deep learning solution that predicts protein structure from a protein sequence. We are introducing experiment guided AlphaFold that solves the inverse problems from experiment observations (capturing all dynamic properties) and also leverage the evolutionary prior embedded within AlphaFold.
Poster,Inverse Reinforcement Learning with Switching Rewards and History Dependency for Characterizing Animal Behaviors,https://ICML.cc//virtual/2025/poster/43528,"Jingyang Ke, Feiyang Wu, Jiyi Wang, Jeffrey Markowitz, Anqi Wu","Traditional approaches to studying decision-making in neuroscience focus on simplified behavioral tasks where animals perform repetitive, stereotyped actions to receive explicit rewards. While informative, these methods constrain our understanding of decision-making to short timescale behaviors driven by explicit goals. In natural environments, animals exhibit more complex, long-term behaviors driven by intrinsic motivations that are often unobservable. Recent works in time-varying inverse reinforcement learning (IRL) aim to capture shifting motivations in long-term, freely moving behaviors. However, a crucial challenge remains: animals make decisions based on their history, not just their current state. To address this, we introduce SWIRL (SWitching IRL), a novel framework that extends traditional IRL by incorporating time-varying, history-dependent reward functions. SWIRL models long behavioral sequences as transitions between short-term decision-making processes, each governed by a unique reward function. SWIRL incorporates biologically plausible history dependency to capture how past decisions and environmental contexts shape behavior, offering a more accurate description of animal decision-making. We apply SWIRL to simulated and real-world animal behavior datasets and show that it outperforms models lacking history dependency, both quantitatively and qualitatively. This work presents the first IRL model to incorporate history-dependent policies and rewards to advance our understanding of complex, naturalistic decision-making in animals.","In the real world, animals don't act based on short-term goals alone. They switch between different objectives—like finding water, resting, or exploring—and use their past experiences to inform future decisions. However, most inverse reinforcement learning (IRL) methods, which aim to recover the underlying reward function (goal) from observed behavior demonstrations, assume behavior is driven by a single, static goal and ignore the influence of past actions. This limits their ability to capture the dynamic, adaptive nature of real animal behavior.We introduces SWIRL, a new IRL framework that captures both goal switching and history dependency. SWIRL recovers switching reward functions that reflect changing motivations and models how recent behavioral history influences decisions—offering a richer, more biologically plausible model of behavior. We evaluate SWIRL on both synthetic and real-world datasets of animal behavior and find SWIRL recovers the underlying goals and behavioral segments more accurately than prior IRL approaches, particularly those that ignore history. By revealing interpretable, history-aware structure in long-term naturalistic behavior, SWIRL provides a valuable tool for neuroscience research. It also offers insights for broader machine learning applications involving switching, context-dependent decision-making."
