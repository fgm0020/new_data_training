type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Prompt-to-Leaderboard: Prompt-Adaptive LLM Evaluations,https://ICML.cc//virtual/2025/poster/46319,"Evan Frick, Connor Chen, Joseph Tennyson, Tianle Li, Wei-Lin Chiang, Anastasios Angelopoulos, Ion Stoica","Large language model (LLM) evaluations typically rely on aggregated metrics like accuracy or human preference, averaging across users and prompts. This averaging obscures user- and prompt-specific variations in model performance. To address this, we propose Prompt-to-Leaderboard (P2L), a method that produces leaderboards specific to a prompt or set of prompts. The core idea is to train an LLM taking natural language prompts as input to output a vector of Bradley-Terry coefficients which are then used to predict the human preference vote. The resulting prompt-dependent leaderboards allow for unsupervised task-specific evaluation, optimal routing of queries to models, personalization, and automated evaluation of model strengths and weaknesses. Data from Chatbot Arena suggest that P2L better captures the nuanced landscape of language model performance than the averaged leaderboard. Furthermore, our findings suggest that P2L's ability to produce prompt-specific evaluations follows a power law scaling similar to that observed in LLMs themselves. In January 2025, the router we trained based on this methodology achieved the \#1 spot on the Chatbot Arena leaderboard. Our code is available at this GitHub link: https://github.com/lmarena/p2l.","Current LLM leaderboards, such as Chatbot Arena, rank models by their average performance across many tasks. However, these general rankings don't indicate which LLM is best for a specific need, for instance, writing code versus crafting a marketing slogan. Specifically, determining the best model for a singular prompt is a significant challenge.We introduce Prompt-to-Leaderboard (P2L) to address this issue. P2L is a deep learning model that takes your specific question or task (a ""prompt"") and instantly generates a custom leaderboard – an ordering of which LLMs are predicted to perform best for that particular prompt. It learns this by analyzing millions of human preferences from real-world comparisons and its performance scales with both increasing data as well as increasing parameter count. P2L not only allows you to choose the best model for your prompt, but it can also tell you which models to use given a cost constraint. It also enables personalized evaluations based on a user’s prompt history and provides automatic analysis of model strengths and weaknesses across different topics—offering a powerful toolkit for informed, adaptive LLM deployment."
Poster,ProofAug: Efficient Neural Theorem Proving via Fine-grained Proof Structure Analysis,https://ICML.cc//virtual/2025/poster/45846,"Haoxiong Liu, Jiacheng Sun, Zhenguo Li, Andrew Yao","The synergy between deep learning models and traditional automation tools, such as built-in tactics of the proof assistant and off-the-shelf automated theorem provers, plays a crucial role in developing robust and efficient neural theorem provers~(NTPs).However, for proof synthesis with LLMs, previous work applies automation tools either only when explicitly invoked by the model or at a single granularity level, failing to fully exploit their power. To solve this issue, we propose ProofAug, a procedure that equips LLMs with automation methods at various granularities through fine-grained structure analysis of model-generated proof proposals. ProofAug also serves as a versatile plug-and-play module that seamlessly integrates with any tree-search algorithm, enabling our construction of an efficient recursive proving (ERP) module to further enhance performance.The superiority of our method is validated on the miniF2F benchmark using the open-source deepseek-math-7b-base model and the Isabelle proof assistant.Notably, by additionally employing a mixed prompting strategy, we achieve a cumulative pass rate of 66.0% after curation of the dataset (61.9% for the original version) with 2100 queries to the model per problem (In contrast, the previous SOTA in Isabelle, Subgoal-XL, only achieves 56.1% using 16384 queries per problem).We also implement a Lean 4 version of ProofAug that can improve the pass@1 performance of Kimina-Prover-Preview-Distill-1.5B from 44.3% to 50.4% on miniF2F-test. Our code is available at https://github.com/haoxiongliu/ProofAug.","Automated proof assistants like Isabelle and Lean help verify mathematical theorems, but even with recent advances in large language models (LLMs), generating accurate proofs remains a major challenge. We observe that one issue of existing systems is that they do not fully leverage existing off-the-shelf automation tools, often calling them only when explicitly told to or at a fixed level of detail. Thus, we developed ProofAug, a new method that helps LLMs write better proofs by smartly integrating automation tools at multiple levels of granularity. It does this by analyzing the structure of partial proofs and inserting the right tactic at the right time — like a good co-pilot helping the model along the way.ProofAug works with a range of search strategies and supports both Isabelle and Lean. On benchmark tests, it sets new performance records for proof generation using fewer computation budget than previous methods. We hope this brings us one step closer to truly capable AI provers."
Poster,Propagate and Inject: Revisiting Propagation-Based Feature Imputation for Graphs with Partially Observed Features,https://ICML.cc//virtual/2025/poster/45329,"Daeho Um, Sunoh Kim, Jiwoong Park, Jongin Lim, Seong Jin Ahn, Seulki Park","In this paper, we address learning tasks on graphs with missing features, enhancing the applicability of graph neural networks to real-world graph-structured data. We identify a critical limitation of existing imputation methods based on feature propagation: they produce channels with nearly identical values within each channel, and these low-variance channels contribute very little to performance in graph learning tasks. To overcome this issue, we introduce synthetic features that target the root cause of low-variance channel production, thereby increasing variance in these channels. By preventing propagation-based imputation methods from generating meaningless feature values shared across all nodes, our synthetic feature propagation scheme mitigates significant performance degradation, even under extreme missing rates. Extensive experiments demonstrate the effectiveness of our approach across various graph learning tasks with missing features, ranging from low to extremely high missing rates. Additionally, we provide both empirical evidence and theoretical proof to validate the low-variance problem. The source code is available at https://github.com/daehoum1/fisf.","Graph neural networks (GNNs) are useful tools that learn from networks, such as  social networks, by using information about each node and how they are connected. But in the real world, important information about these nodes is often missing. To fill in the gaps, a common approach is to copy known values from neighboring nodes. However, we discovered that when these known values are very similar, this method ends up giving nearly the same result to every node. As a result, the model struggles to tell nodes apart — like giving every person the same estimated age, making it hard to make meaningful predictions.To solve this problem, we introduce a new method called FISF. This method adds a small amount of variety to overly similar parts of the data and spreads this variation across the network. In doing so, it creates more meaningful differences in the filled-in data.Our experiments show that FISF significantly improves the performance of GNNs, even when most of the original information is missing. This allows machine learning models to make better decisions using incomplete data in a wide range of real-world applications."
Poster,Propagation of Chaos for Mean-Field Langevin Dynamics and its Application to Model Ensemble,https://ICML.cc//virtual/2025/poster/45210,"Atsushi Nitanda, Anzelle Lee, Damian Kai, Mizuki Sakaguchi, Taiji Suzuki","Mean-field Langevin dynamics (MFLD) is an optimization method derived by taking the mean-field limit of noisy gradient descent for two-layer neural networks in the mean-field regime. Recently, the propagation of chaos (PoC) for MFLD has gained attention as it provides a quantitative characterization of the optimization complexity in terms of the number of particles and iterations. A remarkable progress by Chen et al. (2022) showed that the approximation error due to finite particles remains uniform in time and diminishes as the number of particles increases. In this paper, by refining the defective log-Sobolev inequality---a key result from that earlier work---under the neural network training setting, we establish an improved PoC result for MFLD, which removes the exponential dependence on the regularization coefficient from the particle approximation term of the optimization complexity. As an application, we propose a PoC-based model ensemble strategy with theoretical guarantees.","Modern AI models adjust millions of internal “knobs” during training. A fresh viewpoint treats these adjustments as many particles moving together, which helps predict the time and compute needed. We improve the math behind this idea, eliminating a technical penalty that used to over-estimate training difficulty when the network includes regularization. The result: the wider the network, the closer real training stays to the ideal infinite-particle case. Our theory also supports a practical tip—combining several smaller models trained this way can reliably boost performance."
Poster,Proposer-Agent-Evaluator (PAE): Autonomous Skill Discovery For Foundation Model Internet Agents,https://ICML.cc//virtual/2025/poster/43739,"Yifei Zhou, Qianlan Yang, Kaixiang Lin, Min Bai, Xiong Zhou, Yu-Xiong Wang, Sergey Levine, Li Li","A generalist foundation model agent needs to have a large and diverse skill repertoire, such as finding directions between two travel locations and buying specific items from the Internet. If each skill needs to be specified manually through a fixed set of human-annotated instructions, the agent’s skill repertoire will necessarily be limited due to the scalability of human-annotated instructions. In this work, we address this challenge by proposing Proposer-Agent-Evaluator (PAE), an effective learning system that enables foundation model agents to autonomously discover and practice skills in the wild. After a context-aware task proposer generates instructions based on website information, the agent policy attempts those tasks in the real world with resulting trajectories evaluated by an autonomous VLM-based success evaluator. The success evaluation serves as the reward signal for the agent to refine its policies through RL. We validate PAE on challenging vision-based web navigation, using both real-world and selfhosted websites from WebVoyager and WebArena. Our results show that PAE significantly improves the zero-shot generalization capability of VLM Internet agents (around 50% relative improvement)to both unseen tasks and websites.","We want AI agents, such as virtual assistants, to handle many tasks like navigating websites or shopping online without needing detailed instructions from humans each time. But manually writing instructions for every task isn't scalable. To solve this, we created a method called Proposer-Agent-Evaluator (PAE), which allows AI agents to learn new skills autonomously and achieve self-improvements.In PAE, one component suggests tasks based on information from websites. Another component, the agent itself, attempts these tasks on real websites. A third component evaluates how successful the agent was using visual feedback, guiding the agent to improve its performance automatically through trial and error.We tested PAE on challenging website navigation tasks, including both real and simulated environments. Our experiments showed that agents trained with PAE could handle completely new tasks and websites significantly better (by about 50%) than previous methods, highlighting the potential of AI agents to autonomously acquire new skills and self-improve."
Poster,ProSec: Fortifying Code LLMs with Proactive Security Alignment,https://ICML.cc//virtual/2025/poster/44896,"Xiangzhe Xu, Zian Su, Jinyao Guo, Kaiyuan Zhang, Zhenting Wang, Xiangyu Zhang","While recent code-specific large language models (LLMs) have greatly enhanced their code generation capabilities, the safety of these models remains under-explored, posing potential risks as insecure code generated by these models may introduce vulnerabilities into real-world systems. Existing methods collect security-focused datasets from real-world vulnerabilities for instruction tuning in order to mitigate such issues. However, they are largely constrained by the data sparsity of vulnerable code, and have limited applicability in the multi-stage post-training workflows of modern LLMs. In this paper, we propose ProSec, a novel proactive security alignment approach designed toalign code LLMs with secure coding practices. ProSec systematically exposes the vulnerabilities in a code LLM by synthesizing vulnerability-inducing coding scenarios from Common Weakness Enumerations (CWEs) and generates fixes to vulnerable code snippets, allowing the model to learn secure practices through preference learning objectives. The scenarios synthesized by ProSec trigger 25× more vulnerable code than a normal instruction-tuning dataset, resulting in a security-focused alignment dataset 7× larger than the previous work. Experiments show that models trained with ProSec are 25.2% to 35.4% more secure compared to previous work without degrading models' utility.","AI models are powerful at writing code but may produce insecure code vulnerable to attackers. Existing methods rely on scarce real-world bug examples, limiting their coverage. Our system, PROSEC, automatically generates realistic and diverse coding tasks where models tend to write insecure code, then creates paired secure and insecure implementations to teach the model to generate secure code. This process yields over 20× more vulnerable samples and a dataset 7× larger than previous efforts. Models trained with PROSEC are 25–35% more secure without losing their coding performance."
Poster,Protein Structure Tokenization: Benchmarking and New Recipe,https://ICML.cc//virtual/2025/poster/44084,"Xinyu Yuan, Zichen Wang, Marcus Collins, Huzefa Rangwala","Recent years have witnessed a surge in the development of protein structural tokenization methods, which chunk protein 3D structures into discrete or continuous representations. Structure tokenization enables the direct application of powerful techniques like language modeling for protein structures, and large multimodal models to integrate structures with protein sequences and functional texts. Despite the progress, the capabilities and limitations of these methods remain poorly understood due to the lack of a unified evaluation framework. We first introduce **StructTokenBench**, a framework that comprehensively evaluates the quality and efficiency of structure tokenizers, focusing on fine-grained local substructures rather than global structures, as typical in existing benchmarks. Our evaluations reveal that no single model dominates all benchmarking perspectives. Observations of codebook under-utilization led us to develop **AminoAseed**, a simple yet effective strategy that enhances codebook gradient updates and optimally balances codebook size and dimension for improved tokenizer utilization and quality. Compared to the leading model ESM3, our method achieves an average of 6.31\% performance improvement across 24 supervised tasks, with sensitivity and utilization rates increased by 12.83\% and 124.03\%, respectively. Source code and model weights are available at https://github.com/KatarinaYuan/StructTokenBench.","Proteins are the tiny machines that keep our bodies alive and functioning. To understand how they work, scientists often study their 3D shapes. But analyzing these complex shapes with AI is not easy — we first need to “translate” them into tokens, like how words are made from letters. This process is called protein structure tokenization.Our research introduces a new benchmark, **StructTokenBench**, to evaluate how well different AI methods perform this translation. We tested many approaches and found that each has its strengths and weaknesses. Based on these insights, we developed a new method called **AminoAseed**, which improves how effectively AI can learn from protein shapes.This work could help computers better understand proteins, leading to advances in biology, drug discovery, and disease research. Just as language models transformed how machines understand text, our tools aim to do the same for protein structures — unlocking a new era of scientific discovery."
Poster,PROTOCOL: Partial Optimal Transport-enhanced Contrastive Learning for Imbalanced Multi-view Clustering,https://ICML.cc//virtual/2025/poster/45370,"Xuqian Xue, Yiming Lei, Qi Cai, Hongming Shan, Junping Zhang","While contrastive multi-view clustering has achieved remarkable success, it implicitly assumes balanced class distribution. However, real-world multi-view data primarily exhibits class imbalance distribution. Consequently, existing methods suffer performance degradation due to their inability to perceive and model such imbalance. To address this challenge, we present the first systematic study of imbalanced multi-view clustering, focusing on two fundamental problems: *i. perceiving class imbalance distribution*, and *ii. mitigating representation degradation of minority samples*. We propose PROTOCOL, a novel PaRtial Optimal TranspOrt-enhanced COntrastive Learning framework for imbalanced multi-view clustering. First, for class imbalance perception, we map multi-view features into a consensus space and reformulate the imbalanced clustering as a partial optimal transport (POT) problem, augmented with *progressive mass constraints* and *weighted KL divergence* for class distributions. Second, we develop a POT-enhanced class-rebalanced contrastive learning at both feature and class levels, incorporating *logit adjustment* and *class-sensitive learning* to enhance minority sample representations. Extensive experiments demonstrate that PROTOCOL significantly improves clustering performance on imbalanced multi-view data, filling a critical research gap in this field.","In real-world scenarios, multi-source data often exhibits class imbalance, making it difficult for existing multi-view clustering methods—which often implicitly assume balanced datasets—to effectively perceive and model this issue. To address this challenge, we propose PROTOCOL, a novel PaRtial Optimal TranspOrt-enhanced COntrastive Learning framework that can both perceive class imbalance in multi-view data and mitigate the representation degradation of minority samples. Extensive experimental results demonstrate that PROTOCOL consistently achieves outstanding performance across various imbalance ratios, providing more reliable technical support for data mining in practical fields such as healthcare and sensor networks."
Poster,Proto Successor Measure: Representing the Behavior Space of an RL Agent,https://ICML.cc//virtual/2025/poster/44149,"Siddhant Agarwal, Harshit Sikchi, Peter Stone, Amy Zhang","Having explored an environment, intelligent agents should be able to transfer their knowledge to most downstream tasks within that environment without additional interactions. Referred to as ""zero-shot learning"", this ability remains elusive for general-purpose reinforcement learning algorithms.  While recent works have attempted to produce zero-shot RL agents, they make assumptions about the nature of the tasks or the structure of the MDP. We present *Proto Successor Measure*: the basis set for all possible behaviors of a Reinforcement Learning Agent in a dynamical system. We prove that any possible behavior (represented using visitation distributions) can be represented using an affine combination of these policy-independent basis functions. Given a reward function at test time, we simply need to find the right set of linear weights to combine these bases corresponding to the optimal policy. We derive a practical algorithm to learn these basis functions using reward-free interaction data from the environment and show that our approach can produce the near-optimal policy at test time for any given reward function without additional environmental interactions. Project page: agarwalsiddhant10.github.io/projects/psm.html.","Any human can perform a large number of tasks in any environment by simply exploring it initially. Humans have a wonderful ability to form an abstraction about their surroundings, which enables them to solve any task very quickly. We investigate whether this ability can be transferred to any reinforcement learning agent. Using the mathematical properties of the environment, we construct an abstract space where any behavior of the agent can be represented. Given any task, the agent simply needs to search in this space to find the most performant behavior that solves the task."
Poster,Protriever: End-to-End Differentiable Protein Homology Search for Fitness Prediction,https://ICML.cc//virtual/2025/poster/45825,"Ruben Weitzman, Peter Mørch Groth, Lood van Niekerk, Aoi Otani, Yarin Gal, Debora Marks, Pascal Notin","Retrieving homologous protein sequences is essential for a broad range of protein modeling tasks such as fitness prediction, protein design, structure modeling, and protein-protein interactions. Traditional workflows have relied on a two-step process: first retrieving homologs via Multiple Sequence Alignments (MSA), then training mod- els on one or more of these alignments. However, MSA-based retrieval is computationally expensive, struggles with highly divergent sequences or complex insertions & deletions patterns, and operates independently of the downstream modeling objective. We introduce Protriever, an end-to-end differentiable framework that learns to retrieve relevant homologs while simultaneously training for the target task. When applied to protein fitness prediction, Protriever achieves state-of-the-art performance compared to sequence-based models that rely on MSA-based homolog retrieval, while being two orders of magnitude faster through efficient vector search. Protriever is both architecture and task-agnostic, and can flexibly adapt to different retrieval strategies and protein databases at inference time – offering a scalable alternative to alignment-centric approaches.","Retrieving homologous protein sequences is essential for a broad range of protein modeling tasks such as fitness prediction, protein design, structure modeling, and protein-protein interactions. Traditional workflows have relied on a two-step process: first retrieving homologs via Multiple Sequence Alignments (MSA), then training mod- els on one or more of these alignments. However, MSA-based retrieval is computationally expensive, struggles with highly divergent sequences or complex insertions & deletions patterns, and operates independently of the downstream modeling objective. We introduce Protriever, an end-to-end differentiable framework that learns to retrieve relevant homologs while simultaneously training for the target task. When applied to protein fitness prediction, Protriever achieves state-of-the-art performance compared to sequence-based models that rely on MSA-based homolog retrieval, while being two orders of magnitude faster through efficient vector search. Protriever is both architecture and task-agnostic, and can flexibly adapt to different retrieval strategies and protein databases at inference time – offering a scalable alternative to alignment-centric approaches."
