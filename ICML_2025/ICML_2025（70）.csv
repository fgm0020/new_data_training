type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Demystifying Long Chain-of-Thought Reasoning,https://ICML.cc//virtual/2025/poster/45449,"Edward Yeo, Yuxuan Tong, Xinyao Niu, Graham Neubig, Xiang Yue","Scaling inference compute has become a key driver of advanced reasoning in large language models (LLMs). A proven approach for scaling inference compute is to generate long chains-of-thought (CoTs), enabling models to engage in structured reasoning strategies such as backtracking and error correction. Reinforcement learning (RL) has emerged as a crucial method for developing these capabilities, yet the conditions under which long CoTs emerge remain unclear, and RL training requires careful design choices. In this study, we systematically investigate the underlying *mechanics of long CoT reasoning*—examining the factors that enable models to generate extended reasoning trajectories. Through extensive supervised fine-tuning (SFT) and RL experiments, we identify three key findings: 1) while SFT is not strictly necessary, it significantly simplifies training and improves efficiency; 2) reasoning capabilities tend to emerge with increased training compute but are not guaranteed, making reward shaping essential for stabilizing CoT length growth; and 3) scaling verifiable reward signals is critical for RL, and we find that leveraging noisy, web-extracted solutions with filtering mechanisms shows promising potential, particularly in out-of-distribution (OOD) reasoning tasks such as STEM problem-solving. These insights provide practical guidance for optimizing training strategies to enhance long CoT reasoning in LLMs.","Large language models (LLMs) have made great progress in reasoning, especially with recent breakthroughs like OpenAI’s o1 and Deepseek R1's model. These models can now solve much harder problems — from advanced math to software engineering — by thinking in longer, more structured ways. They don’t just give answers; they reflect on their reasoning, correct mistakes, and explore different solution paths.In our work, we study how to train LLMs to reason this way. First, we show that teaching models with examples of long, step-by-step reasoning helps them reach higher performance and makes further training more effective. Second, we find that traditional training methods often struggle to extend reasoning in a stable way — so we design new rewards that encourage deeper thinking without the model becoming repetitive. Lastly, we explore using large but noisy datasets from the web to train models, and show that, with the right techniques, this “imperfect” data can still help models tackle unfamiliar, challenging tasks in science and engineering."
Poster,Demystifying Singular Defects in Large Language Models,https://ICML.cc//virtual/2025/poster/46453,"Haoqi Wang, Tong Zhang, Mathieu Salzmann","Large transformer models are known to produce high-norm tokens. In vision transformers (ViTs), such tokens have been mathematically modeled through the singular vectors of the linear approximations of layers. However, in large language models (LLMs), the underlying causes of high-norm tokens remain largely unexplored, and their different properties from those of ViTs require a new analysis framework. In this paper, we provide both theoretical insights and empirical validation across a range of recent models, leading to the following observations: i) The layer-wise singular direction predicts the abrupt explosion of token norms in LLMs. ii) The negative eigenvalues of a layer explain its sudden decay. iii) The computational pathways leading to high-norm tokens differ between initial and noninitial tokens. iv) High-norm tokens are triggered by the right leading singular vector of the matrix approximating the corresponding modules. We showcase two practical applications of these findings: the improvement of quantization schemes and the design of LLM signatures. Our findings not only advance the understanding of singular defects in LLMs but also open new avenues for their application. We expect that this work will stimulate further research into the internal mechanisms of LLMs. Code is released at https://github.com/haoqiwang/singular_defect.","Large Language Models (LLMs) are having a pronounced impact on society. Understanding their internal mechanism is thus very important. We gain more understanding of the high-norm phenomenon that appears in almost all contemporary LLMs. In the forward pass, the intermediate activations' norm is not uniformly distributed. Rather, the norms of a few tokens are extremely higher than the norms of other tokens. Interestingly, the directions of all these high-norm tokens are all the same: regardless of what the texts these tokens represent, which layer is in, and what location of the token within the text sequence.We give a mathematical description covering the full lifecycle of the high-norm phenomenon. (1) We distinguish two types of high-norm tokens, the initial high-norm token and the noninitial high-norm token, and explain their differences in their explosion path. (2) We describe how the explosion of norms happens by introducing the concept of the explosion subspace. (3) We can accurately predict the direction of the high-norm tokens by studying the linear approximation of the transformer layers. (4) We describe the decay of norms by the negative eigenvalues.Our insights lead to practical applications. First, we spot how the high-norm phenomenon affects the LLM quantization and propose an easy fix. Second, we design the signature of LLMs that can be used to trace the model lineage. The signature distinguishes whether an LLM was ﬁne-tuned from another model and detects model infringement. Ultimately, we believe that understanding singular defects will not only stimulate novel applications but also spur new insights into the internal mechanism of LLMs."
Poster,Demystifying the Paradox of Importance Sampling with an Estimated History-Dependent Behavior Policy in Off-Policy Evaluation,https://ICML.cc//virtual/2025/poster/46092,"Hongyi Zhou, Josiah Hanna, Jin Zhu, Ying Yang, Chengchun Shi","This paper studies off-policy evaluation (OPE) in reinforcement learning with a focus on behavior policy estimation for importance sampling. Prior work has shown empirically that estimating a history-dependent behavior policy can lead to lower mean squared error (MSE) even when the true behavior policy is Markovian. However, the question of *why* the use of history should lower MSE remains open. In this paper, we theoretically demystify this paradox by deriving a bias-variance decomposition of the MSE of ordinary importance sampling (IS) estimators, demonstrating that history-dependent behavior policy estimation  decreases their asymptotic variances while increasing their finite-sample biases. Additionally, as the estimated behavior policy conditions on a longer history, we show a consistent decrease in variance.  We extend these findings to a range of other OPE estimators, including the sequential IS estimator, the doubly robust estimator and the marginalized IS estimator, with the behavior policy estimated either parametrically or non-parametrically.","Evaluating reinforcement learning policies accurately is often required in A/B testing, which is frequently used in modern technology companies such as Amazon, eBay, Facebook, Google,  Microsoft, Uber for comparing new products/strategies against existing ones. A common method is importance sampling, which relies on estimating the treatment assignment mechanism for historical data. Interestingly, prior studies noticed that estimating this policy using more historical data leads to lower evaluation errors, but why this occurs wasn't clear.In this paper, we mathematically explain this phenomenon by breaking down the evaluation error into bias and variance components. Our analysis reveals that though including historical data slightly increases bias in small samples but asymptotically reduces variance overall. We also extend our theoretical findings to several widely-used policy evaluation methods, provides theoretical insights for applying our theory to practice."
Poster,Dendritic Localized Learning: Toward Biologically Plausible Algorithm,https://ICML.cc//virtual/2025/poster/45791,"Changze Lv, Jingwen Xu, Yiyang Lu, Xiaohua Wang, Zhenghua Wang, Zhibo Xu, Di Yu, Xin Du, Xiaoqing Zheng, Xuanjing Huang","Backpropagation is the foundational algorithm for training neural networks and a key driver of deep learning's success.However, its biological plausibility has been challenged due to three primary limitations: weight symmetry, reliance on global error signals, and the dual-phase nature of training, as highlighted by the existing literature. Although various alternative learning approaches have been proposed to address these issues, most either fail to satisfy all three criteria simultaneously or yield suboptimal results.Inspired by the dynamics and plasticity of pyramidal neurons, we propose Dendritic Localized Learning (DLL), a novel learning algorithm designed to overcome these challenges.Extensive empirical experiments demonstrate that DLL satisfies all three criteria of biological plausibility while achieving state-of-the-art performance among algorithms that meet these requirements.Furthermore, DLL exhibits strong generalization across a range of architectures, including MLPs, CNNs, and RNNs.These results, benchmarked against existing biologically plausible learning algorithms, offer valuable empirical insights for future research.We hope this study can inspire the development of new biologically plausible algorithms for training multilayer networks and advancing progress in both neuroscience and machine learning.Our code is available at https://github.com/Lvchangze/Dendritic-Localized-Learning.","Training AI often uses backpropagation, which works well but doesn't mimic how brains learn. Scientists note three key flaws: it requires unnatural symmetry in connections, relies on global error signals, and separates learning into distinct phases, unlike the brain's integrated process. While other methods tried to fix these, most fall short by either ignoring some flaws or performing poorly.This study introduces Dendritic Localized Learning (DLL), a brain-inspired approach modeled after how neurons’ branching structures (dendrites) adapt. Tests show DLL overcomes all three flaws while matching top AI performance. It works across diverse models, including those for images or language, and outperforms other biologically inspired methods.By bridging neuroscience and AI, DLL offers clues to how brains learn efficiently, potentially improving both AI systems and our understanding of biology. The researchers hope this sparks innovation in brain science and AI development. The code is freely available for others to use and build on."
Poster,Density Ratio Estimation-based Bayesian Optimization with Semi-Supervised Learning,https://ICML.cc//virtual/2025/poster/46666,Jungtaek Kim,"Bayesian optimization has attracted huge attention from diverse research areas in science and engineering, since it is capable of efficiently finding a global optimum of an expensive-to-evaluate black-box function. In general, a probabilistic regression model is widely used as a surrogate function to model an explicit distribution over function evaluations given an input to estimate and a training dataset. Beyond the probabilistic regression-based methods, density ratio estimation-based Bayesian optimization has been suggested in order to estimate a density ratio of the groups relatively close and relatively far to a global optimum. Developing this line of research further, supervised classifiers are employed to estimate a class probability for the two groups instead of a density ratio. However, the supervised classifiers used in this strategy are prone to be overconfident for known knowledge on global solution candidates. Supposing that we have access to unlabeled points, e.g., predefined fixed-size pools, we propose density ratio estimation-based Bayesian optimization with semi-supervised learning to solve this challenge. Finally, we show the empirical results of our methods and several baseline methods in two distinct scenarios with unlabeled point sampling and a fixed-size pool, and analyze the validity of our methods in diverse experiments.","Finding global solutions to problems involving expensive-to-evaluate black-box functions is a key research topic in science and engineering. Bayesian optimization is an effective method for addressing such problems, typically using a probabilistic regression model as a surrogate model. More recently, density ratio estimation-based Bayesian optimization has enabled the use of supervised classifiers. However, these classifiers tend to be overconfident for known knowledge on global solution candidates. To tackle this issue, we propose a density ratio estimation-based Bayesian optimization method with semi-supervised learning, making use of unlabeled data obtained from predefined fixed-size pools or unlabeled point sampling."
Poster,Density Ratio Estimation with Conditional Probability Paths,https://ICML.cc//virtual/2025/poster/45812,"Hanlin Yu, Arto Klami, Aapo Hyvarinen, Anna Korba, Lemir Omar Chehab","Density ratio estimation in high dimensions can be reframed as integrating a certain quantity, the time score, over probability paths which interpolate between the two densities. In practice, the time score has to be estimated based on samples from the two densities. However, existing methods for this problem remain computationally expensive and can yield inaccurate estimates. Inspired by recent advances in generative modeling, we introduce a novel framework for time score estimation, based on a conditioning variable. Choosing the conditioning variable judiciously enables a closed-form objective function. We demonstrate that, compared to previous approaches, our approach results in faster learning of the time score and competitive or better estimation accuracies of the density ratio on challenging tasks. Furthermore, we establish theoretical guarantees on the error of the estimated density ratio.","One of the classical machine learning tasks is learning a probability density from a collection of observations (e.g. images). The density associates each observation with positive number, a probability, indicating how typical he observation is in the context of the data. This is a highly challenging problem because we need to associate such probabilities for all possible observations, not just the ones available in the data. Density estimation is needed within several machine learning methods, and the topic remains a highly active area of research in the field. Advances in accuracy or computational efficiency will help several applications, for instance generative AI.We make contributions for an active line of density estimation research, for methods that solve the problem by contrasting the density of interest with some simpler density, learning the ratio of the associated probabilities. We identify both theoretical and practical limitations in recently proposed methods. We then present a new method that has theoretical guarantees on how accurately we can estimate the density, while also being faster to compute. Our paper focuses on the theory and experimental evaluation on relatively simple benchmark problems, while paving the way for larger scale applications."
Poster,Depth Degeneracy in Neural Networks: Vanishing Angles in Fully Connected ReLU Networks on Initialization,https://ICML.cc//virtual/2025/poster/46710,"Cameron Jakub, Mihai Nica","Despite remarkable performance on a variety of tasks, many properties of deep neural networks are not yet theoretically understood. One such mystery is the depth degeneracy phenomenon: the deeper you make your network, the closer your network is to a constant function on initialization. In this paper, we examine the evolution of the angle between two inputs to a ReLU neural network as a function of the number of layers. By using combinatorial expansions, we find precise formulas for how fast this angle goes to zero as depth increases. These formulas capture microscopic fluctuations that are not visible in the popular framework of infinite width limits, and leads to qualitatively different predictions. We validate our theoretical results with Monte Carlo experiments and show that our results accurately approximate finite network behaviour. We also empirically investigate how the depth degeneracy phenomenon can negatively impact training of real networks. The formulas are given in terms of the mixed moments of correlated Gaussians passed through the ReLU function. We also find a surprising combinatorial connection between these mixed moments and the Bessel numbers that allows us to explicitly evaluate these moments.",
Poster,Dequantified Diffusion-Schrödinger Bridge for Density Ratio Estimation,https://ICML.cc//virtual/2025/poster/43448,"Wei Chen, Shigui Li, Jiacheng Li, Junmei Yang, John Paisley, Delu Zeng","Density ratio estimation is fundamental to tasks involving f-divergences, yet existing methods often fail under significantly different distributions or inadequately overlapping supports --- the density-chasm and the support-chasm problems.Additionally, prior approaches yield divergent time scores near boundaries, leading to instability.We design $\textbf{D}^3\textbf{RE}$, a unified framework for robust, stable and efficient density ratio estimation.We propose the dequantified diffusion bridge interpolant (DDBI), which expands support coverage and stabilizes time scores via diffusion bridges and Gaussian dequantization.Building on DDBI, the proposed dequantified Schr{\""o}dinger bridge interpolant (DSBI) incorporates optimal transport to solve the Schr{\""o}dinger bridge problem, enhancing accuracy and efficiency.Our method offers uniform approximation and bounded time scores in theory, and outperforms baselines empirically in mutual information and density estimation tasks.","In machine learning, it's often important to understand how two probability distributions differ — for example, when comparing real-world data with a model's predictions. A key tool for this is density ratio estimation, which compares the likelihoods of data points under two different distributions. However, existing methods often fail when the distributions are very different or don’t overlap well, leading to inaccurate or unstable results.We developed a new method called D³RE that can estimate these differences more robustly, stably, and efficiently. At the heart of our approach is a technique that uses noise and simulated particle movement — like watching smoke spread in the air — to better connect and compare the datasets. We also incorporate ideas from optimal transport, which helps find the most efficient way to shift one distribution to match another.Our method not only avoids the pitfalls of previous approaches but also achieves better accuracy on tasks like estimating mutual information and learning probability models. This makes it a valuable tool for improving reliability in many machine learning applications."
Poster,Design Considerations in Offline Preference-based RL,https://ICML.cc//virtual/2025/poster/46539,"Alekh Agarwal, Christoph Dann, Teodor Vanislavov Marinov","Offline algorithms for Reinforcement Learning from Human Preferences (RLHF), which use only a fixed dataset of sampled responses given an input, and preference feedback among these responses, have gained increasing prominence in the literature on aligning language models. In this paper, we study how the different design choices made in methods such as DPO, IPO, SLiC and many variants influence the quality of the learned policy, from a theoretical perspective. Our treatment yields insights into the choices of loss function, the policy which is used to normalize log-likelihoods, and also the role of the data sampling policy. Notably, our results do not rely on the standard reparameterization-style arguments used to motivate some of the algorithms in this family, which allows us to give a unified treatment to a broad class of methods. We also conduct a small empirical study to verify some of the theoretical findings on a standard summarization benchmark.","This work provides a theoretical analysis of offline methods for Reinforcement Learning from Human Preferences (RLHF), a post-training technique used to improve language models. We examine how different design choices in algorithms like DPO, IPO, and SLiC impact the quality of the learned policy by providing a general framework for a broad range of offline RLHF techniques. In particular we demonstrate both through theory and empirical evaluation on a text summarization task that the choice of loss function and reference policy are critical. Specifically, the squared loss used by IPO outperforms the logistic loss of DPO because it has better curvature properties, leading to more stable training and preventing catastrophic collapse suffered by DPO where the model's performance degrades sharply after an initial improvement.  Our findings suggest that careful selection of the loss function and ensuring the training data sufficiently covers a wide range of possible responses are crucial for successfully and reliably training preference-aligned models."
Poster,Designing Cyclic Peptides via Harmonic SDE with Atom-Bond Modeling,https://ICML.cc//virtual/2025/poster/45948,"Xiangxin Zhou, Mingyu Li, xiao yi, Jiahan Li, Dongyu Xue, Zaixiang Zheng, Jianzhu Ma, Quanquan Gu","Cyclic peptides offer inherent advantages in pharmaceuticals. For example, cyclic peptides are more resistant to enzymatic hydrolysis compared to linear peptides and usually exhibit excellent stability and affinity. Although deep generative models have achieved great success in linear peptide design, several challenges prevent the development of computational methods for designing diverse types of cyclic peptides. These challenges include the scarcity of 3D structural data on target proteins and associated cyclic peptide ligands, the geometric constraints that cyclization imposes, and the involvement of non-canonical amino acids in cyclization. To address the above challenges, we introduce CpSDE, which consists of two key components: AtomSDE, a generative structure prediction model based on harmonic SDE, and ResRouter, a residue type predictor. Utilizing a routed sampling algorithm that alternates between these two models to iteratively update sequences and structures, CpSDE facilitates the generation of cyclic peptides. By employing explicit all-atom and bond modeling, CpSDE overcomes existing data limitations and is proficient in designing a wide variety of cyclic peptides.Our experimental results demonstrate that the cyclic peptides designed by our method exhibit reliable stability and affinity.","Cyclic peptides are tiny, ring-shaped proteins that show a lot of potential for medicine. Their circular form helps them stay stable and prevents them from easily breaking down in the body, unlike the more common linear peptides. However, designing them using computers presents unique challenges. These challenges include the lack of detailed 3D structures of proteins and cyclic peptides, the complex shapes required for cyclization, and the use of uncommon amino acids.To overcome these challenges, we have created a novel approach called CpSDE. This approach uses two main tools: AtomSDE, which predicts the structure of these peptides, and ResRouter, which determines the type of amino acids to use. By using a back-and-forth method between these two tools, CpSDE can effectively design new cyclic peptides.Our research shows that the cyclic peptides generated with CpSDE are not only stable but also maintain high levels of effectiveness, making them strong candidates for future pharmaceutical developments."
