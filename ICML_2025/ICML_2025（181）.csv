type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Maximum Update Parametrization and Zero-Shot Hyperparameter Transfer for Fourier Neural Operators,https://ICML.cc//virtual/2025/poster/44531,"Shanda Li, Shinjae Yoo, Yiming Yang","Fourier Neural Operators (FNOs) offer a principled approach for solving complex partial differential equations (PDEs). However, scaling them to handle more complex PDEs requires increasing the number of Fourier modes, which significantly expands the number of model parameters and makes hyperparameter tuning computationally impractical. To address this, we introduce $\mu$**Transfer-FNO**, a zero-shot hyperparameter transfer technique that enables optimal configurations, tuned on smaller FNOs, to be directly applied to billion-parameter FNOs _without_ additional tuning. Building on the Maximum Update Parametrization ($\mu$P) framework, we mathematically derive a parametrization scheme that facilitates the transfer of optimal hyperparameters across models with different numbers of Fourier modes in FNOs, which is validated through extensive experiments on various PDEs. Our empirical study shows that $\mu$Transfer-FNO reduces computational cost for tuning hyperparameters on large FNOs while maintaining or improving accuracy.","Scientists use special computer programs called neural networks to solve complex physics equations that describe things like fluid flow, heat transfer, and wave propagation. To handle more complex problems, these programs need to become much larger, but finding the right training settings becomes prohibitively expensive - sometimes requiring months of computer time. Our research solves this with a mathematical discovery: by adjusting certain numbers in a specific way when scaling up the program, the optimal training settings remain constant. This means we can find the best settings using a small, inexpensive version of the program, then apply those same settings to train a much larger version - like using a recipe for a small cake to successfully bake a wedding cake. Testing our approach on fluid dynamics problems, we successfully train programs with nearly one billion parameters while using only 30% of the traditional computational cost, making powerful physics simulators accessible to researchers without breaking computing budgets."
Poster,MCU: An Evaluation Framework for Open-Ended Game Agents,https://ICML.cc//virtual/2025/poster/44393,"Xinyue Zheng, Haowei Lin, Kaichen He, Zihao Wang, Qiang Fu, Haobo Fu, Zilong Zheng, Yitao Liang","Developing AI agents capable of interacting with open-world environments to solve diverse tasks is a compelling challenge. However, evaluating such open-ended agents remains difficult, with current benchmarks facing scalability limitations. To address this, we introduce \textit{Minecraft Universe} (MCU), a comprehensive evaluation framework set within the open-world video game Minecraft. MCU incorporates three key components: (1) an expanding collection of 3,452 composable atomic tasks that encompasses 11 major categories and 41 subcategories of challenges; (2) a task composition mechanism capable of generating infinite diverse tasks with varying difficulty; and (3) a general evaluation framework that achieves 91.5\% alignment with human ratings for open-ended task assessment. Empirical results reveal that even state-of-the-art foundation agents struggle with the increasing diversity and complexity of tasks. These findings highlight the necessity of MCU as a robust benchmark to drive progress in AI agent development within open-ended environments. Our evaluation code and scripts are available at https://github.com/CraftJarvis/MCU.","Developing AI agents that can handle open-ended tasks in dynamic environments, like video games, is a major challenge in artificial intelligence. However, evaluating these agents is difficult due to the lack of scalable and diverse benchmarks. To address this, we introduce *Minecraft Universe* (MCU), a comprehensive evaluation framework set in the popular game Minecraft.  MCU includes thousands of customizable tasks, ranging from simple actions like mining resources to complex challenges like building structures or crafting items. It also features an automated evaluation system that aligns closely with human judgments, making it efficient and reliable. Our experiments show that even the most advanced AI agents struggle with the diversity and complexity of these tasks, highlighting the need for robust benchmarks like MCU to drive progress in AI development.  By providing a standardized testing ground, MCU helps researchers create more adaptable and intelligent agents, bringing us closer to AI that can navigate real-world unpredictability."
Poster,MDDM: Practical Message-Driven Generative Image Steganography Based on Diffusion Models,https://ICML.cc//virtual/2025/poster/45483,"Zihao Xu, Dawei xu, Zihan Li, Chuan Zhang","Generative image steganography (GIS) is an emerging technique that conceals secret messages in the generation of images. Compared to GAN-based or flow-based GIS schemes, diffusion model-based solutions can provide high-quality and more diverse images, thus receiving considerable attention recently. However, previous GIS schemes still face challenges in terms of extraction accuracy, controllability, and practicality. To address the above issues, this paper proposes a practical message-driven GIS framework based on diffusion models, called MDDM. Specifically, by utilizing Cardan Grille, we encode messages into Gaussian noise, which serves as the initial input for image generation, enabling users to generate diverse images via controllable prompts without additional training. During the information extraction process, receivers only need to use the pre-shared Cardan Grille to perform exact diffusion inversion and recover the messages without requiring the image generation seeds or prompts. Experimental results demonstrate that MDDM offers notable advantages in terms of accuracy, controllability, practicality, and security. With flexible strategies, MDDM can always achieve almost 100\% accuracy. Additionally, MDDM demonstrates certain robustness and exhibits potential for application in watermarking tasks.","Image steganography is a common method to hide information in images, but traditional methods may not be secure and reliable enough. With the widespread popularity of AI-generated images, generative image steganography could be a future trend. We have constructed a generative image steganography based on a diffusion model, which can generate arbitrary images for arbitrary messages, just like normal image generation. Our method does not require any training and will be beneficial for future steganography research and applications."
Poster,Measuring Diversity: Axioms and Challenges,https://ICML.cc//virtual/2025/poster/46567,"Mikhail Mironov, Liudmila Prokhorenkova","This paper addresses the problem of quantifying diversity for a set of objects. First, we conduct a systematic review of existing diversity measures and explore their undesirable behavior in certain cases. Based on this review, we formulate three desirable properties (axioms) of a reliable diversity measure: monotonicity, uniqueness, and continuity. We show that none of the existing measures has all three properties and thus these measures are not suitable for quantifying diversity. Then, we construct two examples of measures that have all the desirable properties, thus proving that the list of axioms is not self-contradictory. Unfortunately, the constructed examples are too computationally expensive (NP-hard) for practical use. Thus, we pose an open problem of constructing a diversity measure that has all the listed properties and can be computed in practice or proving that all such measures are NP-hard to compute.","How can one measure diversity of a set of objects, like images, molecules, or recommendations? The need for reliable diversity measures arises because diverse outputs are critical in applications like AI-generated content and recommender systems, where variety enhances creativity and user satisfaction. We review existing diversity measures and find that they may behave unpredictably, failing to capture true diversity. To formally analyze this, we define three essential qualities for a good diversity measure: monotonicity, ensuring diversity increases as objects become more distinct; uniqueness, meaning duplicates reduce diversity compared to unique items; and continuity, requiring small changes in diversity with small changes in object differences. Our analysis shows that no current measure meets all three requirements. Finally, we design two new measures that satisfy these qualities, but they are too complex for practical use. This creates an open challenge: developing a diversity measure that has desirable qualities and is computationally practical for real-world applications."
Poster,Measuring Diversity in Synthetic Datasets,https://ICML.cc//virtual/2025/poster/46014,"Yuchang Zhu, Huizhe Zhang, Bingzhe Wu, Jintang Li, Zibin Zheng, Peilin Zhao, Liang Chen, Yatao Bian","Large language models (LLMs) are widely adopted to generate synthetic datasets for various natural language processing (NLP) tasks, such as text classification and summarization. However, accurately measuring the diversity of these synthetic datasets—an aspect crucial for robust model performance—remains a significant challenge. In this paper, we introduce DCScore, a novel method for measuring synthetic dataset diversity from a classification perspective. Specifically, DCScore formulates diversity evaluation as a sample classification task, leveraging mutual relationships among samples. We further provide theoretical verification of the diversity-related axioms satisfied by DCScore, highlighting its role as a principled diversity evaluation method. Experimental results on synthetic datasets reveal that DCScore enjoys a stronger correlation with multiple diversity pseudo-truths of evaluated datasets, underscoring its effectiveness. Moreover, both empirical and theoretical evidence demonstrate that DCScore substantially reduces computational costs compared to existing methods. Code is available at: https://github.com/bluewhalelab/dcscore.","The evaluation of diversity in synthetic datasets produced by large language models (LLMs) presents a crucial challenge in facilitating their effective utilization. To address this challenge, we introduce DCScore, a novel method for evaluating diversity from a classification perspective.Our investigation reveals that the fundamental determinant of synthetic dataset diversity evaluation lies in sample discriminability—a property inherently addressed by classification methodologies. Consequently, we formalize diversity evaluation as a sample classification task through our proposed DCScore framework. Surprisingly, we found that DCScore worked well in the diversity evaluation of synthetic datasets while presenting lower computational costs.With the increasing usage of synthetic datasets in next-generation LLM training, evaluating data quality—particularly regarding diversity—emerges as a critical requirement. DCScore provides an effective solution for diversity evaluation, thereby promoting more widespread and reliable use of synthetic data in advanced language modeling applications."
Poster,Measuring In-Context Computation Complexity via Hidden State Prediction,https://ICML.cc//virtual/2025/poster/44985,"Vincent Herrmann, Róbert Csordás, Jürgen Schmidhuber","Detecting when a neural sequence model does ""interesting"" computation is an open problem. The next token prediction loss is a poor indicator: Low loss can stem from trivially predictable sequences that are uninteresting, while high loss may reflect unpredictable but also irrelevant information that can be ignored by the model. We propose a better metric: measuring the model's ability to predict its own future hidden states. We show empirically that this metric–in contrast to the next token prediction loss–correlates with the intuitive interestingness of the task. To measure predictability, we introduce the architecture-agnostic ""prediction of hidden states"" (PHi) layer that serves as an information bottleneck on the main pathway of the network (e.g., the residual stream in Transformers). We propose a novel learned predictive prior that enables us to measure the novel information gained in each computation step, which serves as our metric. We show empirically that our metric predicts the description length of formal languages learned in-context, the complexity of mathematical reasoning problems, and the correctness of self-generated reasoning chains.","Large language models, like ChatGPT, have become very powerful—in large part due to their capability to learn _in-context_. This means that these models can make novel inferences at test time. We propose a method that pinpoints when, and to what extent, such a model performs this kind of inference. In other words, we detect when a model is 'thinking hard'. We accomplish this by measuring how predictable the model's current internal states are, given previous states: if they are predictable, no information has been gained. But if they aren't, that means that the model has made new inferences. This method gives us insight into which tasks are challenging and interesting for a model, in the sense of requiring complex in-context computation. Intriguingly, we find that for reasoning tasks, such as solving a complex mathematical problem, the 'in-context computation complexity' as measured by our method is predictive of whether the model will arrive at the correct solution. This is particularly true for difficult problems where more 'thought' is required."
Poster,Measuring Representational Shifts in Continual Learning: A Linear Transformation Perspective,https://ICML.cc//virtual/2025/poster/45616,"Joonkyu Kim, Yejin Kim, Jy-yong Sohn","In continual learning scenarios, catastrophic forgetting of previously learned tasks is a critical issue, making it essential to effectively measure such forgetting. Recently, there has been growing interest in focusing on representation forgetting, the forgetting measured at the hidden layer. In this paper, we provide the first theoretical analysis of representation forgetting and use this analysis to better understand the behavior of continual learning. First, we introduce a new metric called representation discrepancy, which measures the difference between representation spaces constructed by two snapshots of a model trained through continual learning. We demonstrate that our proposed metric serves as an effective surrogate for the representation forgetting while remaining analytically tractable. Second, through mathematical analysis of our metric, we derive several key findings about the dynamics of representation forgetting: the forgetting occurs more rapidly to a higher degree as the layer index increases, while increasing the width of the network slows down the forgetting process. Third, we support our theoretical findings through experiments on real image datasets, including Split-CIFAR100 and ImageNet1K.","Artificial intelligence (AI) models often struggle to retain past knowledge when they are trained on new tasks one after another—a problem known as catastrophic forgetting. While recent studies have shown that this forgetting happens not just in the model's output but deep within its internal representations, understanding this process mathematically has remained a challenge.Our research introduces a new, easy-to-analyze metric called representation discrepancy to track how much the internal knowledge of an AI model changes over time. This allows us to study the model’s “memory” more precisely. Using this metric, we found that forgetting happens faster in deeper layers of the network and that wider networks tend to forget less.Our work offers new insights into how AI models learn—and forget—over time. This understanding is a key step toward building smarter, more reliable AI systems that can learn continuously without losing what they’ve already mastered."
Poster,Measuring Variable Importance in Heterogeneous Treatment Effects with Confidence,https://ICML.cc//virtual/2025/poster/45766,"Joseph Paillard, Angel REYERO LOBO, Vitaliy Kolodyazhniy, Thirion Bertrand, Denis-Alexander Engemann","Causal machine learning (ML) promises to provide powerful tools for estimating individual treatment effects. While causal methods have placed some emphasis on heterogeneity in treatment response, it is of paramount importance to clarify the nature of this heterogeneity, by highlighting which variables drive it.We propose PermuCATE, an algorithm based on the Conditional Permutation Importance (CPI) method, for statistically rigorous global variable importance assessment in the estimation of the Conditional Average Treatment Effect (CATE).Theoretical analysis of the finite sample regime and empirical studies show that PermuCATE has lower variance than the Leave-One-Covariate-Out (LOCO) method and provides a reliable measure of variable importance.This property increases statistical power, which is crucial for causal inference applications with finite sample sizes.We empirically demonstrate the benefits of PermuCATE in simulated and real datasets, including complex settings with high-dimensional, correlated variables.","The same treatment can have varying effects across different individuals. For example, medicines may be more effective for certain subgroups within a population, while potentially causing adverse events in others. Although precision medicine has advanced in predicting how treatments will work for individuals, understanding why these differences occur remains a challenge.Our work tackles this problem by exploring methods that identify which characteristics of a population contribute to this heterogeneity in treatment effects. We focus on methods that reduce the risk of false discoveries—incorrectly suggesting that a characteristic is important when it is not. Additionally, we consider approaches suitable for situations with limited data, which is often the case in medical research.Our findings offer guidance on selecting the most suitable method for understanding what drives heterogeneity in treatment effects.  This could lead to better insights into risk factors for adverse reactions and help in prevention by pinpointing characteristics linked to improved health outcomes for specific groups."
Poster,Mechanisms of Projective Composition of Diffusion Models,https://ICML.cc//virtual/2025/poster/45339,"Arwen Bradley, Preetum Nakkiran, David Berthelot, James Thornton, Joshua M Susskind","We study the theoretical foundations of composition in diffusion models, with a particular focus on out-of-distribution extrapolation and length-generalization. Prior work has shown that composing distributions via linear score combination can achieve promising results, including length-generalization in some cases (Du et al., 2023; Liu et al., 2022). However, our theoretical understanding of how and why such compositions work remains incomplete. In fact, it is not even entirely clear what it means for composition to ""work"". This paper starts to address these fundamental gaps. We begin by precisely defining one possible desired result of composition, which we call *projective composition*. Then, we investigate: (1) when linear score combinations provably achieve projective composition, (2) whether reverse-diffusion sampling can generate the desired composition, and (3) the conditions under which composition fails. We connect our theoretical analysis to prior empirical observations where composition has either worked or failed, for reasons that were unclear at the time. Finally, we propose a simple heuristic to help predict the success or failure of new compositions.","Diffusion composition enables generation of images combining multiple concepts (like ""dog wearing hat"") by adding together outputs from separate concept models (""dog"", ""wearing hat""). This simple approach sometimes works remarkably well, even for complex combinations, but can unexpectedly fail in other cases. Our research precisely defines what ""successful composition"" means mathematically and analyzes when linear combination of model outputs achieves the desired result. We identify conditions where this approach succeeds or fails. This theoretical framework explains previously puzzling observations about compositional generation and provides clear principles for developing more reliable diffusion models that can predictably blend concepts in ways that match our expectations."
Poster,Mechanistic PDE Networks for Discovery of Governing Equations,https://ICML.cc//virtual/2025/poster/46301,"Adeel Pervez, Efstratios Gavves, Francesco Locatello","We present Mechanistic PDE Networks -- a model for discovery of governing *partial differential equations* from data.Mechanistic PDE Networks represent spatiotemporal data as space-time dependent *linear* partial differential equations in neural network hidden representations. The represented PDEs are then solved and decoded for specific tasks. The learned PDE representations naturally express the spatiotemporal dynamics in data in neural network hidden space, enabling increased modeling power. Solving the PDE representations in a compute and memory-efficient way, however, is a significant challenge. We develop a native, GPU-capable, parallel, sparse and differentiable multigrid solver specialized for linear partial differential equations that acts as a module in Mechanistic PDE Networks. Leveraging the PDE solver we propose a discovery architecture that can discovers nonlinear PDEs in complex settings, while being robust to noise. We validate PDE discovery on a number of PDEs including reaction-diffusion and Navier-Stokes equations.","Scientists use observations of natural phenomena to develop general laws that describe the observed phenomena. This process is manual, time consuming and increasing difficult as the amount of available data increases at a fast rate. Machine learning is a tool that can help scientists manage the vast amounts of data. We develop a method for discovery of natural laws directly from data, helping scientists to quickly develop and test theories. We develop our method by combining the structure of scientific laws and data driven methods. The resulting techniques allow scientists to test more complex data and represent more complex equations than prior methods."
