type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Winner-takes-all for Multivariate Probabilistic Time Series Forecasting,https://ICML.cc//virtual/2025/poster/46485,"Adrien Cortes, Remi Rehm, Victor Letzelter","We introduce $\texttt{TimeMCL}$, a method leveraging the Multiple Choice Learning (MCL) paradigm to forecast multiple plausible time series futures. Our approach employs a neural network with multiple heads and utilizes the Winner-Takes-All (WTA) loss to promote diversity among predictions. MCL has recently gained attention due to its simplicity and ability to address ill-posed and ambiguous tasks. We propose an adaptation of this framework for time-series forecasting, presenting it as an efficient method to predict diverse futures, which we relate to its implicit *quantization* objective. We provide insights into our approach using synthetic data and evaluate it on real-world time series, demonstrating its promising performance at a light computational cost.","When we try to predict what might happen in the future based on past data, we often find that there isn’t just one “right” answer — there could be several possible future scenarios. In this work, we introduce TimeMCL, a method that helps machines to predict multiple plausible futures for a time series, such as weather data or stock prices.TimeMCL builds on a technique called Multiple Choice Learning (MCL), which trains a computer model to generate a diverse set of predictions rather than focusing on a single outcome. To make sure these predictions are truly different and not just minor variations, we use a special “Winner-Takes-All” approach that updates only the best-performing prediction for each example.We tested this idea with both simulated and real-world data and found that TimeMCL can provide accurate and varied predictions without needing a lot of computing power."
Poster,WMAdapter: Adding WaterMark Control to Latent Diffusion Models,https://ICML.cc//virtual/2025/poster/43575,"Hai Ci, Yiren Song, Pei Yang, Jinheng Xie, Mike Zheng Shou","Watermarking is essential for protecting the copyright of AI-generated images. We propose WMAdapter, a diffusion model watermark plugin that embeds user-specified watermark information seamlessly during the diffusion generation process. Unlike previous methods that modify diffusion modules to incorporate watermarks, WMAdapter is designed to keep all diffusion components intact, resulting in sharp, artifact-free images. To achieve this, we introduce two key innovations: (1) We develop a contextual adapter that conditions on the content of the cover image to generate adaptive watermark embeddings. (2) We implement an additional finetuning step and a hybrid finetuning strategy that suppresses noticeable artifacts while preserving the integrity of the diffusion components. Empirical results show that WMAdapter provides strong flexibility, superior image quality, and competitive watermark robustness.","AI-generated images are increasingly at risk of misuse, raising concerns about copyright protection. We created WMAdapter, a tool that invisibly marks images during generation without affecting their quality. This helps creators prove ownership and protect their work, offering a simple and effective solution for safeguarding AI-generated content."
Poster,WMarkGPT: Watermarked Image Understanding via Multimodal Large Language Models,https://ICML.cc//virtual/2025/poster/45767,"Tan Songbai, Xuerui Qiu, Yao Shu, Gang Xu, Linrui Xu, Xiangyu Xu, HUIPING ZHUANG, Ming Li, Fei Yu","Invisible watermarking is widely used to protect digital images from unauthorized use. Accurate assessment of watermarking efficacy is crucial for advancing algorithmic development. However, existing statistical metrics, such as PSNR, rely on access to original images, which are often unavailable in text-driven generative watermarking and fail to capture critical aspects of watermarking, particularly visibility. More importantly, these metrics fail to account for potential corruption of image content. To address these limitations, we propose WMarkGPT, the first multimodal large language model (MLLM) specifically designed for comprehensive watermarked image understanding, without accessing original images. WMarkGPT not only predicts watermark visibility but also generates detailed textual descriptions of its location, content, and impact on image semantics, enabling a more nuanced interpretation of watermarked images. Tackling the challenge of precise location description and understanding images with vastly different content, we construct three visual question-answering (VQA) datasets: an object location-aware dataset, a synthetic watermarking dataset, and a real watermarking dataset. We introduce a meticulously designed three-stage learning pipeline to progressively equip WMarkGPT with the necessary abilities. Extensive experiments on synthetic and real watermarking QA datasets demonstrate that WMarkGPT outperforms existing MLLMs, achieving significant improvements in visibility prediction and content description. The datasets and code are released at https://github.com/TanSongBai/WMarkGPT.","Digital watermarks are hidden markers used to protect images from misuse, but it's hard to measure how well they work without comparing them to the original image. Current methods also don't fully assess how visible the watermark is or how it affects the image's content.To solve this, we created WMarkGPT, the first multimodal large language model that can analyze watermarked images without needing the original. It not only detects how noticeable the watermark is but also describes its location, content, and impact on the image in detail—like explaining if it distorts a person's face or blends into the background.To train WMarkGPT, we built three specialized datasets and developed a step-by-step learning process to teach the model these skills. Tests show it outperforms other AI models in judging watermark visibility and describing images accurately."
Poster,Wolfpack Adversarial Attack for Robust Multi-Agent Reinforcement Learning,https://ICML.cc//virtual/2025/poster/46646,"Sunwoo Lee, Jaebak Hwang, Yonghyeon Jo, Seungyul Han","Traditional robust methods in multi-agent reinforcement learning (MARL) often struggle against coordinated adversarial attacks in cooperative scenarios. To address this limitation, we propose the Wolfpack Adversarial Attack framework, inspired by wolf hunting strategies, which targets an initial agent and its assisting agents to disrupt cooperation. Additionally, we introduce the Wolfpack-Adversarial Learning for MARL (WALL) framework, which trains robust MARL policies to defend against the proposed Wolfpack attack by fostering system-wide collaboration. Experimental results underscore the devastating impact of the Wolfpack attack and the significant robustness improvements achieved by WALL. Our code is available at https://github.com/sunwoolee0504/WALL.","AI systems where many agents work together are used in real-world settings, but unexpected problems like sensor errors or lost signals can break their coordination. Some training methods add small disturbances to help agents prepare, but these attacks usually target only one agent, making it easy for others to adapt by helping. Inspired by how wolves hunt in packs, we introduce a “Wolfpack” attack that targets one agent and the teammates who try to help, making it harder for the team to stay organized. We also propose a method to select critical moment to apply the attack during training. In addition, we introduce WALL, a training approach that helps agents build flexible teamwork and recover quickly. Our approach enables more adaptive cooperation and resilience in real-world situations."
Poster,WOMD-Reasoning: A Large-Scale Dataset for Interaction Reasoning in Driving,https://ICML.cc//virtual/2025/poster/44199,"Yiheng Li, Cunxin Fan, Chongjian GE, Seth Zhao, Chenran Li, Chenfeng Xu, Huaxiu Yao, Masayoshi Tomizuka, Bolei Zhou, Chen Tang, Mingyu Ding, Wei Zhan","Language models uncover unprecedented abilities in analyzing driving scenarios, owing to their limitless knowledge accumulated from text-based pre-training. Naturally, they should particularly excel in analyzing rule-based interactions, such as those triggered by traffic laws, which are well documented in texts. However, such interaction analysis remains underexplored due to the lack of dedicated language datasets that address it. Therefore, we propose Waymo Open Motion Dataset-Reasoning (WOMD-Reasoning), a comprehensive large-scale Q&As dataset built on WOMD focusing on describing and reasoning traffic rule-induced interactions in driving scenarios. WOMD-Reasoning also presents by far the largest multi-modal Q&A dataset, with 3 million Q&As on real-world driving scenarios, covering a wide range of driving topics from map descriptions and motion status descriptions to narratives and analyses of agents' interactions, behaviors, and intentions. To showcase the applications of WOMD-Reasoning, we design Motion-LLaVA, a motion-language model fine-tuned on WOMD-Reasoning. Quantitative and qualitative evaluations are performed on WOMD-Reasoning dataset as well as the outputs of Motion-LLaVA, supporting the data quality and wide applications of WOMD-Reasoning, in interaction predictions, traffic rule compliance plannings, etc. The dataset and its vision modal extension are available on https://waymo.com/open/download/. The codes & prompts to build it are available on https://github.com/yhli123/WOMD-Reasoning.","Understanding how vehicles interact on the road - especially when traffic rules are involved - is key in building safe and intelligent driving systems. Today’s language-assisted driving models still struggle with analyzing these situations because there are few training data which can capture the traffic-rule-based interactions.To fix this, we create WOMD-Reasoning, the largest-ever dataset of driving questions and answers built on real-world traffic data. It includes 3 million Q&A examples that describe maps, vehicle movements, and agent interactions, especially those influenced by traffic rules. Unlike past efforts, our dataset focuses not just on what is happening, but why - providing context and reasoning behind road behaviors. We also introduce Motion-LLaVA, a model trained on WOMD-Reasoning, which can understand and explain driving scenarios in a more rule-aware manner. Thanks to the WOMD-Reasoning dataset, our model demonstrates strong performance in predicting interactions and enabling safer, rule-compliant planning.Our work lays the groundwork for more explainable and regulation-aware AI systems in autonomous driving. All data and tools are freely available to the research community."
Poster,World Model Implanting for Test-time Adaptation of Embodied Agents,https://ICML.cc//virtual/2025/poster/43758,"Minjong Yoo, Jinwoo Jang, Sihyung Yoon, Honguk Woo","In embodied AI, a persistent challenge is enabling agents to robustly adapt to novel domains without requiring extensive data collection or retraining. To address this, we present a world model implanting framework (WorMI) that combines the reasoning capabilities of large language models (LLMs) with independently learned, domain-specific world models through test-time composition. By allowing seamless implantation and removal of the world models, the embodied agent's policy achieves and maintains cross-domain adaptability. In the WorMI framework, we employ a prototype-based world model retrieval approach, utilizing efficient trajectory-based abstract representation matching, to incorporate relevant models into test-time composition. We also develop a world-wise compound attention method that not only integrates the knowledge from the retrieved world models but also aligns their intermediate representations with the reasoning model's representation within the agent's policy. This framework design effectively fuses domain-specific knowledge from multiple world models, ensuring robust adaptation to unseen domains. We evaluate our WorMI on the VirtualHome and ALFWorld benchmarks, demonstrating superior zero-shot and few-shot performance compared to several LLM-based approaches across a range of unseen domains. These results highlight the framework’s potential for scalable, real-world deployment in embodied agent scenarios where adaptability and data efficiency are essential.","Robots and virtual assistants often stumble when they are moved from a home environment—where they were trained—to a brand-new setting. Gathering fresh data or retraining them every time is costly and slow. We tackle this by giving the agent a “plug-and-play memory” called WorMI (World-Model Implanting). WorMI lets a large language model reason as usual while seamlessly adding or removing smaller, specialist world models, each learned in a different domain (like a kitchen, a workshop, or a game). At test time the agent quickly retrieves the most relevant specialists using compact prototype taken from its recent experience, then fuses their knowledge with a new attention mechanism that keeps all pieces talking to one another. Because nothing is retrained, the agent adapts on the fly, even to places it has never seen. In two challenging benchmarks, WorMI outperforms other zero-shot and few-shot methods, showing that this modular approach could make future household robots and game characters far more flexible without endless data collection."
Poster,WorldSimBench: Towards Video Generation Models as World Simulators,https://ICML.cc//virtual/2025/poster/44315,"Yiran Qin, Zhelun Shi, Jiwen Yu, Xijun Wang, Enshen Zhou, Lijun Li, Zhenfei Yin, Xihui Liu, Lu Sheng, Jing Shao, LEI BAI, Ruimao Zhang","Recent advancements in predictive models have demonstrated exceptional capabilities in predicting the future state of objects and scenes. However, the lack of categorization based on inherent characteristics continues to hinder the progress of predictive model development. Additionally, existing benchmarks are unable to effectively evaluate higher-capability, highly embodied predictive models from an embodied perspective. In this work, we classify the functionalities of predictive models into a hierarchy and take the first step in evaluating World Simulators by proposing a dual evaluation framework called WorldSimBench. WorldSimBench includes Explicit Perceptual Evaluation and Implicit Manipulative Evaluation, encompassing human preference assessments from the visual perspective and action-level evaluations in embodied tasks, covering three representative embodied scenarios: Open-Ended Embodied Environment, Autonomous, Driving, and Robot Manipulation. In the Explicit Perceptual Evaluation, we introduce the HF-Embodied Dataset, a video assessment dataset based on fine-grained human feedback, which we use to train a Human Preference Evaluator that aligns with human perception and explicitly assesses the visual fidelity of World Simulater. In the Implicit Manipulative Evaluation, we assess the video-action consistency of World Simulators by evaluating whether the generated situation-aware video can be accurately translated into the correct control signals in dynamic environments. Our comprehensive evaluation offers key insights that can drive further innovation in video generation models, positioning World Simulators as a pivotal advancement toward embodied artificial intelligence.","Predictive models are becoming increasingly powerful at forecasting how objects and environments evolve over time. Yet, it's still unclear how to systematically measure their capabilities—especially when these models are used in physically grounded settings like robotics or autonomous driving. Traditional benchmarks often fail to capture the full spectrum of skills needed for real-world, embodied prediction.To address this, we introduce WorldSimBench, a benchmark designed to evaluate “World Simulators”—models that generate future world states visually and physically. We categorize predictive model functionalities into a structured hierarchy and propose a two-part evaluation framework: Explicit Perceptual Evaluation, which measures how realistic the generated videos are using human feedback, and Implicit Manipulative Evaluation, which tests how well these videos can drive real-world actions in tasks like robot control or navigation.By combining human preference alignment and task-grounded performance, WorldSimBench provides a holistic view of predictive model quality. It sets a foundation for building more general, reliable, and physically grounded AI systems capable of seeing, predicting, and acting in the real world."
Poster,Wrapped Gaussian on the manifold of Symmetric Positive Definite Matrices,https://ICML.cc//virtual/2025/poster/45934,"Thibault de Surrel, Fabien Lotte, Sylvain Chevallier, Florian Yger","Circular and non-flat data distribution are prevalent across diverse domains of data science, yet their specific geometric structures often remain underutilized in machine learning frameworks.A principled approach to accounting for the underlying geometry of such data is pivotal, particularly when extending statistical models, like the pervasive Gaussian distribution.In this work, we tackle those issue by focusing on the manifold of symmetric positive definite matrices, a key focus in information geometry.We introduced a non-isotropic wrapped Gaussian by leveraging the exponential map, we derive theoretical properties of this distribution and propose a maximum likelihood framework for parameter estimation. Furthermore, we reinterpret established classifiers on SPD through a probabilistic lens and introduce new classifiers based on the wrapped Gaussian model.Experiments on synthetic and real-world datasets demonstrate the robustness and flexibility of this geometry-aware distribution, underscoring its potential to advance manifold-based data analysis.This work lays the groundwork for extending classical machine learning and statistical methods to more complex and structured data.","In this paper, we introduce a new way of modeling data that lie on a non flat space using a probability distribution. We focus on a special type of matrices, that appear in different areas of data science and hope that our modelization will help researchers betters understand the insights of complex data. We study this probability distribution theoretically, deriving some useful properties. We also show how it can be used in practice, in real algorithms on real data. This work paves the way to extending classical machine learning tools to highly complex and structured data."
Poster,WyckoffDiff -- A Generative Diffusion Model for Crystal Symmetry,https://ICML.cc//virtual/2025/poster/45457,"Filip Ekström Kelvinius, Oskar Andersson, Abhijith Parackal, Dong Qian, Rickard Armiento, Fredrik Lindsten","Crystalline materials often exhibit a high level of symmetry. However, most generative models do not account for symmetry, but rather model each atom without any constraints on its position or element. We propose a generative model, Wyckoff Diffusion (WyckoffDiff), which generates symmetry-based descriptions of crystals. This is enabled by considering a crystal structure representation that encodes all symmetry, and we design a novel neural network architecture which enables using this representation inside a discrete generative model framework. In addition to respecting symmetry by construction, the discrete nature of our model enables fast generation. We additionally present a new metric, Fréchet Wrenformer Distance, which captures the symmetry aspects of the materials generated, and we benchmark WyckoffDiff against recently proposed generative models for crystal generation. As a proof-of-concept study, we use WyckoffDiff to find new materials below the convex hull of thermodynamical stability.","Just as chatbots can generate text, artificial intelligence (AI) can also be used for generating new materials, a hot topic for, e.g., enabling new technology. In this work, we developed an AI model that can generate materials, ensuring that the generated materials have the characteristic symmetrical properties that are found in materials in nature.Instead of viewing materials as atoms in space which in principle can be placed anywhere, we used a description of materials that explicitly includes information about symmetry in materials, so that the model does not have to learn this property by itself. As a proof of concept, we used our materials in a materials generation workflow, where the materials proposed by our model were further validated, and we find several new materials which are also predicted to be stable, i.e., they could exist in nature.This model is a new direction in generating materials, and while it can serve as inspiration for future work, it has already shown potential in materials discovery."
Poster,Wyckoff Transformer: Generation of Symmetric Crystals,https://ICML.cc//virtual/2025/poster/44595,"Nikita Kazeev, Wei Nong, Ignat Romanov, Ruiming Zhu, Andrey Ustyuzhanin, Shuya Yamazaki, Kedar Hippalgaonkar","Crystal symmetry plays a fundamental role in determining its physical, chemical, and electronic properties such as electrical and thermal conductivity, optical and polarization behavior, and mechanical strength. Almost all known crystalline materials have internal symmetry. However, this is often inadequately addressed by existing generative models, making the consistent generation of stable and symmetrically valid crystal structures a significant challenge. We introduce WyFormer, a generative model that directly tackles this by formally conditioning on space group symmetry. It achieves this by using Wyckoff positions as the basis for an elegant, compressed, and discrete structure representation. To model the distribution, we develop a permutation-invariant autoregressive model based on the Transformer encoder and an absence of positional encoding. Extensive experimentation demonstrates WyFormer's compelling combination of attributes: it achieves best-in-class symmetry-conditioned generation, incorporates a physics-motivated inductive bias, produces structures with competitive stability, predicts material properties with competitive accuracy even without atomic coordinates, and exhibits unparalleled inference speed.","When we think of crystals, like sparkling gemstones or intricate snowflakes, we often picture something beautiful. This beauty arises directly from their internal symmetry – the highly organized way atoms, like tiny LEGO bricks, arrange themselves. This precise atomic pattern is not just for show; it's fundamental, dictating a crystal's properties: Will it be strong? Conduct electricity? Be transparent?Scientists are always searching for new materials with amazing properties. But with countless ways atoms could combine, finding useful ones is like searching an infinite haystack. Trying to design new materials without understanding their symmetry rules is like sticking LEGO blocks together without a plan or instructions. While such improvisation might occasionally yield something interesting, it often leads to unstable structures or materials that don't have the desired properties, severely limiting the discovery of truly innovative materials.This is where our AI tool, WyFormer, comes in. It's designed to be much smarter by learning these fundamental ""LEGO instructions"" of crystal symmetry. WyFormer uses concepts like ""symmetry groups"" (the blueprints for atomic arrangement) and ""Wyckoff positions"" (special spots atoms prefer) to describe crystals in a compact and efficient way – essentially giving the AI a simplified language for these complex structures.Our AI, using a powerful Transformer architecture (similar to what powers advanced chatbots), learns to generate new crystal ""recipes"" that automatically follow these symmetry rules. A key feature is its understanding that, much like a cooking recipe, the order in which you list the atomic ingredients doesn't change the final crystal. WyFormer is not only fast but also excels at creating diverse, stable structures and can even predict material properties effectively without needing full 3D atomic details.By teaching AI the fundamental language of crystal symmetry, WyFormer can help scientists discover novel materials with desired properties much more quickly. This could speed up breakthroughs in all sorts of fields, from new types of batteries and solar cells to stronger alloys and more efficient electronics, offering a powerful assistant to explore the vast world of possible materials."
