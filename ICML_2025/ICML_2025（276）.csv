type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Simple Policy Optimization,https://ICML.cc//virtual/2025/poster/45232,"Zhengpeng Xie, Qiang Zhang, Fan Yang, Marco Hutter, Renjing Xu","Model-free reinforcement learning algorithms have seen remarkable progress, but key challenges remain. Trust Region Policy Optimization (TRPO) is known for ensuring monotonic policy improvement through conservative updates within a trust region, backed by strong theoretical guarantees. However, its reliance on complex second-order optimization limits its practical efficiency. Proximal Policy Optimization (PPO) addresses this by simplifying TRPO's approach using ratio clipping, improving efficiency but sacrificing some theoretical robustness. This raises a natural question: Can we combine the strengths of both methods? In this paper, we introduce Simple Policy Optimization (SPO), a novel unconstrained first-order algorithm. By slightly modifying the policy loss used in PPO, SPO can achieve the best of both worlds. Our new objective improves upon ratio clipping, offering stronger theoretical properties and better constraining the probability ratio within the trust region. Empirical results demonstrate that SPO outperforms PPO with a simple implementation, particularly for training large, complex network architectures end-to-end.","We propose an improved version of the well-known Proximal Policy Optimization (PPO) algorithm in reinforcement learning (RL), called Simple Policy Optimization (SPO), which has been demonstrated to be more stable."
Poster,Simple Randomized Rounding for Max-Min Eigenvalue Augmentation,https://ICML.cc//virtual/2025/poster/43967,"Jourdain Lamperski, Haeseong Yang, Oleg Prokopyev","We consider the *max-min eigenvalue augmentation* problem: given $n \times n$ symmetric positive semidefinite matrices $M,A_1,\ldots, A_m$ and a positive integer $k < m$, the goal is to choose a subset $I \subset \{1,\ldots,m\}$ of cardinality at most $k$ that maximizes the minimum eigenvalue of the matrix $M + \sum_{i \in I} A_i$. The problem captures both the  *Bayesian E-optimal design* and *maximum algebraic connectivity augmentation* problems. In contrast to the existing work, we do not assume that the *augmentation matrices* are rank-one matrices, and we focus on the setting in which $k < n$. We show that a *simple* randomized rounding method provides a constant-factor approximation if the *optimal increase* is sufficiently large, specifically, if $\mathrm{OPT} - \lambda_{\mathrm{min}}(M) = \Omega(R \ln k)$, where $\mathrm{OPT}$ is the optimal value, and $R$ is the maximum trace of an augmentation matrix. To establish the guarantee, we derive a matrix concentration inequality that is of independent interest. The inequality can be interpreted as an *intrinsic dimension* analog of the matrix Chernoff inequality for the minimum eigenvalue of a sum of independent random positive semidefinite matrices; such an inequality has already been established for the maximum  eigenvalue, but not for the minimum eigenvalue.",We consider a class of optimization problems that finds applications in statistics and network design. We study a simple algorithm that returns approximate solutions to the problem. We establish theoretical properties of the algorithm. We expect that the techniques that we develop towards this end can be applied to other problem classes.
Poster,Simplicity Bias and Optimization Threshold in Two-Layer ReLU Networks,https://ICML.cc//virtual/2025/poster/43957,"Etienne Boursier, Nicolas Flammarion","Understanding generalization of overparametrized models remains a fundamental challenge in machine learning. The literature mostly studies generalization from an interpolation point of view, taking convergence towards a global minimum of the training loss for granted.  This interpolation paradigm does not seem valid for complex tasks such as in-context learning or diffusion. It has instead been empirically observed that the trained models go from global minima to spurious local minima of the training loss as the number of training samples becomes larger than some level we call optimization threshold. This paper explores theoretically this phenomenon in the context of two-layer ReLU networks. We demonstrate that, despite overparametrization, networks might converge towards simpler solutions rather than interpolating training data, which leads to a drastic improvement on the test loss. Our analysis relies on the so called early alignment phase, during which neurons align toward specific directions. This directional alignment leads to a simplicity bias, wherein the network approximates the ground truth model without converging to the global minimum of the training loss. Our results suggest this bias, resulting in an optimization threshold from which interpolation is not reached anymore, is beneficial and enhances the generalization of trained models.","(1) Neural networks are known for their ability to fit training data exactly, yet still make accurate predictions on new data. Surprisingly, in many modern models, this perfect fitting doesn’t always happen. Our research explores this behavior in a simplified setting using small neural networks. (2) We show that when enough data is available, these networks often settle for simpler solutions that don’t fully match the training data but generalize better. (3) This “simplicity bias” helps explain why such models perform well in real-world tasks."
Poster,Simplifying DINO via Coding Rate Regularization,https://ICML.cc//virtual/2025/poster/43820,"Ziyang Wu, Jingyuan Zhang, Druv Pai, XuDong Wang, Chandan Singh, Jianwei Yang, Jianfeng Gao, Yi Ma","DINO and DINOv2 are two model families being widely used to learn representations from unlabeled imagery data at large scales. Their learned representations often enable state-of-the-art performance for downstream tasks, such as image classification and segmentation. However, they employ many empirically motivated design choices and their training pipelines are highly complex and unstable --- many hyperparameters need to be carefully tuned to ensure that the representations do not collapse --- which poses considerable difficulty to improving them or adapting them to new domains. In this work, we posit that we can remove most such-motivated idiosyncrasies in the pre-training pipelines, and only need to add an explicit coding rate term in the loss function to avoid collapse of the representations. As a result, we obtain highly simplified variants of the DINO and DINOv2 which we call SimDINO and SimDINOv2, respectively. Remarkably, these simplified models are more robust to different design choices, such as network architecture and hyperparameters, and they learn even higher-quality representations, measured by performance on downstream tasks, offering a Pareto improvement over the corresponding DINO and DINOv2 models. This work highlights the potential of using simplifying design principles to improve the empirical practice of deep learning. Code and model checkpoints are available at https://github.com/RobinWu218/SimDINO.","Modern AI systems learn from large amount of data without requiring labels by training themselves to recognize patterns. In the case of visual AI systems, a popular method is called DINO, which has been very successful but is also highly complex and difficult to train --- it requires a lot of manual tweaking and has many technical components to prevent it from learning meaningless features.In this work, we show that much of this complexity isn’t necessary. We propose simplified versions of DINO, called SimDINO and SimDINOv2, which replace the complicated parts with a principled mathematical objective that encourages the model to learn diverse and informative features. This makes the training process significantly easier and more stable.Surprisingly, despite being simpler, our models actually learn better image representations than the original DINO models. This means they perform better on tasks like image classification, object detection, and segmentation --- all without the training headaches. Our work suggests that simpler AI models can be both more powerful and more practical."
Poster,Simultaneous Multi-Robot Motion Planning with Projected Diffusion Models,https://ICML.cc//virtual/2025/poster/45205,"JINHAO LIANG, Jacob Christopher, Sven Koenig, Ferdinando Fioretto","Recent advances in diffusion models hold significant potential in robotics, enabling the generation of diverse and smooth trajectories directly from raw representations of the environment. Despite this promise, applying diffusion models to motion planning remains challenging due to their difficulty in enforcing critical constraints, such as collision avoidance and kinematic feasibility. These limitations become even more pronounced in Multi-Robot Motion Planning (MRMP), where multiple robots must coordinate in shared spaces. To address these challenges, this work proposes **S**imultaneous **M**RMP **D**iffusion (SMD), a novel approach integrating constrained optimization into the diffusion sampling process to produce collision-free, kinematically feasible trajectories. Additionally, the paper introduces a comprehensive MRMP benchmark to evaluate trajectory planning algorithms across scenarios with varying robot densities, obstacle complexities, and motion constraints. Experimental results show SMD consistently outperforms classical and other learning-based motion planners, achieving higher success rates and efficiency in complex multi-robot environments. The code and implementation are available at https://github.com/RAISELab-atUVA/Diffusion-MRMP.","Coordinating multiple robots in a shared space is very challenging. Specifically, each robot must avoid collisions and some physical movement rules carefully. Recent advances in AI called diffusion models can generate realistic and flexible paths, but they often struggle to follow these critical rules. Our research presents a new method, named Simultaneous Multi-Robot Motion Planning Diffusion (SMD), that combines diffusion models with optimization techniques to make sure the robots’ paths are feasible, even in complex environments. We also built a new benchmark to test how well different motion planning methods work in various crowded and complex environments. Our experiments show that SMD performs better than traditional and other AI-based planners in these challenging situations."
Poster,Since Faithfulness Fails: The Performance Limits of Neural Causal Discovery,https://ICML.cc//virtual/2025/poster/46568,"Mateusz Olko, Mateusz Gajewski, Joanna Wojciechowska, Mikołaj Morzy, Piotr Sankowski, Piotr Milos","Neural causal discovery methods have recently improved in terms of scalability and computational efficiency. However, our systematic evaluation highlights significant room for improvement in their accuracy when uncovering causal structures. We identify a fundamental limitation: \textit{unavoidable likelihood score estimation errors disallow distinguishing the true structure},even for small graphs and relatively large sample sizes. Furthermore, we identify the faithfulness property as a critical bottleneck: (i) it is likely to be violated across any reasonable dataset size range, and (ii) its violation directly undermines the performance of neural penalized-likelihood discovery methods. These findings lead us to conclude that progress within the current paradigm is fundamentally constrained, necessitating a paradigm shift in this domain.","Recent advances in neural causal discovery methods have improved their speed and ability to handle large datasets. However, a careful evaluation shows that these methods still struggle to identify true cause-and-effect relationships accurately. A key issue is that these approaches rely on estimating certain scores (likelihood scores), but even small errors in these estimates make it hard to recover the correct causal structure, even with relatively simple graphs and large amounts of data.From the other perspective, the “faithfulness” assumption, underlying most of causal discovery methods, might be the bottleneck.  It expects that the data clearly reflect the underlying causal relationships. In practice, this assumption often doesn’t hold, and when it’s violated, the performance of these methods drops significantly.These issues suggest that current approaches may be fundamentally limited, and that real progress in this area may require a new way of thinking about the problem."
Poster,SING: Spatial Context in Large Language Model for Next-Gen Wearables,https://ICML.cc//virtual/2025/poster/44194,"Ayushi Mishra, Yang Bai, Priyadarshan Narayanasamy, Nakul Garg, Nirupam Roy","Integrating spatial context into large language models (LLMs) has the potential to revolutionize human-computer interaction, particularly in wearable devices. In this work, we present a novel system architecture that incorporates spatial speech understanding into LLMs, enabling contextually aware and adaptive applications for wearable technologies. Our approach leverages microstructure-based spatial sensing to extract precise Direction of Arrival (DoA) information using a monaural microphone. To address the lack of existing dataset for microstructure-assisted speech recordings, we synthetically create a dataset by using the LibriSpeech dataset. This spatial information is fused with linguistic embeddings from OpenAI’s Whisper model, allowing each modality to learn complementary contextual representations. The fused embeddings are aligned with the input space of LLaMA-3.2 3B model and fine-tuned with lightweight adaptation technique LoRA to optimize for on-device processing. SING supports spatially-aware automatic speech recognition (ASR), achieving a mean error of 25.72°—a substantial improvement compared to the 88.52° median error in existing work—with a word error rate (WER) of 5.3. SING also supports soundscaping, for example, inference how many people were talking and their directions, with up to 5 people and a median DoA error of 16°. Our system demonstrates superior performance in spatial speech understanding while addressing the challenges of power efficiency, privacy, and hardware constraints, paving the way for advanced applications in augmented reality, accessibility, and immersive experiences.","Imagine wearing smart earbuds that could not only understand what people are saying but also know exactly where each voice is coming from, enabling revolutionary applications like automatically summarizing who said what in a meeting or helping visually impaired users navigate by identifying the direction of important sounds. Current wearable devices can't do this because traditional spatial audio systems require bulky microphone arrays that are too large and power-hungry for small wearables.  We developed SING, a breakthrough system that achieves precise spatial speech understanding using a single microphone enhanced with a tiny microstructure. This microstructure creates spatial diversity in sound recordings without needing multiple microphones, making it perfect for wearables. Our system combines this compact spatial sensing with OpenAI's Whisper speech recognition and integrates everything into a large language model (LLaMA-3.2) that can reason both what was said and where it came from. SING dramatically improves spatial accuracy, reducing directional errors from 88.52° to just 25.72° while maintaining excellent speech recognition (5.3%-word error rate). It can simultaneously track up to five speakers with 16° median directional accuracy, enabling applications like spatially aware meeting transcription, sound-based navigation for accessibility, and immersive augmented reality experience, all while running efficiently on small wearable devices and preserving privacy through on-device processing."
Poster,SITCOM: Step-wise Triple-Consistent Diffusion Sampling For Inverse Problems,https://ICML.cc//virtual/2025/poster/46601,"Ismail Alkhouri, Shijun Liang, Cheng-Han Huang, Jimmy Dai, Qing Qu, Saiprasad Ravishankar, Rongrong Wang","Diffusion models (DMs) are a class of generative models that allow sampling from a distribution learned over a training set. When applied to solving inverse problems, the reverse sampling steps are modified to approximately sample from a measurement-conditioned distribution. However, these modifications may be unsuitable for certain settings (e.g., presence of measurement noise) and non-linear tasks, as they often struggle to correct errors from earlier steps and generally require a large number of optimization and/or sampling steps. To address these challenges, we state three conditions for achieving measurement-consistent diffusion trajectories. Building on these conditions, we propose a new optimization-based sampling method that not only enforces standard data manifold measurement consistency and forward diffusion consistency, as seen in previous studies, but also incorporates our proposed step-wise and network-regularized backward diffusion consistency that maintains a diffusion trajectory by optimizing over the input of the pre-trained model at every sampling step. By enforcing these conditions (implicitly or explicitly), our sampler requires significantly fewer reverse steps. Therefore, we refer to our method as **S**tep-w**i**se **T**riple-**Co**nsistent Sa**m**pling (**SITCOM**). Compared to SOTA baselines, our experiments across several linear and non-linear tasks (with natural and medical images) demonstrate that SITCOM achieves competitive or superior results in terms of standard similarity metrics and run-time.","Modern image recovery techniques are increasingly powered by diffusion models, a class of AI tools that can generate high-quality images. To apply these models to inverse problems (where we aim to recover an image from partial or corrupted measurements), researchers often adapt the standard generation process to account for the measurements. However, these adapted methods tend to be computationally expensive, especially when the measurements are noisy or the task is non-linear. In our work, we identify three key conditions that any measurement-guided sampling process should meet to stay consistent with both the data and the underlying model. Based on this, we introduce a new method called SITCOM (Step-wise Triple-consistent Sampling) that enforces these conditions during the sampling process. Our results demonstrate that SITCOM recovers images more reliably and efficiently—achieving high-quality results in fewer steps. We show its benefits across nine image recovery tasks, including real-world medical imaging."
Poster,SketchDNN: Joint Continuous-Discrete Diffusion for CAD Sketch Generation,https://ICML.cc//virtual/2025/poster/46031,"Sathvik Chereddy, John Femiani","We present SketchDNN, a generative model for synthesizing CAD sketches that jointly models both continuous parameters and discrete class labels through a unified continuous-discrete diffusion process. Our core innovation is Gaussian-Softmax diffusion, where logits perturbed with Gaussian noise are projected onto the probability simplex via a softmax transformation, facilitating blended class labels for discrete variables. This formulation addresses 2 key challenges, namely, the heterogeneity of primitive parameterizations and the permutation invariance of primitives in CAD sketches. Our approach significantly improves generation quality, reducing Fréchet Inception Distance (FID) from 16.04 to 7.80 and negative log-likelihood (NLL) from 84.8 to 81.33, establishing a new state-of-the-art in CAD sketch generation on the SketchGraphs dataset.","Generating Computer Aided Design (CAD) blueprints holds great promise for streamlining and democratizing CAD design, similar to images/art with tools like Stable Diffusion. We developed a new AI model for generating CAD sketches in a similar fashion to Stable Diffusion, and introduce a new methodology tailored to categorical data. Our methodology has outperformed all alternatives and brings us one step closer to consumer tools for generating CAD blueprints."
Poster,Sketch to Adapt: Fine-Tunable Sketches for Efficient LLM Adaptation,https://ICML.cc//virtual/2025/poster/43470,"Tianyi Zhang, Junda Su, Aditya Desai, Oscar Wu, Zhaozhuo Xu, Anshumali Shrivastava","Adapting pre-trained large language models (LLMs) is crucial but challenging due to their enormous size. Parameter-efficient fine-tuning (PEFT) techniques typically employ additive adapters applied to frozen model weights. To further reduce memory usage, model weights are often compressed through quantization. However, existing PEFT methods often yield suboptimal model quality because they rely on restrictive assumptions, such as low-rank constraints on adapters to limit the number of trainable parameters. We find that sketching, a popular data compression technique, can serve as an efficient LLM adaptation strategy while avoiding the low-rank assumption. We introduce SketchTune, a compressive adaptation strategy that compresses LLM weights into compact fine-tunable sketches, integrating compression and adaptation into a unified framework. This integration eliminates the need for complex two-path computation in existing PEFT techniques, enabling faster and more memory-efficient training and inference. SketchTune is supported by mathematical insights into matrix classes that are better approximated using sketching rather than low-rank methods. Our extensive evaluations with Llama and Mistral models demonstrate that SketchTune outperforms leading PEFT methods across diverse tasks while using substantially smaller base models and comparable trainable parameters. As a highlight,  SketchTune outperforms LoRA, DoRA, and S2FT on commonsense and math benchmarks using 2.6-3.5$\times$ smaller base models and exceeds LoftQ in accuracy by 14.48\% on GSM8K with 7.3$\times$ fewer trainable parameters.","Large language models (LLMs), such as those used in chatbots and search engines, require significant computer resources because of their enormous size. This creates challenges when adapting these models to new tasks, as updating or fine-tuning them is often slow and memory-intensive.Our work introduces SketchTune, a new technique that first compresses the LLM into a much smaller, ""sketched"" version. Unlike most compression methods, SketchTune makes this compressed model fully trainable, so it can still be adapted to new tasks. Instead of updating all the original model's parameters, SketchTune allows fine-tuning by modifying only a small set of parameters within the compressed model.We show that models compressed and adapted with SketchTune can achieve similar or even better performance compared to traditional methods, all while using much less memory and computational power. This approach makes it easier and more efficient for a wider range of people and organizations to use and customize powerful LLMs."
