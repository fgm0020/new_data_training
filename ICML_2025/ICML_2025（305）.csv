type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Time-VLM: Exploring Multimodal Vision-Language Models for Augmented Time Series Forecasting,https://ICML.cc//virtual/2025/poster/44762,"Siru Zhong, Weilin Ruan, Ming Jin, Huan Li, Qingsong Wen, Yuxuan Liang","Recent advancements in time series forecasting have explored augmenting models with text or vision modalities to improve accuracy. While text provides contextual understanding, it often lacks fine-grained temporal details. Conversely, vision captures intricate temporal patterns but lacks semantic context, limiting the complementary potential of these modalities. To address this, we propose Time-VLM, a novel multimodal framework that leverages pre-trained Vision-Language Models (VLMs) to bridge temporal, visual, and textual modalities for enhanced forecasting. Our framework comprises three key components: (1) a Retrieval-Augmented Learner, which extracts enriched temporal features through memory bank interactions; (2) a Vision-Augmented Learner, which encodes time series as informative images; and (3) a Text-Augmented Learner, which generates contextual textual descriptions. These components collaborate with frozen pre-trained VLMs to produce multimodal embeddings, which are then fused with temporal features for final prediction. Extensive experiments demonstrate that Time-VLM achieves superior performance, particularly in few-shot and zero-shot scenarios, thereby establishing a new direction for multimodal time series forecasting. Code is available at https://github.com/CityMind-Lab/ICML25-TimeVLM.","Accurate forecasting of time series — such as electricity usage, weather patterns, or traffic flow — is essential for planning and decision-making in many areas. However, traditional models often struggle with complex patterns, and deep learning methods typically require large amounts of data to work well.In this research, we introduce Time-VLM , a new approach that combines time series with visual and textual information using pre-trained vision-language models (VLMs). Our method automatically transforms time data into meaningful images and text descriptions, allowing the model to understand both the temporal dynamics and the real-world context behind the numbers.This makes it possible to make accurate predictions even when only limited data is available — for example, forecasting energy consumption trends from just a few past observations. We show that our model outperforms existing methods in low-data settings, especially in cross-domain scenarios where no historical data is available for training.Time-VLM opens up new possibilities for applying powerful AI models like VLMs beyond image and language tasks, helping us better understand and predict time-dependent phenomena across a wide range of applications."
Poster,TIMING: Temporality-Aware Integrated Gradients for Time Series Explanation,https://ICML.cc//virtual/2025/poster/43941,"Hyeongwon Jang, Changhun Kim, Eunho Yang","Recent explainable artificial intelligence (XAI) methods for time series primarily estimate point-wise attribution magnitudes, while overlooking the directional impact on predictions, leading to suboptimal identification of significant points. Our analysis shows that conventional Integrated Gradients (IG) effectively capture critical points with both positive and negative impacts on predictions. However, current evaluation metrics fail to assess this capability, as they inadvertently cancel out opposing feature contributions. To address this limitation, we propose novel evaluation metrics—Cumulative Prediction Difference (CPD) and Cumulative Prediction Preservation(CPP)—to systematically assess whether attribution methods accurately identify significant positive and negative points in time series XAI. Under these metrics, conventional IG outperforms recent counterparts. However, directly applying IG to time series data may lead to suboptimal outcomes, as generated paths ignore temporal relationships and introduce out-of-distribution samples. To overcome these challenges, we introduce TIMING, which enhances IG by incorporating temporal awareness while maintaining its theoretical properties. Extensive experiments on synthetic and real-world time series benchmarks demonstrate that TIMING outperforms existing timeseries XAI baselines. Our code is available at https://github.com/drumpt/TIMING.","Time series data—heartbeat traces, financial data, and sensor measurements—drive critical decisions in safety-critical domains. Accurate predictions are essential, but explaining model decisions is equally crucial for building trust. Most XAI algorithms report only how much each moment matters, not whether it helps or hurts predictions, causing evaluation metrics to obscure important points by canceling opposing effects. We introduce Cumulative Prediction Difference (CPD) and Cumulative Prediction Preservation (CPP) metrics that measure ""helpful"" and ""harmful"" moments without letting opposite effects blur together. Under these evaluations, classic Integrated Gradients (IG) outperforms newer alternatives. However, IG ignores temporal structure in time series data. To address this limitation, we develop TIMING, which enhances Integrated Gradients by incorporating sequence information. Across simulated and real-world datasets, TIMING identifies critical moments more accurately than existing tools. This provides clinicians, analysts, and engineers with clearer insight into AI decisions. Our code and evaluation suite are publicly available for others to utilize and build upon."
Poster,TINED: GNNs-to-MLPs by Teacher Injection and Dirichlet Energy Distillation,https://ICML.cc//virtual/2025/poster/44094,"Ziang Zhou, Zhihao DING, Jieming Shi, Qing Li, Shiqi Shen","Graph Neural Networks (GNNs) are pivotal in graph-based learning, particularly excelling in node classification. However, their scalability is hindered by the need for multi-hop data during inference, limiting their application in latency-sensitive scenarios. Recent efforts to distill GNNs into multi-layer perceptrons (MLPs) for faster inference often underutilize the layer-level insights of GNNs. In this paper, we present TINED, a novel approach that distills GNNs to MLPs on a layer-by-layer basis using Teacher Injection and Dirichlet Energy Distillation techniques.We focus on two key operations in GNN layers: feature transformation (FT) and graph propagation (GP). We recognize that FT is computationally equivalent to a fully-connected (FC) layer in MLPs. Thus, we propose directly transferring teacher parameters from an FT in a GNN to an FC layer in the student MLP, enhanced by fine-tuning. In TINED, the FC layers in an MLP replicate the sequence of FTs and GPs in the GNN. We also establish a theoretical bound for GP approximation.Furthermore, we note that FT and GP operations in GNN layers often exhibit opposing smoothing effects: GP is aggressive, while FT is conservative. Using Dirichlet energy, we develop a DE ratio to measure these effects and propose Dirichlet Energy Distillation to convey these characteristics from GNN layers to MLP layers. Extensive experiments show that TINED outperforms GNNs and leading distillation methods across various settings and seven datasets. Source code are available at https://github.com/scottjiao/TINED_ICML25/.","GNNs are powerful for analyzing graph data, like social networks or molecular graphs. However, their core process, ""message passing,"" can be slow during deployment, limiting their use in applications requiring quick responses. A promising solution is to simplify GNNs into Multi-Layer Perceptrons (MLPs) through a process called distillation. A GNN (the teacher) trains an MLP (the student) to perform well and with much faster inference.We introduce a novel distillation method TINED. We focus on two main operations in GNNs: feature transformation (FT) and graph propagation (GP). The MLP is designed to mimic the sequence of FT and GP operations in the GNN, and we also provide a theoretical guarantee for approximating GP. FT resembles fully-connected (FC) layers in MLPs, allowing direct parameter transfer from the GNN to the MLP, followed by fine-tuning. Moreover, we observe that FT and GP have opposite effects: GP smooths aggressively, while FT is more conservative. We measure these effects via Dirichlet energy and transfer them from GNN to MLP.Our approach allows the simpler MLP to match or even outperform the original GNN and other methods. TINED enables faster and more accurate predictions, making it ideal for real-world applications where speed is critical."
Poster,TinyMIG: Transferring Generalization from Vision Foundation Models to Single-Domain Medical Imaging,https://ICML.cc//virtual/2025/poster/45472,"Chuang Liu, Hongyan Xu, Yichao Cao, Xiu Su, Zhe Qu, Tianfa Li, Shan An, Haogang Zhu","Medical imaging faces significant challenges in single-domain generalization (SDG) due to the diversity of imaging devices and the variability among data collection centers. To address these challenges, we propose \textbf{TinyMIG}, a framework designed to transfer generalization capabilities from vision foundation models to medical imaging SDG. TinyMIG aims to enable lightweight specialized models to mimic the strong generalization capabilities of foundation models in terms of both global feature distribution and local fine-grained details during training. Specifically, for global feature distribution, we propose a Global Distribution Consistency Learning strategy that mimics the prior distributions of the foundation model layer by layer. For local fine-grained details, we further design a Localized Representation Alignment method, which promotes semantic alignment and generalization distillation between the specialized model and the foundation model. These mechanisms collectively enable the specialized model to achieve robust performance in diverse medical imaging scenarios. Extensive experiments on large-scale benchmarks demonstrate that TinyMIG, with extremely low computational cost, significantly outperforms state-of-the-art models, showcasing its superior SDG capabilities. All the code and model weights will be publicly available.","Medical images, such as scans from hospitals, often look different depending on the machines used and where they were taken. This makes it hard for AI tools trained on one dataset to work well on new, unseen data — a problem known as single-domain generalization.We introduce  \textbf{TinyMIG}, a method that helps small, efficient AI models learn from powerful, general-purpose vision models (like those behind tools such as ChatGPT or DALL·E). Our method teaches the smaller model to copy how the big model understands both the overall structure and fine details of images during training.To do this, TinyMIG aligns the way the small model “sees” image features with how the big model does, both at a broad and detailed level. This helps the small model adapt better to new types of medical images.Our results show that TinyMIG can outperform other approaches — all while using much less computing power — making it practical for real-world healthcare use."
Poster,TLLC: Transfer Learning-based Label Completion for Crowdsourcing,https://ICML.cc//virtual/2025/poster/46098,"Wenjun Zhang, Liangxiao Jiang, Chaoqun Li","Label completion serves as a preprocessing approach to handling the sparse crowdsourced label matrix problem, significantly boosting the effectiveness of the downstream label aggregation. In recent advances, worker modeling has been proved to be a powerful strategy to further improve the performance of label completion. However, in real-world scenarios, workers typically annotate only a few instances, leading to insufficient worker modeling and thus limiting the improvement of label completion. To address this issue, we propose a novel transfer learning-based label completion (TLLC) method. Specifically, we first identify all high-confidence instances from the whole crowdsourced data as a source domain and use it to pretrain a Siamese network. The abundant annotated instances in the source domain provide essential knowledge for worker modeling. Then, we transfer the pretrained network to the target domain with the instances annotated by each worker separately, ensuring worker modeling captures unique characteristics of each worker. Finally, we leverage the new embeddings learned by the transferred network to complete each worker’s missing labels. Extensive experiments on several widely used real-world datasets demonstrate the effectiveness of TLLC. Our codes and datasets are available at https://github.com/jiangliangxiao/TLLC.","In machine learning, obtaining high-quality annotated data is expensive and time-consuming. Crowdsourcing offers a cost-effective alternative, but due to the lack of expertise among crowd workers and their partial labeling of the data, the crowdsourced data is often noisy and sparse, limiting the performance of downstream tasks. To address this, label completion is proposed to fill in the missing labels in crowdsourced data. Ideally, learning workers’ annotation patterns through worker modeling is valuable for label completion. However, limited annotations per worker hinder effective modeling. The proposed Transfer Learning-based Label Completion (TLLC) method overcomes this by leveraging transfer learning. First, it pretrains a Siamese network on high-confidence data (source domain) to learn general annotation patterns, which avoids modeling workers from scratch. Then, TLLC transfers and fine-tunes the pretrained network on individual workers’ data (target domain) to capture their unique characteristics, which evolves worker modeling from general annotation patterns to individual worker-specific patterns. Finally, these transferred networks are used to predict missing labels. Through TLLC, worker modeling becomes more effective, thereby improving the performance of label completion."
Poster,TMetaNet: Topological Meta-Learning Framework for Dynamic Link Prediction,https://ICML.cc//virtual/2025/poster/46188,"Hao Li, Hao Wan, Yuzhou Chen, Dongsheng Ye, Yulia Gel, Hao Jiang","Dynamic graphs evolve continuously, presenting challenges for traditional graph learning due to their changing structures and temporal dependencies. Recent advancements have shown potential in addressing these challenges by developing suitable meta-learning-based dynamic graph neural network models. However, most meta-learning approaches for dynamic graphs rely on fixed weight update parameters, neglecting the essential intrinsic complex high-order topological information of dynamically evolving graphs. We have designed Dowker Zigzag Persistence (DZP), an efficient and stable dynamic graph persistent homology representation method based on Dowker complex and zigzag persistence, to capture the high-order features of dynamic graphs. Armed with the DZP ideas, we propose TMetaNet, a new meta-learning parameter update model based on dynamic topological features. By utilizing the distances between high-order topological features, TMetaNet enables more effective adaptation across snapshots. Experiments on real-world datasets demonstrate TMetaNet's state-of-the-art performance and resilience to graph noise, illustrating its high potential for meta-learning and dynamic graph analysis. Our code is available at https://github.com/Lihaogx/TMetaNet.","Modern networks like social media or cryptocurrency platforms are constantly changing, making it hard for AI models to keep up and make accurate predictions. Our research introduces a new approach that helps these models adapt by focusing on the “shape” of the network over time, capturing its evolving structure using a technique called persistent homology. We designed a system called TMetaNet that uses this topological insight to guide how the model updates itself as the network changes. This allows it to better predict future connections, even when the data is noisy or unpredictable. Our tests across six real-world datasets showed that TMetaNet consistently outperformed other leading methods, offering both stronger accuracy and better stability. This work could help improve AI systems used in fields like fraud detection, recommendation systems, or online behavior analysis, anywhere networks evolve and smart decisions must keep pace."
Poster,To Each Metric Its Decoding: Post-Hoc Optimal Decision Rules of Probabilistic Hierarchical Classifiers,https://ICML.cc//virtual/2025/poster/46401,"Roman Plaud, Alexandre Perez-Lebel, Matthieu Labeau, Antoine Saillenfest, Thomas Bonald","Hierarchical classification offers an approach to incorporate the concept of mistake severity by leveraging a structured, labeled hierarchy. However, decoding in such settings frequently relies on heuristic decision rules, which may not align with task-specific evaluation metrics. In this work, we propose a framework for the optimal decoding of an output probability distribution with respectto a target metric. We derive optimal decision rules for increasingly complex prediction settings, providing universal algorithms when candidates are limited to the set of nodes. In the most general case of predicting a *subset of nodes*, we focus on rules dedicated to the hierarchical $\mathrm{hF}_{\beta}$ scores, tailored to hierarchical settings. To demonstrate the practical utility of our approach, we conductextensive empirical evaluations, showcasing the superiority of our proposed optimal strategies, particularly in underdetermined scenarios. These results highlight the potential of our methods to enhance the performance and reliability of hierarchical classifiers in real-world applications.","Many real-world tasks require sorting items into categories that form a hierarchy—think of sorting photos first by “animals” or “vehicles,” then by subcategories like “dogs” or “cars.” In such setups, some mistakes matter more than others (e.g., calling a wolf a dog is certainly less serious than calling it a car), but existing methods for selecting categories from an AI system probability estimate usually rely on simple « if-then » rules that don’t line up with how we actually judge performance.We introduce a clear, metric-driven framework that finds the absolute best way to choose categories from an AI’s probability estimates. We work out exact optimal predictions for different scenarios—from picking a single node in the hierarchy to selecting several at once—so that the system optimizes directly for the scores we care about, including specialized scores that balance different kinds of errors.By using these optimal strategies, hierarchical classifiers become noticeably more performant, especially in ambiguous cases. This advance can improve real-world applications—such as medical diagnosis, document organization, or wildlife monitoring—by reducing costly hierarchical misclassifications."
Poster,Token Assorted: Mixing Latent and Text Tokens for Improved Language Model Reasoning,https://ICML.cc//virtual/2025/poster/44409,"Andy (DiJia) Su, Hanlin Zhu, Yingchen Xu, Jiantao Jiao, Yuandong Tian, Qinqing Zheng","Large Language Models (LLMs) excel at reasoning and planning when trained on chain-of-thought (CoT) data, where the step-by-step thought process is explicitly outlined by text tokens.However, this results in lengthy inputs where many words support textual coherence rather than core reasoning information, and processing these inputs consumes substantial computation resources.In this work, we propose a hybrid representation of the reasoning process, where we partially abstract away the initial reasoning steps using latent discrete tokens generated by VQ-VAE,  significantly reducing the length of reasoning traces. We explore the use of latent trace abstractions in two scenarios: 1) training the model from scratch for the Keys-Finding Maze problem, 2) fine-tuning LLMs on this hybrid data with an extended vocabulary including unseen latent tokens, for both logical and mathematical reasoning problems. To facilitate effective learning, we introduce a simple training procedure that randomly mixes latent and text tokens, which enables fast adaptation to new latent tokens. Our approach consistently outperforms the baselines methods in various benchmarks, such as Math (+4.2\%, Llama-3.2-1B), GSM8K (+4.1%, Llama-3.2-3B), and Fresh-Gaokao-Math-2023 (+13.3%, Llama-3.1-8B) with an average reduction of 17% in reasoning trace's length.","We proposed a discrete latent code approach for enhancing the Chain-of-Thought of LLMs, improving its reasoning capability."
Poster,Token Cleaning: Fine-Grained Data Selection for LLM Supervised Fine-Tuning,https://ICML.cc//virtual/2025/poster/43777,"Jinlong Pang, Na Di, Zhaowei Zhu, Jiaheng Wei, Hao Cheng, Chen Qian, Yang Liu","Recent studies show that in supervised fine-tuning (SFT) of large language models (LLMs), data quality matters more than quantity. While most data cleaning methods concentrate on filtering entire samples, the quality of individual tokens within a sample can vary significantly. After pre-training, even in high-quality samples, patterns or phrases that are not task-related can be redundant, uninformative, or even harmful. Continuing to fine-tune on these patterns may offer limited benefit and even degrade downstream task performance.In this paper, we investigate token quality from a noisy-label perspective and propose a generic token cleaning pipeline for SFT tasks. Our method filters out uninformative tokens while preserving those carrying key task-specific information. Specifically, we first evaluate token quality by examining the influence of model updates on each token, then apply a threshold-based separation. The token influence can be measured in a single pass with a fixed reference model or iteratively with self-evolving reference models. The benefits and limitations of both methods are analyzed theoretically by error upper bounds. Extensive experiments show that our framework consistently improves downstream performance. Code is available at https://github.com/UCSC-REAL/TokenCleaning.","Large language models (LLMs) learn to write, summarize, or answer questions by training on vast amounts of text. But not all parts of this text are equally helpful — some words or phrases might be irrelevant or even misleading for the task at hand.We asked: instead of filtering out whole examples during training, what if we look inside each example and clean out just the bad words? We created a method to do exactly that — it checks how much each word helps or hurts the model’s learning, and removes the unhelpful ones while keeping the important ones.This process, called token cleaning, led to models that performed better across a wide range of tasks. It works with both a fixed model or by letting the model evolve as it learns."
Poster,Token Coordinated Prompt Attention is Needed for Visual Prompting,https://ICML.cc//virtual/2025/poster/45424,"Zichen Liu, Xu Zou, Gang Hua, Jiahuan Zhou","Visual prompting techniques are widely used to efficiently fine-tune pretrained Vision Transformers (ViT) by learning a small set of shared prompts for all tokens. However, existing methods overlook the unique roles of different tokens in conveying discriminative information and interact with all tokens using the same prompts, thereby limiting the representational capacity of ViT. This often leads to indistinguishable and biased prompt-extracted features, hindering performance.  To address this issue, we propose a plug-and-play Token Coordinated Prompt Attention (TCPA) module, which assigns specific coordinated prompts to different tokens for attention-based interactions. Firstly, recognizing the distinct functions of CLS and image tokens-global information aggregation and local feature extraction, we disentangle the prompts into CLS Prompts and Image Prompts, which interact exclusively with CLS tokens and image tokens through attention mechanisms. This enhances their respective discriminative abilities. Furthermore, as different image tokens correspond to distinct image patches and contain diverse information, we employ a matching function to automatically assign coordinated prompts to individual tokens. This enables more precise attention interactions, improving the diversity and representational capacity of the extracted features.  Extensive experiments across various benchmarks demonstrate that TCPA significantly enhances the diversity and discriminative power of the extracted features.","Visual prompting techniques are widely used to efficiently fine-tune pretrained Vision Transformers (ViT) by learning a small set of shared prompts for all tokens. However, existing methods overlook the unique roles of different tokens in conveying discriminative information and interact with all tokens using the same prompts, thereby limiting the representational capacity of ViT. This often leads to indistinguishable and biased prompt-extracted features, hindering performance.  To address this issue, we propose a plug-and-play Token Coordinated Prompt Attention (TCPA) module, which assigns specific coordinated prompts to different tokens for attention-based interactions. Extensive experiments across various benchmarks demonstrate that TCPA significantly enhances the diversity and discriminative power of the extracted features."
