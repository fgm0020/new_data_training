type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Training Flexible Models of Genetic Variant Effects from Functional Annotations using Accelerated Linear Algebra,https://ICML.cc//virtual/2025/poster/44064,"Alan Amin, Andres Potapczynski, Andrew Wilson","To understand how genetic variants in human genomes manifest in phenotypes - traits like height or diseases like asthma - geneticists have sequenced and measured hundreds of thousands of individuals. Geneticists use this data to build models that predict how a genetic variant impacts phenotype given genomic features of the variant, like DNA accessibility or the presence of nearby DNA-bound proteins. As more data and features become available, one might expect predictive models to improve. Unfortunately, training these models is bottlenecked by the need to solve expensive linear algebra problems because variants in the genome are correlated with nearby variants, requiring inversion of large matrices. Previous methods have therefore been restricted to fitting small models, and fitting simplified summary statistics, rather than the full likelihood of the statistical model. In this paper, we leverage modern fast linear algebra techniques to develop DeepWAS (Deep genome Wide Association Studies), a method to train large and flexible neural network predictive models to optimize likelihood. Surprisingly, we find that larger models only improve performance when using our full likelihood approach; when trained by fitting traditional summary statistics, larger models perform no better than small ones. We find larger models trained on more features make better predictions, potentially improving disease predictions and therapeutic target identification.","Geneticists want to be able to predict what diseases someone is at risk of from the variants in their genome. They can do so by measuring the disease and genomes of hundreds of thousands of people to learn which variants are correlated to disease. Unfortunately there are many more variants than study participants, so they can’t pinpoint exactly which variants cause disease. Luckily many variants are known to lie in inactive regions of the genome, allowing us to ignore them to focus on the variants more likely to cause disease. In this paper we suggest we can do even better by building a more flexible neural network model that predicts how likely a variant is to contribute to disease based on its genomic region. We solved a few algorithmic challenges that made it very hard to train such a model previously. We build our flexible models and show they better predict disease than previous smaller models."
Poster,Training High Performance Spiking Neural Network  by Temporal Model Calibration,https://ICML.cc//virtual/2025/poster/44216,"Jiaqi Yan, Changping Wang, De Ma, Huajin Tang, Qian Zheng, Gang Pan","Spiking Neural Networks (SNNs) are considered promising energy-efficient models due to their dynamic capability to process spatial-temporal spike information. Existing work has demonstrated that SNNs exhibit temporal heterogeneity, which leads to diverse outputs of SNNs at different time steps and has the potential to enhance their performance. Although SNNs obtained by direct training methods achieve state-of-the-art performance, current methods introduce limited temporal heterogeneity through the dynamics of spiking neurons or network structures. They lack the improvement of temporal heterogeneity through the lens of the gradient. In this paper, we first conclude that the diversity of the temporal logit gradients in current methods is limited. This leads to insufficient temporal heterogeneity and results in temporally miscalibrated SNNs with degraded performance. Based on the above analysis, we propose a Temporal Model Calibration (TMC) method, which can be seen as a logit gradient rescaling mechanism across time steps. Experimental results show that our method can improve the temporal logit gradient diversity and generate temporally calibrated SNNs with enhanced performance. In particular, our method achieves state-of-the-art accuracy on ImageNet, DVSCIFAR10, and N-Caltech101. Codes are available at https://github.com/zju-bmi-lab/TMC.","Spiking Neural Networks (SNNs) are special types of AI models that are very energy-efficient and good at handling information that changes over time. After capturing dynamic features, SNNs will produce different outputs at different time steps, which is great for tasks like recognizing moving objects. However, we discovered that the current methods don't create enough diversity in how SNNs change over time. This results in SNNs that don't perform as well as they could. To address this, we proposed a method called Temporal Model Calibration (TMC), which helps improve the diversity of how SNNs change over time. Our experiments showed that TMC can enhance the performance of SNNs, making them more accurate on tasks like image recognition. Specifically, our method achieved top accuracy on datasets like ImageNet, DVSCIFAR10, and N-Caltech101. The codes for our method are available at https://github.com/zju-bmi-lab/TMC."
Poster,Training Software Engineering Agents and Verifiers with SWE-Gym,https://ICML.cc//virtual/2025/poster/46038,"Jiayi Pan, Xingyao Wang, Graham Neubig, Navdeep Jaitly, Heng Ji, Alane Suhr, Yizhe Zhang","We present SWE-Gym, the first environment for training real-world software engineering (SWE) agents. SWE-Gym contains 2,438 real-world Python task instances, each comprising a codebase with an executable runtime environment, unit tests, and a task specified in natural language. We use SWE-Gym to train language model based SWE agents, achieving up to 19% absolute gains in resolve rate on the popular SWE-Bench Verified and Lite test sets. We also experiment with inference-time scaling through verifiers trained on agent trajectories sampled from SWE-Gym. When combined with our fine-tuned SWE agents, we achieve 32.0% and 26.0% on SWE-Bench Verified and Lite, respectively, reflecting a new state-of-the-art for open-weight SWE agents. To facilitate further research, we publicly release SWE-Gym, models, and agent trajectories.","Software engineering is increasingly being assisted by AI, promising to make coding faster and more accessible. But training these AI “engineers” is hard: they need a rich environment where they can learn by solving real tasks in real codebases—something past tools haven’t offered. That’s where our work, SWE-Gym, comes in.SWE-Gym is a new “training ground” built from 2,438 real-world GitHub issues. Each task comes with a full Python project, unit tests that check the AI’s work, and a clear problem description. Using this setup, we trained two AI models that work together: one proposes code fixes, and another evaluates them. This duo already solves about one-third of the hardest bugs in a standard test set—better than any open AI system to date—and it gets smarter with more practice.By releasing SWE-Gym, along with our code, models, and results, we hope to jumpstart research into trustworthy, open, and reproducible AI software agents that can assist in real-world programming."
Poster,Trajectory Inference with Smooth Schrödinger Bridges,https://ICML.cc//virtual/2025/poster/45838,"Wanli Hong, Yuliang Shi, Jonathan Niles-Weed","Motivated by applications in trajectory inference and particle tracking, we introduce **Smooth Schrödinger Bridges**. Our proposal generalizes prior work by allowing the reference process in the multi-marginal Schrödinger Bridge problem to be a smooth Gaussian process, leading to more regular and interpretable trajectories in applications. Though naïvely smoothing the reference process leads to a computationally intractable problem, we identify a class of processes (including the Matérn processes) for which the resulting Smooth Schrödinger Bridge problem can be *lifted* to a simpler problem on phase space, which can be solved in polynomial time. We develop a practical approximation of this algorithm that outperforms existing methods on numerous simulated and real single-cell RNAseq datasets.","Imagine trying to track the motion of identical ants in a colony using snapshots taken over time. Since they all look the same, it’s hard to tell which ant is which between photos. Due to computational constraints, prior methods only compared adjacent photos to guess the ants' paths, but this often failed because movements depend on longer patterns (like an ant speeding up or changing direction over time). Our new method finds these longer patterns. Instead of only looking one step ahead, it additionally infers information of velocities and accelerations of each ant, ensuring their paths make sense as smooth, natural motions (no sudden jumps). Our approximation scheme makes this algorithm scalable when the dataset expands and it outperforms existing methods on numerous datasets."
Poster,Trajectory World Models for Heterogeneous Environments,https://ICML.cc//virtual/2025/poster/45359,"Shaofeng Yin, Jialong Wu, Siqiao Huang, Xingjian Su, he, Jianye Hao, Mingsheng Long","Heterogeneity in sensors and actuators across environments poses a significant challenge to building large-scale pre-trained world models on top of this low-dimensional sensor information. In this work, we explore pre-training world models for heterogeneous environments by addressing key transfer barriers in both data diversity and model flexibility. We introduce UniTraj, a unified dataset comprising over one million trajectories from 80 environments, designed to scale data while preserving critical diversity. Additionally, we propose TrajWorld, a novel architecture capable of flexibly handling varying sensor and actuator information and capturing environment dynamics in-context. Pre-training TrajWorld on UniTraj yields substantial gains in transition prediction, achieves a new state-of-the-art for off-policy evaluation, and also delivers superior online performance of model predictive control. To the best of our knowledge, this work, for the first time, demonstrates the transfer benefits of world models across heterogeneous and complex control environments. Code and data are available at https://github.com/thuml/TrajWorld.","Robots and control systems often use machine learning models called world models to predict how their actions will affect the environment. However, these models are usually trained in narrow settings with fixed sensor and actuator configurations. In real-world applications, different systems can vary widely in how many sensors or actuators they have, what each one represents, and how they are physically arranged or controlled. This structural heterogeneity makes it hard to train general-purpose models. To address this, we introduce UniTraj, a large dataset with over one million trajectories from 80 diverse control environments. It is designed to scale pre-training while preserving the diversity seen in real systems. We also propose TrajWorld, a model architecture that flexibly adapts to different sensor and actuator structures. TrajWorld learns to infer the underlying dynamics within the context of observed trajectories, allowing it to understand the environment by considering recent history and interactions. This work helps build general world models capable of transferring knowledge across diverse robots and environments, paving the way for multimodal world models that integrate vision and sensor data for a deeper understanding of the physical world."
Poster,Transfer Learning for Nonparametric Contextual Dynamic Pricing,https://ICML.cc//virtual/2025/poster/43468,"Fan Wang, Feiyu Jiang, Zifeng Zhao, Yi Yu","Dynamic pricing strategies are crucial for firms to maximize revenue by adjusting prices based on market conditions and customer characteristics. However, designing optimal pricing strategies becomes challenging when historical data are limited, as is often the case when launching new products or entering new markets.  One promising approach to overcome this limitation is to leverage information from related products or markets to inform the focal pricing decisions. In this paper, we explore transfer learning for nonparametric contextual dynamic pricing under a covariate shift model, where the marginal distributions of covariates differ between source and target domains while the reward functions remain the same. We propose a novel Transfer Learning for Dynamic Pricing (TLDP) algorithm that can effectively leverage pre-collected data from a source domain to enhance pricing decisions in the target domain. The regret upper bound of TLDP is established under a simple Lipschitz condition on the reward function.  To establish the optimality of TLDP, we further derive a matching minimax lower bound, which includes the target-only scenario as a special case and is  presented for the first time in the literature. Extensive numerical experiments validate our approach, demonstrating its superiority over existing methods and highlighting its practical utility in real-world applications.","Imagine you are running an online store and trying to set prices for your products based on customer characteristics to maximize your profit. This approach is known as contextual dynamic pricing. Now, imagine you’ve just launched your store in a new market. You don’t have much customer data yet, but you do have data from a similar market. Can this existing data help you make better pricing decisions in the new market, even if customer characteristics differ?Our research introduces a new method that does exactly this. We develop an algorithm that transfers knowledge from a data-rich market (the source) to a new market (the target). Our method allows customer characteristics to vary across markets but assumes that the way these characteristics influence willingness to pay remains consistent. We provide theoretical guarantees showing that the proposed algorithm achieves optimal performance, and we demonstrate its effectiveness through both simulations and real-world data.This work could help businesses make smarter pricing decisions more quickly in new markets by leveraging the data they already have, without having to wait months to collect new insights."
Poster,Transfer Q-Learning with Composite MDP Structures,https://ICML.cc//virtual/2025/poster/46002,"Jinhang Chai, Elynn Chen, Lin Yang","To bridge the gap between empirical success and theoretical understanding in transfer reinforcement learning (RL), we study a principled approach with provable performance guarantees. We introduce a novel composite MDP framework where high-dimensional transition dynamics are modeled as the sum of a low-rank component representing shared structure and a sparse component capturing task-specific variations. This relaxes the common assumption of purely low-rank transition models, allowing for more realistic scenarios where tasks share core dynamics but maintain individual variations. We introduce UCB-TQL (Upper Confidence Bound Transfer Q-Learning), designed for transfer RL scenarios where multiple tasks share core linear MDP dynamics but diverge along sparse dimensions. When applying UCB-TQL to a target task after training on a source task with sufficient trajectories, we achieve a regret bound of $\tilde{\mathcal{O}}(\sqrt{eH^5N})$ that scales independently of the ambient dimension. Here, $N$ represents the number of trajectories in the target task, while $e$ quantifies the sparse differences between tasks. This result demonstrates substantial improvement over single task RL by effectively leveraging their structural similarities. Our theoretical analysis provides rigorous guarantees for how UCB-TQL simultaneously exploits shared dynamics while adapting to task-specific variations.","When a computer learns a new task, it typically starts from scratch, requiring lots of time and data. Imagine if, instead, it could remember what it learned before and adapt quickly to new challenges, even when conditions change. Our work makes this possible in a specific type of artificial intelligence known as reinforcement learning, where machines learn through trial and error to make good decisions.We designed a new learning method that allows computers to effectively transfer their experience from past tasks to solve new, related ones faster and more accurately. Our key idea was to separate what remains common across tasks from what changes, much like identifying common rules in different board games while noting specific rule differences.By structuring the learning process in this way, our approach helps machines use their experience more wisely. This not only makes learning faster and smarter but also lays the groundwork for practical applications ranging from robots adapting to new environments to better decision-making systems in healthcare or business."
Poster,Transformative or Conservative? Conservation laws for ResNets and Transformers,https://ICML.cc//virtual/2025/poster/44796,"Sibylle Marcotte, Rémi Gribonval, Gabriel Peyré","While conservation laws in gradient flow training dynamics are well understood for (mostly shallow) ReLU and linear networks, their study remains largely unexplored for more practical architectures. For this, we first show that basic building blocks such as ReLU (or linear) shallow networks, with or without convolution, have easily expressed conservation laws, and no more than the known ones. In the case of a single attention layer, we also completely describe all conservation laws, and we show that residual blocks have the same conservation laws as the same block without a skip connection. We then introduce the notion of conservation laws that depend only on *a subset* of parameters (corresponding e.g. to a pair of consecutive layers, to a residual block, or to an attention layer). We demonstrate that the characterization of such laws can be reduced to the analysis of the corresponding building block in isolation. Finally, we examine how these newly discovered conservation principles, initially established in the continuous gradient flow regime, persist under discrete optimization dynamics, particularly in the context of Stochastic Gradient Descent (SGD).","Modern artificial intelligence (AI) systems are powerful, but it's hard to understand exactly how they learn. While we know some basic mathematical rules satisfied by simpler models, the ""conservation laws""—which explain how certain properties remain constant during learning—haven't been fully explored in more advanced models.We find that conservation laws also apply to recent AI systems. These laws explain how certain characteristics of the system are preserved throughout learning, and our findings explain why it is enough to analyze specific parts of the AI system, such as individual blocks or layers.This discovery gives us a better understanding of how modern AI models work internally. Even when these systems are trained with common methods, the conservation laws still hold. This could make AI training more stable and reliable, helping to improve performance in a more predictable way."
Poster,Transformer-Based Spatial-Temporal Counterfactual Outcomes Estimation,https://ICML.cc//virtual/2025/poster/44908,"He Li, Haoang Chi, Mingyu Liu, Wanrong Huang, Liyang Xu, Wenjing Yang","The real world naturally has dimensions of time and space. Therefore, estimating the counterfactual outcomes with spatial-temporal attributes is a crucial problem. However, previous methods are based on classical statistical models, which still have limitations in performance and generalization. This paper proposes a novel framework for estimating counterfactual outcomes with spatial-temporal attributes using the Transformer, exhibiting stronger estimation ability. Under mild assumptions, the proposed estimator within this framework is consistent and asymptotically normal. To validate the effectiveness of our approach, we conduct simulation experiments and real data experiments. Simulation experiments show that our estimator has a stronger estimation capability than baseline methods. Real data experiments provide a valuable conclusion to the causal effect of conflicts on forest loss in Colombia. The source code is available at this [URL](https://github.com/lihe-maxsize/DeppSTCI_Release_Version-master).","Understanding what would have happened in a different situation — known as estimating counterfactual outcomes — is key for answering many real-world questions, such as how a policy might affect the environment. But when these events happen across both space and time, existing methods struggle to give accurate answers. In this work, we propose a new approach to estimate counterfactual outcomes that vary across both space and time, using Transformer models — a powerful and general deep learning architecture known for capturing complex patterns. We evaluate our method on both simulated data and real-world events in Colombia, where we study how violent conflicts affect forest loss. Our model performs better than existing methods and offers new insights into the environmental consequences of conflict."
Poster,Transolver++: An Accurate Neural Solver for PDEs on Million-Scale Geometries,https://ICML.cc//virtual/2025/poster/46177,"HUAKUN LUO, Haixu Wu, Hang Zhou, Lanxiang Xing, Yichen Di, Jianmin Wang, Mingsheng Long","Although deep models have been widely explored in solving partial differential equations (PDEs), previous works are primarily limited to data only with up to tens of thousands of mesh points, far from the million-point scale required by industrial simulations that involve complex geometries. In the spirit of advancing neural PDE solvers to real industrial applications, we present Transolver++, a highly parallel and efficient neural solver that can accurately solve PDEs on million-scale geometries. Building upon previous advancements in solving PDEs by learning physical states via Transolver, Transolver++ is further equipped with an extremely optimized parallelism framework and a local adaptive mechanism to efficiently capture eidetic physical states from massive mesh points, successfully tackling the thorny challenges in computation and physics learning when scaling up input mesh size. Transolver++ increases the single-GPU input capacity to million-scale points for the first time and is capable of continuously scaling input size in linear complexity by increasing GPUs. Experimentally, Transolver++ yields 13\% relative promotion across six standard PDE benchmarks and achieves over 20\% performance gain in million-scale high-fidelity industrial simulations, whose sizes are 100$\times$ larger than previous benchmarks, covering car and 3D aircraft designs.","In many real-world applications, such as car and aircraft design, engineers need to simulate how pressure behaves around complex 3D shapes. Traditionally, these simulations can take hours or even days to complete, as they rely on solving complex mathematical equations. In this paper, we present Transolver++, a powerful AI model that significantly accelerates this process while maintaining high accuracy. Through careful optimization, Transolver++ can handle highly detailed 3D geometries with millions of data points, making it practical for real industrial applications. Once trained, it can simulate new scenarios in under a second, delivering a substantial improvement in speed and efficiency. This advancement marks a major step toward replacing traditional simulation tools with AI-powered solutions in engineering and design."
