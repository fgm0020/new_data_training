type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,TopoTune: A Framework for Generalized Combinatorial Complex Neural Networks,https://ICML.cc//virtual/2025/poster/45244,"Mathilde Papillon, Guillermo Bernardez, Claudio Battiloro, Nina Miolane","Graph Neural Networks (GNNs) effectively learn from relational data by leveraging graph symmetries. However, many real-world systems---such as biological or social networks---feature multi-way interactions that GNNs fail to capture. Topological Deep Learning (TDL) addresses this by modeling and leveraging higher-order structures, with Combinatorial Complex Neural Networks (CCNNs) offering a general and expressive approach that has been shown to outperform GNNs. However, TDL lacks the principled and standardized frameworks that underpin GNN development, restricting its accessibility and applicability. To address this issue, we introduce Generalized CCNNs (GCCNs), a simple yet powerful family of TDL models that can be used to systematically transform any (graph) neural network into its TDL counterpart. We prove that GCCNs generalize and subsume CCNNs, while extensive experiments on a diverse class of GCCNs show that these architectures consistently match or outperform CCNNs, often with less model complexity. In an effort to accelerate and democratize TDL, we introduce TopoTune, a lightweight software for defining, building, and training GCCNs with unprecedented flexibility and ease.","Many AI models rely on graphs to learn from structured data—like social networks, molecular structures, or computer networks—because graphs naturally capture who connects to whom. These systems are powerful, but they typically focus only on one-on-one relationships—like a friendship between two people—while ignoring the fact that real-world interactions often happen in groups. Think of a group text, a chemical reaction involving multiple molecules, or a scientific collaboration. Ignoring these multi-way patterns means missing critical structure in the data. Our research addresses this gap by introducing TopoTune, a simple yet powerful tool that upgrades any existing graph-based AI model to learn from richer, group-based relationships. With just a few lines of code, users can define and train such advanced models, called topological models, that previously required deep expertise to build. Our models match or outperform prior state-of-the-art methods, often with reduced memory needs. With TopoTune, we turn a previously complex and fragmented area of machine learning into a unified, accessible toolkit that lowers the barrier to using topological models in real-world research."
Poster,To Steer or Not to Steer? Mechanistic Error Reduction with Abstention for Language Models,https://ICML.cc//virtual/2025/poster/44524,"Anna Hedström, Salim I. Amoukou, Tom Bewley, Saumitra Mishra, Manuela Veloso","We introduce Mechanistic Error Reduction with Abstention (MERA), a principled framework for steering language models (LMs) to mitigate errors through selective, adaptive interventions. Unlike existing methods that rely on fixed, manually tuned steering strengths, often resulting in under or oversteering, MERA addresses these limitations by (i) optimising the intervention direction, and (ii) calibrating when and how much to steer, thereby provably improving performance or abstaining when no confident correction is possible. Experiments across diverse datasets and LM families demonstrate safe, effective, non-degrading error correction and that MERA outperforms existing baselines. Moreover, MERA can be applied on top of existing steering techniques to further enhance their performance, establishing it as a general-purpose and efficient approach to mechanistic activation steering.","Language models (LM) often make mistakes, even on very simple tasks like choosing the right answer in a multiple-choice question. Fixing these errors is challenging: current methods often require re-training or rely on trial-and-error when prompting, which can be costly and unreliable. Our method, MERA, takes a different approach. It uses a lightweight helper model to first estimate how likely the LM is to be wrong, and then gently shifts the model’s internal activity to reduce the probability of an error being made. If the input is already predicted to be correct, then MERA does nothing. But if the helper model is confident that the language model will make a mistake, we steer the LM with MERA.We tested our approach on simple multi-choice tasks across several LMs and found that it generally helps improve accuracy. This makes MERA an efficient, and practical method to apply after training."
Poster,Toward a Unified Theory of Gradient Descent under Generalized Smoothness,https://ICML.cc//virtual/2025/poster/44126,Alexander Tyurin,"We study the classical optimization problem $\min_{x \in \mathbb{R}^d} f(x)$ and analyze the gradient descent (GD) method in both nonconvex and convex settings. It is well-known that, under the $L$–smoothness assumption ($\|\| \nabla^2 f(x) \|\| \leq L$), the optimal point minimizing the quadratic upper bound $f(x_k) + \langle \nabla f(x_k), x_{k+1} - x_k \rangle + \frac{L}{2} \|\| x_{k+1} - x_k \|\|^2$ is $x_{k+1} = x_k - \gamma_k \nabla f(x_k)$ with step size  $\gamma_k = \frac{1}{L}$. Surprisingly, a similar result can be derived under the $\ell$-generalized smoothness assumption ($\|\| \nabla^2 f(x) \|\| \leq \ell( \|\| \nabla f(x) \|\| )$). In this case, we derive the step size $$\gamma_k = \int_{0}^{1} \frac{d v}{\ell( \|\| \nabla f(x_k) \|\| + \|\| \nabla f(x_k) \|\| v)}.$$ Using this step size rule, we improve upon existing theoretical convergence rates and obtain new results in several previously unexplored setups.","We consider the most classical and fundamental problem in optimization: minimizing a function $f$. This problem arises across a wide range of domains, including physics, economics, engineering, and, notably, machine learning (ML) and artificial intelligence (AI), where the training of new models reduces to optimization problems. Under the classical assumption that $f$ is $L$-smooth, these problems have been extensively studied, numerous textbooks and thousands of research papers have been devoted to it. However, this assumption is often overly restrictive: even simple functions such as $- \log x$ and $- \sqrt{1 - x}$ violate it. Moreover, many modern ML and AI problems do not satisfy $L$-smoothness. In this work, we adopt a more general $\ell$-smoothness assumption, which includes a significantly broader class of functions. Under this assumption, we develop a new optimization method, establish novel theoretical guarantees, and derive state-of-the-art convergence rates that improve the previous results."
Poster,Toward Data-centric Directed Graph Learning: An Entropy-driven Approach,https://ICML.cc//virtual/2025/poster/43944,"Xunkai Li, Zhengyu Wu, Kaichi Yu, Hongchao Qin, Guang Zeng, Rong-Hua Li, Guoren Wang","Although directed graphs (digraphs) offer strong modeling capabilities for complex topological systems, existing DiGraph Neural Networks (DiGNNs) struggle to fully capture the concealed rich structural information.    This data-level limitation results in model-level sub-optimal predictive performance and underscores the necessity of further exploring the potential correlations between the directed edges (topology) and node profiles (features and labels) from a data-centric perspective, thereby empowering model-centric neural networks with stronger encoding capabilities.    In this paper, we propose **E**ntropy-driven **D**igraph knowl**E**dge distillatio**N** (EDEN), which can serve as a data-centric digraph learning paradigm or a model-agnostic hot-and-plug data-centric Knowledge Distillation (KD) module.    EDEN implements data-centric machine learning by constructing a coarse-grained Hierarchical Knowledge Tree (HKT) using proposed hierarchical encoding theory, and refining HKT through mutual information analysis of node profiles to guide knowledge distillation during training.    As a general framework, EDEN naturally extends to undirected graphs and consistently delivers strong performance.     Extensive experiments on 14 (di)graph datasets—spanning both homophily and heterophily settings—and across four downstream tasks show that EDEN achieves SOTA results and significantly enhances existing (Di)GNNs.","We improve how computers learn from directed graphs — networks where connections have direction, like a one-way street. These structures, called Digraphs, are ideal for modeling real-world relationships such as information flow or social interactions, but their complexity makes them harder to process.Instead of designing more complex models, we take a data-centric approach. Our method, EDEN, focuses on improving the graph data itself by uncovering deeper patterns within its directional structure.EDEN does two key things:1. It separates the graph’s structure from node-specific data, like features or labels.2. It builds a tree-like structure where the original nodes sit at the bottom as leaves. From this, EDEN discovers higher-level concepts that sit above as parent nodes, capturing the hidden hierarchy within the data.This hierarchical organization reduces structural noise, removing weak or misleading links, and suggesting meaningful new ones. As a result, EDEN produces cleaner, more informative Digraphs that lead to better machine learning performance.By focusing on the data rather than model complexity, EDEN offers a powerful way to extract value from the structure of directed graphs."
Poster,Toward Efficient Kernel-Based Solvers for Nonlinear PDEs,https://ICML.cc//virtual/2025/poster/43900,"Zhitong Xu, Da Long, Yiming Xu, Guang Yang, Shandian Zhe, Houman Owhadi","We introduce a novel kernel learning framework toward efficiently solving nonlinear partial differential equations (PDEs). In contrast to the state-of-the-art kernel solver that embeds differential operators within kernels, posing challenges with a large number of collocation points, our approach eliminates these operators from the kernel. We model the solution using a standard kernel interpolation form and differentiate the interpolant to compute the derivatives. Our framework obviates the need for complex Gram matrix construction between solutions and their derivatives, allowing for a straightforward implementation and scalable computation. As an instance, we allocate the collocation points on a grid and adopt a product kernel, which yields a Kronecker product structure in the interpolation. This structure enables us to avoid computing the full Gram matrix, reducing costs and scaling efficiently to a large number of collocation points. We provide a proof of the convergence and rate analysis of our method under appropriate regularity assumptions. In numerical experiments, we demonstrate the advantages of our method in solving several benchmark PDEs.","This paper introduced a novel kernel learning framework toward efficiently solving nonlinear partial differential equations (PDEs). Pervious method struggle with computational bottlenecks when the number of collocation points is large. In contrast, our framework allows a straightforward implementation and scalable computation by avoiding the computation of the full Gram matrix. We provide a proof of the convergence and rate analysis of our method under appropriate regularity assumptions. In numerical experiments, we demonstrate the advantages of our method in solving several benchmark PDEs."
Poster,Toward Robust Hyper-Detailed Image Captioning: A Multiagent Approach and Dual Evaluation Metrics for Factuality and Coverage,https://ICML.cc//virtual/2025/poster/45289,"Saehyung Lee, Seunghyun Yoon, Trung Bui, Jing Shi, Sungroh Yoon","Multimodal large language models (MLLMs) excel at generating highly detailed captions but often produce hallucinations. Our analysis reveals that existing hallucination detection methods struggle with detailed captions. We attribute this to the increasing reliance of MLLMs on their generated text, rather than the input image, as the sequence length grows. To address this issue, we propose a multiagent approach that leverages LLM-MLLM collaboration to correct given captions. Additionally, we introduce an evaluation framework and a benchmark dataset to facilitate the systematic analysis of detailed captions. Our experiments demonstrate that the proposed evaluation method aligns better with human judgments of factuality than existing metrics. Moreover, we show that current approaches for enhancing MLLM factuality often fail in hyper-detailed image captioning tasks. In contrast, our approach significantly enhances the factual accuracy of captions, even improving those generated by GPT-4V. Finally, we highlight a limitation of VQA-centric benchmarking by demonstrating that an MLLM's performance on VQA benchmarks may not correlate with its ability to generate detailed image captions.","Multimodal AI systems, like GPT-4V, can describe images in rich detail, but they often make things up. This is especially true when the captions get long and specific, as the models tend to rely more on their own generated words than on the actual image. Current tools for detecting these hallucinations don’t work well on such detailed captions. To tackle this, we developed a new method that uses two AI agents, a language model and a vision-language model, that work together to correct inaccurate image descriptions. We also created a benchmark and evaluation tool that more accurately judges how truthful these captions are, based on how humans would assess them. Our experiments show that this approach significantly improves the accuracy of even the strongest models and exposes weaknesses in common evaluation tests like VQA. This work helps move us closer to AI that we can trust to describe images accurately, especially in high-stakes or detail-critical applications."
Poster,Towards a Formal Theory of Representational Compositionality,https://ICML.cc//virtual/2025/poster/44520,"Eric Elmoznino, Thomas Jiralerspong, Yoshua Bengio, Guillaume Lajoie","Compositionality is believed to be fundamental to intelligence. In humans, it underlies the structure of thought and language. In AI, it enables a powerful form of out-of-distribution generalization, in which a model systematically adapts to novel combinations of known concepts. However, while we have strong intuitions about what compositionality is, we lack satisfying formal definitions for it. Here, we propose such a definition called representational compositionality that is conceptually simple, quantitative, and grounded in algorithmic information theory. Intuitively, representational compositionality states that a compositional representation is both expressive and describable as a simple function of parts. We validate our definition on both real and synthetic data, and show how it unifies disparate intuitions from across the literature in both AI and cognitive science. We hope that our definition can inspire the design of novel, theoretically-driven models that better capture the mechanisms of compositional thought. We make our code available at https://github.com/EricElmoznino/complexity_compositionality.","Compositionality is the human ability to combine simple concepts into complex ideas—such as forming new sentences from known words or imagining novel scenes from familiar objects. In artificial intelligence (AI), compositionality helps models adapt quickly to new situations they have never directly experienced. However, despite its importance, scientists haven't agreed on a clear, quantitative way to measure or even define compositionality.We developed a formal definition of compositionality called ""representational compositionality"" grounded in a mathematical framework known as algorithmic information theory. Simply put, representational compositionality defines a representation as compositional if complex ideas can be easily and concisely described using combinations of simpler parts. We tested our definition with both artificial and real-world data and found it aligns closely with intuitions from cognitive science and AI research.Our work provides researchers with a precise tool to measure compositionality, opening avenues for designing smarter AI systems capable of more human-like learning and reasoning."
Poster,Towards a General Time Series Forecasting Model with Unified Representation and Adaptive Transfer,https://ICML.cc//virtual/2025/poster/46383,"Yihang Wang, Yuying Qiu, Peng Chen, Kai Zhao, Yang Shu, Zhongwen Rao, Lujia Pan, Bin Yang, Chenjuan Guo","With the growing availability of multi-domain time series data, there is an increasing demand for general forecasting models pre-trained on multi-source datasets to support diverse downstream prediction scenarios. Existing time series foundation models primarily focus on scaling up pre-training datasets and model sizes to enhance generalization performance.  In this paper, we take a different approach by addressing two critical aspects of general forecasting models: (1) how to derive unified representations from heterogeneous multi-domain time series data, and (2) how to effectively capture domain-specific features to enable adaptive transfer across various downstream scenarios. To address the first aspect, we propose Decomposed Frequency Learning as the pre-training task, which leverages frequency-based masking and reconstruction to decompose coupled semantic information in time series, resulting in unified representations across domains. For the second aspect, we introduce the Time Series Register, which captures domain-specific representations during pre-training and enhances adaptive transferability to downstream tasks. Our model achieves the state-of-the-art forecasting performance on seven real-world benchmarks, demonstrating remarkable few-shot and zero-shot capabilities.","Time series forecasting plays a crucial role in various domains. However, building specific models for each new task is resource intensive.In this paper, we developed ROSE, a lightweight model that is pretrained from multi-domain data and fine-tuned with minimal downstream data for fast application. ROSE develops pre-training tasks from a frequency domain perspective, which helps to learn generalized representations.In addition, it takes into account domain-specific information, allowing the model to achieve faster and better transfer in downstream tasks.ROSE excels in scenarios with scarce data. Its efficiency and adaptability make it practical for real-world applications where data availability and computational resources are limited."
Poster,Towards a Mechanistic Explanation of Diffusion Model Generalization,https://ICML.cc//virtual/2025/poster/45759,"Matthew Niedoba, Berend Zwartsenberg, Kevin Murphy, Frank Wood","We propose a simple, training-free mechanism which explains the generalization behaviour of diffusion models. By comparing pre-trained diffusion models to their theoretically optimal empirical counterparts, we identify a shared local inductive bias across a variety of network architectures. From this observation, we hypothesize that network denoisers generalize through localized denoising operations, as these operations approximate the training objective well over much of the training distribution. To validate our hypothesis, we introduce novel denoising algorithms which aggregate local empirical denoisers to replicate network behaviour. Comparing these algorithms to network denoisers across forward and reverse diffusion processes, our approach exhibits consistent visual similarity to neural network outputs, with lower mean squared error than previously proposed methods.","Diffusion models are a popular type of AI model for generating images. Starting from random noise, they generate images in a step-by-step process by cleaning up the image through ""denoising"" operations that convert noisy images into clean ones using a neural network. Interestingly, past research has shown that even when these models are built in different ways, they tend to produce similar images if trained on the same data and given the same starting point. This suggests that new images are produced through some shared, underlying mechanism which is common to many image diffusion models. In this work, we investigate what this mechanism might be. In particular, we propose that image diffusion models use a denoising operation made up of a combination of denoising operations applied to smaller patches of the image. To test this hypothesis, we propose a simple approximation called PSPC which mimics the patch-based denoising behaviour, without any training. We find PSPC denoises images in a similar way to complex neural network-based diffusion models, supporting the idea that small, local operations can explain much of how diffusion models generate new images. This finding is an important step towards understanding how diffusion models work and could lead to diffusion models that are cheaper to run, more understandable, and more accountable."
Poster,Towards an Explainable Comparison and Alignment of Feature Embeddings,https://ICML.cc//virtual/2025/poster/45981,"Mohammad Jalali, Bahar Dibaei Nia, Farzan Farnia","While several feature embedding models have been developed in the literature, comparisons of these embeddings have largely focused on their numerical performance in classification-related downstream applications. However, an interpretable comparison of different embeddings requires identifying and analyzing mismatches between sample groups clustered within the embedding spaces. In this work, we propose the Spectral Pairwise Embedding Comparison (SPEC) framework to compare embeddings and identify their differences in clustering a reference dataset. Our approach examines the kernel matrices derived from two embeddings and leverages the eigendecomposition of the difference kernel matrix to detect sample clusters that are captured differently by the two embeddings. We present a scalable implementation of this kernel-based approach, with computational complexity that grows linearly with the sample size. Furthermore, we introduce an optimization problem using this framework to align two embeddings,  ensuring that clusters identified in one embedding are also captured in the other model. We provide numerical results demonstrating the SPEC's application to compare and align embeddings on large-scale datasets such as ImageNet and MS-COCO. The code is available at [https://github.com/mjalali/embedding-comparison](github.com/mjalali/embedding-comparison).","Feature embeddings serve as the lenses through which AI models perceive and interpret data, as they determine how different inputs are represented and compared. Traditionally, embedding models have been compared based on their performance on downstream classification tasks, such as accuracy on the benchmark ImageNet dataset. However, this approach does not reveal how the models differ in their underlying understanding of the data.In this work, we propose a new approach for comparing and aligning embedding models by viewing each embedding as a *mechanism for assigning similarity scores between pairs of samples*. A natural question then arises: how do two embedding models cluster the same reference dataset differently? For example, one image embedding might cluster a collection of dog images by breed, while another might cluster them by color or size.To address this, we develop a spectral method called *SPEC* that identifies clusters of samples that are captured differently by two embedding models. This enables us to explain how different models “see” the world in distinct ways. Beyond interpretability, this analysis also provides a pathway for aligning embeddings, that is, adjusting one embedding to better match the clustering structure of another. Our numerical experiments suggest promising results in applying SPEC to both compare and align embedding models across various domains."
