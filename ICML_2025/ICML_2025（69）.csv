type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Defending LVLMs Against Vision Attacks Through Partial-Perception Supervision,https://ICML.cc//virtual/2025/poster/46083,"Qi Zhou, Dongxia Wang, Tianlin Li, Yun Lin, Yang Liu, Jin Song Dong, Qing Guo","Recent studies have raised significant concerns regarding the vulnerability of Large Vision Language Models (LVLMs) to maliciously injected or perturbed input images, which can mislead their responses. Existing defense methods show that such vision attacks are sensitive to image modifications especially cropping, using majority voting across responses of modified images as corrected responses. However, these modifications often result in partial images and distort the semantics, which reduces response quality on clean images after voting. Instead of directly using responses from partial images for voting, we investigate using them to supervise (guide) the LVLM's responses to the original images at inference time. We propose a black-box, training-free method called **DPS (Defense through Partial-Perception Supervision)**. In this approach, the model is prompted using the responses generated by a model that perceives only a partial image.With DPS, the model can adjust its response based on partial image understanding when under attack, while confidently maintaining its original response for clean input. Empirical experiments show our method outperforms the baseline, cutting the average attack success rate by 76.3\% across six datasets on three popular models.","Large Vision-Language Models (LVLMs), such as GPT-4, Gemini 1.5 Flash, and Qwen-VL, can recognize and understand both images and text. However, recent studies show that these models can be fooled by attackers who subtly modify input images, causing them to produce incorrect answers (misleading attacks) or bypass safety mechanisms (jailbreak attacks). Current defenses often rely on voting across answers from cropped or modified versions of the image, but this can hurt performance on normal, unmodified inputs. We propose a new method called DPS (Defense through Partial-Perception Supervision), which instead uses the responses from cropped images to guide the model’s response on the original image. Experiments show that DPS performs better than existing methods against both misleading and jailbreak attacks, while preserving the model’s normal accuracy. DPS is a practical defense that works without changing or retraining the model, doesn’t rely on knowing the attack strategy, and can be easily combined with other defenses."
Poster,DeFoG: Discrete Flow Matching for Graph Generation,https://ICML.cc//virtual/2025/poster/45644,"Yiming Qin, Manuel Madeira, Dorina Thanou, Pascal Frossard","Graph generative models are essential across diverse scientific domains by capturing complex distributions over relational data. Among them, graph diffusion models achieve superior performance but face inefficient sampling and limited flexibility due to the tight coupling between training and sampling stages. We introduce DeFoG, a novel graph generative framework that disentangles sampling from training, enabling a broader design space for more effective and efficient model optimization. DeFoG employs a discrete flow-matching formulation that respects the inherent symmetries of graphs. We theoretically ground this disentangled formulation by explicitly relating the training loss to the sampling algorithm and showing that DeFoG faithfully replicates the ground truth graph distribution. Building on these foundations, we thoroughly investigate DeFoG's design space and propose novel sampling methods that significantly enhance performance and reduce the required number of refinement steps. Extensive experiments demonstrate state-of-the-art performance across synthetic, molecular, and digital pathology datasets, covering both unconditional and conditional generation settings. It also outperforms most diffusion-based models with just 5–10\% of their sampling steps.","Graphs are a powerful way to represent relationships, such as atoms in a molecule, people in a social network, or roads in a city. Being able to generate new graphs helps researchers design novel drugs, discover new materials, and better understand social or transportation systems.We introduce a new method called DeFoG that teaches computers to generate graphs more efficiently and accurately. Instead of relying on traditional step-by-step recipes, DeFoG learns how to gradually transform random noise into a realistic graph, like carving a sculpture from a block of marble. This makes the generation process faster and more reliable. DeFoG is also designed to be flexible, performing well across different kinds of graphs. It focuses on the structure of the graph itself, rather than arbitrary choices like the order in which the nodes are named. This helps it generalize more easily to different applications.We test DeFoG in a range of settings, including real-world problems such as molecular generation and digital pathology, and show that it creates more accurate graphs in less time. This opens up new possibilities in fields like chemistry, biology, and network design."
Poster,Delay-DSGN: A Dynamic Spiking Graph Neural Network with Delay Mechanisms for Evolving Graph,https://ICML.cc//virtual/2025/poster/43816,"Zhiqiang Wang, Jianghao Wen, Jianqing Liang","Dynamic graph representation learning using Spiking Neural Networks (SNNs) exploits the temporal spiking behavior of neurons, offering advantages in capturing the temporal evolution and sparsity of dynamic graphs. However, existing SNN-based methods often fail to effectively capture the impact of latency in information propagation on node representations. To address this, we propose Delay-DSGN, a dynamic spiking graph neural network incorporating a learnable delay mechanism. By leveraging synaptic plasticity, the model dynamically adjusts connection weights and propagation speeds, enhancing temporal correlations and enabling historical data to influence future representations. Specifically, we introduce a Gaussian delay kernel into the neighborhood aggregation process at each time step, adaptively delaying historical information to future time steps and mitigating information forgetting. Experiments on three large-scale dynamic graph datasets demonstrate that Delay-DSGN outperforms eight state-of-the-art methods, achieving the best results in node classification tasks. We also theoretically derive the constraint conditions between the Gaussian kernel's standard deviation and size, ensuring stable training and preventing gradient explosion and vanishing issues.","In the real world, much of the data can be represented as ""graphs,"" such as social networks and transportation networks. These graphs change over time, and we refer to them as ""dynamic graphs."" To understand and utilize these dynamic graphs, researchers have proposed ""dynamic graph representation learning,"" a method that converts each node in the graph (such as a person or a location) into a numerical vector that computers can process. In recent years, a method called ""Spiking Neural Networks (SNNs)"" has been applied to dynamic graph representation learning. It simulates the working mechanism of biological neurons and is particularly good at processing time-dependent data, making it highly suitable for dynamic graphs that evolve over time. However, existing methods often overlook an important factor during information propagation — ""delay."" That is, it takes time for information to travel from one node to another, and this delay affects how nodes are represented. To address this issue, we propose a new model called Delay-DSGN. This model incorporates a learnable delay mechanism that automatically adjusts the speed and strength of information propagation, allowing it to better capture how information evolves over time. As a result, our model can more accurately understand how dynamic graphs change over time and is applicable to various scenarios that require processing temporal graph structures."
Poster,Deliberation in Latent Space via Differentiable Cache Augmentation,https://ICML.cc//virtual/2025/poster/45729,"Luyang Liu, Jonas Pfeiffer, Jiaxing Wu, Jun Xie, Arthur Szlam","Techniques enabling large language models (LLMs) to ""think more"" by generating and attending to intermediate reasoning steps have shown promise in solving complex problems. However, the standard approaches generate sequences of discrete tokens immediately before responding, and so they can incur significant latency costs and be challenging to optimize. In this work, we demonstrate that a frozen LLM can be augmented with an offline coprocessor that operates on the model's key-value (kv) cache. This coprocessor augments the cache with a set of latent embeddings designed to improve the fidelity of subsequent decoding. We train this coprocessor using the language modeling loss from the decoder on standard pretraining data, while keeping the decoder itself frozen. This approach enables the model to learn, in an end-to-end differentiable fashion, how to distill additional computation into its kv-cache. Because the decoder remains unchanged, the coprocessor can operate offline and asynchronously, and the language model can function normally if the coprocessor is unavailable or if a given cache is deemed not to require extra computation. We show experimentally that when a cache is augmented, the decoder achieves lower perplexity on numerous subsequent tokens.  Furthermore, even without any task-specific training, our experiments demonstrate that cache augmentation consistently improves performance across a range of reasoning-intensive tasks.","Large Language Models (LLMs), the AI behind many chatbots, often need to ""think"" through multiple steps to solve complex problems, but current methods for this can be slow or require changing the LLM itself. This makes it hard to boost their reasoning abilities efficiently.We've developed a way to help an LLM ""think"" more deeply without altering its original design. We introduce a separate ""helper"" system (a coprocessor) that examines the LLM's current working memory. This helper then subtly adds refined, concentrated information—what we call latent embeddings—back into the LLM's memory to improve its understanding. This process is designed to be efficient and can even run in the background or offline.Our approach allows the main LLM—which remains unchanged—to achieve significantly better results on tasks requiring complex reasoning and to make more accurate predictions. Because the helper system is external, the LLM can still function normally if the helper isn't active. This method opens the door for AI to perform more thoughtful deliberation on information, potentially leading to more capable and efficient AI assistants."
Poster,Delta Decompression  for MoE-based LLMs Compression,https://ICML.cc//virtual/2025/poster/43461,"Hao Gu, Wei Li, Lujun Li, Qiyuan Zhu, Mark Lee, Shengjie Sun, Wei Xue, Yike Guo","Mixture-of-Experts (MoE) architectures in large language models (LLMs) achieve exceptional performance, but face prohibitive storage and memory requirements. To address these challenges, we present $D^2$-MoE, a new delta decompression compressor for reducing the parameters of MoE LLMs. Based on observations of expert diversity, we decompose their weights into a shared base weight and unique delta weights.  Specifically, our method first merges each expert's weight into the base weight using the Fisher information matrix to capture shared components.  Then, we compress delta weights through Singular Value Decomposition (SVD) by exploiting their low-rank properties.Finally, we introduce a semi-dynamical structured pruning strategy for the base weights, combining static and dynamic redundancy analysis to achieve further parameter reduction while maintaining input adaptivity. In this way, our $D^2$-MoE successfully compacts MoE LLMs to high compression ratios without additional training. Extensive experiments highlight the superiority of our approach, with over 13\% performance gains than other compressors on Mixtral|Phi-3.5|DeepSeek|Qwen2 MoE  LLMs at 40$\sim$60\% compression rates. Codes are available in https://github.com/lliai/D2MoE.","We present $D^2$-MoE, a new compression framework for MoE LLMs. $D^2$-MoE decomposes expert weights into a shared base weight and unique delta weights. The delta weights are then compressed using SVD, and the base weight is further compressed using a semi-dynamical structured pruning strategy. Experimental results show that $D^2$-MoE outperforms existing methods, maintaining high accuracy and low perplexity even at high compression rates."
Poster,De-mark: Watermark Removal in Large Language Models,https://ICML.cc//virtual/2025/poster/46417,"Ruibo Chen, Yihan Wu, Junfeng Guo, Heng Huang","Watermarking techniques offer a promising way to identify machine-generated content via embedding covert information into the contents generated from language models (LMs). However, the robustness of the watermarking schemes has not been well explored. In this paper, we present De-mark, an advanced framework designed to remove n-gram-based watermarks effectively. Our method utilizes a novel querying strategy, termed random selection probing, which aids in assessing the strength of the watermark and identifying the red-green list within the n-gram watermark. Experiments on popular LMs, such as Llama3 and ChatGPT, demonstrate the efficiency and effectiveness of De-mark in watermark removal and exploitation tasks.","As AI-generated text becomes more realistic and widespread, it's increasingly difficult to tell whether the content was written by a human or a machine. To solve this, researchers have developed watermarking techniques that subtly mark AI-generated text, making it detectable later. But how reliable are these marks?We introduce De-mark, a new method that can effectively remove these hidden watermarks, even when we don’t know how they were created. Our technique uses a novel probing strategy to reveal the hidden rules behind the watermark and reverse them. DE-MARK can also steal a watermarking scheme and apply it to another AI model.Our experiments show that De-mark works on some of the most powerful language models today. This raises important questions about the future of watermarking. While our research helps understand and improve the limits of watermarking, it also highlights the urgent need for more robust and ethical watermarking solutions."
Poster,Demeaned Sparse: Efficient Anomaly Detection by Residual Estimate,https://ICML.cc//virtual/2025/poster/45914,"Yifan Fang, Yifei Fang, Ruizhe Chen, Haote Xu, Xinghao Ding, Yue Huang","Frequency-domain image anomaly detection methods can substantially enhance anomaly detection performance, however, they still lack an interpretable theoretical framework to guarantee the effectiveness of the detection process. We propose a novel test to detect anomalies in structural image via a Demeaned Fourier transform (DFT) under factor model framework, and we proof its effectiveness. We also briefly give the asymptotic theories of our test, the asymptotic theory explains why the test can detect anomalies at both the image and pixel levels within the theoretical lower bound. Based on our test, we derive a module called Demeaned Fourier Sparse (DFS) that effectively enhances detection performance in unsupervised anomaly detection tasks, which can construct masks in the Fourier domain and utilize a distribution-free sampling method similar to the bootstrap method. The experimental results indicate that this module can accurately and efficiently generate effective masks for reconstruction-based anomaly detection tasks, thereby enhancing the performance of anomaly detection methods and validating the effectiveness of the theoretical framework.","Imagine you’re trying to spot a tiny crack in a huge glass window or a small flaw in a complicated machine part just by looking at a photo. Detecting such subtle anomalies in images is really important for things like quality control or medical checks. Some advanced methods analyze images by breaking them down into waves and frequencies—kind of like how a music equalizer splits sound into different tones—to find these unusual patterns.However, these frequency-based methods often don’t have a clear explanation for why they work so well. In our research, we developed a new test that uses a special mathematical “lens,” called the Demeaned Fourier Transform, to highlight anomalies in images. We also explain the theory behind it, showing why this test can catch problems both in the big picture and down to tiny details, almost as well as theoretically possible.Building on this, we created a module called Demeaned Fourier Sparse (DFS) that improves anomaly detection without the need for any prior knowledge of abnormal images. It works by smartly selecting parts of the image in the frequency world, like focusing on certain musical notes to find the source of a strange sound. Our tests show that DFS can quickly and accurately create masks, making anomaly detection more reliable and effective."
Poster,Demonstration Selection for In-Context Learning via Reinforcement Learning,https://ICML.cc//virtual/2025/poster/43807,"Xubin Wang, Jianfei Wu, Yuan Yichen, Deyu Cai, Mingzhe Li, Weijia Jia","Diversity in demonstration selection is critical for enhancing model generalization by enabling broader coverage of structures and concepts. Constructing appropriate demonstration sets remains a key research challenge. This paper introduces the Relevance-Diversity Enhanced Selection (RDES), an innovative approach that leverages reinforcement learning (RL) frameworks to optimize the selection of diverse reference demonstrations for tasks amenable to in-context learning (ICL), particularly text classification and reasoning, in few-shot prompting scenarios. RDES employs frameworks like Q-learning and a PPO-based variant to dynamically identify demonstrations that maximize both diversity (quantified by label distribution) and relevance to the task objective. This strategy ensures a balanced representation of reference data, leading to improved accuracy and generalization. Through extensive experiments on multiple benchmark datasets, including diverse reasoning tasks, and involving 14 closed-source and open-source LLMs, we demonstrate that RDES significantly enhances performance compared to ten established baselines. Our evaluation includes analysis of performance across varying numbers of demonstrations on selected datasets. Furthermore, we investigate incorporating Chain-of-Thought (CoT) reasoning, which further boosts predictive performance. The results highlight the potential of RL for adaptive demonstration selection and addressing challenges in ICL.","Large Language Models (LLMs) are powerful AI tools that can do many language-based tasks, such as text annotation and question answering. One way to make them perform well, especially on tasks with limited examples, is called In-Context Learning (ICL), where you give the model a few examples, or demonstrations, along with the new task. A big challenge in ICL is figuring out which examples to choose. Simply picking examples that are very similar to the new task isn't always the best approach; it's also really important to include diverse examples that show the model different types of situations or labels the model might encounter. This paper introduces a new method called Relevance-Diversity Enhanced Selection (RDES). RDES uses a type of AI learning, like teaching a computer to play a game, to select the best set of examples. This learning process helps RDES find examples that are not only relevant to the task but also cover a wide variety of cases, aiming to improve the model's ability to handle new, unseen examples. The method can even be combined with making the model show its step-by-step thinking, known as Chain-of-Thought (CoT). Our experiments show that RDES helps LLMs perform significantly better on various tasks compared to other methods for choosing examples, improving their accuracy and reasoning capabilities."
Poster,Demystifying Catastrophic Forgetting in Two-Stage Incremental Object Detector,https://ICML.cc//virtual/2025/poster/45396,"Qirui Wu, Shizhou Zhang, De Cheng, Yinghui Xing, di xu, Peng Wang, Yanning Zhang","Catastrophic forgetting is a critical chanllenge for incremental object detection (IOD). Most existing methods treat the detector monolithically, relying on instance replay or knowledge distillation without analyzing component-specific forgetting. Through dissection of Faster R-CNN, we reveal a key insight: Catastrophic forgetting is predominantly localized to the RoI Head classifier, while regressors retain robustness across incremental stages. This finding challenges conventional assumptions, motivating us to develop a framework termed NSGP-RePRE. Regional Prototype Replay (RePRE) mitigates classifier forgetting via replay of two types of prototypes: coarse prototypes represent class-wise semantic centers of RoI features, while fine-grained prototypes model intra-class variations. Null Space Gradient Projection (NSGP) is further introduced to eliminate prototype-feature misalignment by updating the feature extractor in directions orthogonal to subspace of old inputs via gradient projection, aligning RePRE with incremental learning dynamics. Our simple yet effective design allows NSGP-RePRE to achieve state-of-the-art performance on the Pascal VOC and MS COCO datasets under various settings. Our work not only advances IOD methodology but also provide pivotal insights for catastrophic forgetting mitigation in IOD. Code will be available soon.","In this paper, we thoroughly examine Faster R-CNN and find that the main cause of forgetting lies in the classifier within the RoI head. To solve this, we introduce NSGP-RePRE, a method that replays regional prototypes and uses a gradient projection technique to stabilize feature learning. Our approach outperforms existing methods on several benchmarks and offers valuable direction for improving incremental object detection."
Poster,Demystifying Cost-Efficiency in LLM Serving over Heterogeneous GPUs,https://ICML.cc//virtual/2025/poster/43564,"Youhe Jiang, Fangcheng Fu, Xiaozhe Yao, Guoliang HE, Xupeng Miao, Ana Klimovic, Bin Cui, Binhang Yuan, Eiko Yoneki","Recent advancements in Large Language Models (LLMs) have led to increasingly diverse requests, accompanied with varying resource (compute and memory) demands to serve them. However, this in turn degrades the cost-efficiency of LLM serving as common practices primarily rely on homogeneous GPU resources. In response to this problem, this work conducts a thorough study about serving LLMs over heterogeneous GPU resources on cloud platforms. The rationale is that different GPU types exhibit distinct compute and memory characteristics, aligning well with the divergent resource demands of diverse requests. Particularly, through comprehensive benchmarking, we discover that the cost-efficiency of LLM serving can be substantially optimized by meticulously determining GPU composition, deployment configurations, and workload assignments. Subsequently, we design a scheduling algorithm via mixed-integer linear programming, aiming at deducing the most cost-efficient serving plan under the constraints of price budget and real-time GPU availability. Remarkably, our approach effectively outperforms homogeneous and heterogeneous baselines under a wide array of scenarios, covering diverse workload traces, varying GPU availablilities, and multi-model serving. This casts new light on more accessible and efficient LLM serving over heterogeneous cloud resources.","This paper aims to address the questions of why and how heterogeneous cloud resources can be utilized for cost-efficient LLM serving. Specifically, we benchmark the cost-efficiency of LLM serving over heterogeneous GPUs, following which, a novel scheduling algorithm is developed. Experimental results demonstrate that our approach outperforms existing works substantially."
