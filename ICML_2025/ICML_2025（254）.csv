type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Rethinking Latent Redundancy in Behavior Cloning: An Information Bottleneck Approach for Robot Manipulation,https://ICML.cc//virtual/2025/poster/45521,"Shuanghao Bai, Wanqi Zhou, Pengxiang Ding, Wei Zhao, Donglin Wang, Badong Chen","Behavior Cloning (BC) is a widely adopted visual imitation learning method in robot manipulation. Current BC approaches often enhance generalization by leveraging large datasets and incorporating additional visual and textual modalities to capture more diverse information. However, these methods overlook whether the learned representations contain redundant information and lack a solid theoretical foundation to guide the learning process. To address these limitations, we adopt an information-theoretic perspective and introduce mutual information to quantify and mitigate redundancy in latent representations. Building on this, we incorporate the Information Bottleneck (IB) principle into BC, which extends the idea of reducing redundancy by providing a structured framework for compressing irrelevant information while preserving task-relevant features. This work presents the first comprehensive study on redundancy in latent representations across various methods, backbones, and experimental settings, while extending the generalizability of the IB to BC. Extensive experiments and analyses on the CortexBench and LIBERO benchmarks show consistent performance improvements with IB across various settings, underscoring the importance of reducing input data redundancy and highlighting its practical value for real-world applications.","How can behavior cloning (BC) be improved by compressing its learned representations?In BC, observations are encoded into latent representations before being mapped to actions. We ask whether these representations retain unnecessary information. To investigate this, we apply the Information Bottleneck (IB) principle to reduce the mutual information between the input and the latent space, aiming to remove task-irrelevant features.Our findings show that latent representations in standard BC are not optimal.By compressing input information, we suppress irrelevant information and improve performance in robotic manipulation tasks. This suggests that focusing on essential information helps BC generalize better, even without adding model complexity.This study highlights a fundamental trade-off between compression and generalization.Too much information can hurt performance, while targeted compression can enhance it. Our work shows that information-theoretic tools like IB offer a promising direction for designing more efficient and robust imitation learning algorithms."
Poster,Rethinking Point Cloud Data Augmentation: Topologically Consistent Deformation,https://ICML.cc//virtual/2025/poster/44072,"Jian Bi, Qianliang Wu, Xiang Li, Shuo Chen, Jianjun Qian, lei luo, Jian Yang","Data augmentation has been widely used in machine learning. Its main goal is to transform and expand the original data using various techniques, creating a more diverse and enriched training dataset. However, due to the disorder and irregularity of point clouds, existing methods struggle to enrich geometric diversity and maintain topological consistency, leading to imprecise point cloud understanding. In this paper, we propose SinPoint, a novel method designed to preserve the topological structure of the original point cloud through a homeomorphism. It utilizes the Sine function to generate smooth displacements. This simulates object deformations, thereby producing a rich diversity of samples. In addition, we propose a Markov chain Augmentation Process to further expand the data distribution by combining different basic transformations through a random process. Our extensive experiments demonstrate that our method consistently outperforms existing Mixup and Deformation methods on various benchmark point cloud datasets, improving performance for shape classification and part segmentation tasks. Specifically, when used with PointNet++ and DGCNN, our method achieves a state-of-the-art accuracy of 90.2 in shape classification with the real-world ScanObjectNN dataset. We release the code at https://github.com/CSBJian/SinPoint.","Existing data augmentation methods for point clouds struggled with maintaining both geometric diversity and topological consistency. This led to difficulties in understanding point clouds accurately, which hindered performance in tasks like shape classification and part segmentation.We proposed a novel method called SinPoint, which uses a homeomorphism to preserve the topological structure of point clouds. The sine function was utilized to simulate smooth deformations, generating a diverse set of samples. Additionally, we introduced a Markov chain Augmentation Process to randomly combine various transformations and further enrich the data.Our research improves the understanding of point clouds by creating more diverse and topologically consistent data, leading to better performance in shape classification and segmentation tasks. Meanwhile, our method provides a new perspective for point cloud data augmentation, constructing homeomorphic variants of the data to expand the distribution of the data."
Poster,Rethinking Score Distilling Sampling for 3D Editing and Generation,https://ICML.cc//virtual/2025/poster/46625,"Xingyu Miao, Haoran Duan, Yang Long, Jungong Han","Score Distillation Sampling (SDS) has emerged as a prominent method for text-to-3D generation by leveraging the strengths of 2D diffusion models. However, SDS is limited to generation tasks and lacks the capability to edit existing 3D assets. Conversely, variants of SDS that introduce editing capabilities often can not generate new 3D assets effectively. In this work, we observe that the processes of generation and editing within SDS and its variants have unified underlying gradient terms. Building on this insight, we propose Unified Distillation Sampling (UDS), a method that seamlessly integrates both the generation and editing of 3D assets. Essentially, UDS refines the gradient terms used in vanilla SDS methods, unifying them to support both tasks. Extensive experiments demonstrate that UDS not only outperforms baseline methods in generating 3D assets with richer details but also excels in editing tasks, thereby bridging the gap between 3D generation and editing.","Creating or modifying 3D shapes with artificial intelligence is difficult because common tools either generate new objects or edit existing ones, and their results often look blurry or unnatural. We studied several leading methods and observed that they follow the same basic steps. Building on this observation, we present Unified Distillation Sampling, a single procedure that can both generate and edit 3D assets by combining a clean estimate of the model with guidance from a text-based image generator. Our method runs in about the same time as earlier techniques and requires less manual adjustment of its settings. In tests across many scenes, it produced sharper, more realistic objects and more faithful edits than previous methods. This work makes it easier for creators and researchers to turn text into high-quality 3D assets and then reshape them without switching between separate tools."
Poster,Rethinking the Bias of Foundation Model under Long-tailed Distribution,https://ICML.cc//virtual/2025/poster/44301,"Jiahao Chen, Bin Qin, Jiangmeng Li, Hao Chen, Bing Su","Long-tailed learning has garnered increasing attention due to its practical significance. Among the various approaches, the fine-tuning paradigm has gained considerable interest with the advent of foundation models. However, most existing methods primarily focus on leveraging knowledge from these models, overlooking the inherent biases introduced by the imbalanced training data they rely on. In this paper, we examine how such imbalances from pre-training affect long-tailed downstream tasks. Specifically, we find the imbalance biases inherited in foundation models on downstream task as parameter imbalance and data imbalance. During fine-tuning, we observe that parameter imbalance plays a more critical role, while data imbalance can be mitigated using existing re-balancing strategies. Moreover, we find that parameter imbalance cannot be effectively addressed by current re-balancing techniques, such as adjusting the logits, during training, unlike data imbalance. To tackle both imbalances simultaneously, we build our method on causal learning and view the incomplete semantic factor as the confounder, which brings spurious correlations between input samples and labels. To resolve the negative effects of this, we propose a novel backdoor adjustment method that learns the true causal effect between input samples and labels, rather than merely fitting the correlations in the data. Notably, we achieve an average performance increase of about 1.67% on each dataset.","Many real-world datasets are imbalanced — some categories have far more examples than others. This makes it harder for machine learning models to perform well on the less common, or ""tail,"" categories. A popular way to address this is to start with a large, pre-trained “foundation model” and fine-tune it for a specific task. But these foundation models themselves are often trained on imbalanced data, introducing hidden biases that current methods fail to fully address.In our study, we investigate how these pre-existing imbalances affect performance during fine-tuning. We identify two types of inherited bias: parameter imbalance (how the model’s internal settings are skewed) and data imbalance (how the training data is distributed). We find that while current methods can partially fix data imbalance, they struggle to handle parameter imbalance effectively.To solve this, we use a technique called causal learning. Our method treats missing or misleading information as a “confounder” and uses a strategy known as backdoor adjustment to learn the real cause-effect relationships — not just surface-level patterns. Our approach improves performance across several datasets by an average of 1.67%."
Poster,Rethinking the Stability-Plasticity Trade-off in Continual Learning from an Architectural Perspective,https://ICML.cc//virtual/2025/poster/43538,"Aojun Lu, Hangjie Yuan, Tao Feng, Yanan Sun","The quest for Continual Learning (CL) seeks to empower neural networks with the ability to learn and adapt incrementally. Central to this pursuit is addressing the stability-plasticity dilemma, which involves striking a balance between two conflicting objectives: preserving previously learned knowledge and acquiring new knowledge. While numerous CL methods aim to achieve this trade-off, they often overlook the impact of network architecture on stability and plasticity, restricting the trade-off to the parameter level. In this paper, we delve into the conflict between stability and plasticity at the architectural level. We reveal that under an equal parameter constraint, deeper networks exhibit better plasticity, while wider networks are characterized by superior stability. To address this architectural-level dilemma, we introduce a novel framework denoted Dual-Arch, which serves as a plug-in component for CL. This framework leverages the complementary strengths of two distinct and independent networks: one dedicated to plasticity and the other to stability. Each network is designed with a specialized and lightweight architecture, tailored to its respective objective. Extensive experiments demonstrate that Dual-Arch enhances the performance of existing CL methods while being up to 87% more compact in terms of parameters.","Continual learning enables AI systems to continuously acquire and update knowledge, but balancing the plasticity (learn new tasks) and stability (retain old knowledge) remains a major challenge. Traditional methods focus on optimizing parameters but overlook how the design of the AI model's architecture affects this balance. We discovered that deeper AI models excel at learning new tasks, while wider models are better at retaining old knowledge. To leverage both strengths, we introduced Dual-Arch, a framework that combines two specialized models: one deep and narrow for plasticity and another wide and shallow for stability. Our method improves continual learning performance across multiple benchmarks with smaller model size. This advancement could benefit AI applications like personal assistants or robotics, where systems must continuously adapt without losing prior skills."
Poster,Rethinking the Temperature for Federated Heterogeneous Distillation,https://ICML.cc//virtual/2025/poster/44541,"Fan Qi, Daxu Shi, Chuokun Xu, Shuai Li, Changsheng Xu","Federated Distillation (FedKD) relies on lightweight knowledge carriers like logits for efficient client-server communication. Although logit-based methods have demonstrated promise in addressing statistical and architectural heterogeneity in federated learning (FL), current approaches remain constrained by suboptimal temperature calibration during knowledge fusion.To address these limitations, we propose ReT-FHD, a framework featuring: 1) Multi-level Elastic Temperature, which dynamically adjusts distillation intensities across model layers, achieving optimized knowledge transfer between heterogeneous local models; 2) Category-Aware Global Temperature Scaling that implements class-specific temperature calibration based on confidence distributions in global logits, enabling personalized distillation policies; 3) Z-Score Guard, a blockchain-verified validation mechanism mitigating 44\% of label-flipping and model poisoning attacks.  Evaluations across diverse benchmarks with varying model/data heterogeneity demonstrate that the ReT-FHD achieves significant accuracy improvements over baseline methods while substantially reducing communication costs compared to existing approaches. Our work establishes that properly calibrated logits can serve as self-sufficient carriers for building scalable and secure heterogeneous FL systems.","A core challenge in federated learning (FL) is ensuring model logits remain effective and secure across devices with heterogeneous data or architectures. We address this by introducing dynamic temperature scaling to adapt logits to device-specific variations and a blockchain verification mechanism, demonstrating that calibrated logits—without auxiliary parameters—act as self-sufficient representations for scalable, secure FL systems, bridging logit-centric optimization with practical heterogeneity."
Poster,Rethinking Time Encoding via Learnable Transformation Functions,https://ICML.cc//virtual/2025/poster/43983,"Xi Chen, Yateng Tang, Jiarong Xu, Jiawei Zhang, Siwei Zhang, Sijia Peng, Xuehao Zheng, Yun Xiong","Effectively modeling time information and incorporating it into applications or models involving chronologically occurring events is crucial. Real-world scenarios often involve diverse and complex time patterns, which pose significant challenges for time encoding methods. While previous methods focus on capturing time patterns, many rely on specific inductive biases, such as using trigonometric functions to model periodicity. This narrow focus on single-pattern modeling makes them less effective in handling the diversity and complexities of real-world time patterns. In this paper, we investigate to improve the existing commonly used time encoding methods and introduce **Learnable Transformation-based Generalized Time Encoding (LeTE)**. We propose using deep function learning techniques to parameterize nonlinear transformations in time encoding, making them learnable and capable of modeling generalized time patterns, including diverse and complex temporal dynamics. By enabling learnable transformations, LeTE encompasses previous methods as specific cases and allows seamless integration into a wide range of tasks. Through extensive experiments across diverse domains, we demonstrate the versatility and effectiveness of LeTE.","Many AI systems need to understand when things happen—whether it’s predicting user activity, detecting fraud, or modeling social interactions. However, existing methods for representing time often assume simple, repeating patterns such as daily or weekly cycles. These assumptions and inductive biases limit their ability to capture the complex, irregular, and mixed temporal patterns commonly found in real-world data.Our research introduces a new time encoding method called **LeTE (Learnable Transformation-based Generalized Time Encoding)**. Instead of relying on hand-crafted assumptions or injecting strong inductive biases—such as those imposed by fixed trigonometric functions—LeTE offers a fully learnable framework that encodes time directly from data. It uses deep function learning to automatically discover flexible and complex time patterns.This allows the time encoding to adapt to periodic, non-periodic, and mixed time patterns, making it not only more versatile but also inherently interpretable, as LeTE encodes time through explicit, structured, and learnable functions that can be directly examined. LeTE unifies and generalizes previous time encoding techniques, and it can be seamlessly integrated into a wide range of machine learning models.In experiments across several domains, our method consistently improves model performance, demonstrating that learning time embeddings directly from data improves both accuracy and robustness in downstream predictions."
Poster,Rethink the Role of Deep Learning towards Large-scale Quantum Systems,https://ICML.cc//virtual/2025/poster/44924,"Yusheng Zhao, Chi Zhang, Yuxuan Du","Characterizing the ground state properties of quantum systems is fundamental to capturing their behavior but computationally challenging. Recent advances in AI have introduced novel approaches, with diverse machine learning (ML) and deep learning (DL) models proposed for this purpose. However, the necessity and specific role of DL models in these tasks remain unclear, as prior studies often employ varied or impractical quantum resources to construct datasets, resulting in unfair comparisons. To address this, we systematically benchmark DL models against traditional ML approaches across three families of Hamiltonian, scaling up to $127$ qubits in three crucial ground-state learning tasks while enforcing equivalent quantum resource usage. Our results reveal that ML models often achieve performance comparable to or even exceeding that of DL approaches across all tasks. Furthermore, a randomization test demonstrates that measurement input features have minimal impact on DL models' prediction performance. These findings challenge the necessity of current DL models in many quantum system learning scenarios and provide valuable insights into their effective utilization.","Understanding the fundamental behavior of quantum systems is essential, but it is also computationally challenging. To address this, researchers have turned to artificial intelligence (AI), including both advanced ""deep learning"" (DL) and simpler ""traditional machine learning"" (ML). However, it wasn't clear if the advanced DL methods were truly necessary or better, especially since previous comparisons were often unfair. This research conducted a fair head-to-head evaluation. By giving both DL and ML models the same quantum resource to learn from, the study found that simpler ML models often performed just as well, or even better, at predicting quantum system properties. While current simpler ML methods may be more effective for many quantum learning tasks, discovering DL methods that are well-matched to these tasks remains an important direction for future research."
Poster,Retraining-free Merging of Sparse MoE via Hierarchical Clustering,https://ICML.cc//virtual/2025/poster/44392,"I-Chun Chen, Hsu-Shen Liu, Wei-Fang Sun, Chen-Hao Chao, Yen-Chang Hsu, Chun-Yi Lee","Sparse Mixture-of-Experts (SMoE) models represent a significant advancement in large language model (LLM) development through their efficient parameter utilization. These models achieve substantial performance improvements at reducedinference costs. However, the deployment of SMoE models faces constraints from extensive memory requirements of expert components in resource-limited environments. To address these limitations, this paper introduces Hierarchical Clustering for Sparsely activated Mixture of Experts (HC-SMoE), a task-agnostic expert merging framework for parameter reduction without retraining. HC-SMoE introduces a novel hierarchical clustering approach based on expert outputs to ensure merging robustness independent of routing decisions. The proposed output-based clustering method enables effective capture of functional relationships between experts for large-scale architectures. We provide theoretical analysis and comprehensive evaluations across multiple zero-shot language tasks to demonstrate HC-SMoE’s effectiveness in state-of-the-art models including Qwen and Mixtral. The experimental results validate HC-SMoE’s superior performance and practical applicability for real-world deployments. Our implementation is available at https://github.com/wazenmai/HC-SMoE.","Modern language technologies rely on very large systems that can generate human-like text. To make these systems faster and more efficient, researchers often divide them into smaller expert components, where only a few are used at a time. This design saves computation, but the storage requirements for all the expert components still remain high, which limits deployment in memory-constrained environments.This research introduces a method to reduce the number of expert components without rebuilding the system from scratch. The key idea is to merge similar experts by analyzing the way they behave when given the same input. To do this, we use a process called hierarchical clustering that progressively groups experts based on how similarly they respond to the same input. We demonstrate that this approach maintains strong performance across a wide range of language tasks while significantly reducing memory usage. This makes large-scale language technologies more accessible and easier to deploy in real-world applications."
Poster,Retraining with Predicted Hard Labels Provably Increases Model Accuracy,https://ICML.cc//virtual/2025/poster/43932,"Rudrajit Das, Inderjit Dhillon, Alessandro Epasto, Adel Javanmard, Jieming Mao, Vahab Mirrokni, Sujay Sanghavi, Peilin Zhong","The performance of a model trained with noisy labels is often improved by simply *retraining* the model with its *own predicted hard labels* (i.e., $1$/$0$ labels). Yet, a detailed theoretical characterization of this phenomenon is lacking. In this paper, we theoretically analyze retraining in a linearly separable binary classification setting with randomly corrupted labels given to us and prove that retraining can improve the population accuracy obtained by initially training with the given (noisy) labels. To the best of our knowledge, this is the first such theoretical result. Retraining finds application in improving training with local label differential privacy (DP), which involves training with noisy labels. We empirically show that retraining selectively on the samples for which the predicted label matches the given label significantly improves label DP training at no extra privacy cost; we call this consensus-based retraining. For example, when training ResNet-18 on CIFAR-100 with $\epsilon=3$ label DP, we obtain more than $6$% improvement in accuracy with consensus-based retraining.","Training machine learning (ML) models with incorrect or noisy supervision (i.e., labels) is a common challenge in the real world. Surprisingly, simply retraining a model using its own predicted labels often improves its performance -- even though those predictions come from the same model initially trained on bad data. Despite the practical success of this trick, a solid mathematical understanding of how/when/why it works has been missing.We theoretically analyze model retraining for a binary (two-class) classification problem where the given labels are corrupted, and characterize the conditions under which retraining can improve the model's performance.We also explore how this idea helps in label differential privacy (DP), a private machine learning technique wherein the privacy of the training labels is protected by deliberately adding label noise. We propose consensus-based retraining, a method that only uses those examples for which the model's prediction matches the given label. We empirically show that consensus-based retraining leads to significant performance gains.Ultimately, our paper offers theoretical insight and practical value for building better ML models under noisy supervision with the simple idea of retraining."
