type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Counterfactual Contrastive Learning with Normalizing Flows for Robust Treatment Effect Estimation,https://ICML.cc//virtual/2025/poster/45050,"Jiaxuan Zhang, Emadeldeen Eldele, Fuyuan CAO, Yang Wang, Xiaoli Li, Jiye Liang","Estimating Individual Treatment Effects (ITE) from observational data is challenging due to covariate shift and counterfactual absence. While existing methods attempt to balance distributions globally, they often lack fine-grained sample-level alignment, especially in scenarios with significant individual heterogeneity. To address these issues, we reconsider counterfactual as a proxy to emulate balanced randomization. Furthermore, we derive a theoretical bound that links the expected ITE estimation error to both factual prediction errors and representation distances between factuals and counterfactuals. Building on this theoretical foundation, we propose FCCL, a novel method designed to effectively capture the nuances of potential outcomes under different treatments by (i) generating diffeomorphic counterfactuals that adhere to the data manifold while maintaining high semantic similarity to their factual counterparts, and (ii) mitigating distribution shift via sample-level alignment grounded in our derived generalization-error bound, which considers factual-counterfactual similarity and category consistency. Extensive evaluations on benchmark datasets demonstrate that FCCL outperforms 13 state-of-the-art methods, particularly in capturing individual-level heterogeneity and handling sparse boundary samples.","In many real-world scenarios, making personalized decisions is essential: digital marketing for tailoring customer strategies, social sciences for policy evaluation, and healthcare for personalized treatment planning. Estimating individual treatment effects (ITE) supports these needs by evaluating how a specific treatment would affect a specific individual. However, this task is challenging because we can only observe factual outcomes, not the counterfactual outcomes—i.e., what would have happened under a different treatment scenario. To address this, we emulate the randomized controlled trials (RCTs) conditions to infer the missing counterfactual outcomes. Our approach generates counterfactuals that are both realistic and meaningful, and it leverages the relationship between factual and counterfactual samples to learn consistent representations for estimating potential outcomes under different treatments. Notably, our method improves the accuracy of ITE estimation, particularly for boundary cases and heterogeneous individuals."
Poster,Counterfactual Effect Decomposition in Multi-Agent Sequential Decision Making,https://ICML.cc//virtual/2025/poster/44311,"Stelios Triantafyllou, Aleksa Sukovic, Yasaman Zolfimoselo, Goran Radanovic","We address the challenge of explaining counterfactual outcomes in multi-agent Markov decision processes. In particular, we aim to explain the total counterfactual effect of an agent's action on the outcome of a realized scenario through its influence on the environment dynamics and the agents' behavior. To achieve this, we introduce a novel causal explanation formula that decomposes the counterfactual effect by attributing to each agent and state variable a score reflecting their respective contributions to the effect. First, we show that the total counterfactual effect of an agent's action can be decomposed into two components: one measuring the effect that propagates through all subsequent agents' actions and another related to the effect that propagates through the state transitions. Building on recent advancements in causal contribution analysis, we further decompose these two effects as follows. For the former, we consider agent-specific effects -- a causal concept that quantifies the counterfactual effect of an agent's action that propagates through a subset of agents. Based on this notion, we use Shapley value to attribute the effect to individual agents. For the latter, we consider the concept of structure-preserving interventions and attribute the effect to state variables based on their ""intrinsic'' contributions. Through extensive experimentation, we demonstrate the interpretability of our approach in a Gridworld environment with LLM-assisted agents and a sepsis management simulator.","When a decision-making system fails, it is important to understand what went wrong and why. A common approach to this problem involves estimating the probability that the system would not have failed if a particular decision had been different. This quantity is known as the counterfactual effect, and it captures how pivotal a specific decision was to the failure. While informative, counterfactual effects can be difficult to interpret in complex systems where multiple agents make decisions over time. To our knowledge, our work is the first to address this interpretability challenge in such multi-agent sequential decision making settings. We introduce a systematic approach to decomposing the effect of an agent’s decision into its influence through other agents and through the underlying environment. The result is a set of scores attributed to each agent and environment state, reflecting their contribution to the counterfactual effect under analysis. Our method can be integrated with existing causal analysis tools to retrospectively analyze failures, offering more nuanced explanations and more principled judgments of accountability."
Poster,Counterfactual Graphical Models: Constraints and Inference,https://ICML.cc//virtual/2025/poster/44882,"Juan Correa, Elias Bareinboim","Graphical models have been widely used as parsimonious encoders of constraints of the underlying probability models. When organized in a structured way, these models can facilitate the derivation of non-trivial constraints, the inference of quantities of interest, and the optimization of their estimands. In particular, causal diagrams allow for the efficient representation of structural constraints of the underlying causal system. In this paper, we introduce an efficient graphical construction called Ancestral Multi-world Networks that is sound and complete for reading counterfactual independences from a causal diagram using d-separation. Moreover, we introduce the counterfactual (ctf-) calculus, which can be used to transform counterfactual quantities using three rules licensed by the constraints encoded in the diagram. This result generalizes Pearl’s celebrated do-calculus from interventional to counterfactual reasoning.","Counterfactual inference allows us to consider, given the factual outcome, how a situation may have evolved had we done something differently. Formally answering this kind of question from empirical data requires strong assumptions about the mechanism that generates the data. In this work, we examine probabilistic models found in the literature to define criteria and rules that allow us to infer counterfactual queries from data collected within the context of empirical sciences. Whenever a query cannot be inferred from these rules, it can be concluded that the assumptions in the model are not sufficient for the task; hence, further data or knowledge of the model are needed."
Poster,Counterfactual Voting Adjustment for Quality Assessment and Fairer Voting in Online Platforms with Helpfulness Evaluation,https://ICML.cc//virtual/2025/poster/44380,"Chang Liu, Yixin Wang, Moontae Lee","Efficient access to high-quality information is vital for online platforms. To promote more useful information, users not only create new content but also evaluate existing content, often through helpfulness voting. Although aggregated votes help service providers rank their user content, these votes are often biased by disparate accessibility per position and the cascaded influence of prior votes. For a fairer assessment of information quality, we propose the Counterfactual Voting Adjustment (CVA), a causal framework that accounts for the context in which individual votes are cast. Through preliminary and semi-synthetic experiments, we show that CVA effectively models the position and herding biases, accurately recovering the predefined content quality. In a real experiment, we demonstrate that reranking content based on the learned quality by CVA exhibits stronger alignment with both user sentiment and quality evaluation assessed by GPT-4o, outperforming system rankings based on aggregated votes and model-based rerankings without causal inference. Beyond the individual quality inference, our embeddings offer comparative insights into the behavioral dynamics of expert user groups across 120 major StackExchange communities.","Online information such as product reviews and Q\&A content is highly valuable, and efficient access to high-quality information benefits users and platforms. The helpfulness voting (upvote/downvote) feature has been widely adopted to address challenges like information overload, diversity, and noise. However, helpfulness votes are often biased due to social influences, such as prior votes and displayed ranking. This work investigates how these biases affect voting behavior and proposes a framework that integrates causal inference with a behavioral model to learn fairer assessments of information quality using only observational data. Our results show that reranking content based on the proposed model better aligns with true quality proxies like comment sentiment and GPT-4o evaluations, outperforming rankings based on raw vote scores or models lacking causal adjustments. With our fairer estimated content quality, platforms can apply better rankings and strengthen their content as a valuable knowledge asset. For users, improved rankings reduce cognitive effort in finding useful information and support fair recognition of their under-appreciated contributions. Additionally, by quantifying the biases, our model offers insights into the behavioral patterns of different StackExchange communities, enabling platforms to understand and address community-specific voting dynamics without costly interventions or human moderator hiring."
Poster,Counting atoms faster: policy-based nuclear magnetic resonance pulse sequencing for atomic abundance measurement,https://ICML.cc//virtual/2025/poster/43724,"Rohan Shenoy, Evan Coleman, Hans Gaensbauer, Elsa Olivetti","Quantifying the elemental composition of a material is a general scientific challenge with broad relevance to environmental sustainability. Existing techniques for the measurement of atomic abundances generally require laboratory conditions and expensive equipment. As a result, they cannot be deployed *in situ* without significant capital investment, limiting their proliferation. Measurement techniques based on nuclear magnetic resonance (NMR) hold promise in this setting due to their applicability across the periodic table, their non-destructive manipulation of samples, and their amenability to *in silico* optimization. In this work, we learn policies to modulate NMR pulses for rapid atomic abundance quantification. Our approach involves three inter-operating agents which (1) rapidly align nuclear spins for measurement, (2) quickly force relaxation to equilibrium, and (3) toggle control between agents (1) and (2) to minimize overall measurement time. To demonstrate this technique, we consider a specific use case of low-magnetic-field carbon-13 quantification for low-cost, portable analysis of foodstuffs and soils. We find significant performance improvements relative to traditional NMR pulse sequencing, and discuss limitations on the applicability of this approach.","Counting the number of atoms of a given element in a sample of material is a general scientific challenge in environmental sustainability. For example, you might want to test whether a food product is exposing you to lead or cadmium poisoning without sending it to a laboratory for testing. Current methods to count atoms generally require expensive and non-portable equipment. As a result, they cannot be used in everyday settings or in remote areas without impractical costs. Measurement techniques based on nuclear magnetic resonance (NMR) are promising to address this challenge because they can target many elements in the periodic table, and they can measure samples of material without destroying or altering them. In this work, we show how to use reinforcement learning in NMR to count atoms faster. We do so by building three inter-operating systems which (1) cause a sample to ""chirp"" a loud radio-wave signal which is related to the count of atoms in the sample, (2) quiet the chirp to quickly reset the system, and (3) switch control between behaviors (1) and (2) to improve overall performance. To demonstrate this technique, we build an example in simulation to demonstrate its application to low-cost, portable analysis of foodstuffs and soils. We find significant performance improvements relative to the traditional approach in NMR, and discuss the limitations of our method."
Poster,Counting in Small Transformers: The Delicate Interplay between Attention and Feed-Forward Layers,https://ICML.cc//virtual/2025/poster/45629,"Freya Behrens, Luca Biggio, Lenka Zdeborová","Next to scaling considerations, architectural design choices profoundly shape the solution space of transformers. In this work, we analyze the solutions simple transformer blocks implement when tackling the histogram task: counting items in sequences. Despite its simplicity, this task reveals a complex interplay between predictive performance, vocabulary and embedding sizes, token-mixing mechanisms, and feed-forward layer capacity. We identify two theoretical counting strategies transformers adopt, relation-based and inventory-based counting, each defining distinct learning regimes for the task. These strategies dictate how functionality is distributed between attention and feed-forward layers. We further show that adding softmax and beginning-of-sequence tokens allow for more robustness when embedding dimensions are comparatively small. Empirical introspection of trained models closely confirms both the learning regimes of the various architectures and the formation of these strategies during training. We demonstrate how a basic task that requires only aggregation and selection is significantly impacted by minor design changes.","We studied how small changes to a popular type of AI model for language modelling, a transformer, affect how it solves a very basic task: counting how many times each item appears in a list. Even though this sounds simple, the way the model goes about solving it can vary a lot depending on how it is built. We found that transformers use two main strategies to count: one compares items in the list directly, while the other keeps track of everything and pulls out the answer later. These strategies split the work differently across parts of the model and sometimes the part that looks at all the items together does most of the work, and other times it’s the part that processes each item one by one. Surprisingly, even small changes can make the model much better at counting, like adding a special symbol at the start of the list or tweaking how the model blends information. This shows that model design really matters, even for simple tasks and that those tasks might not be so simple."
Poster,Covered Forest: Fine-grained generalization analysis of graph neural networks,https://ICML.cc//virtual/2025/poster/43559,"Antonis Vasileiou, Ben Finkelshtein, Floris Geerts, Ron Levie, Christopher Morris","The expressive power of message-passing graph neural networks (MPNNs) is reasonably well understood, primarily through combinatorial techniques from graph isomorphism testing. However, MPNNs' generalization abilities---making meaningful predictions beyond the training set---remain less explored. Current generalization analyses often overlook graph structure, limit the focus to specific aggregation functions, and assume the impractical, hard-to-optimize $0$-$1$ loss function. Here, we extend recent advances in graph similarity theory to assess the influence of graph structure, aggregation, and loss functions on MPNNs' generalization abilities. Our empirical study supports our theoretical insights, improving our understanding of MPNNs' generalization properties.","Machine learning models are most useful when they can make reliable predictions not just on the data they were trained on, but also on new, unseen data. In this project, we investigate this ability---called generalization---for graph neural networks (GNNs), a type of neural network designed to work with graph-structured data such as social networks or chemical molecules. We develop mathematical tools to estimate how many training examples are needed to ensure good performance on new data. Importantly, we also reveal how the graphs’ structure- how their nodes and connections are arranged- impacts the model’s ability to generalize. These insights help guide the design of more effective GNNs and the more efficient use of training data in practice."
Poster,Cover learning for large-scale topology representation,https://ICML.cc//virtual/2025/poster/44511,"Luis Scoccola, Uzu Lim, Heather Harrington","Classical unsupervised learning methods like clustering and linear dimensionality reduction parametrize large-scale geometrywhen it is discrete or linear, while more modern methods from manifold learning find low dimensional representation or infer local geometry by constructing a graph on the input data. More recently, topological data analysis popularized the use of simplicial complexes to represent data topology with two main methodologies: topological inference with geometric complexes and large-scale topology representation with Mapper graphs -- central to these is the nerve construction from topology, which builds a simplicial complex given any cover of a space by subsets. While successful, these have limitations: geometric complexes scale poorly with data size, and Mapper graphs can be hard to tune and only contain low dimensional information. In this paper, we propose to study the problem of learning covers in its own right, and from the perspective of optimization. We describe a method to learn topologically-faithful covers of geometric datasets, and show that the simplicial complexes thus obtained can outperform standard topological inference approaches in terms of size, and Mapper-type algorithms in terms of representation of large-scale topology.","1. We propose the cover learning problem as a general unsupervised learning problem. Given an input geometric data set (such as a point cloud), the goal is to produce a cover of the data (a set of subsets whose union is the entire dataset), which encodes the large-scale topology of the data. Cover learning generalizes clustering, and has applications for both data visualization and topological inference (as in topological data analysis).2. We give a formal interpretation of the cover learning problem from the viewpoint of geometry and topology, and derive a principled loss function for cover learning in the idealized scenario where the data consists of a Riemannian manifold.3. We propose practical estimators for the terms in our loss function, in the case where the space is a weighted graph, and show that optimization is feasible using known optimization tools, including (graph) neural networks and topological optimization.4. We provide an implementation of ShapeDiscover, a cover learning algorithm based on our theory, and showcase it on two sets of experiments: a quantitative one on topological inference, and a qualitative one on large-scale topology visualization. In the first case, ShapeDiscover learns topologically correct simplicial complexes, on synthetic and real data, of smaller size than those obtained with previous topological inference approaches. In the second, ShapeDiscover represents the large-scale topology of real data better, and with more intuitive parameters, than previous TDA algorithms that fit the cover learning framework."
Poster,Cowpox: Towards the Immunity of VLM-based Multi-Agent Systems,https://ICML.cc//virtual/2025/poster/46436,"YUTONG WU, Jie Zhang, Yiming Li, Chao Zhang, Qing Guo, Han Qiu, Nils Lukas, Tianwei Zhang","Vision Language Model (VLM) Agents are stateful, autonomous entities capable of perceiving and interacting with their environments through vision and language.Multi-agent systems comprise specialized agents who collaborate to solve a (complex) task. A core security property is **robustness**, stating that the system maintains its integrity during adversarial attacks. Multi-agent systems lack robustness, as a successful exploit against one agent can spread and **infect** other agents to undermine the entire system's integrity. We propose a defense Cowpox to provably enhance the robustness of a multi-agent system by a distributed mechanism that improves the **recovery rate** of agents by limiting the expected number of infections to other agents.The core idea is to generate and distribute a special *cure sample* that immunizes an agent against the attack before exposure. We demonstrate the effectiveness of Cowpox empirically and provide theoretical robustness guarantees.","In today's world, artificial intelligence systems are becoming more advanced and capable of interacting with the world through both images and language. Some of these AI systems, called Vision-Language Model (VLM) Agents, can even work together in teams—each agent doing a specific job—to tackle complex problems.However, like humans, these AI teams can face serious risks. If one agent is tricked or attacked, the problem can quickly spread to others, just like a virus, threatening the entire team’s ability to function. This makes security, especially something called robustness—the system’s ability to stay safe and reliable under attack—extremely important.To tackle this, the researchers propose a new exploratory defense method called Cowpox. Inspired by the idea of vaccines, Cowpox helps protect these AI agents before they’re attacked. It does this by sending out special ""cure samples"" that can train agents to recognize and resist the threats early on. Think of it like giving the team a heads-up and a shield before danger strikes."
Poster,CPCF: A Cross-Prompt Contrastive Framework for Referring Multimodal Large Language Models,https://ICML.cc//virtual/2025/poster/46688,"Lanyun Zhu, Deyi Ji, Tianrun Chen, Haiyang Wu, De Wen Soh, Jun Liu","Referring MLLMs extend conventional multimodal large language models by allowing them to receive referring visual prompts and generate responses tailored to the indicated regions. However, these models often suffer from suboptimal performance due to incorrect responses tailored to misleading areas adjacent to or similar to the target region. This work introduces CPCF, a novel framework to address this issue and achieve superior results. CPCF contrasts outputs generated from the indicated visual prompt with those from contrastive prompts sampled from misleading regions, effectively suppressing the influence of erroneous information outside the target region on response generation. To further enhance the effectiveness and efficiency of our framework, several novel designs are proposed, including a prompt extraction network to automatically identify suitable contrastive prompts, a self-training method that leverages unlabeled data to improve training quality, and a distillation approach to reduce the additional computational overhead associated with contrastive decoding. Incorporating these novel designs, CPCF achieves state-of-the-art performance, as demonstrated by extensive experiments across multiple benchmarks. Project page: https://lanyunzhu.site/CPCF/","Conventional MLLMs are typically limited to answering abstract and general questions about the entire image, whereas referring MLLMs are designed to receive visual prompts that point to specific regions and generate responses tailored to those indicated areas. However, these models often struggle with suboptimal performance, frequently producing incorrect responses caused by confusion with misleading regions adjacent to or visually similar to the target. To address this issue, this work proposes a novel framework, CPCF, which incorporates an automatic contrastive decoding strategy to reduce such errors, a self-training method to enhance its effectiveness, and a distillation algorithm to mitigate the additional computational overhead introduced by contrastive decoding. Experimental results across multiple benchmarks demonstrate the superior performance of CPCF, paving the way for more reliable and fine-grained MLLMs with fewer mistakes and more accurate region-specific understanding."
