type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,How Transformers Learn Structured Data: Insights From Hierarchical Filtering,https://ICML.cc//virtual/2025/poster/46167,"Jerome Garnier-Brun, Marc Mezard, Emanuele Moscato, Luca Saglietti","Understanding the learning process and the embedded computation in transformers is becoming a central goal for the development of interpretable AI. In the present study, we introduce a hierarchical filtering procedure for data models of sequences on trees, allowing us to hand-tune the range of positional correlations in the data. Leveraging this controlled setting, we provide evidence that vanilla encoder-only transformers can approximate the exact inference algorithm when trained on root classification and masked language modeling tasks, and study *how* this computation is discovered and implemented. We find that correlations at larger distances, corresponding to increasing layers of the hierarchy, are sequentially included by the network during training. By comparing attention maps from models trained with varying degrees of filtering and by probing the different encoder levels, we find clear evidence of a reconstruction of correlations on successive length scales corresponding to the various levels of the hierarchy, which we relate to a plausible implementation of the exact inference algorithm within the same architecture.","Modern artificial intelligence models called transformers power many state-of-the-art technologies, at the forefront of which are Large Language Models such as ChatGPT, Gemini, or Claude, to name a few. These models work by detecting and using intricate patterns and correlations in text, but how they learn to do this is still not fully understood.In our study, we investigate this question using a simplified setting where we generate artificial sequences with a built-in layered structure, somewhat like how language is organized into phrases, subphrases, and words. This controlled setup lets us adjust how much structure is present and observe how it is learned by deep neural networks.We show that standard transformer models, when trained on this kind of data, begin to approximate a known step-by-step method for processing such structures, called belief propagation, even without being explicitly told to do so. Remarkably, this approximation is learned progressively during training, and implemented in a way that is both intuitive and interpretable within the model’s architecture. This provides insight into how current AI systems can, through training alone, come to perform structured algorithmic computations."
Poster,HPS: Hard Preference Sampling for Human Preference Alignment,https://ICML.cc//virtual/2025/poster/44422,"Xiandong Zou, Wanyu LIN, Yuchen Li, Pan Zhou","Aligning Large Language Model (LLM) responses with human preferences is vital for building safe and controllable AI systems. While preference optimization methods based on Plackett-Luce (PL) and Bradley-Terry (BT) models have shown promise, they face challenges such as poor handling of harmful content, inefficient use of dispreferred responses, and, specifically for PL, high computational costs. To address these issues, we propose Hard Preference Sampling (HPS), a novel framework for robust and efficient human preference alignment.  HPS introduces a training loss that prioritizes the most preferred response while rejecting all dispreferred and harmful ones. It emphasizes “hard” dispreferred responses — those closely resembling preferred ones — to enhance the model’s rejection capabilities. By leveraging a single-sample Monte Carlo sampling strategy, HPS reduces computational overhead while maintaining alignment quality. Theoretically, HPS improves sample efficiency over existing PL methods and maximizes the reward margin between preferred and dispreferred responses, ensuring clearer distinctions. Experiments on HH-RLHF and PKU-Safety datasets validate HPS’s effectiveness, achieving comparable BLEU and reward scores while greatly improving reward margins and thus reducing harmful content generation.","Large language models (LLMs) are powerful tools, but they don’t always respond in ways that are safe, helpful, or aligned with human values. Sometimes, they generate content that’s misleading, inappropriate, or even harmful. This raises a crucial question: how can we reliably fine-tune LLMs to give preferred responses while avoiding dispreferred ones?To address this, we propose Hard Preference Sampling (HPS), a novel preference optimization framework for robust and efficient human preference alignment. HPS introduces a training loss that prioritizes the most preferred response while rejecting all dispreferred and harmful ones. It emphasizes “hard” dispreferred responses—those closely resembling preferred ones—to enhance the model’s rejection capabilities. By leveraging a streamlined sampling approach, HPS reduces computational overhead while maintaining alignment quality.Our findings have implications for how we fine-tune language models more effectively and efficiently to align with human preferences, highlighting that focusing on “hard” dispreferred responses is crucial for improving trustworthiness."
Poster,H-Tuning: Toward Low-Cost and Efficient ECG-based Cardiovascular Disease Detection with Pre-Trained Models,https://ICML.cc//virtual/2025/poster/45284,"Rushuang Zhou, Yuanting Zhang, Yining Dong","Fine-tuning large-scale pre-trained models provides an effective solution to alleviate the label scarcity problem in cardiovascular diseases (CVDs) detection using electrocardiogram (ECG). However,  as the pre-trained models scale up, the computational costs for fine-tuning and inference become unaffordable on low-level devices deployed for clinical applications. Additionally, maintaining the model performance under low budgets in computational resources remains a significant challenge. However, a comprehensive study that can address them in a joint framework is still lacking. Here, we propose a holistic method (H-Tuning) for low-cost and efficient fine-tuning of pre-trained models on downstream datasets. Then, the inference costs of the models fine-tuned by H-Tuning are further reduced significantly using a knowledge distillation technique. Experiments on four ECG datasets demonstrate that H-Tuning reduces the GPU memory consumption during fine-tuning by 6.34 times while achieving comparable CVDs detection performance to standard fine-tuning. With the knowledge distillation technique, the model inference latency and the memory consumption are reduced by 4.52 times and 19.83 times. As such, the proposed joint framework allows for the utilization of pre-trained models with high computation efficiency and robust performance, exploring a path toward low-cost and efficient CVDs detection. Code is available at https://github.com/KAZABANA/H-Tuning","With the advancement of deep learning, researchers have started to use large pre-trained and foundation models for automatic cardiovascular diseases (CVDs) detection using electrocardiograms. They can alleviate the shortage of labeled data in clinical practice and achieve high detection performance. However, the computational costs required for fine-tuning and deploying them are too high for the low-level devices deployed for clinical applications. This presents a challenge: How can we leverage these foundation models without exceeding the limited computational resources available in healthcare environments?We developed H-Tuning, a method that efficiently fine-tunes pre-trained models, drastically reducing the GPU memory required by over 6.34 times while preserving detection accuracy. Additionally, we employed knowledge distillation to minimize inference costs further, cutting latency and memory usage by nearly 19.8 times and 4.5 times, respectively.Our research enables the deployment of large foundation models with high computational efficiency, exploring a path toward low-cost and efficient CVDs detection."
Poster,Human-Aligned Image Models Improve Visual Decoding from the Brain,https://ICML.cc//virtual/2025/poster/44377,"Nona Rajabi, Antonio Ribeiro, Miguel Vasco, Farzaneh Taleb, Mårten Björkman, Danica Kragic","Decoding visual images from brain activity has significant potential for advancing brain-computer interaction and enhancing the understanding of human perception. Recent approaches align the representation spaces of images and brain activity to enable visual decoding. In this paper, we introduce the use of human-aligned image encoders to map brain signals to images. We hypothesize that these models more effectively capture perceptual attributes associated with the rapid visual stimuli presentations commonly used in visual brain data recording experiments. Our empirical results support this hypothesis, demonstrating that this simple modification improves image retrieval accuracy by up to 21\% compared to state-of-the-art methods. Comprehensive experiments confirm consistent performance improvements across diverse EEG architectures, image encoders, alignment methods, participants, and brain imaging modalities.","Understanding what someone is seeing based on their brain activity has exciting possibilities, such as helping people to communicate without speaking and learning more about how we perceive the world. One way scientists approach this is by linking patterns in brain signals with the visual content of images. In this study, we explore a new method that uses image-processing models trained to perceive images more similarly to humans. These models help translate brain signals into images more accurately, especially during fast-paced visual experiments often used in brain research. Our results show that this approach can improve the accuracy of matching brain signals to images by up to 21% compared to leading methods. We tested our method across different brain recording techniques, participants, and model types, and consistently saw better performance."
Poster,Human Body Restoration with One-Step Diffusion Model and A New Benchmark,https://ICML.cc//virtual/2025/poster/46455,"Jue Gong, Jingkai Wang, Zheng Chen, Xing Liu, Hong Gu, Yulun Zhang, Xiaokang Yang","Human body restoration, as a specific application of image restoration, is widely applied in practice and plays a vital role across diverse fields. However, thorough research remains difficult, particularly due to the lack of benchmark datasets. In this study, we propose a high-quality dataset automated cropping and filtering (HQ-ACF) pipeline. This pipeline leverages existing object detection datasets and other unlabeled images to automatically crop and filter high-quality human images. Using this pipeline, we constructed a person-based restoration with sophisticated objects and natural activities (*PERSONA*) dataset, which includes training, validation, and test sets. The dataset significantly surpasses other human-related datasets in both quality and content richness. Finally, we propose *OSDHuman*, a novel one-step diffusion model for human body restoration. Specifically, we propose a high-fidelity image embedder (HFIE) as the prompt generator to better guide the model with low-quality human image information, effectively avoiding misleading prompts. Experimental results show that OSDHuman outperforms existing methods in both visual quality and quantitative metrics. The dataset and code are available at: https://github.com/gobunu/OSDHuman.","In everyday life, we often capture human photos that are blurry, noisy, or low in resolution, making it difficult for both viewers and machines to perceive details clearly. Fixing such flaws usually requires large collections of clean before-and-after examples, but no substantial public dataset of high-quality human images existed before our work. To address this, we developed an automated system that scans existing image repositories and retains only sharp, well-framed pictures of people. Using this tool, we built a new dataset called *PERSONA*, which surpasses prior human-related datasets in both scale and diversity, and is freely available to the public. We also propose *OSDHuman*, a fast, one-step AI model designed to restore degraded human images more efficiently than traditional multi-step approaches. OSDHuman uses a high-fidelity prompt generator to extract useful cues from low-quality images while filtering out noise, effectively guiding the restoration process. Our model demonstrates superior performance in facial clarity, clothing textures, and body structure accuracy across both synthetic and real-world scenarios. Due to its efficiency and low computational requirements, it has potential applications in smartphones, surveillance systems, and creative tools. We hope these contributions advance research in human image restoration and enhance everyday visual experiences."
Poster,Human Cognition-Inspired Hierarchical Fuzzy Learning Machine,https://ICML.cc//virtual/2025/poster/45364,"Junbiao Cui, Qin Yue, Jianqing Liang, Jiye Liang","Classification is a cornerstone of machine learning research. Most of the existing classifiers assume that the concepts corresponding to classes can be precisely defined. This notion diverges from the widely accepted understanding in cognitive science, which posits that real-world concepts are often inherently ambiguous. To bridge this big gap, we propose a Human Cognition-Inspired Hierarchical Fuzzy Learning Machine (HC-HFLM), which leverages a novel hierarchical alignment loss to integrate rich class knowledge from human knowledge system into learning process. We further theoretically prove that minimizing this loss can align the hierarchical structure derived from data with those contained in class knowledge, resulting in clear semantics and high interpretability. Systematic experiments verify that the proposed method can achieve significant gains in interpretability and generalization performance.","This paper proposes a human cognition-inspired hierarchical fuzzy learning machine,  achieving significant gains in interpretability and generalization performance."
Poster,Hybrid Batch Normalisation: Resolving the Dilemma of Batch Normalisation in Federated Learning,https://ICML.cc//virtual/2025/poster/43475,"Hongyao Chen, Tianyang Xu, Xiaojun Wu, Josef Kittler","Batch Normalisation (BN) is widely used in conventional deep neural network training to harmonise the input-output distributions for each batch of data.However, federated learning, a distributed learning paradigm, faces the challenge of dealing with non-independent and identically distributed data among the client nodes. Due to the lack of a coherent methodology for updating BN statistical parameters, standard BN degrades the federated learning performance.To this end, it is urgent to explore an alternative normalisation solution for federated learning. In this work, we resolve the dilemma of the BN layer in federated learning by developing a customised normalisation approach, Hybrid Batch Normalisation (HBN). HBN separates the update of statistical parameters (*i.e.*, means and variances used for evaluation) from that of learnable parameters (*i.e.*, parameters that require gradient updates), obtaining unbiased estimates of global statistical parameters in distributed scenarios. In contrast with the existing solutions, we emphasise the supportive power of global statistics for federated learning. The HBN layer introduces a learnable hybrid distribution factor, allowing each computing node to adaptively mix the statistical parameters of the current batch with the global statistics. Our HBN can serve as a powerful plugin to advance federated learning performance.It reflects promising merits across a wide range of federated learning settings, especially for small batch sizes and heterogeneous data. Code is available at https://github.com/Hongyao-Chen/HybridBN.",We propose a hybrid batch normalisation approach in federated learning. We achieve more effective normalisation in data heterogeneous distribution federated learning by adaptively mixing historical unbiased global statistics with local batch statistics. Our hybrid batch normalistion layer can serve as a powerful plugin to advance federated learning performance.
Poster,HybridGS: High-Efficiency Gaussian Splatting Data Compression using Dual-Channel Sparse Representation and Point Cloud Encoder,https://ICML.cc//virtual/2025/poster/46362,"Qi Yang, Le Yang, Geert Van der Auwera, Zhu Li","Most existing 3D Gaussian Splatting (3DGS) compression schemes focus on producing compact 3DGS representation via implicit data embedding. They have long encoding and decoding times and highly customized data format, making it difficult for widespread deployment. This paper presents a new 3DGS compression framework called HybridGS, which takes advantage of both compact generation and standardized point cloud data encoding. HybridGS first generates compact and explicit 3DGS data. A dual-channel sparse representation is introduced to supervise the primitive position and feature bit depth. It then utilizes a canonical point cloud encoder to carry out further data compression and form standard output bitstreams. A simple and effective rate control scheme is proposed to pivot the interpretable data compression scheme. HybridGS does not include any modules aimed at improving 3DGS quality during generation. But experiment results show that it still provides comparable reconstruction performance against state-of-the-art methods, with evidently faster encoding and decoding speed. The code is publicly available at https://github.com/Qi-Yangsjtu/HybridGS .","Current 3D Gaussian Splatting (3DGS) methods suffer from long encoding and decoding times, which make it challenging to be standardized and widely deployed. In this paper, we design a new 3DGS compression pipeline, HybridGS, by combining compact 3DGS generation and point cloud encoders. Our results show that HybridGS can realize comparable compression ratios with SOTA methods, while obviously achieving faster encoding and decoding speeds: from over 1 minute to 0.4~1.6 seconds."
Poster,Hybrid Quantum-Classical Multi-Agent Pathfinding,https://ICML.cc//virtual/2025/poster/45635,"Thore Gerlach, Loong Kuan Lee, Frederic BARBARESCO, Nico Piatkowski","Multi-Agent Path Finding (MAPF) focuses on determining conflict-free paths for multiple agents navigating through a shared space to reach specified goal locations.  This problem becomes computationally challenging, particularly when handling large numbers of agents, as frequently encountered in practical applications like coordinating autonomous vehicles. Quantum Computing (QC) is a promising candidate in overcoming such limits. However, current quantum hardware is still in its infancy and thus limited in terms of computing power and error robustness. In this work, we present the first optimal hybrid quantum-classical MAPF algorithms which are based on branch-and-cut-and-prize. QC is integrated by iteratively solving QUBO problems, based on conflict graphs. Experiments on actual quantum hardware and results on benchmark data suggest that our approach dominates previous QUBO formulations and state-of-the-art MAPF solvers.","Coordinating multiple agents—like drones or delivery robots—to move without collisions is a complex and critical challenge for urban logistics and automated warehouses. This paper introduces two new hybrid quantum-classical algorithms, to solve these large-scale pathfinding problems optimally. By combining classical computing with quantum techniques, the algorithms break the problem into smaller tasks using a mathematical method called Quadratic Unconstrained Binary Optimization (QUBO), which quantum computers handle well. They start with initial paths for each agent and refine them iteratively, using quantum computing to identify better routes while checking for conflicts with classical methods. The algorithms repeatedly adjust and optimize until a collision-free, efficient set of paths is found. The developed algorithms are tested using both classical computers and actual quantum hardware, showing that the proposed hybird method can outperform previous approaches even with current, limited quantum devices. This work highlights how blending quantum and classical computing can already improve real-world applications, such as managing urban drone deliveries or robot fleets. As quantum hardware continues to advance, this hybrid approach promises even greater efficiency and scalability."
Poster,Hybrid Spiking Vision Transformer for Object Detection with Event Cameras,https://ICML.cc//virtual/2025/poster/45011,"Qi Xu, Jie Deng, Jiangrong Shen, Biwu Chen, Huajin Tang, Gang Pan","Event-based object detection has attracted increasing attention for its high temporal resolution, wide dynamic range, and asynchronous address-event representation. Leveraging these advantages, spiking neural networks (SNNs) have emerged as a promising approach, offering low energy consumption and rich spatiotemporal dynamics. To further enhance the performance of event-based object detection, this study proposes a novel hybrid spike vision Transformer (HsVT) model. The HsVT model integrates a spatial feature extraction module to capture local and global features, and a temporal feature extraction module to model time dependencies and long-term patterns in event sequences. This combination enables HsVT to capture spatiotemporal features, improving its capability in handling complex event-based object detection tasks. To support research in this area, we developed the Fall Detection dataset as a benchmark for event-based object detection tasks. The Fall DVS detection dataset protects facial privacy and reduces memory usage thanks to its event-based representation. Experimental results demonstrate that HsVT outperforms existing SNN methods and achieves competitive performance compared to ANN-based models, with fewer parameters and lower energy consumption.","Conventional cameras operate at fixed frame rates, leading to motion blur during fast motion and limited dynamic range under extreme lighting. Event cameras asynchronously capture brightness changes with low latency, enabling high temporal resolution and improved performance in challenging conditions. However, how to efficiently process such asynchronous and sparse data is still a big challenge. Therefore, we propose a hybrid spiking vision Transformer model (HsVT) that combines the low-energy properties of brain-like spiking neural networks (SNNs) with the powerful modeling capabilities of Transformer architectures. The HsVT model is built from four blocks, each combining spatial and temporal feature extraction. Spatial features are captured using multi-axis attention mechanisms and multi-layer perceptrons, while temporal dynamics are implemented by LSTM and a novel Spiking Temporal Feature Extraction (STFE) module we designed. We also construct an event-based fall detection dataset, which not only protects user privacy but also reduces the storage cost. On GEN1 datasets, HsVT outperforms existing SNN methods and achieves similar performance to ANN with fewer parameters and lower power consumption."
