type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,FicGCN: Unveiling the Homomorphic Encryption Efficiency from Irregular Graph Convolutional Networks,https://ICML.cc//virtual/2025/poster/44172,"Zhaoxuan Kan, Husheng Han, shangyi shi, Tenghui Hua, Hang Lu, Xiaowei Li, Jianan Mu, Xing Hu","Graph Convolutional Neural Networks (GCNs) have gained widespread popularity in various fields like personal healthcare and financial systems, due to their remarkable performance. Despite the growing demand for cloud-based GCN services, privacy concerns over sensitive graph data remain significant. Homomorphic Encryption (HE) facilitates Privacy-Preserving Machine Learning (PPML) by allowing computations to be performed on encrypted data. However, HE introduces substantial computational overhead, particularly for GCN operations that require rotations and multiplications in matrix products. The sparsity of GCNs offers significant performance potential, but their irregularity introduces additional operations that reduce practical gains. In this paper, we propose FicGCN, a HE-based framework specifically designed to harness the sparse characteristics of GCNs and strike a globally optimal balance between aggregation and combination operations. FicGCN employs a latency-aware packing scheme, a Sparse Intra-Ciphertext Aggregation (SpIntra-CA) method to minimize rotation overhead, and a region-based data reordering driven by local adjacency structure. We evaluated FicGCN on several popular datasets, and the results show that FicGCN achieved the best performance across all tested datasets, with up to a $4.10\times$ improvement over the latest design.","Graph AI is transforming fields like healthcare and finance by analyzing complex relationships in data, but cloud-based services raise serious privacy concerns for sensitive information. While encryption protects data, it often makes AI computations painfully slow - especially for advanced models like Graph Convolutional Networks (GCNs) that need to process intricate connections. Our solution, FicGCN, breaks this bottleneck by cleverly optimizing how encrypted graph data gets processed. By reorganizing data more efficiently and eliminating unnecessary cryptographic operations, FicGCN achieves something remarkable: it runs privacy-preserving GCNs up to 4.1 times faster than current methods while maintaining complete security. This breakthrough means hospitals can safely analyze patient records in the cloud, financial institutions can detect fraud without exposing sensitive transactions, and various industries can finally harness powerful graph AI without compromising privacy. The technology represents a crucial step toward making privacy-preserving artificial intelligence practical for real-world applications that affect millions of people."
Poster,FIC-TSC: Learning Time Series Classification with Fisher Information Constraint,https://ICML.cc//virtual/2025/poster/45977,"Xiwen Chen, Wenhui Zhu, Peijie Qiu, Hao Wang, Huayu Li, ZIHAN LI, Yalin Wang, Aristeidis Sotiras, Abolfazl Razi","Analyzing time series data is crucial to a wide spectrum of applications, including economics, online marketplaces, and human healthcare. In particular, time series classification plays an indispensable role in segmenting different phases in stock markets, predicting customer behavior, and classifying worker actions and engagement levels. These aspects contribute significantly to the advancement of automated decision-making and system optimization in real-world applications. However, there is a large consensus that time series data often suffers from domain shifts between training and test sets, which dramatically degrades the classification performance. Despite the success of (reversible) instance normalization in handling the domain shifts for time series regression tasks, its performance in classification is unsatisfactory. In this paper, we propose $\textit{FIC-TSC}$, a training framework for time series classification that leverages Fisher information as the constraint. We theoretically and empirically show this is an efficient and effective solution to guide the model converges toward flatter minima, which enhances its generalizability to distribution shifts. We rigorously evaluate our method on 30 UEA multivariate and 85 UCR univariate datasets. Our empirical results demonstrate the superiority of the proposed method over 14 recent state-of-the-art methods.","Time series data—like patterns in brain signals or motion sensor readings—is often used to classify different types of behaviors or conditions. For example, in healthcare, it can help distinguish between healthy and abnormal heart activity. However, models trained for this kind of classification often fail when applied to new data collected under slightly different conditions—a common real-world problem known as domain shift. Our work introduces a new method, called FIC-TSC, that helps machine learning models remain accurate even when the data changes. It does this by applying a principle from statistics called Fisher information, which encourages the model to learn more stable and reliable decision boundaries. We tested our approach on over 100 benchmark datasets and found it consistently outperformed most other leading methods. This makes our technique a strong candidate for real-world applications where reliability across different environments is essential."
Poster,Field Matching: an Electrostatic Paradigm to Generate and Transfer Data,https://ICML.cc//virtual/2025/poster/46213,"Alexander Kolesov, S. Manukhov, Vladimir Palyulin, Aleksandr Korotin","We propose Electrostatic Field Matching (EFM), a novel method that is suitable for both generative modelling and distribution transfer tasks. Our approach is inspired by the physics of an electrical capacitor. We place source and target distributions on the capacitor plates and assign them positive and negative charges, respectively. We then learn the capacitor's electrostatic field using a neural network approximator. To map the distributions to each other, we start at one plate of the capacitor and move the samples along the learned electrostatic field lines until they reach the other plate. We theoretically justify that this approach provably yields the distribution transfer. In practice, we demonstrate the performance of our EFM in toy and image data experiments.","Modern AI systems that transform one image to another or generate images often rely on a class of generative models based on thermodynamics such as Diffusion Models. Despite producing high-quality samples these models are relatively slow, taking many steps during the inference. An alternative among the physics-inspired generative models is PFGM which uses the electrostatic theory. However it is suited only for unconditional generation tasks.Our research focuses on a new  physics-based methodology called Electrostatic field matching (EFM). Contrary to PFGM it is well-suited for unpaired translation as well as image generation tasks. The methodology uses the idea of multi-dimensional capacitor with equally charged plates. The movement along the corresponding electrostatic field lines transforms one data distribution into another.Provided the ground-truth field in the capacitor our approach accelerates the inference process. This opens the door to making powerful AI-based image editing tools much more practical and accessible in everyday applications."
Poster,Finding Wasserstein Ball Center: Efficient Algorithm and The Applications in Fairness,https://ICML.cc//virtual/2025/poster/45217,"Yuntao Wang, Yuxuan Li, Qingyuan Yang, Hu Ding","Wasserstein Barycenter (WB) is a fundamental geometric optimization problem in machine learning, whose objective is to find a representative probability measure that minimizes the sum of Wasserstein distances to given distributions. WB has a number of applications in various areas.  However, WB may lead to unfair outcome towards underrepresented groups in some applications (e.g., a ""minority'' distribution may be far away from the obtained WB under Wasserstein distance). To address this issue, we propose an alternative objective called  ""Wasserstein Ball Center (WBC)''. Specifically, WBC is a distribution that encompasses all input distributions within the minimum Wasserstein distance, which can be formulated as a ``minmax'' optimization problem. We show that the WBC problem with fixed support is equivalent to solving a large-scale linear programming (LP) instance, which is quite different from the previously studied LP model for WB. By incorporating some novel observations on the induced normal equation, we propose an efficient algorithm that accelerates the interior point method by $O(\min(N^2m, Nm^2, m^4))$ times (""$N$'' is the number of distributions and  ""$m$'' is the support size).  Finally,  we conduct a set of experiments on  both synthetic and real-world datasets, demonstrating the computational efficiency  of our algorithm, and showing its ability to provide more fairness for input distributions.","In this paper, we present an efficient algorithm to compute Wasserstein ball center, an alternative of Wasserstein barycenter with emphasis on minority probability distributions, which makes it more suitable for the data fusion tasks that are sensitive to fairness."
Poster,Fine-Grained Captioning of Long Videos through Scene Graph Consolidation,https://ICML.cc//virtual/2025/poster/44795,"Sanghyeok Chu, Seonguk Seo, Bohyung Han","Recent advances in vision-language models have led to impressive progress in caption generation for images and short video clips. However, these models remain constrained by their limited temporal receptive fields, making it difficult to producecoherent and comprehensive captions for long videos. While several methods have been proposed to aggregate information across video segments, they often rely on supervised fine-tuning or incur significant computational overhead. To address these challenges, we introduce a novel framework for long video captioning based on graph consolidation. Our approach first generates segment-level captions, corresponding to individual frames or short video intervals, using off-the-shelf visual captioning models. These captions are then parsed into individual scene graphs, which are subsequently consolidated into a unified graph representation that preserves both holistic context and fine-grained details throughout the video. A lightweight graph-to-text decoder then produces the final video-level caption. This framework effectively extends the temporal understanding capabilities of existing models without requiring any additional fine-tuning on long video datasets. Experimental results show that our method significantly outperforms existing LLM-based consolidation approaches, achieving strong zero-shot performance while substantially reducing computational costs.","Recent advances in AI models have led to impressive progress in caption generation for images and short video clips; however, captioning long videos remains challenging due to their limited temporal understanding.To address these challenges, we introduce a novel framework for long video captioning based on graph consolidation. The proposed framework achieves stronger captioning performance and lower computational cost without requiring additional training on long videos."
Poster,Finite-Sample Convergence Bounds for Trust Region Policy Optimization in Mean Field Games,https://ICML.cc//virtual/2025/poster/45512,"Antonio Ocello, Daniil Tiapkin, Lorenzo Mancini, Mathieu Lauriere, Eric Moulines","We introduce Mean Field Trust Region Policy Optimization (MF-TRPO), a novel algorithm designed to compute approximate Nash equilibria for ergodic Mean Field Games (MFGs) in finite state-action spaces. Building on the well-established performance of TRPO in the reinforcement learning (RL) setting, we extend its methodology to the MFG framework, leveraging its stability and robustness in policy optimization. Under standard assumptions in the MFG literature, we provide a rigorous analysis of MF-TRPO, establishing theoretical guarantees on its convergence. Our results cover both the exact formulation of the algorithm and its sample-based counterpart, where we derive high-probability guarantees and finite sample complexity. This work advances MFG optimization by bridging RL techniques with mean-field decision-making, offering a theoretically grounded approach to solving complex multi-agent problems.","We present a new algorithm called Mean-Field Trust Region Policy Optimization (MF-TRPO) that helps large groups of decision-makers learn how to act in a stable and competitive way. Inspired by tools from reinforcement learning, this method is designed to be reliable even when working with many agents in a data-driven manner. We also show that the method works in theory and in practice, giving clear guidelines on how much data is needed."
Poster,Finite-Time Analysis of Discrete-Time Stochastic Interpolants,https://ICML.cc//virtual/2025/poster/45078,"Yuhao Liu, Yu Chen, Rui Hu, Longbo Huang","The stochastic interpolant framework offers a powerful approach for constructing generative models based on ordinary differential equations (ODEs) or stochastic differential equations (SDEs) to transform arbitrary data distributions. However, prior analyses of this framework have primarily focused on the continuous-time setting, assuming perfect solution of the underlying equations. In this work, we present the first discrete-time analysis of the stochastic interpolant framework, where we introduce a innovative discrete-time sampler and derive a finite-time upper bound on its distribution estimation error. Our result provides a novel quantification on how different factors, including the distance between source and target distributions and estimation accuracy, affect the convergence rate and also offers a new principled way to design efficient schedule for convergence acceleration. Finally, numerical experiments are conducted on the discrete-time sampler to corroborate our theoretical findings.","The stochastic interpolant framework is a powerful method used to build models that can generate new data by transforming one type of data into another. It relies on mathematical equations that describe how systems change over time, helping these models learn how to modify data in useful ways. However, most research on these models has focused on continuous-time settings, assuming that the equations can be solved perfectly.In our work, we shift the focus to how these models behave in discrete-time settings, which is more realistic for many practical applications. We introduce a method for sampling data in this discrete-time framework and show how accurately the model can estimate the desired data distribution over time. Our results also explain how factors like the difference between the starting and target data sets influence how quickly the model can reach the desired outcome. Additionally, we provide strategies for speeding up this process.To validate our findings, we conduct experiments that demonstrate how the theory works in practice. This research offers both a deeper understanding of how these models perform in real-world settings and practical methods for improving their efficiency."
Poster,Finite-Time Convergence Rates in Stochastic Stackelberg Games with Smooth Algorithmic Agents,https://ICML.cc//virtual/2025/poster/43965,"Eric Frankel, Kshitij Kulkarni, Dmitriy Drusvyatskiy, Sewoong Oh, Lillian Ratliff","Decision-makers often adaptively influence downstream competitive agents' behavior to minimize their cost, yet in doing so face critical challenges:  $(i)$ decision-makers might not *a priori* know the agents' objectives; $(ii)$ agents might *learn* their responses, introducing stochasticity and non-stationarity into the decision-making process; and $(iii)$ there may be additional non-strategic environmental stochasticity. Characterizing convergence of this complex system is contingent on how the decision-maker controls for the tradeoff between the induced drift and additional noise from the learning agent behavior and environmental stochasticity. To understand how the learning agents' behavior is influenced by the decision-maker’s actions, we first consider a decision-maker that deploys an arbitrary sequence of actions which induces a sequence of games and corresponding equilibria.   We characterize how the drift and noise in the agents' stochastic algorithms decouples from their optimization error. Leveraging this decoupling and accompanying finite-time efficiency estimates, we design decision-maker algorithms that control the induced drift relative to the agent noise. This enables efficient finite-time tracking of game theoretic equilibrium concepts that adhere to the incentives of the players' collective learning processes.","Many modern problems to which machine learning is applied are such that a decision-maker takes consequential actions that influence downstream user behavior or subsequent actions.  Decision-makers in such settings are adaptively shaping downstream competitive agents' behavior in order to minimize their cost, yet in doing so face critical challenges:  $(i)$ decision-makers might not *a priori* know the agents' objectives; $(ii)$ agents might *learn* their response, introducing stochasticity into the decision-making process; and $(iii)$ there may be additional non-strategic environmental stochasticity.  Characterizing convergence of this complex system is contingent on how the decision-maker accounts for the tradeoff in the ""drift"" they induce in the agents' learning processes and the noise from the learning agents' behavior and the environmental stochasticity. To understand how the learning agents' behavior is influenced by the decision-maker’s actions, we consider a decision-maker that deploys an (potentially arbitrary) sequence of actions each of which induces a game amongst the agents and corresponding equilibria.   We characterize how the drift and noise in the agents' stochastic algorithms decouples from their optimization error. Leveraging this decoupling and accompanying efficiency estimates, we design decision-maker algorithms that control the induced drift relative to the agent noise. Further, we establish a hierarchy of reasonable interaction models that allow progressively more gradient information on the part of the decision-maker, and synthesize appropriate algorithms. This enables efficient finite-time tracking of game theoretic equilibrium concepts that are meaningful in the sense that they respect the incentive structure of the players' learning processes."
Poster,Finite-Time Global Optimality Convergence in Deep Neural Actor-Critic Methods for Decentralized Multi-Agent Reinforcement Learning,https://ICML.cc//virtual/2025/poster/44842,"Zhiyao Zhang, Myeung Suk Oh, Hairi, Ziyue Luo, Alvaro Velasquez, Jia (Kevin) Liu","Actor-critic methods for decentralized multi-agent reinforcement learning (MARL) facilitate collaborative optimal decision making without centralized coordination, thus enabling a wide range of applications in practice. To date, however, most theoretical convergence studies for existing actor-critic decentralized MARL methods are limited to the guarantee of a stationary solution under the linear function approximation. This leaves a significant gap between the highly successful use of deep neural actor-critic for decentralized MARL in practice and the current theoretical understanding. To bridge this gap, in this paper, we make the first attempt to develop a deep neural actor-critic method for decentralized MARL, where both the actor and critic components are inherently non-linear. We show that our proposed method enjoys a global optimality guarantee with a finite-time convergence rate of $\mathcal{O}(1/T)$, where $T$ is the total iteration times. This marks the first global convergence result for deep neural actor-critic methods in the MARL literature. We also conduct extensive numerical experiments, which verify our theoretical results.","Actor-critic methods for decentralized multi-agent reinforcement learning (MARL) facilitate collaborative optimal decision making without centralized coordination, thus enabling a wide range of applications in practice. To date, however, most theoretical convergence studies for existing actor-critic decentralized MARL methods are limited to the guarantee of a stationary solution under the linear function approximation. This leaves a significant gap between the highly successful use of deep neural actor-critic for decentralized MARL in practice and the current theoretical understanding. To bridge this gap, in this paper, we make the first attempt to develop a deep neural actor-critic method for decentralized MARL, where both the actor and critic components are inherently non-linear. We show that our proposed method enjoys a global optimality guarantee with a finite-time convergence rate of $\mathcal{O}(1/T)$, where $T$ is the total iteration times. This marks the first global convergence result for deep neural actor-critic methods in the MARL literature. We also conduct extensive numerical experiments, which verify our theoretical results."
Poster,FireFlow: Fast Inversion of Rectified Flow for Image Semantic Editing,https://ICML.cc//virtual/2025/poster/45703,"Yingying Deng, Xiangyu He, Changwang Mei, Peisong Wang, Fan Tang","Though Rectified Flows (ReFlows) with distillation offer a promising way for fast sampling, its fast inversion transforms images back to structured noise for recovery and following editing remains unsolved. This paper introduces FireFlow, an embarrassingly simple yet effective zero-shot approach that inherits the startling capacity of ReFlow-based models (such as FLUX) in generation while extending its capabilities to accurate inversion and editing in **8** steps. We first demonstrate that a carefully designed numerical solver is pivotal for ReFlow inversion, enabling accurate inversion and reconstruction with the precision of a second-order solver while maintaining the practical efficiency of a first-order Euler method. This solver achieves a $3\times$ runtime speedup compared to state-of-the-art ReFlow inversion and editing techniques while delivering smaller reconstruction errors and superior editing results in a training-free mode. The code is available at [this-URL](https://github.com/HolmesShuan/FireFlow-Fast-Inversion-of-Rectified-Flow-for-Image-Semantic-Editing).","In the field of artificial intelligence, a technique called Rectified Flows (ReFlows) has been developed to generate images quickly. However, once produced, these images have been difficult to revert to their original form for purposes like editing and recovery.Our research introduces FireFlow, a method that enhances the capabilities of current ReFlow models. FireFlow allows images to be accurately reversed from their generated form back to their original state in just 8 steps. This is achieved using a specially designed numerical approach, which combines the precision of advanced methods with the speed of simpler techniques.This advancement has the potential to make image editing and recovery much more efficient and accurate, without requiring additional training. FireFlow is 3x faster than the best existing methods, and it improves the quality of image reconstruction and editing. This represents a significant step forward in making machine learning tools more accessible and practical for real-world applications, helping society to better utilize transformative AI technologies."
