type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Cavia: Camera-controllable Multi-view Video Diffusion with View-Integrated Attention,https://ICML.cc//virtual/2025/poster/44487,"Dejia Xu, Yifan Jiang, Chen Huang, Liangchen Song, Thorsten Gernoth, Liangliang Cao, Zhangyang “Atlas” Wang, Hao Tang","In recent years there have been remarkable breakthroughs in image-to-video generation. However, the 3D consistency and camera controllability of generated frames have remained unsolved. Recent studies have attempted to incorporate camera control into the generation process, but their results are often limited to simple trajectories or lack the ability to generate consistent videos from multiple distinct camera paths for the same scene. To address these limitations, we introduce Cavia, a novel framework for camera-controllable, multi-view video generation, capable of converting an input image into multiple spatiotemporally consistent videos. Our framework extends the spatial and temporal attention modules into view-integrated attention modules, improving both viewpoint and temporal consistency. This flexible design allows for joint training with diverse curated data sources, including scene-level static videos, object-level synthetic multi-view dynamic videos, and real-world monocular dynamic videos. To the best of our knowledge, Cavia is the first framework that enables users to generate multiple videos of the same scene with precise control over camera motion, while simultaneously preserving object motion. Extensive experiments demonstrate that Cavia surpasses state-of-the-art methods in terms of geometric consistency and perceptual quality.","We present Cavia, the first framework that enables users to generate multiple videos of the same scene with precise control over camera motion, while simultaneously preserving object motion. Cavia enables improved 3D consistency and camera controllability of generated videos."
Poster,CEGA: A Cost-Effective Approach for Graph-Based Model Extraction and Acquisition,https://ICML.cc//virtual/2025/poster/45765,"Zebin Wang, Menghan Lin, Bolin Shen, Ken Anderson, Molei Liu, Tianxi Cai, Yushun Dong","Graph Neural Networks (GNNs) have demonstrated remarkable utility across diverse applications, and their growing complexity has made Machine Learning as a Service (MLaaS) a viable platform for scalable deployment. However, this accessibility also exposes GNN to serious security threats, most notably model extraction attacks (MEAs), in which adversaries strategically query a deployed model to construct a high-fidelity replica. In this work, we evaluate the vulnerability of GNNs to MEAs and explore their potential for cost-effective model acquisition in non-adversarial research settings. Importantly, adaptive node querying strategies can also serve a critical role in research, particularly when labeling data is expensive or time-consuming. By selectively sampling informative nodes, researchers can train high-performing GNNs with minimal supervision, which is particularly valuable in domains such as biomedicine, where annotations often require expert input. To address this, we propose a node querying strategy tailored to a highly practical yet underexplored scenario, where bulk queries are prohibited, and only a limited set of initial nodes is available. Our approach iteratively refines the node selection mechanism over multiple learning cycles, leveraging historical feedback to improve extraction efficiency. Extensive experiments on benchmark graph datasets demonstrate our superiority over comparable baselines on accuracy, fidelity, and F1 score under strict query-size constraints. These results highlight both the susceptibility of deployed GNNs to extraction attacks and the promise of ethical, efficient GNN acquisition methods to support low-resource research environments. Our implementation is publicly available at [https://github.com/LabRAI/CEGA](https://github.com/LabRAI/CEGA).","Graph Neural Networks (GNNs) are tools that help us understand complex data with a graph structure, such as how people are connected in a social network or how medicine participates in human metabolism. However, training these models usually requires a significant amount of computational resources and a large number of labeled samples, which can be costly or difficult to obtain. For convenience, many graph-based machine learning models are stored on online servers, raising concerns about their features being extracted by adversaries, which can cause significant financial and reputational loss.In our paper, we investigate strategies for extracting the functionality of graph-based models and evaluate their potential in promoting ethical model acquisition, as well as inspiring defensive structures against malicious model extraction. Specifically, we discussed a convenient situation where we could not ask too many questions to the server upfront or all at once.To help other researchers explore this highly practical yet less studied field, we have created **CEGA**, an easy-to-use tool that enables researchers to apply our approach to their graph learning tasks. With CEGA, people can train effective GNNs for their tasks by _learning_ from existing strong models using minimal supervision."
Poster,CellFlux: Simulating Cellular Morphology Changes via Flow Matching,https://ICML.cc//virtual/2025/poster/46535,"Yuhui Zhang, Yuchang Su, Chenyu Wang, Tianhong Li, Zoe Wefers, Jeffrey J. Nirschl, James Burgess, Daisy Yi Ding, Alejandro Lozano, Emma Lundberg, Serena Yeung","Building a virtual cell capable of accurately simulating cellular behaviors in silico has long been a dream in computational biology. We introduce CellFlux, an image-generative model that simulates cellular morphology changes induced by chemical and genetic perturbations using flow matching. Unlike prior methods, CellFlux models distribution-wise transformations from unperturbed to perturbed cell states, effectively distinguishing actual perturbation effects from experimental artifacts such as batch effects—a major challenge in biological data. Evaluated on chemical (BBBC021), genetic (RxRx1), and combined perturbation (JUMP) datasets, CellFlux generates biologically meaningful cell images that faithfully capture perturbation-specific morphological changes, achieving a 35% improvement in FID scores and a 12% increase in mode-of-action prediction accuracy over existing methods. Additionally, CellFlux enables continuous interpolation between cellular states, providing a potential tool for studying perturbation dynamics. These capabilities mark a significant step toward realizing virtual cell modeling for biomedical research. Project page: https://yuhui-zh15.github.io/CellFlux/.","Scientists have long dreamed of creating a “virtual cell”—a computer model that can accurately simulate how real cells respond to drug or genetic perturbations. Our work introduces CellFlux, a new image-generative model that simulates how cell shape changes under different experimental conditions. Unlike previous methods that directly generate perturbed cell images, CellFlux reformulates the problem as a transformation between two distributions: unperturbed and perturbed cells. It learns this transformation using a principled technique called flow matching. This formulation and solution address a fundamental challenge in biology: batch effects, which—similar to distribution shifts in machine learning—often confound true biological signals with experimental noise. We tested CellFlux on three chemical and genetic perturbation datasets and found that it produces more accurate and biologically meaningful cell images than previous methods. It improves image quality by 35% and biological metrics by 12%. Even more excitingly, CellFlux can simulate smooth and continuous transitions in cell shape between different states—like watching a time-lapse of a cell responding to treatment—providing a valuable tool for studying perturbation dynamics. Overall, CellFlux marks a significant step toward realizing virtual cell modeling for biomedical research."
Poster,Censor Dependent Variational Inference,https://ICML.cc//virtual/2025/poster/44532,"Chuanhui Liu, Xiao Wang","This paper provides a comprehensive analysis of variational inference in latent variable models for survival analysis, emphasizing the distinctive challenges associated with applying variational methods to survival data. We identify a critical weakness in the existing methodology, demonstrating how a poorly designed variational distribution may hinder the objective of survival analysis tasks—modeling time-to-event distributions. We prove that the optimal variational distribution, which perfectly bounds the log-likelihood, may depend on the censoring mechanism. To address this issue, we propose censor-dependent variational inference (CDVI), tailored for latent variable models in survival analysis. More practically, we introduce CD-CVAE, a V-structure Variational Autoencoder (VAE) designed for the scalable implementation of CDVI. Further discussion extends some existing theories and training techniques to survival analysis. Extensive experiments validate our analysis and demonstrate significant improvements in the estimation of individual survival distributions.","Unlike supervised learning, where full labels are available, and unsupervised learning, which uses no labels, censored data provides only partial outcome information, for example, knowing a patient survived up to a certain time without knowing the exact time of death.Does the standard inference paradigm used in latent probabilistic models fall short in handling such data? If so, what changes are needed to address this challenge? Our paper gives a clear and well-supported “yes” and shows that the key is teaching the model to recognize whether each outcome is fully observed—a concept we call a censor-dependent structure in the inference process. This idea allows many existing theories and algorithms to be extended beyond fully labeled settings to better handle censored data, and we explore several of these extensions in the paper. To support practical use, we release a free, easy-to-use algorithm called CD-CVAE, which achieves state-of-the-art performance.Our findings provide guidance for building scalable probabilistic models that treat censored datasets with care."
Poster,CERTAIN: Context Uncertainty-aware One-Shot Adaptation for Context-based Offline Meta Reinforcement Learning,https://ICML.cc//virtual/2025/poster/44655,"Hongtu Zhou, Ruiling Yang, Yakun Zhu, Haoqi Zhao, Hai Zhang, Di Zhang, Junqiao Zhao, Chen Ye, Changjun Jiang","Existing context-based offline meta-reinforcement learning (COMRL) methods primarily focus on task representation learning and given-context adaptation performance. They often assume that the adaptation context is collected using task-specific behavior policies or through multiple rounds of collection. However, in real applications, the context should be collected by a policy in a one-shot manner to ensure efficiency and safety. We find that intrinsic context ambiguity across multiple tasks and out-of-distribution (OOD) issues due to distribution shift significantly affect the performance of one-shot adaptation, which has been largely overlooked in most COMRL research. To address this problem, we propose using heteroscedastic uncertainty in representation learning to identify ambiguous and OOD contexts, and train an uncertainty-aware context collecting policy for effective one-shot online adaptation. The proposed method can be integrated into various COMRL frameworks, including classifier-based, reconstrution-based and contrastive learning-based approaches. Empirical evaluations on benchmark tasks show that our method can improve one-shot adaptation performance by up to 36% and zero-shot adaptation performance by up to 34% compared to existing baseline COMRL methods.","Imagine trying to teach a robot how to do many different tasks, like driving a car, sorting packages, or playing games. Instead of training it from scratch every time, we want the robot to quickly figure out new tasks by learning how to learn — this is called meta-reinforcement learning.In the real world, the robot doesn’t have the luxury of practicing a task many times before doing it. It needs to adapt based on just one try — we call this one-shot adaptation. But that’s hard, especially when:1. The hints it gets about the new task are confusing or unclear.2. The new task is very different from anything it has seen before.Most current methods don’t handle these problems well.This paper introduces a new approach that helps the robot know when it’s unsure or facing something unfamiliar. It does this by measuring uncertainty during learning and using that information to gather better clues about the task. This way, the robot can make smarter decisions even with limited experience."
Poster,Certifiably Robust Model Evaluation in Federated Learning under Meta-Distributional Shifts,https://ICML.cc//virtual/2025/poster/44641,"Amir Najafi, Samin Mahdizadeh Sani, Farzan Farnia","We address the challenge of certifying the performance of a federated learning model on an unseen target network using only measurements from the source network that trained the model. Specifically, consider a source network ""A"" with $K$ clients, each holding private, non-IID datasets drawn from heterogeneous distributions, modeled as samples from a broader meta-distribution $\mu$. Our goal is to provide certified guarantees for the model’s performance on a different, unseen network ""B"", governed by an unknown meta-distribution $\mu'$, assuming the deviation between $\mu$ and $\mu'$ is bounded—either in Wasserstein distance or an $f$-divergence. We derive worst-case uniform guarantees for both the model’s average loss and its risk CDF, the latter corresponding to a novel, adversarially robust version of the Dvoretzky–Kiefer–Wolfowitz (DKW) inequality. In addition, we show how the vanilla DKW bound enables principled certification of the model's true performance on unseen clients within the same (source) network. Our bounds are efficiently computable, asymptotically minimax optimal, and preserve clients' privacy.We also establish non-asymptotic generalization bounds that converge to zero as $K$ grows and the minimum per-client sample size exceeds $\mathcal{O}(\log K)$. Empirical evaluations confirm the practical utility of our bounds across real-world tasks. The project code is available at: github.com/samin-mehdizadeh/Robust-Evaluation-DKW","We propose a privacy-preserving and polynomial-time procedure for evaluating the performance of a given machine learning model over a federated network of $K$ clients. Our goal, however, is to provide robust (worst-case) performance guarantees—i.e., bounds that remain valid when the model is deployed on a closely distributed but unseen network. This scenario frequently arises in pilot deployments, where the pilot is conducted in a slightly different region, city, or community. We demonstrate that both the model’s average loss and its risk CDF can be uniformly and robustly bounded, provided the aforementioned privacy and efficiency constraints are met. To achieve this, we reformulate classical results in statistics—namely, the Glivenko–Cantelli theorem and the Dvoretzky–Kiefer–Wolfowitz (DKW) inequality—into novel, adversarially robust versions that account for distributional shifts. These robust formulations underpin our theoretical guarantees and allow us to quantify uncertainty under worst-case deviations. Finally, we validate our bounds through extensive numerical experiments on real-world datasets, demonstrating both their practical accuracy and their resilience in heterogeneous and privacy-sensitive settings."
Poster,Certification for Differentially Private Prediction in Gradient-Based Training,https://ICML.cc//virtual/2025/poster/43655,"Matthew Wicker, Philip Sosnin, Igor Shilov, Adrianna Janik, Mark Müller, Yves-Alexandre de Montjoye, Adrian Weller, Calvin Tsay","We study private prediction where differential privacy is achieved by adding noise to the outputs of a non-private model. Existing methods rely on noise proportional to the global sensitivity of the model, often resulting in sub-optimal privacy-utility trade-offs compared to private training. We introduce a novel approach for computing dataset-specific upper bounds on prediction sensitivity by leveraging convex relaxation and bound propagation techniques. By combining these bounds with the smooth sensitivity mechanism, we significantly improve the privacy analysis of private prediction compared to global sensitivity-based approaches. Experimental results across real-world datasets in medical image classification and natural language processing demonstrate that our sensitivity bounds are can be orders of magnitude tighter than global sensitivity. Our approach provides a strong basis for the development of novel privacy preserving technologies.","Protecting users' private data when using machine learning models is a growing concern, especially in sensitive areas like healthcare and natural language processing. One way to ensure privacy is by adding random noise to a model’s predictions; however, current methods often add more noise than is necessary, reducing model performance. Our research presents a new way to compute the right amount of noise, by better understanding how sensitive a model's predictions are to changes in the data. Specifically, instead of using a global estimate, we develop a way to compute (or at least bound) more precise, data-specific estimates. Our method is demonstrated on real-world tasks, including medical image analysis and text processing, and we found that it significantly outperforms existing techniques."
Poster,Certified Unlearning for Neural Networks,https://ICML.cc//virtual/2025/poster/46518,"Anastasiia Koloskova, Youssef Allouah, Animesh Jha, Rachid Guerraoui, Sanmi Koyejo","We address the problem of machine unlearning, where the goal is to remove the influence of specific training data from a model upon request, motivated by privacy concerns and regulatory requirements such as the “right to be forgotten.” Unfortunately, existing methods rely on restrictive assumptions or lack formal guarantees.To this end, we propose a novel method for certified machine unlearning, leveraging the connection between unlearning and privacy amplification by stochastic post-processing. Our method uses noisy fine-tuning on the retain data, i.e., data that does not need to be removed, to ensure provable unlearning guarantees. This approach requires no assumptions about the underlying loss function, making it broadly applicable across diverse settings. We analyze the theoretical trade-offs in efficiency and accuracy and demonstrate empirically that our method not only achieves formal unlearning guarantees but also performs effectively in practice, outperforming existing baselines.","Imagine you've shared personal information with a company, only to later decide you want it deleted. While companies can remove your data from their records, the artificial intelligence (AI) models trained on that data might still retain its influence. This poses a challenge: how can we ensure that AI models ""forget"" specific data upon request?Our research tackles this issue by introducing a method that allows AI models to unlearn particular pieces of information when asked. Unlike previous approaches that often come with limitations or lack formal assurances, our technique provides certified guarantees that the specified data no longer affects the model's behavior.We achieve this by retraining the AI model using only the data meant to be retained, adding a layer of randomness to ensure the unwanted information is effectively removed. This approach doesn't rely on specific assumptions about the model's design, making it versatile across various applications.Through theoretical analysis and practical experiments, we demonstrate that our method not only ensures the desired unlearning but also maintains the model's performance. This advancement is a step forward in respecting individual privacy rights in the age of AI."
Poster,CFP-Gen: Combinatorial Functional Protein Generation via Diffusion Language Models,https://ICML.cc//virtual/2025/poster/45932,"Junbo Yin, Chao Zha, Wenjia He, Chencheng Xu, Xin Gao","Existing PLMs generate protein sequences based on a single-condition constraint from a specific modality, struggling to simultaneously satisfy multiple constraints across different modalities. In this work, we introduce CFP-GEN, a novel diffusion language model for Combinatorial Functional Protein GENeration. CFP-GEN facilitates the de novo protein design by integrating multimodal conditions with functional, sequence, and structural constraints. Specifically, an Annotation-Guided Feature Modulation (AGFM) module is introduced to dynamically adjust the protein feature distribution based on composable functional annotations, e.g., GO terms, IPR domains and EC numbers. Meanwhile, the ResidueControlled Functional Encoding (RCFE) module captures residue-wise interaction to ensure more precise control. Additionally, off-the-shelf 3D structure encoders can be seamlessly integrated to impose geometric constraints. We demonstrate that CFP-GEN enables high-throughput generation of novel proteins with functionality comparable to natural proteins, while achieving a high success rate in designing multifunctional proteins.","We developed a new AI algorithm capable of generating entirely new proteins that do not exist in nature, yet exhibit functional properties comparable to natural proteins.This process is similar to how text-to-image models generate images from a description — but instead of pictures, our model generates proteins based on desired biological functions.By simply specifying what a protein should do, the model designs novel sequences that are ready for use in drug discovery, synthetic biology, and medical applications.This unlocks a new way to explore the protein universe, i.e., not by randomly generating proteins, but by purposefully designing them based on desired functions, making the process far more efficient than previous approaches."
Poster,CFPT: Empowering Time Series Forecasting through Cross-Frequency Interaction and Periodic-Aware Timestamp Modeling,https://ICML.cc//virtual/2025/poster/44425,"Feifei Kou, Jiahao Wang, Lei Shi, Yuhan Yao, Yawen Li, Suguo Zhu, Zhongbao Zhang, Junping Du","Long-term time series forecasting has been widely studied, yet two aspects remain insufficiently explored: the interaction learning between different frequency components  and the exploitation of periodic characteristics inherent in timestamps. To address the above issues, we propose **CFPT**, a novel method that empowering time series forecasting through **C**ross-**F**requency Interaction (CFI) and **P**eriodic-Aware **T**imestamp Modeling (PTM). To learn cross-frequency interactions, we design the CFI branch to process signals in frequency domain and captures their interactions through a feature fusion mechanism. Furthermore, to enhance prediction performance by leveraging timestamp periodicity, we develop the PTM branch which transforms timestamp sequences into 2D periodic tensors and utilizes 2D convolution to capture both intra-period dependencies and inter-period correlations of time series based on timestamp patterns. Extensive experiments on multiple real-world benchmarks demonstrate that CFPT achieves state-of-the-art performance in long-term forecasting tasks. The code is publicly available at this repository: https://github.com/BUPT-SN/CFPT.","Long-term time series forecasting has been widely studied for applications spanning numerous sectors, including energy consumption, transportation, and financial markets. However, two aspects remain insufficiently explored: the interaction learning between different frequency components and the exploitation of periodic characteristics inherent in timestamps.We propose CFPT, a novel framework that empowers time series forecasting through two specialized branches. The Cross-Frequency Interaction (CFI) branch processes signals in the frequency domain and captures interactions between low-frequency components carrying fundamental patterns and high-frequency components reflecting short-term dynamics. Meanwhile, our Periodic-Aware Timestamp Modeling (PTM) branch transforms timestamp sequences into 2D periodic tensors, utilizing 2D convolution to capture both intra-period dependencies and inter-period correlations based on timestamp patterns.Our extensive experiments on multiple real-world benchmarks demonstrate that CFPT achieves state-of-the-art performance in long-term forecasting tasks. This advancement enhances prediction accuracy and provides deeper insights into temporal data patterns, helping to improve decision-making processes across diverse domains."
