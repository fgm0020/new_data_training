type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Action-Minimization Meets Generative Modeling: Efficient Transition Path Sampling with the Onsager-Machlup Functional,https://ICML.cc//virtual/2025/poster/45309,"Sanjeev Raja, Martin Šípka, Michael Psenka, Tobias Kreiman, Michal Pavelka, Aditi Krishnapriyan","Transition path sampling (TPS), which involves finding probable paths connecting two points on an energy landscape, remains a challenge due to the complexity of real-world atomistic systems. Current machine learning approaches rely on expensive training procedures and under-utilize growing quantities of atomistic data, limiting scalability and generalization. Generative models of atomistic conformational ensembles sample temporally independent states from energy landscapes, but their application to TPS remains mostly unexplored. In this work, we address TPS by interpreting candidate paths as trajectories sampled from stochastic dynamics induced by the learned score function of generative models, namely denoising diffusion and flow matching. Under these dynamics, finding high-likelihood transition paths becomes equivalent to minimizing the Onsager-Machlup (OM) action functional, enabling us to repurpose pre-trained generative models for TPS in a zero-shot fashion. We demonstrate our approach on a Müller-Brown potential and several fast-folding proteins, where we obtain diverse, physically realistic transition pathways, as well as tetrapeptides, where we demonstrate successful TPS on systems not seen by the generative model during training. Our method can be easily incorporated into new generative models, making it practically relevant as models continue to scale and improve.","Understanding how molecules transition from one stable configuration to another—like how a protein folds or a chemical reaction occurs—is a fundamental challenge in biology and chemistry with tangible applications that have the potential to improve technology and human health. These molecular transitions are rare and hard to observe directly, making them difficult to simulate even with powerful computers. Our research tackles this by reimagining how to find these molecular transitions using machine learning. Specifically, we show that existing generative AI models, originally trained to create static molecular structures, can be repurposed—without retraining—to predict the entire pathway a molecule might follow during such a transition. We do this by combining these models with principles from physics, using a tool called the Onsager-Machlup action to identify the most likely transition paths. This lets us generate physically accurate and diverse transition pathways far more efficiently than traditional simulation methods. Our method works with any generative AI model that produces molecular structures, and we’re sharing our code to encourage others to apply it as these models continue to improve. By enabling faster, more scalable simulations of rare molecular events, our work opens new avenues for drug discovery, protein design, and understanding the physical mechanisms of life."
Poster,ActionPiece: Contextually Tokenizing Action Sequences for Generative Recommendation,https://ICML.cc//virtual/2025/poster/44439,"Yupeng Hou, Jianmo Ni, Zhankui He, Noveen Sachdeva, Wang-Cheng Kang, Ed Chi, Julian McAuley, Derek Cheng","Generative recommendation (GR) is an emerging paradigm where user actions are tokenized into discrete token patterns and autoregressively generated as predictions. However, existing GR models tokenize each action independently, assigning the same fixed tokens to identical actions across all sequences without considering contextual relationships. This lack of context-awareness can lead to suboptimal performance, as the same action may hold different meanings depending on its surrounding context. To address this issue, we propose ActionPiece to explicitly incorporate context when tokenizing action sequences. In ActionPiece, each action is represented as a *set* of item features. Given the action sequence corpora, we construct the vocabulary by merging feature patterns as new tokens, based on their co-occurrence frequency both within individual sets and across adjacent sets. Considering the unordered nature of feature sets, we further introduce set permutation regularization, which produces multiple segmentations of action sequences with the same semantics. Our code is available at: https://github.com/google-deepmind/action_piece.","Many online services, like streaming platforms or shopping websites, recommend what you might want to do next based on your past actions, such as what you watched or bought. Recent AI systems try to generate these recommendations by learning from patterns in user activity, where each action (like watching a movie) is turned into a string of symbols the machine can understand. However, current methods always use the same symbols for the same action, no matter what happened before or after. This ignores context, for example, watching a family movie after a string of horror films might mean something different than watching it after cartoons. Our work, ActionPiece, is the first to make this process context-aware. It converts user actions into symbol sequences that adapt depending on surrounding actions, capturing richer meaning. This helps AI models better understand what people are doing and why, leading to smarter personalized recommendations."
Poster,Activation by Interval-wise Dropout: A Simple Way to Prevent Neural Networks from Plasticity Loss,https://ICML.cc//virtual/2025/poster/44937,"Sangyeon Park, Isaac Han, Seungwon Oh, KyungJoong Kim","Plasticity loss, a critical challenge in neural network training, limits a model's ability to adapt to new tasks or shifts in data distribution. While widely used techniques like L2 regularization and Layer Normalization have proven effective in mitigating this issue, Dropout remains notably ineffective. This paper introduces AID (Activation by Interval-wise Dropout), a novel method inspired by Dropout, designed to address plasticity loss. Unlike Dropout, AID generates subnetworks by applying Dropout with different probabilities on each preactivation interval. Theoretical analysis reveals that AID regularizes the network, promoting behavior analogous to that of deep linear networks, which do not suffer from plasticity loss. We validate the effectiveness of AID in maintaining plasticity across various benchmarks, including continual learning tasks on standard image classification datasets such as CIFAR10, CIFAR100, and TinyImageNet. Furthermore, we show that AID enhances reinforcement learning performance in the Arcade Learning Environment benchmark.","When we train AI models, we want them to keep learning new things over time. But often, after learning something new, they become less able to adapt—this is called “loss of plasticity”. Our work introduces a simple method called AID (Activation by Interval-wise Dropout), which helps neural networks stay flexible and open to new knowledge, even as they continue to train.AID builds on a popular method called Dropout, which helps prevent overfitting by randomly turning off some parts of the network during training. However, AID improves on this idea by turning off different parts of the network based on certain conditions, rather than purely at random. It encourages the network to behave more like a linear system, which past research shows is naturally good at staying adaptable.We tested AID on standard image recognition problems and tasks where the data or target change over time, like classifying images in CIFAR10, CIFAR100, and TinyImageNet. We also tried it in reinforcement learning environments, where AI agents learn in non-stationary environment. Across these challenges, AID helped models maintain their ability to learn and adjust, showing promise as an easy way to improve the long-term adaptability of AI systems."
Poster,Activation Space Interventions Can Be Transferred Between Large Language Models,https://ICML.cc//virtual/2025/poster/45778,"Narmeen Oozeer, Dhruv Nathawani, Nirmalendu Prakash, Michael Lan, Abir HARRASSE, Amirali Abdullah","The study of representation universality in AI models reveals growing convergence across domains, modalities, and architectures. However, the practical applications of representation universality remain largely unexplored. We bridge this gap by demonstrating that safety interventions can be transferred between models through learned mappings of their shared activation spaces. We demonstrate this approach on two well-established AI safety tasks: backdoor removal and refusal of harmful prompts, showing successful transfer of steering vectors that alter the models' outputs in a predictable way. Additionally, we propose a new task, corrupted capabilities, where models are fine-tuned to embed knowledge tied to a backdoor. This tests their ability to separate useful skills from backdoors, reflecting real-world challenges. Extensive experiments across Llama, Qwen and Gemma model families show that our method enables using smaller models to efficiently align larger ones. Furthermore, we demonstrate that autoencoder mappings between base and fine-tuned models can serve as reliable ""lightweight safety switches"", allowing dynamic toggling between model behaviors.","Recent work has found that large language models can develop similar internal thought patterns to one another, even at different sizes. We design a lightweight translator between language model thought patterns that transfers behaviors from one model to another. This translator has multiple applications, particularly in AI safety, a field that aims to fix harmful behaviors in models, such as writing harmful code or responding to dangerous requests. Fixing these problems often means retraining the whole model, which is a costly and time consuming process. Our research advances AI safety as it allows us to transfer safe model behaviors from small models to larger models without retraining either model. For example, if we find a safety switch inside the thoughts of a small model that allows us to change it from being dangerous to harmless, then we can pass this safety switch through our translator to obtain a safety switch in a larger model. This avoids needing to spend resources to find the safety switch in a large model. Our experiments across many models confirm that these translations successfully act as switches that toggle new behaviors on demand."
Poster,Active Evaluation Acquisition for Efficient LLM Benchmarking,https://ICML.cc//virtual/2025/poster/45957,"Yang Li, Jie Ma, Miguel Ballesteros, Yassine Benajiba, Graham Horwood","As large language models (LLMs) become increasingly versatile, numerous large scale benchmarks have been developed to thoroughly assess their capabilities. These benchmarks typically consist of diverse datasets and prompts to evaluate different aspects of LLM performance. However, comprehensive evaluations on hundreds or thousands of prompts incur tremendous costs in terms of computation, money, and time. In this work, we investigate strategies to improve evaluation efficiency by selecting a subset of examples from each benchmark using a learned policy. Our approach models the dependencies across test examples, allowing accurate prediction of the evaluation outcomes for the remaining examples based on the outcomes of the selected ones. Consequently, we only need to acquire the actual evaluation outcomes for the selected subset. We rigorously explore various subset selection policies and introduce a novel RL-based policy that leverages the captured dependencies. Empirical results demonstrate that our approach significantly reduces the number of evaluation prompts required while maintaining accurate performance estimates compared to previous methods.","As AI language models grow more powerful, evaluating their capabilities has become increasingly expensive and time-consuming. Current benchmarks require running thousands of test questions (called prompts) on each model, which can cost millions of dollars and slow down progress. Our research tackles the challenge of how to evaluate these models more efficiently without sacrificing accuracy.We developed a method that learns which prompts are the most informative for each model. Instead of testing every model on every prompt, our system selects a small, customized set of prompts and predicts the rest using a statistical model trained on previous evaluations. This approach is inspired by how a doctor might diagnose a patient using only the most relevant tests.We tested our method on five major evaluation benchmarks, including those used by HuggingFace and Chatbot Arena, and found that we can cut evaluation costs significantly—sometimes by over 90%—while still producing accurate assessments.Our work enables faster and cheaper evaluation of new language models, making it easier for researchers and practitioners to understand model strengths and weaknesses, monitor progress, and ensure responsible deployment of AI systems."
Poster,Active feature acquisition via explainability-driven ranking,https://ICML.cc//virtual/2025/poster/45710,"Osman Berke Guney, Ketan Saichandran, Karim Elzokm, Ziming Zhang, Vijaya Kolachalama","In many practical applications, including medicine, acquiring all relevant data for machine learning models is often infeasible due to constraints on time, cost, and resources. This makes it important to selectively acquire only the most informative features, yet traditional static feature selection methods fall short in scenarios where feature importance varies across instances. Here, we propose an active feature acquisition (AFA) framework, which dynamically selects features based on their importance to each individual case. Our method leverages local explanation techniques to generate instance-specific feature importance rankings. We then reframe the AFA problem as a feature prediction task, introducing a policy network grounded in a decision transformer architecture. This policy network is trained to select the next most informative feature by learning from the feature importance rankings. As a result, features are acquired sequentially, ordered by their predictive significance, leading to more efficient feature selection and acquisition. Extensive experiments on multiple datasets demonstrate that our approach outperforms current state-of-the-art AFA methods in both predictive accuracy and feature acquisition efficiency. These findings highlight the promise of an explainability-driven AFA strategy in scenarios where the cost of feature acquisition is a key concern.","In areas like medicine, gathering all the data needed for computer models can be difficult because it often takes too much time, money, or resources. This means it is important to focus on collecting only the most useful information for each situation. However, traditional methods do not adjust well when different people need different types of data. To solve this, we developed a new approach that chooses which data to collect based on what’s most important for each individual. Our method first determines which information will be most useful, then collects it step by step, prioritizing the most important pieces. When tested on different examples, our approach outperformed existing methods by making more accurate predictions while using fewer resources. This shows that focusing on the right information for each case can make data collection smarter and more efficient."
Poster,Active Fine-Tuning of Multi-Task Policies,https://ICML.cc//virtual/2025/poster/44397,"Marco Bagatella, Jonas Hübotter, Georg Martius, Andreas Krause","Pre-trained generalist policies are rapidly gaining relevance in robot learning due to their promise of fast adaptation to novel, in-domain tasks.This adaptation often relies on collecting new demonstrations for a specific task of interest and applying imitation learning algorithms, such as behavioral cloning.However, as soon as several tasks need to be learned, we must decide *which tasks should be demonstrated and how often?*We study this multi-task problem and explore an interactive framework in which the agent *adaptively* selects the tasks to be demonstrated.We propose AMF (Active Multi-task Fine-tuning), an algorithm to maximize multi-task policy performance under a limited demonstration budget by collecting demonstrations yielding the largest information gain on the expert policy.We derive performance guarantees for AMF under regularity assumptions and demonstrate its empirical effectiveness to efficiently fine-tune neural policies in complex and high-dimensional environments.","Current machine learning methods for robotic control can learn to perform a variety of tasks, especially when additional data demonstrating these tasks is collected. As data collection can be costly, we design an algorithm that decides how much data should be collected for each task to be learned. Intuitively, our algorithm focuses on tasks that the learning agent can learn the most about. We show that this algorithm can be mathematically proven to perform well in a simplified setting, and apply it to several simulated robot arms, which need to learn to move and utilize objects around them."
Poster,Active Learning for Efficient Discovery of Optimal Combinatorial Perturbations,https://ICML.cc//virtual/2025/poster/44533,"Jason Qin, Hans-Hermann Wessels, Carlos Fernandez-Granda, Yuhan Hao","Combinatorial CRISPR screening enables large-scale identification of synergistic gene pairs for combination therapies, but exhaustive experimentation is infeasible. We introduce NAIAD, an active learning framework that efficiently discovers optimal gene pairs by leveraging single-gene perturbation effects and adaptive gene embeddings that scale with the training data size, mitigating overfitting in small-sample learning while capturing complex gene interactions as more data is collected. Evaluated on four CRISPR datasets with over 350,000 interactions, NAIAD trained on small datasets outperforms existing models by up to 40\%. Its recommendation system prioritizes gene pairs with maximum predicted effects, accelerating discovery with fewer experiments. We also extend NAIAD to optimal drug combination identification among 2,000 candidates. Overall, NAIAD enhances combinatorial perturbation design and drives advances in genomics research and therapeutic development in combination therapy. Our code is publicly available at: https://github.com/NeptuneBio/NAIAD","Treating complex diseases like cancer or metabolic disorders often requires targeting more than one gene. But here’s the challenge: the human genome contains around 20,000 genes, which means there are approximately 200 million possible two-gene combinations and for four genes, the number expands into the quadrillions. How can we identify effective gene combinations within this massive combinatorial space?To address this, we've developed an efficient system called NAIAD, which is an integration of AI and laboratory experiments that work iteratively in a loop. We're not using AI to replace lab work; instead, we use AI to narrow down the search space and actively guide scientists toward the most promising gene combinations to test experimentally. For example, NAIAD was able to identify about 150 of the top 200 most promising gene combinations out of 150,000 possibilities by measuring only a small subset: in total 2,500 gene combinations across four rounds of AI + experiments iterations.To support the research community, we’ve made NAIAD publicly available. This tool can improve the design of gene combination experiments and accelerate the discovery of new combination therapies, driving progress in medicine."
Poster,Active Learning of Deep Neural Networks via Gradient-Free Cutting Planes,https://ICML.cc//virtual/2025/poster/43666,"Erica Zhang, Fangzhao Zhang, Mert Pilanci","Active learning methods aim to improve sample complexity in machine learning. In this work, we investigate an active learning scheme via a novel gradient-free cutting-plane training method for ReLU networks of arbitrary depth and develop a convergence theory. We demonstrate, for the first time, that cutting-plane algorithms, traditionally used in linear models, can be extended to deep neural networks despite their nonconvexity and nonlinear decision boundaries. Moreover, this training method induces the first deep active learning scheme known to achieve convergence guarantees, revealing a geometric contraction rate of the feasible set. We exemplify the effectiveness of our proposed active learning method against popular deep active learning baselines via both synthetic data experiments and sentimental classification task on real datasets.","When training AI systems, it's often expensive and time-consuming to collect labeled data. Active learning helps by letting the model choose which examples it wants to learn from, reducing the number of labels needed. In this work, we propose a new way to train deep neural networks that doesn't rely on gradients—the usual way most models learn—but instead uses a method inspired by cutting away infeasible answers (a strategy known as cutting-plane optimization) until only the best ones remain. While this approach has long been used for simpler models, we are the first to show it can work for deep networks too. Even more exciting, our method is the first of its kind to offer theoretical guarantees: we can prove that it will steadily get closer to the correct decision. This is something current deep active learning algorithms cannot do. We test our method on both simple and real-world tasks, showing it performs well even compared to popular active learning techniques used in deep learning today. This opens the door to new ways of understanding and improving how deep learning models learn from limited data."
Poster,Active Learning with Selective Time-Step Acquisition for PDEs,https://ICML.cc//virtual/2025/poster/44573,"Yegon Kim, Hyunsu Kim, Gyeonghoon Ko, Juho Lee","Accurately solving partial differential equations (PDEs) is critical to understanding complex scientific and engineering phenomena, yet traditional numerical solvers are computationally expensive. Surrogate models offer a more efficient alternative, but their development is hindered by the cost of generating sufficient training data from numerical solvers. In this paper, we present a novel framework for active learning (AL) in PDE surrogate modeling that reduces this cost. Unlike the existing AL methods for PDEs that always acquire entire PDE trajectories, our approach strategically generates only the most important time steps with the numerical solver, while employing the surrogate model to approximate the remaining steps. This dramatically reduces the cost incurred by each trajectory and thus allows the active learning algorithm to try out a more diverse set of trajectories given the same budget. To accommodate this novel framework, we develop an acquisition function that estimates the utility of a set of time steps by approximating its resulting variance reduction. We demonstrate the effectiveness of our method on several benchmark PDEs, including the Burgers' equation, Korteweg–De Vries equation, Kuramoto–Sivashinsky equation, the incompressible Navier-Stokes equation, and the compressible Navier-Stokes equation.Experiments show that our approach improves performance by large margins over the best existing method. Our method not only reduces average error but also the 99\%, 95\%, and 50\% quantiles of error, which is rare for an AL algorithm. All in all, our approach offers a data-efficient solution to surrogate modeling for PDEs.","Many scientific and engineering problems rely on partial differential equations (PDEs) — mathematical rules that describe how things like air, water or traffic flow change over time. Unfortunately, computer programs that solve these equations with high accuracy can take hours or even days, so researchers often build faster “surrogate” models that learn from a limited set of high-quality simulations. The catch is that every extra simulation to learn from still costs valuable computer time and energy.Our work introduces a smarter data-collection strategy called Selective Time-Step Acquisition for PDEs (STAP). Instead of asking the expensive simulator to generate every moment in a scenario, STAP first lets a lightweight surrogate guess the easy moments and then pinpoints only the most informative time steps for precise simulation. In this way, each new training example gives more “bang for the buck.”Across five classic PDE benchmarks — from shock-forming Burgers waves to turbulent Navier–Stokes flows — STAP cut simulation costs while also lowering prediction errors compared with existing active-learning methods. By squeezing more knowledge out of fewer simulations, our approach can accelerate research in climate science, engineering design and any field that depends on large-scale PDE modeling."
