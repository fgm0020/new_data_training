type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Settling the Maximin Share Fairness for Scheduling among Groups of Machines,https://ICML.cc//virtual/2025/poster/44880,"Bo Li, Fangxiao WANG, Xing Shiji","We study the fair scheduling of jobs among groups of (unrelated) machines and focus on the maximin share (MMS) fairness at the group level.     The problem was first introduced by Li et al. [NeurIPS 2023], where each group consists of a number of identical machines (or identical up to different speeds), and the cost of a group is determined by the minimum makespan on completing all jobs assigned to it.    It is left as an open problem when the machines within each group are unrelated.    In this paper, we first resolve this problem and design a polynomial-time algorithm that computes a 2-approximate MMS allocation via linear programming techniques.    We complement this result with a hard instance, showing that no algorithm can be better than $(2-\frac{1}{n})$-approximate MMS, where $n$ is the number of machines.    Thus the approximation ratio 2 is asymptotically tight.    When the groups consist of identical machines, we improve the approximation ratio to $\frac{4}{3}$.","The fair scheduling of jobs among groups of (unrelated) machines is studied in the paper and the maximin share at the group level is considered. Our paper uncovers many open problems and further directions.We show that no algorithm can be better than $(2-\frac{1}{n})$-approximate MMS, where $n$ is the number of machines and a 2-approximate MMS allocation can be computed in polynomial time via linear programming techniques.When the groups consist of identical machines, we improve the approximation ratio to $\frac{4}{3}$."
Poster,Set Valued Predictions For Robust Domain Generalization,https://ICML.cc//virtual/2025/poster/45305,"Ron Tsibulsky, Daniel Nevo, Uri Shalit","Despite the impressive advancements in modern machine learning, achieving robustness in Domain Generalization (DG) tasks remains a significant challenge. In DG, models are expected to perform well on samples from unseen test distributions (also called domains), by learning from multiple related training distributions. Most existing approaches to this problem rely on single-valued predictions, which inherently limit their robustness. We argue that set-valued predictors could be leveraged to enhance robustness across unseen domains, while also taking into account that these sets should be as small as possible. We introduce a theoretical framework defining successful set prediction in the DG setting, focusing on meeting a predefined performance criterion across as many domains as possible, and provide theoretical insights into the conditions under which such domain generalization is achievable. We further propose a practical optimization method compatible with modern learning architectures, that balances robust performance on unseen domains with small prediction set sizes. We evaluate our approach on several real-world datasets from the WILDS benchmark, demonstrating its potential as a promising direction for robust domain generalization.","Modern machine learning systems often struggle when faced with new or different data than what they were trained on. This challenge is known as domain generalization. In this work, we explore how predicting sets of possible answers, rather than just a single answer, can help models remain accurate and reliable when tested on unfamiliar data.We introduce a new way to define success for these set-based predictions and provide both theoretical foundations and practical tools to achieve it. A key challenge we tackle is the tradeoff between making prediction sets small, so they remain specific and useful, and ensuring they are large enough to consistently include the correct answer, even in environments the model hasn't seen before.We evaluate our approach on real-world datasets and demonstrate that it achieves strong performance across diverse test conditions, while keeping the prediction sets as compact as possible. Our findings suggest a promising path for building machine learning systems that are both robust and adaptable in practice."
Poster,"SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model Post-training",https://ICML.cc//virtual/2025/poster/44633,"Tianzhe Chu, Yuexiang Zhai, Jihan Yang, Shengbang Tong, Saining Xie, Dale Schuurmans, Quoc Le, Sergey Levine, Yi Ma","Supervised fine-tuning (SFT) and reinforcement learning (RL) are widely used post-training techniques for foundation models. However, their roles in enhancing model generalization capabilities remain unclear. This paper studies the difference between SFT and RL on generalization and memorization, focusing on text-based rule variants and visual variants. We introduce GeneralPoints, an arithmetic reasoning card game, and adopt V-IRL, a real-world navigation environment, to assess how models trained with SFT and RL generalize to unseen variants in both textual and visual domains. We show that RL, especially when trained with an outcome-based reward, generalizes across both rule-based textual and  visual variants. SFT, in contrast, tends to memorize training data and struggles to generalize out-of-distribution scenarios. Further analysis reveals that RL improves the model's underlying visual recognition capabilities, contributing to its enhanced generalization in the visual domain. Despite RL's superior generalization, we show that SFT remains essential for effective RL training; SFT stabilizes the model's output format, enabling subsequent RL to achieve its performance gains. These findings demonstrates the capability of RL for acquiring generalizable knowledge in complex, multi-modal tasks.","Today's powerful AI models often undergo additional training to specialize them for complex tasks. Two common methods-supervised fine-tuning (SFT) and reinforcement learning-are widely used, but it's unclear how they affect a model's ability to adapt to new challenges versus merely memorizing training data.To investigate this, we designed comparative experiments to test how SFT and RL perform in arithmetic reasoning tasks (GeneralPoints) and visual navigation tasks (V-IRL). We found that RL, with rewards tied to final outcomes like winning a game, generalizes better to unseen textual and visual challenges. SFT, however, often memorizes training examples and struggles with new scenarios. Despite RL's superior generalization, we also show that SFT is helpful for effective RL training in stabilizing the model's output format.Our findings contribute to the fundamental understanding of training methods in modern AI systems. We hope this work to be an example of further comparative studies on AI. We also released data, checkpoints, and code for researchers to play with."
Poster,SGD Jittering: A Training Strategy for Robust and Accurate Model-Based Architectures,https://ICML.cc//virtual/2025/poster/43503,"Peimeng Guan, Mark Davenport","Inverse problems aim to reconstruct unseen data from corrupted or perturbed measurements. While most work focuses on improving reconstruction quality, generalization accuracy and robustness are equally important, especially for safety-critical applications. Model-based architectures (MBAs), such as loop unrolling methods, are considered more interpretable and achieve better reconstructions. Empirical evidence suggests that MBAs are more robust to perturbations than black-box solvers, but the accuracy-robustness tradeoff in MBAs remains underexplored. In this work, we propose a simple yet effective training scheme for MBAs, called SGD jittering, which injects noise iteration-wise during reconstruction. We theoretically demonstrate that SGD jittering not only generalizes better than the standard mean squared error training but is also more robust to average-case attacks. We validate SGD jittering using denoising toy examples, seismic deconvolution, and single-coil MRI reconstruction. Both SGD jittering and its SPGD extension yield cleaner reconstructions for out-of-distribution data and demonstrates enhanced robustness against adversarial attacks.","Machine learning methods for image and signal reconstruction problems (also known as inverse problems) should be both accurate and robust to noise. However, conventional training often fails to achieve both due to the robustness–accuracy tradeoff. We introduce SGD jittering, a simple yet effective noise injection training strategy for model-based architectures. Our theoretical and empirical results show that SGD jittering significantly improves robustness and generalization over conventional mean squared error (MSE) training."
Poster,ShadowKV: KV Cache in Shadows for High-Throughput Long-Context LLM Inference,https://ICML.cc//virtual/2025/poster/44053,"Hanshi Sun, Li-Wen Chang, Wenlei Bao, Size Zheng, Ningxin Zheng, Xin Liu, Harry Dong, Yuejie Chi, Beidi Chen","With the widespread deployment of long-context large language models (LLMs), there has been a growing demand for efficient support of high-throughput inference. However, as the key-value (KV) cache expands with the sequence length, the increasing memory footprint and the need to access it for decoding both result in low throughput when serving long-context LLMs. While various dynamic sparse attention methods have been proposed to accelerate inference while maintaining generation quality, they either fail to sufficiently reduce GPU memory usage or introduce significant decoding latency by offloading the KV cache to the CPU. We present ShadowKV, a high-throughput long-context LLM inference system that stores the low-rank key cache and offloads the value cache to reduce the memory footprint for larger batch sizes and longer sequences. To minimize decoding latency, ShadowKV employs an accurate KV selection strategy that reconstructs minimal sparse KV pairs on-the-fly. By evaluating ShadowKV on benchmarks like RULER, LongBench, and models such as Llama-3.1-8B and GLM-4-9B-1M, we demonstrate that it achieves up to 6$\times$ larger batch sizes and 3.04$\times$ higher throughput on an A100 GPU without sacrificing accuracy, even surpassing the performance achievable with infinite batch size under the assumption of infinite GPU memory.","Large language models that can understand very long texts require significant computer memory, which makes them slow and expensive to use, especially when many people are using them at once. Our research introduces ShadowKV, a new system designed to significantly speed up these models. ShadowKV works by smartly managing the model's memory: it keeps a small, compressed version of the most important data on the GPU and moves the less critical data to CPU. When the model needs information, ShadowKV quickly finds and retrieves only what's essential, avoiding delays and ensuring the model remains accurate. This allows us to handle many more requests and much longer texts simultaneously, making powerful long-context AI more efficient and accessible for broader use."
Poster,SHARP-Distill: A 68× Faster Recommender System with Hypergraph Neural Networks and Language Models,https://ICML.cc//virtual/2025/poster/46524,"Saman Forouzandeh, Parham Moradi, Mahdi Jalili","This paper proposes SHARP-Distill (\textbf{S}peedy \textbf{H}ypergraph \textbf{A}nd \textbf{R}eview-based \textbf{P}ersonalised \textbf{Distill}ation), a novel knowledge distillation approach based on the teacher-student framework that combines Hypergraph Neural Networks (HGNNs) with language models to enhance recommendation quality while significantly improving inference time. The teacher model leverages HGNNs to generate user and item embeddings from interaction data, capturing high-order and group relationships, and employing a pre-trained language model to extract rich semantic features from textual reviews. We utilize a contrastive learning mechanism to ensure structural consistency between various representations. The student includes a shallow and lightweight GCN called CompactGCN designed to inherit high-order relationships while reducing computational complexity. Extensive experiments on real-world datasets demonstrate that SHARP-Distill achieves up to 68× faster inference time compared to HGNN and 40× faster than LightGCN while maintaining competitive recommendation accuracy.","Online platforms like Amazon, Netflix, and Spotify use recommendation systems to suggest products, movies, or music you might like. These systems work by analyzing your past behavior and finding patterns with other users who have similar tastes. However, the most accurate recommendation systems are very slow and expensive to run, making them impractical for real-time use when millions of people are browsing simultaneously.We developed SHARP-Distill, a new approach that makes recommendation systems 68 times faster while maintaining nearly the same accuracy. Our method works like a master-apprentice relationship: we first train a highly accurate but slow ""teacher"" system that combines two types of information - how users interact with items (like purchases and ratings) and what they write in reviews. Then, we create a much simpler ""student"" system that learns from the teacher to make the same quality recommendations but much faster.The key innovation is teaching the simple system not just the final answers, but also the reasoning process the complex system uses. This is like teaching someone to solve math problems by showing them both the answers and the step-by-step thinking, rather than just memorizing solutions.This breakthrough makes high-quality personalized recommendations accessible to smaller companies that couldn't afford expensive computer systems before, and reduces energy consumption for large platforms. The faster system can provide instant recommendations even during peak usage times, improving user experience while being more environmentally friendly."
Poster,Sharp Generalization for Nonparametric Regression by Over-Parameterized Neural Networks: A Distribution-Free Analysis in Spherical Covariate,https://ICML.cc//virtual/2025/poster/44526,Yingzhen Yang,"Sharp generalization bound for neural networks trained by gradient descent (GD) is of central interest in statistical learning theory and deep learning. In this paper, we consider nonparametric regressionby an over-parameterized two-layer NN trained by GD. We show that, if the neural network is trained by GD with early stopping, then the trained network renders a sharp rate of the nonparametric regression risk of $O(\epsilon_n^2)$,  which is the same rate as that for the classical kernel regression trained by GD with early stopping, where $\epsilon_n$ is the critical population rate of the Neural Tangent Kernel (NTK) associated with the network and $n$ is the size of the training data. It is remarked that our result does not require distributional assumptions on the covariate as long as the covariate lies on the unit sphere, in a strong contrast with many existing results which rely on specific distributions such as the spherical uniform data distribution or distributions satisfying certain restrictive conditions.As a special case of our general result, when the eigenvalues of the associated NTKdecay at a rate of $\lambda_j \asymp j^{-\frac{d}{d-1}}$ for $j \ge 1$ which happens under certain distributional assumption such as the training features follow the spherical uniform distribution, we immediately obtain the minimax optimal rate of$O(n^{-\frac{d}{2d-1}})$, which is the major results of several existing works in this direction. The neural network width in our general result is lower bounded by a function of only $d$ and $\epsilon_n$, and such width does not depend on the minimum eigenvalue of the empirical NTK matrix whose lower bound usually requires additional assumptions on the training data.Our results are built upon two significant technical results which are of independent interest. First, uniform convergence to the NTK is established during the training process by GD, so that we can have a nice decomposition of the neural network function at any step of the GD into a function in the ReproducingKernel Hilbert Space associated with the NTK and an error function with a small $L^{\infty}$-norm. Second, local Rademacher complexity is employedto tightly bound the Rademacher complexity of the function class comprising all the possible neural network functions obtained by GD. Our resultformally fills the gap between training a classical kernel regression model and training an over-parameterized but finite-width neural network by GD for nonparametric regression without distributional assumptions about the spherical covariate.","Understanding how well neural networks trained by gradient descent (GD) can generalize to new data is a core challenge in modern machine learning. In this work, we study a specific problem: predicting smooth relationships between inputs and outputs (nonparametric regression) using a two-layer neural network trained by GD. We show that, with early stopping, such a network can match the best-known performance of classical kernel methods — a class of powerful, well-understood algorithms — without relying on strong assumptions about the data distribution.Our results show that even with minimal structural assumptions (only requiring the input data to lie on a sphere), these neural networks achieve the same optimal prediction accuracy as if the data had followed more idealized, structured distributions. This makes our findings more widely applicable.To prove our results, we developed two new techniques: one that tracks how the network evolves during training, and another that carefully measures the complexity of all functions the network could learn. These tools may be useful in understanding broader classes of learning algorithms."
Poster,"Sharp Optimality of Simple, Plug-in Estimation of the Fisher Information of a Smoothed Density",https://ICML.cc//virtual/2025/poster/45297,Subhodh Kotekal,"Given independent and identically distributed data from a compactly supported, $\alpha$-Hölder density $f$, we study estimation of the Fisher information of the Gaussian-smoothed density $f*\varphi_t$, where $\varphi_t$ is the density of $N(0, t)$. We derive the minimax rate including the sharp dependence on $t$ and show some simple, plug-in type estimators are optimal for $t > 0$, even though extra debiasing steps are widely employed in the literature to achieve the sharp rate in the unsmoothed ($t = 0$) case. Due to our result's sharp characterization of the scaling in $t$, plug-in estimators of the mutual information and entropy are shown to achieve the parametric rate by way of the I-MMSE and de Bruijn's identities.","It is often difficult to estimate even simple functions of an unknown, data-generating distribution given access only to samples, particularly when the distribution is quite complicated. It is typically suboptimal (in a statistical sense) to estimate by just computing the target function on the empirical distribution of the data points. Classical work has proposed many complicated techniques to do optimal estimation, but the methodologies appear brittle and too tailored. A quite different approach recently proposed in the literature is to add noise to the data, with the idea that the noised distribution will become simpler, looking more and more like the noise distribution. It may now be optimal to simply compute the target on the empirical distribution of the noised data points. In this paper, we sharply characterize the statistical limits of estimating a fundamental functional, the Fisher information, of a smooth density corrupted by additive Gaussian noise. Interestingly, there is a critical level of noise below which the problem is actually harder than if there were no noise. Nevertheless, we show that the simple plug-in strategy is indeed optimal. Using some fundamental identities, we describe how to estimate other information-theoretic quantities, like the entropy and the mutual information, from our results. Our results provide support for the noising approach."
Poster,SHE: Streaming-media Hashing Retrieval,https://ICML.cc//virtual/2025/poster/45670,"Ruitao Pu, Yang Qin, Xiaomin Song, Dezhong Peng, Zhenwen Ren, Yuan Sun","Recently, numerous cross-modal hashing (CMH) methods have been proposed, yielding remarkable progress. As a static learning paradigm, existing CMH methods often implicitly assume that all modalities are prepared before processing. However, in practice applications (such as multi-modal medical diagnosis), it is very challenging to collect paired multi-modal data simultaneously. Specifically, they are collected chronologically, forming streaming-media data (SMA). To handle this, all previous CMH methods require retraining on data from all modalities, which inevitably limits the scalability and flexibility of the model. In this paper, we propose a novel CMH paradigm named Streaming-media Hashing rEtrieval (SHE) that enables parallel training of each modality. Specifically, we first propose a knowledge library mining module (KLM) that extracts a prototype knowledge library for each modality, thereby revealing the commonality distribution of the instances from each modality. Then, we propose a knowledge library transfer module (KLT) that updates and aligns the new knowledge by utilizing the historical knowledge library, ensuring semantic consistency. Finally, to enhance intra-class semantic relevance and inter-class semantic disparity, we develop a discriminative hashing learning module (DHL). Comprehensive experiments on four benchmark datasets demonstrate the superiority of our SHE compared to 14 competitors.","Cross-modal hashing (CMH) techniques have achieved impressive progress in retrieving related content across different modalities such as images and text. However, most existing CMH methods assume that all modalities are available at once, which is unrealistic in many real-world scenarios, like medical diagnostics, where data from different modalities arrive sequentially. This creates a challenge for current CMH approaches, as they require full retraining whenever new data arrives, limiting scalability and flexibility.To address this, we propose a new CMH paradigm called Streaming-media Hashing rEtrieval (SHE), which supports asynchronous, parallel training for each modality. SHE introduces a Knowledge Library Mining (KLM) module to capture the semantic commonalities within each stream. A Knowledge Library Transfer (KLT) module then ensures semantic consistency by aligning newly arrived data with historical knowledge. To improve discriminative power, a Discriminative Hashing Learning (DHL) module enhances intra-class similarity and inter-class separation.This work provides a scalable, flexible solution for real-time multimodal retrieval, significantly advancing the applicability of CMH in dynamic, real-world settings."
Poster,ShieldAgent: Shielding Agents via Verifiable Safety Policy Reasoning,https://ICML.cc//virtual/2025/poster/45989,"Zhaorun Chen, Mintong Kang, Bo Li","Autonomous agents powered by foundation models have seen widespread adoption across various real-world applications. However, they remain highly vulnerable to malicious instructions and attacks, which can result in severe consequences such as privacy breaches and financial losses. More critically, existing guardrails for LLMs are not applicable due to the complex and dynamic nature of agents. To tackle these challenges, we propose ShieldAgent, the first guardrail agent designed to enforce explicit safety policy compliance for the action trajectory of other protected agents through logical reasoning. Specifically, ShieldAgent first constructs a safety policy model by extracting verifiable rules from policy documents and structuring them into a set of action-based probabilistic rule circuits. Given the action trajectory of the protected agent, ShieldAgent retrieves relevant rule circuits and generates a shielding plan, leveraging its comprehensive tool library and executable code for formal verification. In addition, given the lack of guardrail benchmarks for agents, we introduce ShieldAgent-Bench, a dataset with 3K safety-related pairs of agent instructions and action trajectories, collected via SOTA attacks across 6 web environments and 7 risk categories. Experiments show that ShieldAgent achieves SOTA on ShieldAgent-Bench and three existing benchmarks, outperforming prior methods by 11.3% on average with a high recall of 90.1%. Additionally, ShieldAgent reduces API queries by 64.7% and inference time by 58.2%, demonstrating its high precision and efficiency in safeguarding agents. Our project is available and continuously maintained here: https://shieldagent-aiguard.github.io/","As artificial intelligence (AI) agents become part of everyday technology, like online assistants that help shop, manage data, or answer questions, keeping these systems safe is increasingly important. However, many current AI “agents” are easily tricked by malicious commands and adversarial attacks, which can lead to data leaks, privacy risks, or financial losses. Existing safety tools often fail because they are designed for simple text models, not for complex, real-world AI agents that interact with websites and other systems over time.Our work introduces ShieldAgent, a new AI safeguard for other AI agents. ShieldAgent watches the actions of these agents and checks them against constitutional safety rules (like government regulations or company policies) using advanced logic and verification tools. This means ShieldAgent doesn’t just look for bad words or obvious mistakes—it carefully reasons about what the agent is trying to do and whether it might break any important rules.To test ShieldAgent, we built a large benchmark of tricky real-world situations—much larger and more realistic than previous tests. In experiments, ShieldAgent caught more unsafe behaviors in general AI agents than any prior guardrail systems and did so more efficiently, saving both time and computing costs. By making AI agents safer and more trustworthy, ShieldAgent can help pave the way for reliable AI systems in daily life."
