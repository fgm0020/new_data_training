type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Improved Discretization Complexity Analysis of Consistency Models: Variance Exploding Forward Process and Decay Discretization Scheme,https://ICML.cc//virtual/2025/poster/46054,"Ruofeng Yang, Bo Jiang, Cheng Chen, Shuai Li","Consistency models, a new class of one-step generative models, have shown competitive performance with multi-step diffusion models. The most challenging part of consistency models is the training process, which discretizes the continuous diffusion process into $K$ steps and trains a one-step mapping function on these discretized timepoints. Despite the empirical success, only a few works focus on the discretization complexity $K$, and their setting is far from that of empirical works. More specifically, the current theoretical works analyze the variance preserving (VP) diffusion process with a uniform stepsize, while empirical works adopt a variance exploding (VE) process with a decay discretization stepsize. As a result, these works suffer from large discretization complexity and fail to explain the empirical success of consistency models. To close the gap between theory and application, we analyze consistency models with (1) VE process and (2) decay stepsize and prove the state-of-the-art discretization complexity for consistency models. This result is competitive with the results of diffusion models and shows the potential of consistency models. To balance the computation and performance, previous empirical work further proposes a $2$-step consistency algorithm. In this work, we also analyze the role of $2$-step sampling and show that it improves the discretization complexity compared with one-step generation.","Consistency models, a new class of one-step generative models, have shown competitive performance with multi-step diffusion models. The most challenging part of consistency models is the training process, which discretizes the continuous diffusion process into $K$ steps and trains a one-step mapping function on these discretized timepoints. Despite the empirical success, only a few works focus on the discretization complexity $K$, and their setting is far from that of empirical works. More specifically, the current theoretical works analyze the variance preserving (VP) diffusion process with a uniform stepsize, while empirical works adopt a variance exploding (VE) process with a decay discretization stepsize. As a result, these works suffer from large discretization complexity and fail to explain the empirical success of consistency models. To close the gap between theory and application, we analyze consistency models with (1) VE process and (2) decay stepsize and prove the state-of-the-art discretization complexity for consistency models. This result is competitive with the results of diffusion models and shows the potential of consistency models. To balance the computation and performance, previous empirical work further proposes a $2$-step consistency algorithm. In this work, we also analyze the role of $2$-step sampling and show that it improves the discretization complexity compared with one-step generation."
Poster,Improved Expressivity of Hypergraph Neural Networks through High-Dimensional Generalized Weisfeiler-Leman Algorithms,https://ICML.cc//virtual/2025/poster/44021,"Detian Zhang, Zhang Chengqiang, Yanghui Rao, Qing Li, Chunjiang Zhu","The isomorphism problem is a key challenge in both graph and hypergraph domains, crucial for applications like protein design, chemical pathways, and community detection.Hypergraph isomorphism, which models high-order relationships in real-world scenarios, remains underexplored compared to the graph isomorphism.Current algorithms for hypergraphs, like the 1-dimensional generalized Weisfeiler-Lehman test (1-GWL), lag behind advancements in graph isomorphism tests, limiting most hypergraph neural networks to 1-GWL's expressive power.To address this, we propose the high-dimensional GWL (k-GWL), generalizing k-WL from graphs to hypergraphs.We prove that k-GWL reduces to k-WL for simple graphs, and thus develop a unified isomorphism method for both graphs and hypergraphs. We also successfully establish a clear and complete understanding of the GWL hierarchy of expressivity, showing that (k+1)-GWL is more expressive than k-GWL with illustrative examples.Based on k-GWL, we develop a hypergraph neural network model named k-HNN with improved expressive power of k-GWL, which achieves superior performance on real-world datasets, including a 6\% accuracy improvement on the Steam-Player dataset over the runner-up.Our code is available at https://github.com/talence-zcq/KGWL.","The expressive power of graph machine learning characterizes what functions the models can approximate, or equivalently how strong they can distinguish two similar but different hypergraphs. We establish a generalized WL hierarchy for hypergraphs with increasing expressivity, with the notable difference between 1-GFWL vs. 2-GOWL, unlike its graph counterpart. The hierarchy allows us to design hypergraph neural networks with the desired expressivity, improves upon most existing hypergraph neural networks whose expressive power is upper bounded by 1-GWL."
Poster,Improved Last-Iterate Convergence of Shuffling Gradient Methods for Nonsmooth Convex Optimization,https://ICML.cc//virtual/2025/poster/46103,"Zijian Liu, Zhengyuan Zhou","We study the convergence of the shuffling gradient method, a popular algorithm employed to minimize the finite-sum function with regularization, in which functions are passed to apply (Proximal) Gradient Descent (GD) one by one whose order is determined by a permutation on the indices of functions. In contrast to its easy implementation and effective performance in practice, the theoretical understanding remains limited. A recent advance by (Liu & Zhou, 2024b) establishes the first last-iterate convergence results under various settings, especially proving the optimal rates for smooth (strongly) convex optimization. However, their bounds for nonsmooth (strongly) convex functions are only as fast as Proximal GD. In this work, we provide the first improved last-iterate analysis for the nonsmooth case demonstrating that the widely used Random Reshuffle ($\textsf{RR}$) and Single Shuffle ($\textsf{SS}$) strategies are both provably faster than Proximal GD, reflecting the benefit of randomness. As an important implication, we give the first (nearly) optimal convergence result for the suffix average under the $\textsf{RR}$ sampling scheme in the general convex case, matching the lower bound shown by (Koren et al., 2022).","Shuffling gradient methods are widely implemented in practice but with fewer theoretical convergence guarantees. Especially, for nonsmooth convex problems, whether the last iterate of shuffling gradient methods outperforms Proximal Gradient Descent (GD) remains unclear.This work addresses this question by proving that the last-iterate convergence rates of two popular shuffling strategies, Random Reshuffle ($\textsf{RR}$) and Single Shuffle ($\textsf{SS}$), are both faster than Proximal GD (conditionally for $\textsf{SS}$). Remarkably, our analysis builds upon a more general framework not limited to shuffling gradient methods and results in a new sufficient condition for the last-iterate convergence of first-order methods with a general form.These new results demonstrate the benefit of randomness in $\textsf{RR}$ and $\textsf{SS}$ as it indeed boosts better convergence."
Poster,Improved Learning via k-DTW: A Novel Dissimilarity Measure for Curves,https://ICML.cc//virtual/2025/poster/45076,"Amer Krivosija, Alexander Munteanu, André Nusser, Chris Schwiegelshohn","This paper introduces $k$-Dynamic Time Warping ($k$-DTW), a novel dissimilarity measure for polygonal curves. $k$-DTW has stronger metric properties than Dynamic Time Warping (DTW) and is more robust to outliers than the Fréchet distance, which are the two gold standards of dissimilarity measures for polygonal curves. We show interesting properties of $k$-DTW and give an exact algorithm as well as a $(1+\varepsilon)$-approximation algorithm for $k$-DTW by a parametric search for the $k$-th largest matched distance. We prove the first dimension-free learning bounds for curves and further learning theoretic results. $k$-DTW not only admits smaller sample size than DTW for the problem of learning the median of curves, where some factors depending on the curves' complexity $m$ are replaced by $k$, but we also show a surprising separation on the associated Rademacher and Gaussian complexities: $k$-DTW admits strictly smaller bounds than DTW, by a factor $\tilde\Omega(\sqrt{m})$ when $k\ll m$. We complement our theoretical findings with an experimental illustration of the benefits of using $k$-DTW for clustering and nearest neighbor classification.","This paper introduces $k$-Dynamic Time Warping ($k$-DTW), a new way to measure how different polygonal curves are. It sums only $k$ large values and ignores smaller ones. It is more robust than traditional methods like Fréchet distance and captures the geometry better than Dynamic Time Warping. The choice of the parameter $k$ interpolates between the two classic distances. The paper presents two algorithms for $k$-DTW, one exact and one faster approximate. It shows that $k$-DTW allows for learning with fewer samples compared to DTW. The new distance excels in tasks like clustering and classifying curves. These findings are illustrated via experiments."
Poster,Improved Lower Bounds for First-order Stochastic Non-convex Optimization under Markov Sampling,https://ICML.cc//virtual/2025/poster/43690,"Zhenyu Sun, Ermin Wei","Unlike its vanilla counterpart with i.i.d. samples, stochastic optimization with Markovian sampling allows the sampling scheme following a Markov chain. This problem encompasses various applications that range from asynchronous distributed optimization to reinforcement learning. In this work, we lower bound the sample complexity of finding $\epsilon$-approximate critical solutions for any first-order methods when sampling is Markovian. We show that for samples drawn from stationary Markov processes with countable state space, any algorithm that accesses smooth, non-convex functions through queries to a stochastic gradient oracle, requires at least $\Omega(\epsilon^{-4})$ samples. Moreover, for finite Markov chains, we show a $\Omega(\epsilon^{-2})$ lower bound and propose a new algorithm, called MaC-SAGE, that is proven to (nearly) match our lower bound.","This research looks at how we can solve optimization problems when data is not randomly shuffled, but instead follows a pattern—like stepping from one state to another in a sequence, much like how weather changes from sunny to rainy over time. This kind of data shows up in areas like machine learning, robotics, and systems that work in parallel or over time. We studied how hard it is, in theory, to find good solutions under this kind of patterned data. We proved that, depending on how the data moves between states, there is a minimum amount of data needed to reach a ""good enough"" solution—generally much more than if the data were completely random. To tackle this challenge, we also designed a new method called MaC-SAGE, which performs nearly as well as the best possible under these conditions. This helps improve how we train learning systems that face time-related or structured data."
Poster,Improved Off-policy Reinforcement Learning in Biological Sequence Design,https://ICML.cc//virtual/2025/poster/46683,"Hyeonah Kim, Minsu Kim, Taeyoung Yun, Sanghyeok Choi, Emmanuel Bengio, Alex Hernandez-Garcia, Jinkyoo Park","Designing biological sequences with desired properties is challenging due to vast search spaces and limited evaluation budgets. Although reinforcement learning methods use proxy models for rapid reward evaluation, insufficient training data can cause proxy misspecification on out-of-distribution inputs. To address this, we propose a novel off-policy search, $\delta$-Conservative Search, that enhances robustness by restricting policy exploration to reliable regions. Starting from high-score offline sequences, we inject noise by randomly masking tokens with probability $\delta$, then denoise them using our policy. We further adapt $\delta$ based on proxy uncertainty on each data point, aligning the level of conservativeness with model confidence. Experimental results show that our conservative search consistently enhances the off-policy training, outperforming existing machine learning methods in discovering high-score sequences across diverse tasks, including DNA, RNA, protein, and peptide design.","In biology and chemistry, generative models are increasingly used to propose novel candidates, such as DNA, RNA, or protein sequences, with desired properties. Because real-world experiments are costly, researchers often turn to active learning, where a generative model is trained using feedback from a proxy model that approximates experimental outcomes. After each round, a few candidates are tested in the lab, and the resulting data is used to update the proxy (and the generative model). However, with limited data, proxy models can become unreliable on out-of-distribution inputs, leading to reward hacking, where the generative model exploits proxy errors rather than proposing truly effective candidates.To address this, we introduce a conservative search strategy that adapts the exploration range based on the uncertainty of the proxy model. By constraining how far the model can deviate from known high-quality sequences, especially when predictions are unreliable, our method helps prevent over-optimizing on spurious signals. Our experiments demonstrate that this strategy consistently enhances performance across various biological sequence design tasks, including DNA, RNA, and protein optimization. Notably, while exploration is locally restricted in each round, the model eventually discovers novel high-performing candidates over active rounds by making the proposed candidate more meaningful at each round. More broadly, the principle of aligning exploration with model confidence may benefit other AI-driven scientific discovery efforts where data is limited and reliable generalization is critical."
Poster,Improved Online Confidence Bounds for Multinomial Logistic Bandits,https://ICML.cc//virtual/2025/poster/45882,"Joongkyu Lee, Min-hwan Oh","In this paper, we propose an improved online confidence bound for multinomial logistic (MNL) models and apply this result to MNL bandits, achieving variance-dependent optimal regret. Recently, Lee & Oh (2024) established an online confidence bound for MNL models and achieved nearly minimax-optimal regret in MNL bandits. However, their results still depend on the norm-boundedness of the unknown parameter $B$ and the maximum size of possible outcomes $K$. To address this, we first derive an online confidence bound of $\mathcal{O} (\sqrt{d \log t} + B )$, which is a significant improvement over the previous bound of $\mathcal{O} (B \sqrt{d} \log t \log K )$ (Lee & Oh, 2024). This is mainly achieved by establishing tighter self-concordant properties of the MNL loss and introducing a novel intermediary term to bound the estimation error. Using this new online confidence bound, we propose a constant-time algorithm, **OFU-MNL++**, which achieves a variance-dependent regret bound of $\mathcal{O} \Big( d \log T \sqrt{ \sum_{t=1}^T \sigma_t^2 } \Big) $ for sufficiently large $T$, where $\sigma_t^2$ denotes the variance of the rewards at round $t$, $d$ is the dimension of the contexts, and $T$ is the total number of rounds. Furthermore, we introduce an Maximum Likelihood Estimation (MLE)-based algorithm that achieves an anytime, **OFU-M$^2$NL**, $\operatorname{poly}(B)$-free regret of $\mathcal{O} \Big( d \log (BT) \sqrt{ \sum_{t=1}^T \sigma_t^2 } \Big) $.","Many AI systems repeatedly face the challenge of choosing from multiple options — such as which product to recommend or which ad to show — while learning from user feedback to improve over time. This paper tackles that challenge and proposes a new algorithm that achieves state-of-the-art performance in both learning efficiency and computational speed.Our method enables AI systems to make smarter, more confident decisions even under uncertainty. It introduces a more effective way to gauge how reliable the system’s knowledge is, while avoiding the heavy computations that previous methods require.As a result, our algorithm is faster, more scalable, and easier to deploy in real-world applications. It helps AI systems learn quickly, use fewer resources, and make better choices — enabling more responsive and intelligent tools for recommendation, search, and personalized services."
Poster,"Improved Regret Analysis in Gaussian Process Bandits: Optimality for Noiseless Reward, RKHS norm, and Non-Stationary Variance",https://ICML.cc//virtual/2025/poster/43519,"Shogo Iwazaki, Shion Takeno","We study the Gaussian process (GP) bandit problem, whose goal is to minimize regret under an unknown reward function lying in some reproducing kernel Hilbert space (RKHS). The maximum posterior variance analysis is vital in analyzing near-optimal GP bandit algorithms such as maximum variance reduction (MVR) and phased elimination (PE).Therefore, we first show the new upper bound of the maximum posterior variance, which improves the dependence of the noise variance parameters of the GP. By leveraging this result, we refine the MVR and PE to obtain (i) a nearly optimal regret upper bound in the noiseless setting and (ii) regret upper bounds that are optimal with respect to the RKHS norm of the reward function. Furthermore, as another application of our proposed bound, we analyze the GP bandit under the time-varying noise variance setting, which is the kernelized extension of the linear bandit with heteroscedastic noise. For this problem, we show that MVR and PE-based algorithms achieve noise variance-dependent regret upper bounds, which matches our regret lower bound.","In many decision-making situations, we need to learn which options work best by trying them and observing the results. This process is tricky because we often do not know how our choices lead to desirable rewards, and the results can be noisy or unclear, especially when the conditions change over time. Many existing methods struggle to deal with this kind of uncertainty.Our research improves the way we analyze decision-making strategies in such uncertain environments. We developed a new way to better measure how unsure a system is about its predictions. Using this, we updated the existing theory of two important learning methods to make them more effective, especially when there is little noise or when the amount of noise changes over time.These improvements help us understand how learning systems behave in challenging situations.We expect that our result will lead to better tools for real-world decision-making applications."
Poster,Improved Sample Complexity for Private Nonsmooth Nonconvex Optimization,https://ICML.cc//virtual/2025/poster/44864,"Guy Kornowski, Daogao Liu, Kunal Talwar","We study differentially private (DP) optimization algorithms for stochastic and empirical objectives which are neither smooth nor convex, and propose methods that return a Goldstein-stationary point with sample complexity bounds that improve on existing works.We start by providing a single-pass $(\epsilon,\delta)$-DP algorithm that returns an $(\alpha,\beta)$-stationary point as long as the dataset is of size $\widetilde{\Omega}(\sqrt{d}/\alpha\beta^{3}+d/\epsilon\alpha\beta^{2})$, which is $\Omega(\sqrt{d})$ times smaller than the algorithm of Zhang et al. (2024) for this task, where $d$ is the dimension.We then provide a multi-pass polynomial time algorithm which further improves the sample complexity to $\widetilde{\Omega}\left(d/\beta^2+d^{3/4}/\epsilon\alpha^{1/2}\beta^{3/2}\right)$, by designing a sample efficient ERM algorithm, and proving that Goldstein-stationary points generalize from the empirical loss to the population loss.","We design algorithms that solve data-dependent optimization problems which lack smoothness and convexity, so that even after seeing the solution to the problem, the data itself remains private. Such optimization problems arise regularly when training neural networks, when one wants to maintain the privacy of the training data.The privacy of the data is measured via a well-studied notion called differential privacy, and the returned solution is an approximate stationary point of the loss function. A private algorithm that solves such problems was previously suggested by Zhang et al. (2024).The private algorithms we propose and analyze in this work find such solutions, using less data. Equivalently, given the same amount of data, they find solutions with higher accuracy than previous algorithms."
Poster,Improved Theoretically-Grounded Evolutionary Algorithms for Subset Selection with a Linear Cost Constraint,https://ICML.cc//virtual/2025/poster/45538,"Dan-Xuan Liu, Chao Qian","The subset selection problem with a monotone and submodular objective function under a linear cost constraint has wide applications, such as maximum coverage, influence maximization, and feature selection, just to name a few. Various greedy algorithms have been proposed with good performance both theoretically and empirically. Recently, evolutionary algorithms (EAs), inspired by Darwin's evolution theory, have emerged as a prominent methodology, offering both empirical advantages and theoretical guarantees. Among these, the multi-objective EA, POMC, has demonstrated the best empirical performance to date, achieving an approximation guarantee of $(1/2)(1-1/e)$. However, there remains a gap in the approximation bounds of EAs compared to greedy algorithms, and their full theoretical potential is yet to be realized. In this paper, we re-analyze the approximation performance of POMC theoretically, and derive an improved guarantee of $1/2$, which thus provides theoretical justification for its encouraging empirical performance. Furthermore, we propose a novel multi-objective EA, EPOL, which not only achieves the best-known practical approximation guarantee of $0.6174$, but also delivers superior empirical performance in applications of maximum coverage and influence maximization. We hope this work can help better solving the subset selection problem, but also enhance our theoretical understanding of EAs.","Selecting the best subset of items (e.g., features in a dataset or influencers in a social network) while balancing quality and cost is a common challenge in AI. Greedy algorithms—step-by-step methods—have long been used for this, but evolutionary algorithms (EAs), inspired by natural selection, have recently shown promise. One EA, called POMC, works well in practice but had a weaker theoretical guarantee than greedy methods.In this work, we improved POMC’s theoretical guarantee, proving it can achieve at least half the optimal solution’s value. We also designed a new EA, EPOL, which not only matches the best-known theoretical performance (61.74% of optimal) but also outperforms existing methods in real-world tasks like identifying key influencers or selecting important data features.Our findings advance both the practical use and theoretical understanding of evolutionary algorithms, offering better tools for subset selection problems. This work bridges the gap between theory and practice, helping researchers and practitioners make smarter, data-driven choices."
