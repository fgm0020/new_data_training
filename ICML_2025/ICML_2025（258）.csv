type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Riemannian Diffusion Adaptation for Distributed Optimization on Manifolds,https://ICML.cc//virtual/2025/poster/46403,"Xiuheng Wang, Ricardo Borsoi, Cédric Richard, Ali Sayed","Online distributed optimization is particularly useful for solving optimization problems with streaming data collected by multiple agents over a network. When the solutions lie on a Riemannian manifold, such problems become challenging to solve, particularly when efficiency and continuous adaptation are required. This work tackles these challenges and devises a diffusion adaptation strategy for decentralized optimization over general manifolds. A theoretical analysis shows that the proposed algorithm is able to approach network agreement after sufficient iterations, which allows a non-asymptotic convergence result to be derived. We apply the algorithm to the online decentralized principal component analysis problem and Gaussian mixture model inference. Experimental results with both synthetic and real data illustrate its performance.","How can a network of devices, like sensors, robots, or phones, work together to solve complex problems using data that keeps arriving over time? This question becomes even harder when the solutions aren’t simple numbers or vectors, but lie on curved spaces called manifolds, which are common in real-world applications like machine learning, signal processing, and control.In this paper, we introduce a new method that helps multiple devices cooperatively learn from data as it streams in, without relying on a central server. Our method allows each device to update its understanding continuously and also communicate with its neighborhood to stay in agreement. Over time, the devices all move toward a shared solution.We back up our method with mathematical guarantees, showing that it converges reliably. We also test it on two common learning tasks: finding patterns in big data and grouping similar pieces of information. In both cases, it works well, even with real-world data, proving that this kind of teamwork among devices is both possible and powerful."
Poster,Riemann Tensor Neural Networks: Learning Conservative Systems with Physics-Constrained Networks,https://ICML.cc//virtual/2025/poster/44688,"Anas Jnini, Lorenzo Breschi, Flavio Vella","Divergence-free symmetric tensors (DFSTs) are fundamental in continuum mechanics, encoding conservation laws such as mass and momentum conservation. We introduce Riemann Tensor Neural Networks (RTNNs), a novel neural architecture that inherently satisfies the DFST condition to machine precision, providing a strong inductive bias for enforcing these conservation laws. We prove that RTNNs can approximate any sufficiently smooth DFST with arbitrary precision and demonstrate their effectiveness as surrogates for conservative PDEs, achieving improved accuracy across benchmarks. This work is the first to use DFSTs as an inductive bias in neural PDE surrogates and to explicitly enforce the conservation of both mass and momentum within a physics-constrained neural architecture.","Traditional neural networks used to model physical systems often ignore fundamental conservation laws—like mass or momentum conservation—so they can drift into predictions that are physically impossible.We introduce Riemann Tensor Neural Networks (RTNNs), a new architecture that embeds these conservation principles directly into its design by outputting specially structured tensors that are divergence-free by construction. This means RTNNs fields never violate mass or momentum conservation, down to machine precision. We also prove that RTNNs can approximate any smooth conserved flow as accurately as desired.By hard-wiring physics into the model, RTNNs produce more physically consistent predictions on standard fluid-flow benchmarks compared to previous approaches. This makes them powerful surrogate models for complex simulations that can be written in conservation form."
Poster,RIFLEx: A Free Lunch for Length Extrapolation in Video Diffusion Transformers,https://ICML.cc//virtual/2025/poster/43698,"Min Zhao, Guande He, Yixiao Chen, Hongzhou Zhu, Chongxuan Li, Jun Zhu","Recent advancements in video generation have enabled models to synthesize high-quality, minute-long videos. However, generating even longer videos with temporal coherence remains a major challenge and existing length extrapolation methods lead to temporal repetition or motion deceleration. In this work, we systematically analyze the role of frequency components in positional embeddings and identify an intrinsic frequency that primarily governs extrapolation behavior. Based on this insight, we propose RIFLEx, a minimal yet effective approach that reduces the intrinsic frequency to suppress repetition while preserving motion consistency, without requiring any additional modifications. RIFLEx offers a true free lunch—achieving high-quality $2\times$ extrapolation on state-of-the-art video diffusion transformers in a completely training-free manner. Moreover, it enhances quality and enables $3\times$ extrapolation by minimal fine-tuning without long videos.","While AI can now create short, high-quality videos, making them significantly longer while keeping motion smooth and non-repetitive over time remains a major hurdle. Existing methods often result in awkward temporal issues like repeating actions or unnatural slowdowns.We investigated how these AI video models handle time. Our analysis revealed that a specific internal mechanism, which we call an ""intrinsic frequency,"" is primarily responsible for these extrapolation problems. Based on this finding, we developed a simple technique named RIFLEx that adjusts this frequency.RIFLEx offers a straightforward way to improve long video generation. It allows advanced AI models to double video length smoothly without any extra training, essentially providing a performance boost ""for free."" Furthermore, with just a small amount of tuning (even without using long videos), RIFLEx can enable videos to be tripled in length while enhancing quality. This work makes generating extended, coherent video content with AI more feasible."
Poster,"Right Now, Wrong Then: Non-Stationary Direct Preference Optimization under Preference Drift",https://ICML.cc//virtual/2025/poster/44703,"Seongho Son, William Bankes, Sayak Ray Chowdhury, Brooks Paige, Ilija Bogunovic","Current Large Language Model (LLM) preference optimization algorithms do not account for temporal preference drift, which can lead to severe misalignment. To address this limitation, we propose **Non-Stationary Direct Preference Optimisation (NS-DPO)** that models time-dependent reward functions with a Dynamic Bradley-Terry model. NS-DPO proposes a computationally efficient solution by introducing only a single discount parameter in the loss function, which is used for exponential weighting that proportionally focuses learning on more time-relevant datapoints. We theoretically analyze the convergence of NS-DPO in a general setting where the exact nature of the preference drift is not known, providing upper bounds on the estimation error and regret caused by non-stationary preferences. Finally, we demonstrate the effectiveness of NS-DPO for fine-tuning LLMs under drifting preferences. Using scenarios where various levels of preference drift is introduced, with popular LLM reward models and datasets, we show that NS-DPO fine-tuned LLMs remain robust under non-stationarity, significantly outperforming baseline algorithms that ignore temporal preference changes, without sacrificing performance in stationary cases.","Large Language Models (LLMs), like those powering chatbots and virtual assistants, are trained to align with human preferences. However, these preferences can evolve over time. For example, answer to the question ""How good are the large language models (LLMs) in solving math questions?"" in the year 2025 and 2020 can be largely different. Such shifts can confuse LLMs if the data contains both recent and old information.Our research introduces a method called Non-Stationary Direct Preference Optimization (NS-DPO). This approach assigns more weight to recent data during training, helping LLMs stay attuned to current human preferences. We provide both theoretical analysis and experimental evidence showing that NS-DPO maintains model performance even as preferences change over time.As LLMs become increasingly integrated into daily life, ensuring they adapt to evolving human perspectives is crucial. Our work offers a step towards more reliable AI systems."
Poster,Right Time to Learn: Promoting Generalization via Bio-inspired Spacing Effect in Knowledge Distillation,https://ICML.cc//virtual/2025/poster/44991,"Guanglong Sun, Hongwei Yan, Liyuan Wang, Qian Li, Bo Lei, Yi Zhong","Knowledge distillation (KD) is a powerful strategy for training deep neural networks (DNNs). While it was originally proposed to train a more compact “student” model from a large “teacher” model, many recent efforts have focused on adapting it as an effective way to promote generalization of the model itself, such as online KD and self KD. Here, we propose an easy-to-use and compatible strategy named Spaced KD to improve the effectiveness of both online KD and self KD, in which the student model distills knowledge from a teacher model trained with a space interval ahead. This strategy is inspired by a prominent theory named spacing effect in the field of biological learning and memory, positing that appropriate intervals between learning trials can significantly enhance learning performance. We provide an in-depth theoretical and empirical analysis showing that the benefits of the proposed spacing effect in KD stem from seeking a flat minima during stochastic gradient descent (SGD). We perform extensive experiments to demonstrate the effectiveness of our Spaced KD in improving the learning performance of DNNs (e.g., the additional performance gain is up to 2.31% and 3.34% on Tiny-ImageNet over online KD and self KD, respectively). Our codes have been released on github~\url{https://github.com/SunGL001/Spaced-KD}.","How can we help AI systems learn more effectively and generalize better — even in unfamiliar situations? Inspired by how humans and animals learn better when study sessions are spaced out over time, we propose a new way to train AI called Spaced Knowledge Distillation. This method introduces short delays between the updates of a “teacher” model and a “student” model, mimicking the benefits of spaced learning in biology.By carefully timing when the student learns from the teacher, our method encourages the student model to settle into more stable and reliable learning patterns. This results in better performance on real-world tasks and stronger resistance to noisy or unexpected data.Our approach works with existing training techniques, doesn’t add extra cost, and consistently improves performance across different AI models and datasets. It shows that in both brains and machines, when you learn matters just as much as what you learn."
Poster,Ringmaster ASGD: The First Asynchronous SGD with Optimal Time Complexity,https://ICML.cc//virtual/2025/poster/45264,"Artavazd Maranjyan, Alexander Tyurin, Peter Richtarik","Asynchronous Stochastic Gradient Descent (Asynchronous SGD) is a cornerstone method for parallelizing learning in distributed machine learning. However, its performance suffers under arbitrarily heterogeneous computation times across workers, leading to suboptimal time complexity and inefficiency as the number of workers scales. While several Asynchronous SGD variants have been proposed, recent findings by Tyurin & Richtárik (NeurIPS 2023) reveal that none achieve optimal time complexity, leaving a significant gap in the literature. In this paper, we propose Ringmaster ASGD, a novel Asynchronous SGD method designed to address these limitations and tame the inherent challenges of Asynchronous SGD. We establish, through rigorous theoretical analysis, that Ringmaster ASGD achieves optimal time complexity under arbitrarily heterogeneous and dynamically fluctuating worker computation times. This makes it the first Asynchronous SGD method to meet the theoretical lower bounds for time complexity in such scenarios.","When training machine learning models across many computers, it’s common for some to work slower than others. This imbalance can make the whole process inefficient — like trying to row a boat with paddlers moving at different speeds. A popular method called Asynchronous SGD tries to handle this by letting faster machines move ahead without waiting. But recent research showed that no existing version of this method makes the best use of time when machines vary in speed, especially at large scale.We introduce a new method, Ringmaster ASGD, that coordinates these machines more effectively. Even when their speeds change unpredictably, our method keeps training efficient. We prove that it achieves the best possible speed in such scenarios.This could help a wide range of users — from companies training large language models to researchers working on scientific simulations — to build machine learning systems that are faster, more scalable, and better suited to real-world computing environments."
Poster,R.I.P.: Better Models by Survival of the Fittest Prompts,https://ICML.cc//virtual/2025/poster/44431,"Ping Yu, Weizhe Yuan, Olga Golovneva, Tianhao Wu, Sainbayar Sukhbaatar, JASON WESTON, Jing Xu","Training data quality is one of the most important drivers of final model quality. In this work, we introduce a method for evaluating data integrity based on the assumption that low-quality input prompts result in high variance and low quality responses. This is achieved by measuring the rejected response quality and the reward gap between the chosen and rejected preference pair. Our method, Rejecting Instruction Preferences (RIP) can be used to filter prompts from existing training sets, or to make high quality synthetic datasets, yielding large performance gains across various benchmarks compared to unfiltered data. Using Llama 3.1-8B-Instruct, RIP improves AlpacaEval2 LC Win Rate by 9.4%, Arena-Hard by 8.7%, and WildBench by 9.9%. Using Llama 3.3-70B-Instruct, RIP improves Arena-Hard from 67.5 to 82.9, from 18th place to 6th overall in the leaderboard.","The quality of training data is crucial for building powerful AI models. In this work, we introduce a simple yet effective way to improve training data by identifying and removing bad prompts—questions or instructions that lead to poor or inconsistent answers. Our method, called Rejecting Instruction Preferences (RIP), looks at two signals that are indicative of quality of the given instruction:1) If a model can produce really bad answers given a particular instruction, that’s a warning sign—the instruction itself might be unclear, misleading, or too open-ended. In other words, the worse the model could do, the more likely the instruction is low quality. 2) how much better a model’s preferred answer is compared to a rejected one. If the gap is small, it suggests the prompt may be confusing or low quality.Our method takes advantage of this idea. By filtering out such prompts, RIP helps models learn from clearer, more useful examples. This leads to much better performance across a wide range of tests. For example, using RIP with Meta’s Llama 3.1 models boosted scores by up to 10% on several standard evaluations. On a competitive leaderboard, our approach moved a top-tier model from 18th to 6th place."
Poster,RISE: Radius of Influence based Subgraph Extraction for 3D Molecular Graph Explanation,https://ICML.cc//virtual/2025/poster/44150,"Jingxiang Qu, Wenhan Gao, Jiaxing Zhang, Xufeng Liu, Hua Wei, Haibin Ling, Yi Liu","3D Geometric Graph Neural Networks (GNNs) have emerged as transformative tools for modeling molecular data. Despite their predictive power, these models often suffer from limited interpretability, raising concerns for scientific applications that require reliable and transparent insights. While existing methods have primarily focused on explaining molecular substructures in 2D GNNs, the transition to 3D GNNs introduces unique challenges, such as handling the implicit dense edge structures created by a cutoff radius. To tackle this, we introduce a novel explanation method specifically designed for 3D GNNs, which localizes the explanation to the immediate neighborhood of each node within the 3D space. Each node is assigned an radius of influence, defining the localized region within which message passing captures spatial and structural interactions crucial for the model's predictions. This method leverages the spatial and geometric characteristics inherent in 3D graphs. By constraining the subgraph to a localized radius of influence, the approach not only enhances interpretability but also aligns with the physical and structural dependencies typical of 3D graph applications, such as molecular learning.","Understanding how artificial intelligence (AI) models make decisions is crucial -- especially when they are used in chemistry or drug development. One promising type of molecular AI models, called 3D Graph Neural Networks (GNNs), is good at predicting molecular properties by considering the 3D shapes of molecules. But these models are often regarded as “black boxes” -- it’s hard to know how they make the final predictions.Our research introduces **RISE** (Radius of Influence-based Subgraph Extraction), a new pipeline designed to make these models more transparent and understandable. RISE works by identifying a “radius of influence” around each atom -- essentially a distance within which other atoms significantly affect the model’s prediction. By doing this, RISE can highlight the most important parts of a molecule in a way that aligns with real chemistry, such as identifying actual chemical bonds.Compared to previous methods, RISE is both more accurate and more interpretable. It avoids technical shortcuts about uninterpretable explanations, and it consistently identifies important subgraphs with less edges. This makes RISE especially useful for scientists who want to know how AI models make decisions for molecular learning tasks."
Poster,Risk and cross validation in ridge regression with correlated samples,https://ICML.cc//virtual/2025/poster/45831,"Alexander Atanasov, Jacob A Zavatone-Veth, Cengiz Pehlevan","Recent years have seen substantial advances in our understanding of high-dimensional ridge regression, but existing theories assume that training examples are independent. By leveraging techniques from random matrix theory and free probability, we provide sharp asymptotics for the in- and out-of-sample risks of ridge regression when the data points have arbitrary correlations. We demonstrate that in this setting, the generalized cross validation estimator (GCV) fails to correctly predict the out-of-sample risk. However, in the case where the noise residuals have the same correlations as the data points, one can modify the GCV to yield an efficiently-computable unbiased estimator that concentrates in the high-dimensional limit, which we dub CorrGCV. We further extend our asymptotic analysis to the case where the test point has nontrivial correlations with the training set, a setting often encountered in time series forecasting. Assuming knowledge of the correlation structure of the time series, this again yields an extension of the GCV estimator, and sharply characterizes the degree to which such test points yield an overly optimistic prediction of long-time risk. We validate the predictions of our theory across a variety of high dimensional data.","Natural time series data are ubiquitously correlated. However, cross-validation methods for estimating the error of predictions made using even the simplest linear regression methods assume that samples are independent. Here, we introduce an efficiently computable estimator for the out-of-sample risk of ridge regression when the data points have arbitrary correlations. We dub this estimator the CorrGCV, as it is a correlation-corrected version of the generalized cross validation (GCV) estimator."
Poster,Risk-Sensitive Theory of Mind: Coordinating with Agents of Unknown Bias using Cumulative Prospect Theory,https://ICML.cc//virtual/2025/poster/45542,"Mason O. Smith, Wenlong Zhang","Humans are often modeled as rational actors by interactive agents when they are in fact frequently observed to make biased decisions. This erroneous assumption may cause an agent’s model of the human to fail, especially when interaction occurs in bias-inducing settings that prompt risky decisions. To address this, this paper formulates a risk-sensitive multi-agent coordination problem and presents the novel Risk-Sensitive Theory of Mind (RS-ToM) framework that allows an autonomous agent to reason about and adapt to a partner of unknown risk-sensitivity. In simulated studies, we show that an agent with an RS-ToM is able to better coordinate with such a partner when compared to an agent that assumes their partner is rational. Thus, we observe significant improvements to team performance, coordination fluency, compliance with partner risk-preferences, and predictability. The presented results suggest that an RS-ToM will be able to model and plan with partners that exhibit these risk-sensitive biases in the real world.","Machines often fail to consider that humans are not perfectly rational agents. This can lead to a machine that does not truly understand what their human partner wants or intends to do. Therefore, this paper proposes a machine learning framework called a Risky-Sensitive Theory of Mind (RS-ToM) that can model humans who are subject to risk-sensitive biases. In simulated experiments, we show that our approach can adapt to agents of varying and unknown risk-sensitivity in a way that the standard assumption of ""humans are rational"" fails to do. Consequently, the presented results suggest that an RS-ToM will be able to model and plan with partners that exhibit these risk-sensitive biases in the real world."
