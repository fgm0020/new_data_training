type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Learning Progress Driven Multi-Agent Curriculum,https://ICML.cc//virtual/2025/poster/46153,"Wenshuai Zhao, Zhiyuan Li, Joni Pajarinen","The number of agents can be an effective curriculum variable for controlling the difficulty of multi-agent reinforcement learning (MARL) tasks. Existing work typically uses manually defined curricula such as linear schemes. We identify two potential flaws while applying existing reward-based automatic curriculum learning methods in MARL: (1) The expected episode return used to measure task difficulty has high variance; (2) Credit assignment difficulty can be exacerbated in tasks where increasing the number of agents yields higher returns which is common in many MARL tasks. To address these issues, we propose to control the curriculum by using a TD-error based *learning progress* measure and by letting the curriculum proceed from an initial context distribution to the final task specific one. Since our approach maintains a distribution over the number of agents and measures learning progress rather than absolute performance, which often increases with the number of agents, we alleviate problem (2). Moreover, the learning progress measure naturally alleviates problem (1) by aggregating returns. In three challenging sparse-reward MARL benchmarks, our approach outperforms state-of-the-art baselines.","Training teams of AI agents to work together is challenging, especially when they receive little feedback (reward) from the environment. Traditionally, researchers make the task easier at first — for example, by using fewer agents — and then slowly increase the difficulty. But this approach is often hand-crafted and doesn't always work well.We explored whether an AI system could automatically decide how many agents to train with at each stage, based on how much it's learning. At first, we adapted an existing method that picks easier tasks by checking how much reward the agents get. But this method struggled: in multi-agent settings, high rewards don't always mean better learning due to the credit assignment problem.To fix this, we proposed a new method that looks at how much the agents' policies improves over time — their ""learning progress"" — instead of just their rewards. This progress is measured using the TD error signals that are more stable and informative.Our experiments on several complex benchmarks show that our method helps agents learn faster and more effectively than previous approaches. This work could improve how AI teams are trained in environments where feedback is rare."
Poster,Learning Representations of Instruments for Partial Identification of Treatment Effects,https://ICML.cc//virtual/2025/poster/43986,"Jonas Schweisthal, Dennis Frauen, Maresa Schröder, Konstantin Hess, Niki Kilbertus, Stefan Feuerriegel","Reliable estimation of treatment effects from observational data is important in many disciplines such as medicine. However, estimation is challenging when unconfoundedness as a standard assumption in the causal inference literature is violated. In this work, we leverage arbitrary (potentially high-dimensional) instruments to estimate bounds on the conditional average treatment effect (CATE). Our contributions are three-fold: (1) We propose a novel approach for partial identification through a mapping of instruments to a discrete representation space so that we yield valid bounds on the CATE. This is crucial for reliable decision-making in real-world applications. (2) We derive a two-step procedure that learns tight bounds using a tailored neural partitioning of the latent instrument space. As a result, we avoid instability issues due to numerical approximations or adversarial training. Furthermore, our procedure aims to reduce the estimation variance in finite-sample settings to yield more reliable estimates. (3) We show theoretically that our procedure obtains valid bounds while reducing estimation variance. We further perform extensive experiments to demonstrate the effectiveness across various settings. Overall, our procedure offers a novel path for practitioners to make use of potentially high-dimensional instruments (e.g., as in Mendelian randomization).","Estimating how a treatment affects individuals using only observational data is crucial in fields like medicine, but standard methods break down when hidden factors influence both treatment and outcome. To address this, we use variables called “instruments”—for example, genetic markers—that affect treatment but not directly the outcome, even if these instruments are complex and high-dimensional. Our method transforms these instruments into a simple, discrete form that guarantees valid upper and lower bounds on the treatment effect for each person, ensuring we never make overconfident claims. To do so, we train a two-step neural network that learns the tightest possible bounds while avoiding instability from hard numerical approximations or adversarial techniques; this also reduces uncertainty when data are limited. We prove that our approach always produces correct bounds and yields less variance than existing methods. Through extensive experiments, we show that our method works well across different settings. By making it practical to use complicated instruments, such as genetic data in Mendelian randomization, our work helps researchers and clinicians make safer, evidence-based decisions when unmeasured confounding is a concern."
Poster,Learning Robust Neural Processes with Risk-Averse Stochastic Optimization,https://ICML.cc//virtual/2025/poster/45775,"Huafeng Liu, Yiran Fu, Liping Jing, Hui Li, Shuyang Lin, Jingyue Shi, Deqiang Ouyang, Jian Yu","Neural processes (NPs) are a promising paradigm to enable skill transfer learning across tasks with the aid of the distribution of functions. The previous NPs employ the empirical risk minimization principle in optimization. However, the fast adaption ability to different tasks can vary widely, and the worst fast adaptation can be catastrophic in risk-sensitive tasks. To achieve robust neural processes modeling, we consider the problem of training models in a risk-averse manner, which can control the worst fast adaption cases at a certain probabilistic level. By transferring the risk minimization problem to a two-level finite sum minimax optimization problem, we can easily solve it via a double-looped stochastic mirror prox algorithm with a task-aware variance reduction mechanism via sampling samples across all tasks. The mirror prox technique ensures better handling of complex constraint sets and non-Euclidean geometries, making the optimization adaptable to various tasks. The final solution, by aggregating prox points with the adaptive learning rates, enables a stable and high-quality output. The proposed learning strategy can work with various NPs flexibly and achieves less biased approximation with a theoretical guarantee. To illustrate the superiority of the proposed model, we perform experiments on both synthetic and real-world data, and the results demonstrate that our approach not only helps to achieve more accurate performance but also improves model robustness.","How can AI systems quickly learn new skills from just a few examples reliably, especially in high-stakes scenarios like healthcare or robotics? Current methods (called neural processes) are powerful but can fail unpredictably during rapid adaptation—with potentially serious consequences.We tackle this by redesigning training to prioritize ""safety nets."" Instead of aiming for average performance, we focus on minimizing risks in worst-case scenarios. Our method uses advanced math (a mirror-prox algorithm) to balance fast adaptation and stability across diverse tasks. By smartly sharing insights from all tasks during training, we ensure AI adapts more robustly without compromising accuracy.Tests on synthetic and real-world data prove our approach not only boosts performance but also builds resilience against unexpected challenges—theoretically guaranteed. This could help deploy trustworthy AI in risk-sensitive fields where failures are unacceptable."
Poster,Learning Safe Control via On-the-Fly Bandit Exploration,https://ICML.cc//virtual/2025/poster/44982,"Alexandre Capone, Ryan Cosner, Aaron Ames, Sandra Hirche","Control tasks with safety requirements under high levels of model uncertainty are increasingly common. Machine learning techniques are frequently used to address such tasks, typically by leveraging model error bounds to specify robust constraint-based safety filters. However, if the learned model uncertainty is very high, the corresponding filters are potentially invalid, meaning no control input satisfies the constraints imposed by the safety filter. While most works address this issue by assuming some form of safe backup controller, ours tackles it by collecting additional data on the fly using a Gaussian process bandit-type algorithm. We combine a control barrier function with a learned model to specify a robust certificate that ensures safety if feasible. Whenever infeasibility occurs, we leverage the control barrier function to guide exploration, ensuring the collected data contributes toward the closed-loop system safety. By combining a safety filter with exploration in this manner, our method provably achieves safety in a general setting that does not require any prior model or backup controller, provided that the true system lies in a reproducing kernel Hilbert space. To the best of our knowledge, it is the first safe learning-based control method that achieves this.","Deploying robots in an unknown environment is especially challenging. It is unclear how they will behave, which can result in unsafe behavior, such as a collision, internal damage to the machine, or even posing risks to other humans. We mitigate this by proposing a method that acts safely given the current information, and collects new data if it estimates that it does not have sufficient information to perform safe actions."
Poster,Learning Safe Strategies for Value Maximizing Buyers in Uniform Price Auctions,https://ICML.cc//virtual/2025/poster/44067,"Negin Golrezaei, Sourav Sahoo","We study the bidding problem in repeated uniform price multi-unit auctions from the perspective of a single *value-maximizing* buyer who aims to maximize their cumulative value over $T$ rounds while adhering to return-on-investment (RoI) constraints in each round. Buyers adopt $m$-*uniform bidding* format, where they submit $m$ bid-quantity pairs $(b_i, q_i)$ to demand $q_i$ units at bid $b_i$. We introduce *safe* bidding strategies as those that satisfy RoI constraints in every auction, regardless of competing bids. We show that these strategies depend only on the bidder’s valuation curve, and the bidder can focus on a finite subset of this class without loss of generality. While the number of strategies in this subset is exponential in $m$, we develop a polynomial-time algorithm to learn the optimal safe strategy that achieves sublinear regret in the online setting, where regret is measured against a clairvoyant benchmark that knows the competing bids *a priori* and selects a fixed hindsight optimal safe strategy. We then evaluate the performance of safe strategies against a clairvoyant that selects the optimal strategy from a richer class of strategies in the online setting. In this scenario, we compute the *richness ratio*, $\alpha\in(0, 1]$ for the class of strategies chosen by the clairvoyant and show that our algorithm, designed to learn safe strategies, achieves $\alpha$-approximate sublinear regret against these stronger benchmarks. Experiments on semi-synthetic data from real-world auctions show that safe strategies substantially outperform the derived theoretical bounds, making them quite appealing in practice.","**What’s the problem?**In many real-world auctions—like those for emissions permits, government bonds, or electricity—multiple identical items are sold at the same price. Buyers participate in these auctions repeatedly and want to get as much value as possible from what they buy, while ensuring that each purchase gives a good return on investment (RoI). This work looks at how a single such buyer should bid over time.**What does the research do?**The authors define a class of *safe* bidding strategies that guarantee the buyer meets their RoI constraint in every auction, regardless of what other bidders do. These strategies are based entirely on how much the buyer values each unit. While there are exponentially many possible strategies, the paper develops an efficient algorithm to learn the best one over time. This algorithm performs nearly as well as an ideal bidder who knows all future competition in advance.**Why does this matter for decision-makers?**Safe bidding strategies are easy to understand, computationally efficient, and robust—even when compared to more flexible or “ideal” strategies. Experiments using data inspired by real-world auctions show that these strategies perform significantly better than conservative theoretical predictions. Because of this, these strategies offer a powerful, robust approach for bidders in high-stakes markets."
Poster,Learning Safety Constraints for Large Language Models,https://ICML.cc//virtual/2025/poster/45876,"Xin Chen, Yarden As, Andreas Krause","Large language models (LLMs) have emerged as powerful tools but pose significant safety risks through harmful outputs and vulnerability to adversarial attacks. We propose SaP–short for Safety Polytope–a geometric approach to LLM safety, that learns and enforces multiple safety constraints directly in the model's representation space. We develop a framework that identifies safe and unsafe regions via the polytope's facets, enabling both detection and correction of unsafe outputs through geometric steering. Unlike existing approaches that modify model weights, SaP operates post-hoc in the representation space, preserving model capabilities while enforcing safety constraints. Experiments across multiple LLMs demonstrate that our method can effectively detect unethical inputs, reduce adversarial attack success rates while maintaining performance on standard tasks, thus highlighting the importance of having an explicit geometric model for safety. Analysis of the learned polytope facets reveals emergence of specialization in detecting different semantic notions of safety, providing interpretable insights into how safety is captured in LLMs' representation space.","Large language models (LLMs) are powerful tools, but their propensity for generating harmful content and susceptibility to adversarial attacks raises significant safety concerns. We introduce Safety Polytope (SaP), a novel geometric framework designed to enhance LLM safety. SaP learns and enforces safety constraints directly within the model's inner workings, specifically in its representation space.This approach defines a ""safe zone"" using a geometric structure called a polytope. By identifying safe and unsafe regions within this space, SaP can detect and correct potentially harmful outputs. When the model is about to generate unsafe content, SaP ""steers"" its behavior back towards the safe zone.Experiments demonstrate that SaP effectively detects unethical inputs and reduces the success rate of adversarial attacks, all while maintaining the model's performance on standard tasks. This work highlights the benefit of employing an explicit geometric model to address safety in LLMs."
Poster,Learnings from Scaling Visual Tokenizers for Reconstruction and Generation,https://ICML.cc//virtual/2025/poster/45528,"Philippe Hansen-Estruch, David Yan, Ching-Yao Chuang, Orr Zohar, Jialiang Wang, Tingbo Hou, Tao Xu, Sriram Vishwanath, Peter Vajda, Xinlei Chen","Visual tokenization via auto-encoding empowers state-of-the-art image and video generative models by compressing pixels into a latent space. However, questions remain about how auto-encoder design impacts reconstruction and downstream generative performance. This work explores scaling in auto-encoders for reconstruction and generation by replacing the convolutional backbone with an enhanced Vision Transformer for Tokenization (ViTok). We find scaling the auto-encoder bottleneck correlates with reconstruction but exhibits a nuanced relationship with generation. Separately, encoder scaling yields no gains, while decoder scaling improves reconstruction with minimal impact on generation. As a result, we determine that scaling the current paradigm of auto-encoders is not effective for improving generation performance. Coupled with Diffusion Transformers, ViTok achieves competitive image reconstruction and generation performance on 256p and 512p ImageNet-1K. In videos, ViTok achieves SOTA reconstruction and generation performance on 16-frame 128p UCF-101.","Visual tokenization is a method that compresses the original visual data into forms easier to generate in. Typically auto-encoders use CNNs to perform this compression, but ViTs have been explored as well. Our research investigates how scaling these auto-encoders affects the quality of reconstruction (how accurately the original image is rebuilt) and how it effects downstream generation of images or videos.We discovered that making the compression part (bottleneck) bigger helps reconstruct images better but doesn't consistently enhance the quality of generations. Enlarging the encoder showed no gain, whereas enlarging the decoder improved image reconstruction but again had limited effect on generation.Ultimately, our findings indicate that simply making current auto-encoder designs larger doesn't significantly enhance their ability to generate better images or videos. Still, when combined with other techniques, our ViTok approach achieves strong performance in recreating and generating realistic visuals, even surpassing previous best results for short video clips."
Poster,Learning Single Index Models with Diffusion Priors,https://ICML.cc//virtual/2025/poster/44269,"Anqi Tang, Youming Chen, Shuchen Xue, Zhaoqiang Liu","Diffusion models (DMs) have demonstrated remarkable ability to generate diverse and high-quality images by efficiently modeling complex data distributions. They have also been explored as powerful generative priors for signal recovery, resulting in a substantial improvement in the quality of reconstructed signals. However, existing research on signal recovery with diffusion models either focuses on specific reconstruction problems or is unable to handle nonlinear measurement models with discontinuous or unknown link functions. In this work, we focus on using DMs to achieve accurate recovery from semi-parametric single index models, which encompass a variety of popular nonlinear models that may have {\em discontinuous} and {\em unknown} link functions. We propose an efficient reconstruction method that only requires one round of unconditional sampling and (partial) inversion of DMs. Theoretical analysis on the effectiveness of the proposed methods has been established under appropriate conditions. We perform numerical experiments on image datasets for different nonlinear measurement models. We observe that compared to competing methods, our approach can yield more accurate reconstructions while utilizing significantly fewer neural function evaluations.","In many real-world applications (such as imaging or signal processing), we often need to recover an image or signal from measurements that are incomplete, indirect, or distorted in a complex way. Sometimes, the way these measurements are taken is nonlinear and hard to describe with a simple formula, especially when the relationship between the true signal and the observed data is unknown or contains abrupt changes.Our work explores how to use powerful image generation tools, known as diffusion models, to solve this problem. Diffusion models have recently gained attention for their ability to generate highly realistic images, but we show they can also help recover original signals from challenging observations. Our focus is on two representative types of measurements: one where only the sign of each pixel is observed (known as 1-bit measurements), and another where the measurement is a cubic function of the original signal. Our method works in two simple steps. First, it estimates the noise through a partial inversion of the diffusion process based on the observed measurements. Then, it applies a pre-trained diffusion model to denoise this estimate and recover the original image. This avoids reliance on detailed knowledge of the measurement process, making the method both fast and efficient.Experiments on standard image datasets show that our method achieves more accurate reconstructions than previous techniques, using significantly fewer neural function evaluations. Our work opens the door to better signal recovery in practical settings where measurement systems are imperfect, unknown, or too complex to model directly."
Poster,Learning Smooth and Expressive Interatomic Potentials for Physical Property Prediction,https://ICML.cc//virtual/2025/poster/45302,"Xiang Fu, Brandon Wood, Luis Barroso-Luque, Daniel S. Levine, Meng Gao, Misko Dzamba, Larry Zitnick","Machine learning interatomic potentials (MLIPs) have become increasingly effective at approximating quantum mechanical calculations at a fraction of the computational cost. However, lower errors on held out test sets do not always translate to improved results on downstream physical property prediction tasks. In this paper, we propose testing MLIPs on their practical ability to conserve energy during molecular dynamic simulations. If passed, improved correlations are found between test errors and their performance on physical property prediction tasks. We identify choices which may lead to models failing this test, and use these observations to improve upon highly-expressive models. The resulting model, eSEN, provides state-of-the-art results on a range of physical property prediction tasks, including materials stability prediction, thermal conductivity prediction, and phonon calculations.","Molecular simulations guide the discovery of new batteries, catalysts, and numerious other critical fields. Machine learning interatomic potentials (MLIPs) are promising to accelerate these simulations, yet a model that looks great on standard benchmarks may not perform well in downstream tasks. We propose a practical quality check and design eSEN, a new MLIP that reliably delivers state‑of‑the‑art predictions for material stability, thermal conductivity, and atomic vibrations, accelerating the search for better materials."
Poster,Learning Soft Sparse Shapes for Efficient Time-Series Classification,https://ICML.cc//virtual/2025/poster/46130,"Zhen Liu, Yicheng Luo, Boyuan Li, Emadeldeen Eldele, Min Wu, Qianli Ma","Shapelets are discriminative subsequences (or shapes) with high interpretability in time series classification. Due to the time-intensive nature of shapelet discovery, existing shapelet-based methods mainly focus on selecting discriminative shapes while discarding others to achieve candidate subsequence sparsification. However, this approach may exclude beneficial shapes and overlook the varying contributions of shapelets to classification performance. To this end, we propose a Soft sparse Shapes (SoftShape) model for efficient time series classification. Our approach mainly introduces soft shape sparsification and soft shape learning blocks. The former transforms shapes into soft representations based on classification contribution scores, merging lower-scored ones into a single shape to retain and differentiate all subsequence information. The latter facilitates intra- and inter-shape temporal pattern learning, improving model efficiency by using sparsified soft shapes as inputs. Specifically, we employ a learnable router to activate a subset of class-specific expert networks for intra-shape pattern learning. Meanwhile, a shared expert network learns inter-shape patterns by converting sparsified shapes into sequences. Extensive experiments show that SoftShape outperforms state-of-the-art methods and produces interpretable results.","Shapelets are discriminative subsequences with high interpretability in time series classification. Traditional shapelet-based methods mainly focus on the selection of discriminative shapes while discarding non-essential ones to accelerate the shapelet discovery process. In this paper, we introduce SoftShape, a soft shapelet learning framework for time series classification. SoftShape consists of two main components: first, it employs a Soft Shape Sparsification mechanism, leveraging attention-based soft weighting to retain key shapelets rather than discarding them outright. Second, it incorporates a dual-pattern learning strategy that integrates a mixture-of-experts architecture for intra-shape learning alongside sequence-aware inter-shape modeling, thereby capturing both local and global temporal patterns. Experiments on 128 UCR time series datasets demonstrate that SoftShape outperforms existing state-of-the-art methods and provides good interpretable results."
