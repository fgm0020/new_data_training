type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,MTSTRec: Multimodal Time-Aligned Shared Token Recommender,https://ICML.cc//virtual/2025/poster/43526,"Ming-Yi Hong, Yen-Jung Hsu, Miao-Chen Chiang, Che Lin","Sequential recommendation in e-commerce utilizes users' anonymous browsing histories to personalize product suggestions without relying on private information. Existing item ID-based methods and multimodal models often overlook the temporal alignment of modalities like textual descriptions, visual content, and prices in user browsing sequences. To address this limitation, this paper proposes the Multimodal Time-aligned Shared Token Recommender (MTSTRec), a transformer-based framework with a single time-aligned shared token per product for efficient cross-modality fusion. MTSTRec preserves the distinct contributions of each modality while aligning them temporally to better capture user preferences. Extensive experiments demonstrate that MTSTRec achieves state-of-the-art performance across multiple sequential recommendation benchmarks, significantly improving upon existing multimodal fusion. Our code is available at https://github.com/idssplab/MTSTRec.","Online shopping platforms often recommend products to users based on their browsing history, but traditional methods usually rely only on product IDs and ignore important information from other modalities like images, text descriptions, and prices. Even when multimodal data is included, the timing of these elements—like when a user views an image or reads a description—is often misaligned, leading to less accurate recommendations.To solve this, we developed MTSTRec, a new recommendation model that aligns these different types of information, like images, text, and prices, over time.  This allows the system to better understand user behavior and make more accurate suggestions.Our experiments show that MTSTRec consistently outperforms other recommendation models, leading to more relevant product suggestions for users. This improvement could make online shopping experiences faster and more personalized, benefiting both customers and retailers. In the future, we plan to adapt MTSTRec for broader applications, unlocking its potential to enhance user experiences and decision-making in multiple domains."
Poster,MUDDFormer: Breaking Residual Bottlenecks in Transformers via Multiway Dynamic Dense Connections,https://ICML.cc//virtual/2025/poster/43924,"Da Xiao, Qingye Meng, Shengping Li, xingyuan yuan","We propose MUltiway Dynamic Dense (MUDD) connections, a simple yet effective method to address the limitations of residual connections and enhance cross-layer information flow in Transformers. Unlike existing dense connection approaches with static and shared connection weights, MUDD generates connection weights dynamically depending on hidden states at each sequence position and for each decoupled input stream (the query, key, value or residual) of a Transformer block. MUDD connections can be seamlessly integrated into any Transformer architecture to create MUDDFormer. Extensive experiments show that MUDDFormer significantly outperforms Transformers across various model architectures and scales in language modeling, achieving performance of Transformers trained with ~1.8x--2.4x compute. Notably, MUDDPythia-2.8B matches Pythia-6.9B in pretraining ppl and downstream tasks and even rivals Pythia-12B in five-shot settings, while adding only 0.23% parameters and 0.4% computation. Code in JAX and PyTorch and pre-trained models are available at https://github.com/Caiyun-AI/MUDDFormer.","Most Transformer large language models rely on “residual connections,” fixed shortcuts that pass information from one layer to the next. These shortcuts act like a narrow service road: as traffic grows, they clog up, so builders respond by widening the entire highway—training ever-bigger, more expensive models.We introduce Multiway Dynamic Dense (MUDD) connections, which instead add flexible extra lanes only where and when traffic needs them. For every token the model processes and for every internal signal (queries, keys, values, etc.), MUDD automatically chooses the best blend of old and new information, using connection weights that adapt on the fly. Plugging MUDD connections into standard Transformer architectures—creating a model we call MUDDFormer—lets a 2.8-billion-parameter model match a 6.9-billion-parameter model, while adding just 0.4% more computation. In practice, this cuts the training cost and energy use of state-of-the-art language models by up to 60%.This breakthrough not only makes cutting-edge AI more accessible and sustainable but also offers a path to developing highly capable yet more efficient AI systems. By releasing our MUDDFormer designs and source code openly, we hope to empower more researchers and organizations to build better and greener models."
Poster,MuLan: Adapting Multilingual Diffusion Models for Hundreds of Languages with Negligible Cost,https://ICML.cc//virtual/2025/poster/45950,"Sen Xing, Muyan Zhong, Zeqiang Lai, Liangchen Li, Jiawen Liu, Yaohui Wang, Jifeng Dai, Wenhai Wang","In this work, we explore a cost-effective framework for multilingual image generation. We find that, unlike models tuned on high-quality images with multilingual annotations, leveraging text encoders pre-trained on widely available, noisy Internet image-text pairs significantly enhances data efficiency in text-to-image (T2I) generation across multiple languages. Based on this insight, we introduce MuLan,Multi-Language adapter, a lightweight language adapter with fewer than 20M parameters, trained alongside a frozen text encoder and image diffusion model. Compared to previous multilingual T2I models, this framework offers: (1) Cost efficiency. Using readily accessible English data and off-the-shelf multilingual text encoders minimizes the training cost; (2) High performance. Achieving comparablegeneration capabilities in over 110 languages with CLIP similarity scores nearly matching those in English (39.57 for English vs. 39.61 for other languages); and (3) Broad applicability. Seamlessly integrating with compatible community tools like LoRA, LCM, ControlNet, and IP-Adapter, expanding its potential use cases.","Generating images from text descriptions is usually resource-intensive, particularly for languages other than English, because high-quality multilingual datasets are costly and limited. To address this, we developed MuLan, a cost-effective method for multilingual image generation. Instead of using expensive, high-quality datasets, we used widely available, noisy Internet data combined with multilingual text encoders. Our key innovation is a lightweight language adapter, called MuLan, which has fewer than 20 million parameters and works alongside existing text and image models.MuLan significantly reduces training costs while achieving high-quality image generation in more than 110 languages. Remarkably, the image quality for other languages closely matches the performance in English, making advanced text-to-image generation accessible globally. Furthermore, our approach easily integrates with popular community tools, enhancing its versatility and potential applications. This work democratizes access to powerful multilingual image generation technologies, allowing users around the world to create high-quality images efficiently and affordably."
Poster,Multiaccuracy and Multicalibration via Proxy Groups,https://ICML.cc//virtual/2025/poster/43844,"Beepul Bharti, Mary Clemens-Sewall, Paul H. Yi, Jeremias Sulam","As the use of predictive machine learning algorithms increases in high-stakes decision-making, it is imperative that these algorithms are fair across sensitive groups. However, measuring and enforcing fairness in real-world applications can be challenging due to missing or incomplete sensitive group information. Proxy-sensitive attributes have been proposed as a practical and effective solution in these settings, but only for parity-based fairness notions. Knowing how to evaluate and control for fairness with missing sensitive group data for newer, different, and more flexible frameworks, such as multiaccuracy and multicalibration, remains unexplored. In this work, we address this gap by demonstrating that in the absence of sensitive group data, proxy-sensitive attributes can provably be used to derive actionable upper bounds on the true multiaccuracy and multicalibration violations, providing insights into a predictive model’s potential worst-case fairness violations. Additionally, we show that adjusting models to satisfy multiaccuracy and multicalibration across proxy-sensitive attributes can significantly mitigate these violations for the true, but unknown, sensitive groups. Through several experiments on real-world datasets, we illustrate that approximate multiaccuracy and multicalibration can be achieved even when sensitive group data is incomplete or unavailable.","As machine learning models are increasingly used to make important decisions, like who gets a loan or access to healthcare, it’s critical that they treat different sensitive groups fairly. In many real-world cases, however, we don’t have complete information about people’s sensitive attributes, like race or biological sex. This makes it hard to evaluate or enforce fairness. In this work, we show that we can still make fairness assessments using proxy sensitive attributes. While proxy attributes have been used before for traditional notions of fairness, we extend their use to newer, more flexible fairness concepts called multiaccuracy and multicalibration. We prove that proxy attributes can help estimate how unfair a model might be in the worst case, even without knowing the true sensitive groups. We also show that building models to satisfy fairness across these proxies can lead to useful guarantees on a model's fairness. We test our approach on real datasets to illustrate the utility of our results."
Poster,Multi-agent Architecture Search via Agentic Supernet,https://ICML.cc//virtual/2025/poster/44335,"Guibin Zhang, Luyang Niu, Junfeng Fang, Kun Wang, LEI BAI, Xiang Wang","Large Language Model (LLM)-empowered multi-agent systems extend the cognitive boundaries of individual agents through disciplined collaboration and interaction, while constructing these systems often requires labor-intensive manual designs. Despite the availability of methods to automate the design of agentic workflows, they typically seek to identify a static, complex, one-size-fits-all system, which, however, fails to dynamically allocate inference resources based on the difficulty and domain of each query. To address this challenge, we shift away from the pursuit of a monolithic agentic system, instead optimizing the \textbf{agentic supernet}, a probabilistic and continuous distribution of agentic architectures. We introduce \textbf{MaAS}, an automated framework that samples query-dependent agentic systems from the supernet, delivering high-quality solutions and tailored resource allocation (\textit{e.g.}, LLM calls, tool calls, token cost). Comprehensive evaluation across six benchmarks demonstrates that MaAS \textbf{(I)} requires only $6\\sim45\\%$ of the inference costs of existing handcrafted or automated multi-agent systems, \textbf{(II)} surpasses them by $0.54\\%\sim11.82\\%$, and \textbf{(III)} enjoys superior cross-dataset and cross-LLM-backbone transferability.","MaAS extends traditional neural architecture search into the agentic AI domain, introducing the first agentic supernet that dynamically adjusts its complexity based on task demands."
Poster,Multi-Armed Bandits with Interference: Bridging Causal Inference and Adversarial Bandits,https://ICML.cc//virtual/2025/poster/46529,"Su Jia, Peter Frazier, Nathan Kallus","Experimentation with interference poses a significant challenge in contemporary online platforms. Prior research on experimentation with interference has concentrated on the final output of a policy. Cumulative performance, while equally important, is less well understood. To address this gap, we introduce the problem of Multi-armed Bandits with Interference (MABI), where the learner assigns an arm to each of $N$ experimental units over $T$ rounds. The reward of each unit in each round depends on the treatments of all units, where the interference between two units decays in their distance. The reward functions are chosen by an adversary and may vary arbitrarily over time and across different units. We first show that the optimal expected regret (against the best fixed-arm policy) is $\tilde O(\sqrt T)$, and can be achieved by a switchback policy. However, the regret (as a random variable) for any switchback policy suffers a high variance, since it does not account for $N$. We propose a policy based on a novel clustered randomization scheme, whose regret (i) is optimal in  expectation and (ii) admits a high probability bound that vanishes in $N$.","Imagine we’re running an online food delivery platform and want to test multiple promotion campaigns (i.e., treatments) to maximize total revenue over a sales season. A key challenge is interference between locations (e.g., ZIP codes): the effectiveness of a promotion at one location can depend heavily on what promotions are assigned to nearby locations, since they may compete for shared resources like delivery drivers.A naive approach is to assign promotions independently to each location and average the resulting revenues. Another naive method is switchback: assigning the historically best-performing promotion to all locations in each period.We propose a more effective alternative based on clustered randomization: we first group locations into clusters and assign promotions at the cluster level, favoring arms with strong historical performance. We show that this approach outperforms the above baselines by achieving the best possible worst-case expected revenue while also being more robust — i.e., significantly less likely to result in very low revenue."
Poster,Multi-band Frequency Reconstruction for Neural Psychoacoustic Coding,https://ICML.cc//virtual/2025/poster/44519,"Dianwen Ng, Kun Zhou, Yi-Wen Chao, Zhiwei Xiong, Bin Ma, EngSiong Chng","Achieving high-fidelity audio compression while preserving perceptual quality across diverse audio types remains a significant challenge in Neural Audio Coding (NAC). This paper introduces MUFFIN, a fully convolutional NAC framework that leverages psychoacoustically guided multi-band frequency reconstruction. Central to MUFFIN is the Multi-Band Spectral Residual Vector Quantization (MBS-RVQ) mechanism, which quantizes latent speech across different frequency bands. This approach optimizes bitrate allocation and enhances fidelity based on psychoacoustic studies, achieving efficient compression with unique perceptual features that separate content from speaker attributes through distinct codebooks. MUFFIN integrates a transformer-inspired convolutional architecture with proposed modified snake activation functions to capture fine frequency details with greater precision. Extensive evaluations on diverse datasets (LibriTTS, IEMOCAP, GTZAN, BBC) demonstrate MUFFIN’s ability to consistently surpass existing performance in audio reconstruction across various domains. Notably, a high-compression variant achieves an impressive SOTA 12.5 kHz rate while preserving reconstruction quality. Furthermore, MUFFIN excels in downstream generative tasks, demonstrating its potential as a robust token representation for integration with large language models. These results establish MUFFIN as a groundbreaking advancement in NAC and as the first neural psychoacoustic coding system. Speech demos and codes are available at \url{https://demos46.github.io/muffin/} and \url{https://github.com/dianwen-ng/MUFFIN}.","Despite recent progress in neural audio coding (NAC), most systems still struggle to maintain perceptual quality at high compression rates, especially across diverse audio types. Moreover, they largely ignore psychoacoustic principles that underpin how humans perceive sound. We introduce MUFFIN, the first Neural Psychoacoustic Codec (NPC), which leverages a novel multi-band spectral quantization strategy aligned with human auditory perception. By separating and encoding low, mid, and high-frequency bands differently, MUFFIN preserves critical features like speech intelligibility, content articulation, and speaker identity. Our model also uses an enhanced snake activation for fine spectral detail. MUFFIN achieves state-of-the-art audio quality at extreme compression rates, enabling high-fidelity audio even at just 12.5 Hz. It improves zero-shot text-to-speech synthesis and offers disentangled token representations, making it ideal for integration with large language models. This positions MUFFIN as a key building block for bandwidth-efficient, perceptually rich, and controllable audio applications—from streaming to assistive AI."
Poster,Multidimensional Adaptive Coefficient for Inference Trajectory Optimization in Flow and Diffusion,https://ICML.cc//virtual/2025/poster/45075,"Dohoon Lee, Jaehyun Park, Hyunwoo Kim, Kyogu Lee","Flow and diffusion models have demonstrated strong performance and training stability across various tasks but lack two critical properties of simulation-based methods: freedom of dimensionality and adaptability to different inference trajectories. To address this limitation, we propose the Multidimensional Adaptive Coefficient (MAC), a plug-in module for flow and diffusion models that extends conventional unidimensional coefficients to multidimensional ones and enables inference trajectory-wise adaptation. MAC is trained via simulation-based feedback through adversarial refinement. Empirical results across diverse frameworks and datasets demonstrate that MAC enhances generative quality with high training efficiency. Consequently, our work offers a new perspective on inference trajectory optimality, encouraging future research to move beyond vector field design and to leverage training-efficient, simulation-based optimization.","Consider the drawing process of a horse: we might first clarify the head, then refine the body—illustrating ""Multidimensionality."" For other animals, like a frog, it might be better to draw the body first, then complete the head—illustrating ""Adaptability."" Our research asks: which multidimensional adaptive inference trajectories yield the best generation quality?To answer this, we propose the Multidimensional Adaptive Coefficient (MAC), a plug-in module for flow and diffusion frameworks—standard tools in generative modeling. Across diverse frameworks and datasets, MAC discovers optimal inference trajectories, significantly improving generation quality and inference efficiency while achieving strong training efficiency.Our findings enhance generative modeling and offer a new perspective on inference trajectory optimality by enabling flexibility in multidimensionality and adaptability."
Poster,Multi-Domain Graph Foundation Models: Robust Knowledge Transfer via Topology Alignment,https://ICML.cc//virtual/2025/poster/46509,"Shuo Wang, Bokui Wang, Zhixiang Shen, Boyan Deng, zhao kang","Recent advances in CV and NLP have inspired researchers to develop general-purpose graph foundation models through pre-training across diverse domains. However, a fundamental challenge arises from the substantial differences in graph topologies across domains. Additionally, real-world graphs are often sparse and prone to noisy connections and adversarial attacks. To address these issues, we propose the Multi-Domain Graph Foundation Model (MDGFM), a unified framework that aligns and leverages cross-domain topological information to facilitate robust knowledge transfer. MDGFM bridges different domains by adaptively balancing features and topology while refining original graphs to eliminate noise and align topological structures. To further enhance knowledge transfer, we introduce an efficient prompt-tuning approach. By aligning topologies, MDGFM not only improves multi-domain pre-training but also enables robust knowledge transfer to unseen domains. Theoretical analyses provide guarantees of MDGFM's effectiveness and domain generalization capabilities. Extensive experiments on both homophilic and heterophilic graph datasets validate the robustness and efficacy of our method.","Graphs are powerful tools for representing complex systems like social networks or scientific data. But when these graphs come from very different sources—like Facebook friends versus academic papers—it becomes hard for machines to understand and transfer knowledge between them. Our research introduces **MDGFM** to help computers learn from multiple kinds of graphs and apply that knowledge to unfamiliar domains.Instead of using fixed structures, MDGFM learns to refine and align the graph's layout, removing noise and highlighting meaningful patterns. It also uses a special prompting strategy to adapt what it learned to new types of graphs. This makes it more flexible and accurate when dealing with new or messy data. We test MDGFM on various graph types and find that it outperforms current methods, even when it sees very little new data or is attacked by fake connections."
Poster,Multilayer Matrix Factorization via Dimension-Reducing Diffusion Variational Inference,https://ICML.cc//virtual/2025/poster/45997,"Junbin Liu, Farzan Farnia, Wing-Kin Ma","Multilayer matrix factorization (MMF) has recently emerged as a generalized model of, and potentially a more expressive approach than, the classic matrix factorization.This paper considers MMF under a probabilistic formulation, and our focus is on inference methods under variational inference.The challenge in this context lies in determining a variational process that leads to a computationally efficient and accurate approximation of the maximum likelihood inference. One well-known example is the variational autoencoder (VAE), which uses neural networks for the variational process.In this work, we take insight from variational diffusion models in the context of generative models to develop variational inference for MMF.We propose a dimension-reducing diffusion process that results in a new way to interact with the layered structures of the MMF model.Experimental results demonstrate that the proposed diffusion variational inference method leads to improved performance scores compared to several existing methods, including the VAE.","Matrix factorization is a computational technique that helps researchers analyze high-dimensional data and uncover simpler, more understandable patterns. Recently, researchers developed multilayer matrix factorization (MMF), which uses multiple layers to retrieve patterns from complex data. The challenge is that these multilayer models are computationally difficult to handle. To address this, we drew inspiration from diffusion models, a powerful generative AI technique that has revolutionized image generation. We developed a new MMF method that borrows key insights from diffusion models. Our approach systematically breaks down the problem layer by layer. We tested our method against established techniques like the variational autoencoders (VAE), and our approach delivered promising results. This advancement may give researchers a more powerful tool for uncovering hidden structures in complex high-dimensional data. The potential applications are broad, from analyzing remote sensing images to isolating individual voices in audio recordings."
