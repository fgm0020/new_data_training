type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Preference learning made easy: Everything should be understood through win rate,https://ICML.cc//virtual/2025/poster/45135,"Lily Zhang, Rajesh Ranganath","Preference learning, or the task of aligning generative models to preference comparison data, has yet to reach the conceptual maturity of classification, density estimation, etc. To close this gap, this work presents a framework to understand preference learning starting from the sampling distribution of pairwise preference data. First, we prove that the only evaluation of a generative model that respects both preferences and prevalences in the data distribution is a form of win rate, justifying win rate as the focal point to understand preference learning. We then analyze preference learning methods as win rate optimization (WRO) or non-WRO. We present novel instances of WRO beyond existing examples (RLHF, NLHF) and identify two key theoretical benefits of all such methods. We prove that common non-WRO methods like DPO and SFT on preferred samples lack these properties and suggest ways to mitigate such theoretical limitations. We also show that WRO underperforms in practice due optimization difficulties and that optimization success predicts performance better than choices which affect the objective's solution. Our analysis highlights best practices for existing methods and provides recommendations for future research, guided by the principle that one should either align non-WRO methods more closely with WRO or improve the optimization of WRO objectives.","When we train AI models, it’s important to make sure they do what people actually want. The primary paradigm for doing this is to ask humans to choose between several model-generated options and use this information to continue to train models. This is called preference learning. Compared to other tasks like training models to classifying images or generate realistic text, preference learning is still not well understood.This research introduces a clearer way to think about preference learning. We show that win rate — how often a model generates content preferred over a competitor — is the only evaluation metric that respects the properties of the preference data being collected. This gives us a solid foundation to study preference learning.We divide preference-learning methods into two groups: those that aim to directly improve win rate (which we call WRO methods) and those that don’t (non-WRO methods). We introduce new WRO methods, explain why they’re theoretically stronger, and show that common techniques like SFT (supervised fine-tuning) or DPO (direct preference optimization) miss out on these strengths—though we offer ideas to make them better.Interestingly, even though WRO methods are better in theory, they often perform worse in practice because they are harder to optimize. Our findings suggest that improving how these methods are trained may matter more than choosing the perfect method on paper.Overall, our work helps researchers better understand what works in preference learning and offers guidance on how to improve preference learning to get AI systems to better match what people actually want."
Poster,Preference Optimization for Combinatorial Optimization Problems,https://ICML.cc//virtual/2025/poster/45664,"Mingjun Pan, Guanquan Lin, You-Wei Luo, Bin Zhu, Zhien Dai, Lijun Sun, Chun Yuan","Reinforcement Learning (RL) has emerged as a powerful tool for neural combinatorial optimization, enabling models to learn heuristics that solve complex problems without requiring expert knowledge. Despite significant progress, existing RL approaches face challenges such as diminishing reward signals and inefficient exploration in vast combinatorial action spaces, leading to inefficiency. In this paper, we propose **Preference Optimization**, a novel method that transforms quantitative reward signals into qualitative preference signals via statistical comparison modeling, emphasizing the superiority among sampled solutions. Methodologically, by reparameterizing the reward function in terms of policy and utilizing preference models, we formulate an entropy-regularized RL objective that aligns the policy directly with preferences while avoiding intractable computations. Furthermore, we integrate local search techniques into the fine-tuning rather than post-process to generate high-quality preference pairs, helping the policy escape local optima. Empirical results on various benchmarks, such as the Traveling Salesman Problem (TSP), the Capacitated Vehicle Routing Problem (CVRP) and the Flexible Flow Shop Problem (FFSP), demonstrate that our method significantly outperforms existing RL algorithms, achieving superior convergence efficiency and solution quality.","Many real-world tasks like planning delivery routes or scheduling jobs require finding the best arrangement among an enormous  feasible solutions, but traditional reinforcement learning methods struggle as they receive ever-smaller numerical rewards and are consuming in exploring nearly infinite action space.We introduce Preference Optimization, which compares pairs of candidate solutions to turn raw scores into simple preferrable signals. By aligning the learning process with these qualitative preferences and integrating local improvements into training rather than afterward, our method keeps learning process stable and guides the system more directly toward high-quality solutions.This approach makes neural solvers learn faster, escape local optimal, ultimately find significantly better and more efficient solutions to these complex problems."
Poster,Premise-Augmented Reasoning Chains Improve Error Identification in Math reasoning with LLMs,https://ICML.cc//virtual/2025/poster/46462,"Sagnik Mukherjee, Abhinav Chinta, Takyoung Kim, Tarun Anoop Sharma, Dilek Hakkani-Tür","Chain-of-Thought (CoT) prompting enhances mathematical reasoning in large language models (LLMs) by enabling detailed step-by-step solutions. However, due to the verbosity of LLMs, the resulting reasoning chains can be long, making it harder to verify the reasoning steps and trace issues resulting from dependencies between the steps that may be farther away in the sequence of steps. Importantly, mathematical reasoning allows each step to be derived from a small set of premises, which are a subset of the preceding steps in the reasoning chain. In this paper, we present a framework that identifies the premises for each step, to improve the evaluation of reasoning. We restructure conventional linear reasoning chains into Premise Augmented Reasoning Chains (PARC) by introducing premise links, resulting in a directed acyclic graph where the nodes are the steps and the edges are the premise links. Through experiments with a PARC-based dataset that we built, namely (Premises and ERrors identification in LLMs), we demonstrate that LLMs can reliably identify premises within complex reasoning chains. In particular, even open-source LLMs achieve 90% recall in premise identification.  We also show that PARC helps to identify errors in reasoning chains more reliably. The accuracy of error identification improves by 6% to 16% absolute when step-by-step verification is carried out in PARC under the premises.Our findings highlight the utility of premise-centric representations in addressing complex problem-solving tasks and open new avenues for improving the reliability of LLM-based reasoning evaluations.","Large language models (LLMs) like ChatGPT can solve math problems step by step, but they often make mistakes that are hard to spot. This paper proposes a new way to trace each step’s logic by linking it only to the specific earlier steps it depends on, similar to how we show our work in math class. This forms a structure called a Premise-Augmented Reasoning Chain (PARC). Using this method and a new dataset called PERL, the authors show that LLMs can better detect both direct mistakes and hidden errors that build up over time. The approach improves the accuracy of identifying errors and could make LLMs more trustworthy for tasks that require careful reasoning."
Poster,Preserving AUC Fairness in Learning with Noisy Protected Groups,https://ICML.cc//virtual/2025/poster/44611,"Mingyang Wu, Li Lin, Wenbin Zhang, Xin Wang, Zhenhuan Yang, Shu Hu","The Area Under the ROC Curve (AUC) is a key metric for classification, especially under class imbalance, with growing research focus on optimizing AUC over accuracy in applications like medical image analysis and deepfake detection. This leads to fairness in AUC optimization becoming crucial as biases can impact protected groups. While various fairness mitigation techniques exist, fairness considerations in AUC optimization remain in their early stages, with most research focusing on improving AUC fairness under theassumption of clean protected groups. However, these studies often overlook the impact of noisy protected groups, leading to fairness violations in practice. To address this, we propose the first robust AUC fairness approach under noisy protected groups with fairness theoretical guarantees using distributionally robust optimization. Extensive experiments on tabular and image datasets show that our method outperforms state-of-the-art approaches in preserving AUC fairness. The code is in https://github.com/Purdue-M2/AUC_Fairness_with_Noisy_Groups.","In many AI applications, such as medical image analysis and deepfake detection, the Area Under the ROC Curve (AUC) is a crucial metric for evaluating how well a model performs. However, in situations where certain groups of people are underrepresented or have different characteristics, it's important to consider fairness alongside performance. Traditional fairness methods for AUC optimization often assume that groups are clearly defined and free from errors. In reality, these groups are often noisy, leading to unfair outcomes that can affect certain communities.To solve this problem, we introduce a new approach to AUC fairness that works even when there is noise in the data regarding protected groups. By using a method called distributionally robust optimization, our approach ensures fairness while maintaining strong performance. Through rigorous testing on both tabular data and image data, we show that our method outperforms existing approaches in achieving fairness without sacrificing accuracy. This breakthrough helps create more reliable and unbiased AI systems for real-world applications."
Poster,Pre-training Auto-regressive Robotic Models with 4D Representations,https://ICML.cc//virtual/2025/poster/46596,"Dantong Niu, Yuvan Sharma, Haoru Xue, Giscard Biamby, Junyi Zhang, Ziteng Ji, Trevor Darrell, Roi Herzig","Foundation models pre-trained on massive unlabeled datasets have revolutionized natural language and computer vision, exhibiting remarkable generalization capabilities, thus highlighting the importance of pre-training. Yet, efforts in robotics have struggled to achieve similar success, limited by either the need for costly robotic annotations or the lack of representations that effectively model the physical world. In this paper, we introduce ARM4R, an **A**uto-regressive **R**obotic **M**odel that leverages low-level **4**D **R**epresentations learned from human video data to yield a better pre-trained robotic model. Specifically, we focus on utilizing 3D point tracking representations from videos derived by lifting 2D representations into 3D space via monocular depth estimation across time. These 4D representations maintain a shared geometric structure between the points and robot state representations up to a linear transformation, enabling efficient transfer learning from human video data to low-level robotic control. Our experiments show that ARM4R can transfer efficiently from human video data to robotics and consistently improves performance on tasks across various robot environments and configurations.","Modern AI models have made big advances in understanding language and images by learning from huge amounts of data found online. But in robotics, we haven’t seen the same kind of success—mostly because training robots usually requires expensive, detailed data, and it is difficult to capture the detailed dynamics of the real world. Our research introduces a new approach called ARM4R that helps robots learn more effectively from human videos. Instead of relying on costly robot-specific data, we use regular video footage of people and track how their body points move in 3D over time. This creates a kind of ""4D"" representation (3D in space + time), that is general enough to be extended to robots as well. We show that our method helps robots perform better across a variety of tasks and setups."
Poster,Pretraining Generative Flow Networks with Inexpensive Rewards for Molecular Graph Generation,https://ICML.cc//virtual/2025/poster/43446,"Mohit Pandey, Gopeshh Subbaraj, Artem Cherkasov, Martin Ester, Emmanuel Bengio","Generative Flow Networks (GFlowNets) have recently emerged as a suitable framework for generating diverse and high-quality molecular structures by learning from rewards treated as unnormalized distributions. Previous works in this framework often restrict exploration by using predefined molecular fragments as building blocks, limiting the chemical space that can be accessed. In this work, we introduce Atomic GFlowNets (A-GFNs), a foundational generative model leveraging individual atoms as building blocks to explore drug-like chemical space more comprehensively. We propose an unsupervised pre-training approach using drug-like molecule datasets, which teaches A-GFNs about inexpensive yet informative molecular descriptors such as drug-likeliness, topological polar surface area, and synthetic accessibility scores. These properties serve as proxy rewards, guiding A-GFNs towards regions of chemical space that exhibit desirable pharmacological properties. We further implement a goal-conditioned finetuning process, which adapts A-GFNs to optimize for specific target properties. In this work, we pretrain A-GFN on a subset of ZINC dataset, and by employing robust evaluation metrics we show the effectiveness of our approach when compared to other relevant baseline methods for a wide range of drug design tasks.  The code is accessible at https://github.com/diamondspark/AGFN.","Chemists urgently need faster and more effective ways to design new drug molecules. However, many existing AI tools rely on assembling compounds from pre-made molecular fragments, which limits their ability to explore the full range of chemical possibilities.We present Atomic GFlowNet, an AI system that builds molecules atom by atom, much like constructing a structure with Lego bricks. This fine-grained approach allows it to access a much wider and more diverse chemical space.To begin, we train the model on millions of existing drug-like molecules, guiding it with simple, low-cost objectives such as synthetic accessibility and drug-likeness. Once this foundation is established, we can quickly adapt the same model using a small amount of additional data to pursue more challenging goals, like binding to a specific disease-related protein.In our evaluations, Atomic GFlowNet generated significantly more diverse and promising molecules than leading methods. It was also able to improve known drug candidates after just a single day of computation. This work offers a faster and more comprehensive path to discovering future medicines and other high-value chemical compounds."
Poster,Pre-Training Graph Contrastive Masked Autoencoders are Strong Distillers for EEG,https://ICML.cc//virtual/2025/poster/44482,"Xinxu Wei, kanhao zhao, Yong Jiao, Hua Xie, Lifang He, Yu Zhang","Effectively utilizing extensive unlabeled high-density EEG data to improve performance in scenarios with limited labeled low-density EEG data presents a significant challenge. In this paper, we address this challenge by formulating it as a graph transfer learning and knowledge distillation problem. We propose a Unified Pre-trained Graph Contrastive Masked Autoencoder Distiller, named EEG-DisGCMAE, to bridge the gap between unlabeled and labeled as well as high- and low-density EEG data. Our approach introduces a novel unified graph self-supervised pre-training paradigm, which seamlessly integrates the graph contrastive pre-training with the graph masked autoencoder pre-training. Furthermore, we propose a graph topology distillation loss function, allowing a lightweight student model trained on low-density data to learn from a teacher model trained on high-density data during pre-training and fine-tuning. This method effectively handles missing electrodes through contrastive distillation. We validate the effectiveness of EEG-DisGCMAE across four classification tasks using two clinical EEG datasets with abundant data.","Electroencephalography (EEG) is a common way to measure brain activity using sensors placed on the head. While expensive EEG devices with many sensors provide detailed and accurate readings, they are difficult to use outside of clinical settings. Cheaper EEG devices with fewer sensors are more practical for everyday use, but they often miss key brain signals. Our work helps bridge this gap. We created a learning system that first studies large amounts of high-quality EEG data to understand general patterns of brain activity. This process, called pre-training, allows the system to gain useful knowledge even before tackling specific tasks. Then, it teaches smaller models working with low-cost EEG data to perform just as well as those using expensive equipment. This approach makes EEG analysis more accurate, affordable, and ready for use in real-world health and research applications."
Poster,"Prices, Bids, Values: One ML-Powered Combinatorial Auction to Rule Them All",https://ICML.cc//virtual/2025/poster/46478,"Ermis Soumalias, Jakob Heiss, Jakob Weissteiner, Sven Seuken","We study the design of *iterative combinatorial auctions (ICAs)*.The main challenge in this domain is that the bundle space grows exponentially in the number of items. To address this, recent work has proposed machine learning (ML)-based preference elicitation algorithms that aim to elicit only the most critical information from bidders to maximize efficiency.However, while the SOTA ML-based algorithms elicit bidders' preferences via *value queries*, ICAs that are used in practice elicit information via *demand queries*. In this paper, we introduce a novel ML algorithm that provably makes use of the full information from both value and demand queries, and we show via experiments that  combining both query types results in significantly better learning performance in practice. Building on these insights, we present MLHCA, a new ML-powered auction that uses value and demand queries. MLHCA significantly outperforms the previous SOTA, reducing efficiency loss by up to a factor 10, with up to 58% fewer queries. Thus, MLHCA achieves large efficiency improvements while also reducing bidders' cognitive load, establishing a new benchmark  for both practicability and efficiency. Our code is available at https://github.com/marketdesignresearch/MLHCA.","Imagine an auction where you want to buy a *combination* of items, not just one. These are called ""combinatorial auctions"". The challenge is that as more items are added, the number of possible combinations explodes, making it hard for buyers to express their preferences to the auctioneer. Therefore, the auctioneer needs to decide which items to assign to which buyers based on incomplete information, resulting in sub-optimal assignments. Our research introduces a new approach using machine learning (ML) to make these complex auctions much more efficient. Traditionally, these auctions ask buyers about their value of specific combinations of items (""value queries"") or what they would buy at different prices (""demand queries""). We've developed a novel ML algorithm, called MLHCA, that intelligently combines both types of queries.By doing this, MLHCA significantly improves how well the auction learns buyers' true preferences, leading to better outcomes. In our experiments, MLHCA dramatically reduced the ""efficiency loss"" (how far the auction outcome is from the ideal) by up to a **factor of 10** and could match the previous state-of-the-art auction with up to **58% fewer questions** for buyers to answer. This means more effective auctions and less effort for participants.For real-world applications of these auction formats like **spectrum auctions**, our simulations show that this improved efficiency could translate to approximately **100 million USD in additional value** per auction. MLHCA sets a new standard for how practical and efficient combinatorial auctions can be."
Poster,Primal-Dual Neural Algorithmic Reasoning,https://ICML.cc//virtual/2025/poster/44369,"Yu He, Ellen Vitercik","Neural Algorithmic Reasoning (NAR) trains neural networks to simulate classical algorithms, enabling structured and interpretable reasoning over complex data. While prior research has predominantly focused on learning exact algorithms for polynomial-time-solvable problems, extending NAR to harder problems remains an open challenge. In this work, we introduce a general NAR framework grounded in the primal-dual paradigm, a classical method for designing efficient approximation algorithms. By leveraging a bipartite representation between primal and dual variables, we establish an alignment between primal-dual algorithms and Graph Neural Networks. Furthermore, we incorporate optimal solutions from small instances to greatly enhance the model’s reasoning capabilities. Our empirical results demonstrate that our model not only simulates but also outperforms approximation algorithms for multiple tasks, exhibiting robust generalization to larger and out-of-distribution graphs. Moreover, we highlight the framework’s practical utility by integrating it with commercial solvers and applying it to real-world datasets.","Neural networks have shown promise in simulating simple algorithms like sorting and searching. However, extending this ability to complex problems remains a challenge. Many of the real-world problems are too difficult to solve exactly within a reasonable time. To apply neural networks in practice, they must be able to learn efficient approximations for such problems. In this work, we present a framework that trains neural networks to follow the primal-dual method, a classical approach used to design approximation algorithms for hard problems. We represent these algorithms as graphs, enabling the network to learn reasoning that mirrors the primal-dual method. To improve learning, we incorporate optimal solutions from small problem instances, allowing the model to recognize patterns that apply to larger tasks. Our results show that the model not only replicates but can also outperform the algorithms in some cases. We demonstrate its practical utility by applying it to real-world datasets and enhancing commercial solvers."
Poster,PRIME: Deep Imbalanced Regression with Proxies,https://ICML.cc//virtual/2025/poster/44388,"Jongin Lim, Sucheol Lee, Daeho Um, Sung-Un Park, Jinwoo Shin","Data imbalance remains a fundamental challenge in real-world machine learning. However, most existing work has focused on classification, leaving imbalanced regression underexplored despite its importance in many applications. To address this gap, we propose PRIME, a framework that leverages learnable proxies to construct a balanced and well-ordered feature space for imbalanced regression. At its core, PRIME arranges proxies to be uniformly distributed in the feature space while preserving the ordinal structure of regression targets, and then aligns each sample feature to its corresponding proxy. By using proxies as reference points, PRIME induces the desired structure of learned representations, promoting better generalization, especially in underrepresented target regions. Moreover, since proxy-based alignment resembles classification, PRIME enables the seamless application of class imbalance techniques to regression, facilitating more balanced feature learning. Extensive experiments demonstrate the effectiveness and broad applicability of PRIME, achieving state-of-the-art performance on four real-world regression benchmark datasets across diverse target domains.","In many real-world situations, artificial intelligence (AI) systems struggle when certain types of data are rare—for example, predicting rare events or extreme values. While researchers have made progress on this problem for classification tasks, less attention has been paid to similar challenges in predicting continuous values, known as regression.To bridge this gap, we developed a new method called PRIME. PRIME uses “proxies”, or reference points, to help the AI model learn in a more balanced and organized way, even when the training data is uneven. These proxies are arranged to reflect the order of target values, and each data point is trained to align with its appropriate proxy.Our work provides a flexible and unified framework that brings class imbalance solutions into regression tasks, paving the way for a new paradigm in handling imbalanced regression."
