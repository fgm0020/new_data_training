type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Self-supervised Masked Graph Autoencoder via Structure-aware Curriculum,https://ICML.cc//virtual/2025/poster/46366,"Haoyang Li, Xin Wang, Zeyang Zhang, Zongyuan Wu, Linxin Xiao, Wenwu Zhu","Self-supervised learning (SSL) on graph-structured data has attracted considerable attention recently. Masked graph autoencoder, as one promising generative graph SSL approach that aims to recover masked parts of the input graph data, has shown great success in various downstream graph tasks. However, existing masked graph autoencoders fail to consider the degree of difficulty of recovering the masked edges that often have different impacts on the model performance, resulting in suboptimal node representations. To tackle this challenge, in this paper, we propose a novel curriculum based self-supervised masked graph autoencoder that is able to capture and leverage the underlying degree of difficulty of data dependencies hidden in edges, and design better mask-reconstruction pretext tasks for learning informative node representations. Specifically, we first design a difficulty measurer to identify the underlying structural degree of difficulty of edges during the masking step. Then, we adopt a self-paced scheduler to determine the order of masking edges, which encourages the graph encoder to learn from easy to difficult parts. Finally, the masked edges are gradually incorporated into the reconstruction pretext task, leading to high-quality node representations. Experiments on several real-world node classification and link prediction datasets demonstrate the superiority of our proposed method over state-of-the-art graph self-supervised learning baselines. This work is the first study of curriculum strategy for masked graph autoencoders, to the best of our knowledge.","Graphs such as social networks and citation maps are common in the real world. Teaching AI models to understand them without relying on human-annotated labels is a key challenge. One popular approach trains models by hiding parts of a graph and asking them to predict what is missing. However, it often treats all missing parts as equally difficult, which can limit learning effectiveness.We propose a new method that improves model training by starting with easier tasks and gradually progressing to more difficult ones. Our method estimates how challenging each part of the graph is to recover and adjusts the training schedule accordingly.This progressive learning strategy helps the model build better representations of graph data. Across multiple real-world benchmarks, our method outperforms existing techniques on tasks such as node classification and link prediction. To our knowledge, this is the first work to introduce curriculum-based training in self-supervised learning for graph models."
Poster,Self-Supervised Transformers as Iterative Solution Improvers for Constraint Satisfaction,https://ICML.cc//virtual/2025/poster/45737,"Yudong W Xu, Wenhao Li, Scott Sanner, Elias Khalil","We present a Transformer-based framework for Constraint Satisfaction Problems (CSPs). CSPs find use in many applications and thus accelerating their solution with machine learning is of wide interest. Most existing approaches rely on supervised learning from feasible solutions or reinforcement learning, paradigms that require either feasible solutions to these NP-Complete CSPs or large training budgets and a complex expert-designed reward signal. To address these challenges, we propose ConsFormer, a self-supervised framework that leverages a Transformer as a solution refiner. ConsFormer constructs a solution to a CSP iteratively in a process that mimics local search. Instead of using feasible solutions as labeled data, we devise differentiable approximations to the discrete constraints of a CSP to guide model training. Our model is trained to improve random assignments for a single step but is deployed iteratively at test time, circumventing the bottlenecks of supervised and reinforcement learning. Experiments on Sudoku, Graph Coloring, Nurse Rostering, and MAXCUT demonstrate that our method can tackle out-of-distribution CSPs simply through additional iterations.","Solving problems under specific rules and restrictions is part of many real-life tasks, from completing puzzles like Sudoku to scheduling employee shifts. These problems are often hard to solve, and even the best traditional methods can struggle as the problems grow larger and more complex.Artificial intelligence has been used to help tackle these problems more efficiently. However, many existing methods rely on having examples of good solutions or require extensive trial and error, which can be slow or impractical. We introduce ConsFormer which takes a different approach. It trains an AI model to make small improvements to a solution in a single step, without needing correct answers during training. When deployed, ConsFormer is repeatedly used to make steady improvements, starting from a random guess and refining it step by step.ConsFormer works across different problems and can handle more challenging instances simply by running more improvement steps. This makes it a promising tool for solving complex real-world constraint reasoning problems efficiently."
Poster,Semantics-aware Test-time Adaptation for 3D Human Pose Estimation,https://ICML.cc//virtual/2025/poster/44013,"Qiuxia Lin, Glory Rongyu CHEN, Kerui Gu, Angela Yao","This work highlights a semantics misalignment in 3D human pose estimation. For the task of test-time adaptation, the misalignment manifests as overly smoothed and unguided predictions. The smoothing settles predictions towards some average pose. Furthermore, when there are occlusions or truncations, the adaptation becomes fully unguided. To this end, we pioneer the integration of a semantics-aware motion prior for the test-time adaptation of 3D pose estimation. We leverage video understanding and a well-structured motion-text space to adapt the model motion prediction to adhere to video semantics during test time. Additionally, we incorporate a missing 2D pose completion based on the motion-text similarity. The pose completion strengthens the motion prior's guidance for occlusions and truncations. Our method significantly improves state-of-the-art 3D human pose estimation TTA techniques, with more than 12% decrease in PA-MPJPE on 3DPW and 3DHP.","When computers try to estimate how people move in 3D from a single-view video, they often struggle—especially when parts of the person are hidden. This leads to unrealistic or static poses that don’t match the expected activity, a problem we refer to as semantic misalignment. Our research addresses this by helping the computer understand human activity when doing predictions, like walking or climbing stairs. We use ChatGPT to identify the activity from video and guide the motion predictions to align with that activity using a shared motion-language space. We also complete missing body parts in a way that matches the intended action. Our research significantly improves prediction quality, achieving over a 12% accuracy boost on major 3D human pose datasets."
Poster,Semantic Shift Estimation via Dual-Projection and Classifier Reconstruction for Exemplar-Free Class-Incremental Learning,https://ICML.cc//virtual/2025/poster/43787,"Run He, Di Fang, Yicheng Xu, Yawen Cui, Ming Li, Cen Chen, Ziqian Zeng, HUIPING ZHUANG","Exemplar-Free Class-Incremental Learning (EFCIL) aims to sequentially learn from distinct categories without retaining exemplars but easily suffers from catastrophic forgetting of learned knowledge. While existing EFCIL methods leverage knowledge distillation to alleviate forgetting, they still face two critical challenges: semantic shift and decision bias. Specifically, the embeddings of old tasks shift in the embedding space after learning new tasks, and the classifier becomes biased towards new tasks due to training solely with new data, hindering the balance between old and new knowledge. To address these issues, we propose the Dual-Projection Shift Estimation and Classifier Reconstruction (DPCR) approach for EFCIL. DPCR effectively estimates semantic shift through a dual-projection, which combines a learnable transformation with a row-space projection to capture both task-wise and category-wise shifts. Furthermore, to mitigate decision bias, DPCR employs ridge regression to reformulate a classifier reconstruction process. This reconstruction exploits previous in covariance and prototype of each class after calibration with estimated shift, thereby reducing decision bias. Extensive experiments demonstrate that, on various datasets, DPCR effectively balances old and new tasks, outperforming state-of-the-art EFCIL methods. Our codes are available at https://github.com/RHe502/ICML25-DPCR.","We want to teach the computer to recognize new types of objects continually. However, the learned concepts are quickly forgotten when learning new objects. We attribute this to concept shift and model’s tendency to favor new task after learning new tasks. To overcome this problem, we learn a model combining two projections (TSSP and CIP) to rectify the concept shift during the continual learning. Also, the favor of new task is also corrected by a reconstruction process. These two components form our method DPCR and it achieves significant improvement over existing methods. Our proposed method can further alleviate the forgetting issue of models and obtain better models."
Poster,Semi-Supervised Blind Quality Assessment with Confidence-quantifiable Pseudo-label Learning for Authentic Images,https://ICML.cc//virtual/2025/poster/46701,"Yan Zhong, Chenxi Yang, Suyuan Zhao, Tingting Jiang","This paper presents CPL-IQA, a novel semi-supervised blind image quality assessment (BIQA) framework for authentic distortion scenarios. To address the challenge of limited labeled data in IQA area, our approach leverages confidence-quantifiable pseudo-label learning to effectively utilize unlabeled authentically distorted images. The framework operates through a preprocessing stage and two training phases: first converting MOS labels to vector labels via entropy minimization, followed by an iterative process that alternates between model training and label optimization. The key innovations of CPL-IQA include a manifold assumption-based label optimization strategy and a confidence learning method for pseudo-labels, which enhance reliability and mitigate outlier effects. Experimental results demonstrate the framework's superior performance on real-world distorted image datasets, offering a more standardized semi-supervised learning paradigm without requiring additional supervision or network complexity.","Assessing the quality of images is crucial for applications like photography, social media, and medical imaging. However, most methods require large amounts of labeled data, which is expensive and time-consuming to collect. This is especially challenging for ""authentic"" images—real-world photos with natural distortions like blur or noise—since their quality scores often vary even among similar-looking images.We propose a new method called CPL-IQA that combines labeled and unlabeled images to train a quality assessment model more efficiently. Our key innovation is a technique to estimate confidence scores for ""pseudo-labels"" (predicted quality scores for unlabeled images). By converting simple quality score labels into vector labels and refining them iteratively, our method ensures reliable predictions without needing extra data or complex networks.CPL-IQA outperforms existing methods on real-world image datasets, offering a practical solution for scenarios where labeled data is scarce. This could benefit industries relying on image quality, from smartphone cameras to healthcare imaging, by reducing the need for costly manual labeling while maintaining accuracy."
Poster,SEMU: Singular Value Decomposition for Efficient Machine Unlearning,https://ICML.cc//virtual/2025/poster/44285,"Marcin Sendera, Łukasz Struski, Kamil Książek, Kryspin Musiol, Jacek Tabor, Dawid Rymarczyk","While the capabilities of generative foundational models have advanced rapidly in recent years, methods to prevent harmful and unsafe behaviors remain underdeveloped. Among the pressing challenges in AI safety, machine unlearning (MU) has become increasingly critical to meet upcoming safety regulations. Most existing MU approaches focus on altering the most significant parameters of the model. However, these methods often require fine-tuning substantial portions of the model, resulting in high computational costs and training instabilities, which are typically mitigated by access to the original training dataset.In this work, we address these limitations by leveraging Singular Value Decomposition (SVD) to create a compact, low-dimensional projection that enables the selective forgetting of specific data points. We propose Singular Value Decomposition for Efficient Machine Unlearning (SEMU), a novel approach designed to optimize MU in two key aspects. First, SEMU minimizes the number of model parameters that need to be modified, effectively removing unwanted knowledge while making only minimal changes to the model's weights. Second, SEMU eliminates the dependency on the original training dataset, preserving the model's previously acquired knowledge without additional data requirements.Extensive experiments demonstrate that SEMU achieves competitive performance while significantly improving efficiency in terms of both data usage and the number of modified parameters.","While the capabilities of generative foundational models have advanced rapidly in recent years, methods to prevent harmful and unsafe behaviors remain underdeveloped. Among the pressing challenges in AI safety, machine unlearning (MU) has become increasingly critical to meet upcoming safety regulations. Most existing MU approaches focus on altering the most significant parameters of the model. However, these methods often require fine-tuning substantial portions of the model, resulting in high computational costs and training instabilities, which are typically mitigated by access to the original training dataset.In this work, we address these limitations by leveraging Singular Value Decomposition (SVD) to create a compact, low-dimensional projection that enables the selective forgetting of specific data points. We propose Singular Value Decomposition for Efficient Machine Unlearning (SEMU), a novel approach designed to optimize MU in two key aspects. First, SEMU minimizes the number of model parameters that need to be modified, effectively removing unwanted knowledge while making only minimal changes to the model's weights. Second, SEMU eliminates the dependency on the original training dataset, preserving the model's previously acquired knowledge without additional data requirements.Extensive experiments demonstrate that SEMU achieves competitive performance while significantly improving efficiency in terms of both data usage and the number of modified parameters."
Poster,SENSEI: Semantic Exploration Guided by Foundation Models to Learn Versatile World Models,https://ICML.cc//virtual/2025/poster/44870,"Cansu Sancaktar, Christian Gumbsch, Andrii Zadaianchuk, Pavel Kolev, Georg Martius","Exploration is a cornerstone of reinforcement learning (RL). Intrinsic motivation attempts to decouple exploration from external, task-based rewards. However, established approaches to intrinsic motivation that follow general principles such as information gain, often only uncover low-level interactions. In contrast, children’s play suggests that they engage in meaningful high-level behavior by imitating or interacting with their caregivers. Recent work has focused on using foundation models to inject these semantic biases into exploration. However, these methods often rely on unrealistic assumptions, such as language-embedded environments or access to high-level actions. We propose SEmaNtically Sensible ExploratIon (SENSEI), a framework to equip model-based RL agents with an intrinsic motivation for semantically meaningful behavior. SENSEI distills a reward signal of interestingness from Vision Language Model (VLM) annotations, enabling an agent to predict these rewards through a world model. Using model-based RL, SENSEI trains an exploration policy that jointly maximizes semantic rewards and uncertainty. We show that in both robotic and video game-like simulations SENSEI discovers a variety of meaningful behaviors from image observations and low-level actions. SENSEI provides a general tool for learning from foundation model feedback, a crucial research direction, as VLMs become more powerful.","AI agents often explore their environment by trial and error, but humans, especially children, learn by doing things that feel meaningful, often through observing and imitating others. We developed SENSEI, a method that helps AI explore more like humans. SENSEI uses powerful AI chatbots, trained on vast amounts of internet data, to act as an “artificial caregiver”. As the agent interacts with its environment, this caregiver provides feedback about which scenes seem interesting. The agent then seeks out these interesting situations and tries new actions to explore further. This allows the agent to discover useful behaviors in both robot simulations and video games, using only raw images (like a video game screen) and simple controls (like button presses). Our work offers a new way for AI to explore, taking into account what humans might find interesting."
Poster,Separating Knowledge and Perception with Procedural Data,https://ICML.cc//virtual/2025/poster/44033,"Adrian Rodriguez-Munoz, Manel Baradad, Phillip Isola, Antonio Torralba","We train representation models with procedural data only, and apply them on visual similarity, classification, and semantic segmentation tasks without further training by using visual memory---an explicit database of reference image embeddings. Unlike prior work on visual memory, our approach achieves full compartmentalization with respect to all real-world images while retaining strong performance. Compared to a model trained on Places, our procedural model performs within 1\% on NIGHTS visual similarity, outperforms by 8\% and 15\% on CUB200 and Flowers102 fine-grained classification, and is within 10\% on  ImageNet-1K classification. It also demonstrates strong zero-shot segmentation, achieving an $R^2$ on COCO within 10\% of the models trained on real data. Finally, we analyze procedural versus real data models, showing that parts of the same object have dissimilar representations in procedural models, resulting in incorrect searches in memory and explaining the remaining performance gap.","Standard machine learning approaches train vision models with real world images, which makes it difficult to learn (and forget) knowledge and carries privacy and interpretability concerns. In this work, we train vision models with non-realistic images generated with code, and use real world images only through an external memory database. This external memory is easily editable, making the overall models interpretable, flexible, and private. Moreover, despite being trained on non-realistic data the models achieve strong performance. Our work contributes towards making vision models more private and interpretable."
Poster,SepLLM: Accelerate Large Language Models by Compressing One Segment into One Separator,https://ICML.cc//virtual/2025/poster/45536,"Guoxuan Chen, Han Shi, jiawei li, Yihang Gao, Xiaozhe Ren, Yimeng Chen, Xin Jiang, Zhenguo Li, Weiyang Liu, Chao Huang","Large Language Models (LLMs) have exhibited exceptional performance across a spectrum of natural language processing tasks. However, their substantial sizes pose considerable challenges, particularly in computational demands and inference speed, due to their quadratic complexity. In this work, we have identified a key pattern: certain seemingly meaningless separator tokens (i.e., punctuations) contribute disproportionately to attention scores compared to semantically meaningful tokens. This observation suggests that information of the segments between these separator tokens can be effectively condensed into the separator tokens themselves without significant information loss. Guided by this insight, we introduce SepLLM, a plug-and-play framework that accelerates inference by compressing these segments and eliminating redundant tokens. Additionally, we implement efficient kernels for training acceleration. Experimental results across training-free, training-from-scratch, and post-training settings demonstrate SepLLM's effectiveness. Notably, using the Llama-3-8B backbone, SepLLM achieves over 50% reduction in KV cache on the GSM8K-CoT benchmark while maintaining comparable performance. Furthermore, in streaming settings, SepLLM effectively processes sequences of up to 4 million tokens or more while maintaining consistent language modeling capabilities.","SepLLM introduces a novel perspective in language modeling, proposing that separator tokens in LLMs naturally serve as division and summarization points for the segments they divide. Leveraging this insight, SepLLM enables sparse modeling of natural language by intentionally compressing segment information into separator tokens during pretraining. This reduces attention computation, minimizes KV cache size, and improves training and inference efficiency.Essentially, SepLLM is a native sparse attention mechanism that aligns closely with the natural semantic distribution of natural language. Since separators act as natural boundaries within language, the segments they divide are inherently coherent, self-contained, and semantically unified units. Thus, separators naturally become the ideal summarization and compression points for such semantic units. After training, SepLLM can also function as a KV cache compression approach to further reduce inference overhead.In summary, **SepLLM can be regarded as a native sparse attention mechanism inherent to the structure of natural language, and it is highly suitable to serve as a fundamental baseline model for sparse attention mechanisms in LLMs.**"
Poster,SERENA: A Unified Stochastic Recursive Variance Reduced Gradient Framework for Riemannian Non-Convex Optimization,https://ICML.cc//virtual/2025/poster/46244,"Yan Liu, Mingjie Chen, Chaojie Ji, Hao Zhang, Ruxin Wang","Recently, the expansion of Variance Reduction (VR) to Riemannian stochastic non-convex optimization has attracted increasing interest. Inspired by recursive momentum, we first introduce Stochastic Recursive Variance Reduced Gradient (SRVRG) algorithm and further present Stochastic Recursive Gradient Estimator (SRGE) in Euclidean spaces, which unifies the prevailing variance reduction estimators. We then extend SRGE to Riemannian spaces, resulting in a unified Stochastic rEcursive vaRiance reducEd gradieNt frAmework (SERENA) for Riemannian non-convex optimization. This framework includes the proposed R-SRVRG, R-SVRRM, and R-Hybrid-SGD methods, as well as other existing Riemannian VR methods.  Furthermore, we establish a unified theoretical analysis for Riemannian non-convex optimization under retraction and vector transport. The IFO complexity of our proposed R-SRVRG and R-SVRRM to converge to $\varepsilon$-accurate solution is $\mathcal{O}\left(\min \{n^{1/2}{\varepsilon^{-2}}, \varepsilon^{-3}\}\right)$ in the finite-sum setting and ${\mathcal{O}\left( \varepsilon^{-3}\right)}$ for the online case, both of which align with the lower IFO complexity bound. Experimental results indicate that the proposed algorithms surpass other existing Riemannian optimization methods.","In practical machine learning tasks, some tasks have parameter spaces that are not the familiar Euclidean space, but rather Riemannian spaces; for example, the parameter space may be a sphere. We study algorithms for solving optimization problems in machine learning within Riemannian spaces. We first present a new algorithm that is theoretically consistent with the best-known results and also performs excellently in numerical experiments. Additionally, we provide a unified algorithmic framework that encompasses several previous algorithms, which facilitates a better understanding and application of such algorithms."
