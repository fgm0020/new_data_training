type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Enhancing Foundation Models for Time Series Forecasting via Wavelet-based Tokenization,https://ICML.cc//virtual/2025/poster/46131,"Luca Masserano, Abdul Fatir Ansari, Boran Han, Xiyuan Zhang, Christos Faloutsos, Michael Mahoney, Andrew Wilson, Youngsuk Park, Syama Sundar Yadav Rangapuram, Danielle Maddix, Yuyang Wang","How to best develop foundational models for time series forecasting remains an important open question. Tokenization is a crucial consideration in this effort: what is an effective discrete vocabulary for a real-valued sequential input? To address this question, we develop WaveToken, a wavelet-based tokenizer that allows models to learn complex representations directly in the space of time-localized frequencies. Our method first scales and decomposes the input time series, then thresholds and quantizes the wavelet coefficients, and finally pre-trains an autoregressive model to forecast coefficients for the forecast horizon. By decomposing coarse and fine structures in the inputs, wavelets provide an eloquent and compact language for time series forecasting that simplifies learning. Empirical results on a comprehensive benchmark, including 42 datasets for both in-domain and zero-shot settings, show that WaveToken: i) performs on par or better than recently proposed foundation models for forecasting while using a much smaller vocabulary (1024 tokens), and is competitive with modern deep learning models trained specifically on each dataset; ii) exhibits superior generalization capabilities, achieving the best average rank across all datasets for three complementary metrics; and iii) easily captures complex temporal patterns of practical relevance that are challenging for other recent pre-trained models, including trends, sparse spikes, and non-stationary time series with varying frequencies evolving over time.","Predicting future events from past data (time series forecasting) is crucial in many fields, from finance to climate science. While powerful AI models (referred to as ""foundation models"") excel at language, adapting them to understand continuous time series data is challenging. A key hurdle is ""tokenization"": finding an effective way to convert real-valued sequences into a discrete ""language"" these models can process, especially one that captures both broad trends and sudden changes efficiently. This paper introduces WaveToken, a novel method that uses wavelets—mathematical tools that break down signals into different frequencies at specific times. WaveToken first decomposes the time series into these wavelet components, then simplifies and converts them into a compact set of ""tokens"". A foundation model is then trained to predict these future wavelet tokens. WaveToken performs as well as or better than existing advanced forecasting models, even those specifically trained for individual datasets, but with a significantly smaller vocabulary (fewer ""words""). This compactness helps it generalize better to unseen data. Crucially, WaveToken can accurately capture complex patterns like trends, sudden spikes, and signals with evolving frequencies—areas where other models often falter, making it a promising approach for more robust and efficient time series forecasting."
Poster,Enhancing Foundation Models with Federated Domain Knowledge Infusion,https://ICML.cc//virtual/2025/poster/46374,"Jiaqi Wang, Jingtao Li, Weiming Zhuang, Chen Chen, Lingjuan Lyu, Fenglong Ma","Vision foundation models (FMs) like CLIP have exhibited exceptional capabilities in visual and linguistic understanding, particularly in zero-shot inference tasks. However, these models struggle with data that significantly deviates from their training samples, necessitating fine-tuning, which is often infeasible in centralized settings due to data privacy concerns. Federated learning (FL) combined with parameter-efficient fine-tuning (PEFT) offers a potential solution, yet existing methods face issues with domain-specific characteristics and out-of-domain generalization. We propose a cross-silo Federated Adapter Generalization (FedAG), a novel federated fine-tuning approach that leverages multiple fine-grained adapters to capture domain-specific knowledge while enhancing out-of-domain generalization. Our method uses quality-aware in-domain mutual learning and attention-regularized cross-domain learning to integrate domain-specific insights effectively. Experiments of the CLIP model on three domain-shifting datasets, ImageCLEF-DA, Office-Home, and DomainNet, demonstrate the superior performance of FedAG in both in-domain and out-of-domain scenarios. We envision this work as a milestone for generalizing CLIP to handle the challenge of out-of-domain knowledge under federated learning setting.","(1) AI models like CLIP are great at understanding images and text but struggle when faced with unfamiliar data, especially in sensitive areas like healthcare or finance where data can’t be shared. (2) To solve this, we created a method called FedAG that allows multiple institutions to collaboratively fine-tune such models without sharing private data. It uses small, smart components called adapters to learn from each institution’s unique data, while also learning how to generalize across different data sources. (3) This approach helps the model perform well not just within known settings, but also in new, unseen scenarios—paving the way for more trustworthy and versatile AI that respects data privacy."
Poster,Enhancing Graph Contrastive Learning for Protein Graphs from Perspective of Invariance,https://ICML.cc//virtual/2025/poster/44491,"YUSONG WANG, Shiyin Tan, Jialun Shen, Yicheng Xu, Haobo Song, Qi Xu, Prayag Tiwari, Mingkun Xu","Graph Contrastive Learning (GCL) improves Graph Neural Network (GNN)-based protein representation learning by enhancing its generalization and robustness. Existing GCL approaches for protein representation learning rely on 2D topology, where graph augmentation is solely based on topological features, ignoring the intrinsic biological properties of proteins. Besides, 3D structure-based protein graph augmentation remains unexplored, despite proteins inherently exhibiting 3D structures. To bridge this gap, we propose novel biology-aware graph augmentation strategies from the perspective of invariance and integrate them into the protein GCL framework. Specifically, we introduce Functional Community Invariance (FCI)-based graph augmentation, which employs spectral constraints to preserve topology-driven community structures while incorporating residue-level chemical similarity as edge weights to guide edge sampling and maintain functional communities. Furthermore, we propose 3D Protein Structure Invariance (3-PSI)-based graph augmentation, leveraging dihedral angle perturbations and secondary structure rotations to retain critical 3D structural information of proteins while diversifying graph views.Extensive experiments on four different protein-related tasks demonstrate the superiority of our proposed GCL protein representation learning framework.","Proteins are essential building blocks of life, and understanding their structure and function is crucial for many scientific advancements, like developing new medicines. Computers can help us study proteins by learning to ""recognize"" and ""understand"" them. Our research introduces new and improved ways for computers to learn about proteins. Currently, many computer methods learn about proteins by looking at simplified, 2D maps of their connections. This often misses important details about what proteins actually do and their complex 3D shapes. We've developed new techniques that teach computers by showing them slightly different versions of the same protein, helping them focus on the most important features. One technique considers the biological roles of different parts of a protein, ensuring that these functional groups are preserved even as the computer sees slightly altered views. Another technique focuses on the protein's 3D shape, making small adjustments to its structure (like wiggling or rotating parts) while keeping its overall form intact. By learning from these more biologically and structurally realistic variations, computers can build a much better understanding of proteins. Our tests show that these new methods significantly improve the computer's ability to perform various tasks related to proteins, paving the way for faster and more accurate discoveries in biology and medicine."
Poster,Enhancing Graph Invariant Learning from a Negative Inference Perspective,https://ICML.cc//virtual/2025/poster/46664,"Kuo Yang, Zhengyang Zhou, Qihe Huang, Wenjie Du, Limin Li, Wu Jiang, Yang Wang","The out-of-distribution (OOD) generalization challenge is a longstanding problem  in graph learning. Through studying the fundamental cause of data distribution shift, i.e., the changes of environments, significant progress has been achieved in addressing this issue. However, we observe that existing works still fail to effectively address complex environment shifts. Existing practices place excessive attention on extracting causal subgraphs, inevitably treating spurious subgraphs as environment variables. While spurious subgraphs are controlled by environments, the space of environment changes encompass more than the scale of spurious subgraphs. Therefore, existing efforts have a limited inference space for environments,  leading to failure under severe environment changes. To tackle this issue, we propose a negative inference graph OOD framework (NeGo)  to broaden the inference space for environment factors. Inspired by the successful practice of prompt learning in capturing underlying semantics and causal associations in large language models, we design a negative prompt environment inference to extract underlying environment information. We further introduce the environment-enhanced invariant subgraph learning to effectively exploit inferred environment embedding, ensuring the robust extraction of causal subgraph in the environment shifts. Lastly, we conduct a comprehensive evaluation of NeGo on real-world datasets and synthetic datasets across domains. NeGo outperforms baselines on nearly all datasets, which verify the effectiveness of our framework.","Whether artificial intelligence models can remain effective in constantly changing scenarios is a widely recognized challenge. Our research focuses on graph-structured data, such as molecular graphs and social networks. We believe that for models to handle different scenarios, they should not only learn how to produce correct answers but also learn to recognize which answers are wrong. Therefore, we introduce the concept of negative learning. Moreover, what exactly these scenarios entail is still unknown. To address this, we design a mechanism to automatically understand and capture such scenarios. Finally, we conduct experiments on datasets from various scenarios and find that our method achieves the best performance."
Poster,Enhancing Ligand Validity and Affinity in Structure-Based Drug Design with Multi-Reward Optimization,https://ICML.cc//virtual/2025/poster/44456,"Seungbeom Lee, Munsun Jo, Jungseul Ok, Dongwoo Kim","Deep learning-based Structure-based drug design aims to generate ligand molecules with desirable properties for protein targets. While existing models have demonstrated competitive performance in generating ligand molecules, they primarily focus on learning the chemical distribution of training datasets, often lacking effective steerability to ensure the desired chemical quality of generated molecules. To address this issue, we propose a multi-reward optimization framework that fine-tunes generative models for attributes, such as binding affinity, validity, and drug-likeness, together. Specifically, we derive direct preference optimization for a Bayesian flow network, used as a backbone for molecule generation, and integrate a reward normalization scheme to adopt multiple objectives. Experimental results show that our method generates more realistic ligands than baseline models while achieving higher binding affinity, expanding the Pareto front empirically observed in previous studies.","Designing new drugs often involves finding molecules that can effectively bind to disease-related proteins. While AI models have made progress in generating such molecules, they typically focus on the chemical distribution of training datasets and lack effective steerability to ensure the desired chemical properties of generated molecules. We propose a new method that allows users to steer the AI toward generating molecules with specific desirable features—such as strong binding affinity and drug-like properties—simultaneously. Our approach fine-tunes the model with multiple objectives, enabling the generation of more realistic and effective drug candidates. Experimental results demonstrate that our approach outperforms baseline models, offering a more practical solution for drug discovery tasks."
Poster,Enhancing Logits Distillation with Plug&Play Kendall's  $\tau$ Ranking Loss,https://ICML.cc//virtual/2025/poster/44135,"Yuchen Guan, Runxi Cheng, Kang Liu, Chun Yuan","Knowledge distillation typically minimizes the Kullback–Leibler (KL) divergence between teacher and student logits. However, optimizing the KL divergence can be challenging for the student and often leads to sub-optimal solutions. We further show that gradients induced by KL divergence scale with the magnitude of the teacher logits, thereby diminishing updates on low-probability channels. This imbalance weakens the transfer of inter-class information and in turn limits the performance improvements achievable by the student. To mitigate this issue, we propose a plug-and-play auxiliary ranking loss based on Kendall’s $\tau$ coefficient that can be seamlessly integrated into any logit-based distillation framework. It supplies inter-class relational information while rebalancing gradients toward low-probability channels. We demonstrate that the proposed ranking loss is largely invariant to channel scaling and optimizes an objective aligned with that of KL divergence, making it a natural complement rather than a replacement. Extensive experiments on CIFAR-100, ImageNet, and COCO datasets, as well as various CNN and ViT teacher-student architecture combinations, demonstrate that our plug-and-play ranking loss consistently boosts the performance of multiple distillation baselines.","Knowledge distillation transfers capabilities from a powerful teacher model to a lightweight student model. However, existing distillation losses overlook low-probability channels and suffer from suboptimal optimization, limiting the transfer of inter-class relational knowledge and hindering performance gains. To mitigate this issue, we propose a plug-and-play auxiliary ranking loss based on Kendall’s $\tau$ coefficient. It supplies low-probability channel information and aligns optimization objectives, seamlessly integrating with most distillation frameworks. Extensive experiments across multiple datasets and various teacher-student architecture combinations demonstrate that our plug-and-play ranking loss consistently boosts the performance of multiple distillation baselines."
Poster,Enhancing Parallelism in Decentralized Stochastic Convex Optimization,https://ICML.cc//virtual/2025/poster/43463,"Ofri Eisen, Ron Dorfman, Kfir Levy","Decentralized learning has emerged as a powerful approach for handling large datasets across multiple machines in a communication-efficient manner. However, such methods often face scalability limitations, as increasing the number of machines beyond a certain point negatively impacts convergence rates. In this work, we propose *Decentralized Anytime SGD*, a novel decentralized learning algorithm that significantly extends the critical parallelism threshold, enabling the effective use of more machines without compromising performance. Within the stochastic convex optimization (SCO) framework, we establish a theoretical upper bound on parallelism that surpasses the current state-of-the-art, allowing larger networks to achieve favorable statistical guarantees and closing the gap with centralized learning in highly connected topologies.","When training machine learning models on large datasets, we often need to split the work across multiple computers to make the process faster and more manageable. However, there is a frustrating catch: adding more machines beyond a certain point actually makes the learning process less efficient.We developed a new training algorithm called Decentralized Anytime SGD that increases the number of machines you can use before hitting this performance wall. Our approach allows larger networks of computers to work together more efficiently by improving how they share information and coordinate their learning progress.Through mathematical analysis, we proved that our method can handle significantly larger networks of machines while still maintaining good learning performance. This improvement brings decentralized learning much closer to the performance you would get from a single, centralized system, but with all the practical benefits of distributed computing. Our work allows organizations to use more machines effectively for training AI models, improving the scalability of distributed machine learning."
Poster,Enhancing Performance of Explainable AI Models with Constrained Concept Refinement,https://ICML.cc//virtual/2025/poster/45067,"Geyu Liang, Senne Michielssen, Salar Fattahi","The trade-off between accuracy and interpretability has long been a challenge in machine learning (ML). This tension is particularly significant for emerging *interpretable-by-design* methods, which aim to redesign ML algorithms for trustworthy interpretability but often sacrifice accuracy in the process. In this paper, we address this gap by investigating the impact of deviations in concept representations—an essential component of interpretable models—on prediction performance and propose a novel framework to mitigate these effects. The framework builds on the principle of optimizing concept embeddings under constraints that preserve interpretability. Using a generative model as a test-bed, we rigorously prove that our algorithm achieves zero loss while progressively enhancing the interpretability of the resulting model. Additionally, we evaluate the practical performance of our proposed framework in generating explainable predictions for image classification tasks across various benchmarks. Compared to existing explainable methods, our approach not only improves prediction accuracy while preserving model interpretability across various large-scale benchmarks but also achieves this with significantly lower computational cost.","In recent years, artificial intelligence (AI) systems—especially deep learning models—have achieved remarkable success in tasks like image recognition. However, these models often operate as ""black boxes,"" making it difficult for users to understand why a model makes a certain decision. This lack of transparency raises concerns in high-stakes applications such as healthcare, finance, and criminal justice.Our paper introduces a new method called Constrained Concept Refinement (CCR) to help make AI decisions more interpretable and trustworthy. The key idea is to guide the model’s internal reasoning using human-understandable concepts (such as “has wings” or “is furry”) while enforcing constraints that make these explanations consistent, sparse, and grounded in real data. Unlike many previous methods, CCR is both easy to implement and computationally efficient. It also allows users to fine-tune explanations by adjusting a few intuitive parameters, without requiring deep changes to the underlying model.Through experiments on image classification tasks, we show that CCR produces clearer and more faithful concept-based explanations compared to existing approaches. Our method provides a practical step toward building AI systems that are not only powerful but also more understandable and trustworthy to human users."
Poster,Enhancing Rating-Based Reinforcement Learning to Effectively Leverage Feedback from Large Vision-Language Models,https://ICML.cc//virtual/2025/poster/44273,"Minh-Tung Luu, Younghwan Lee, Donghoon Lee, Sunho Kim, MinJun Kim, Chang Yoo","Designing effective reward functions remains a fundamental challenge in reinforcement learning (RL), as it often requires extensive human effort and domain expertise. While RL from human feedback has been successful in aligning agents with human intent, acquiring high-quality feedback is costly and labor-intensive, limiting its scalability. Recent advancements in foundation models present a promising alternative--leveraging AI-generated feedback to reduce reliance on human supervision in reward learning. Building on this paradigm, we introduce ERL-VLM, an enhanced rating-based RL method that effectively learns reward functions from AI feedback. Unlike prior methods that rely on pairwise comparisons, ERL-VLM queries large vision-language models (VLMs) for absolute ratings of individual trajectories, enabling more expressive feedback and improved sample efficiency. Additionally, we propose key enhancements to rating-based RL, addressing instability issues caused by data imbalance and noisy labels. Through extensive experiments across both low-level and high-level control tasks, we demonstrate that ERL-VLM significantly outperforms existing VLM-based reward generation methods. Our results demonstrate the potential of AI feedback for scaling RL with minimal human intervention, paving the way for more autonomous and efficient reward learning.","Teaching robots to perform tasks using reinforcement learning often requires carefully designing a reward function. This function tells the robot what is good or bad behavior. Creating such a function usually takes a lot of time and human effort, making it a major challenge in real-world applications. Instead of designing rewards manually, researchers have developed methods that learn them directly from human feedback. However, collecting enough high-quality feedback still involves significant human effort, which can be costly and difficult to scale. Our work introduces a way to automate this process using AI tools like ChatGPT or Gemini. These tools evaluate the robot’s behavior and provide scores, similar to how a teacher grades a student. The robot learns from these scores and improves over time. All that a human needs to provide is a simple description of the task in plain language, making it easier for anyone to help train intelligent systems without technical expertise.This framework offers a scalable and practical solution for generating large amounts of feedback to teach robots. It significantly reduces human effort in both designing reward functions and providing detailed feedback, enabling more efficient and accessible reinforcement learning in real-world scenarios."
Poster,Enhancing Spectral GNNs: From Topology and Perturbation Perspectives,https://ICML.cc//virtual/2025/poster/45423,"Taoyang Qin, Ke-Jia CHEN, Zheng Liu","Spectral Graph Neural Networks process graph signals using the spectral properties of the normalized graph Laplacian matrix. However, the frequent occurrence of repeated eigenvalues limits the expressiveness of spectral GNNs. To address this, we propose a higher-dimensional sheaf Laplacian matrix, which not only encodes the graph's topological information but also increases the upper bound on the number of distinct eigenvalues. The sheaf Laplacian matrix is derived from carefully designed perturbations of the block form of the normalized graph Laplacian, yielding a perturbed sheaf Laplacian (PSL) matrix with more distinct eigenvalues. We provide a theoretical analysis of the expressiveness of spectral GNNs equipped with the PSL and establish perturbation bounds for the eigenvalues. Extensive experiments on benchmark datasets for node classification demonstrate that incorporating the perturbed sheaf Laplacian enhances the performance of spectral GNNs.","Many graph neural networks (GNNs) process graph-structured data (or signals) by leveraging the spectral properties of a special matrix or operator known as the graph Laplacian. When the normalized graph Laplacian has repeated eigenvalues, a GNN’s ability to process data in the spectral domain is weakened, limiting the model’s expressiveness. Drawing on cellular sheaf theory, we use the sheaf Laplacian—associating each edge with a small vector space—and apply carefully designed perturbations to its block structure to construct a higher-dimensional perturbed sheaf Laplacian (PSL) with a richer spectrum of eigenvalues.Our theoretical analysis and empirical experiments both demonstrate the effectiveness of PSL-based spectral GNNs."
