type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Divide and Conquer: Grounding LLMs as Efficient Decision-Making Agents via Offline Hierarchical Reinforcement Learning,https://ICML.cc//virtual/2025/poster/43989,"Zican Hu, Wei Liu, Xiaoye Qu, Xiangyu Yue, Chunlin Chen, Zhi Wang, Yu Cheng","While showing sophisticated reasoning abilities, large language models (LLMs) still struggle with long-horizon decision-making tasks due to deficient exploration and long-term credit assignment, especially in sparse-reward scenarios. Inspired by the divide-and-conquer principle, we propose an innovative framework **GLIDER** (**G**rounding **L**anguage Models as Eff**I**cient **D**ecision-Making Agents via Offline Hi**E**rarchical **R**einforcement Learning) that introduces a parameter-efficient and generally applicable hierarchy to LLM policies. We develop a scheme where the low-level controller is supervised with abstract, step-by-step plans that are learned and instructed by the high-level policy. This design decomposes complicated problems into a series of coherent chain-of-thought reasoning sub-tasks, providing flexible temporal abstraction to significantly enhance exploration and learning for long-horizon tasks. Furthermore, GLIDER facilitates fast online adaptation to non-stationary environments owing to the strong transferability of its task-agnostic low-level skills. Experiments on ScienceWorld and ALFWorld benchmarks show that GLIDER achieves consistent performance gains, along with enhanced generalization capabilities.","Large language models (LLMs) have difficulty handling complex decision-making tasks, especially when feedback is limited. They often get lost in long-term planning and struggle to explore effectively, like a chess player who can't think multiple moves ahead.We developed GLIDER, a framework that breaks down complex tasks into smaller, manageable steps. Like a skilled manager delegating tasks, GLIDER uses a two-level system where high-level planning guides step-by-step execution.This approach helps LLMs tackle challenging tasks more efficiently and adapt to new situations better, showing significant improvements in virtual environments that test reasoning and problem-solving abilities."
Poster,Divide and Conquer: Learning Label Distribution with Subtasks,https://ICML.cc//virtual/2025/poster/44379,"Haitao Wu, Weiwei Li, Xiuyi Jia","Label distribution learning (LDL) is a novel learning paradigm that emulates label polysemy by assigning label distributions over the label space. However, recent LDL work seems to exhibit a notable contradiction: 1) existing LDL methods employ auxiliary tasks to enhance performance, which narrows their focus to specific applications, thereby lacking generalizability; 2) conversely, LDL methods without auxiliary tasks rely on losses tailored solely to the primary task, lacking beneficial data to guide the learning process. In this paper, we propose S-LDL, a novel and minimalist solution that generates subtask label distributions, i.e., a form of extra supervised information,to reconcile the above contradiction. S-LDL encompasses two key aspects: 1) an algorithm capable of generating subtasks withoutany prior/expert knowledge; and 2) a plug-andplay framework seamlessly compatible with existing LDL methods, and even adaptable to derivative tasks of LDL. Our analysis and experiments demonstrate that S-LDL is effective and efficient. To the best of our knowledge, this paper represents the first endeavor to address LDL via subtasks.","Teaching ML models to handle ambiguous labels, where an input might belong to multiple categories in different proportions, is challenging. Current approaches either: 1) rely on extra, task-specific knowledge that limits their broader use, or 2) use simple methods that miss valuable learning signals.We introduce $\mathcal{S}$-LDL, a flexible solution that automatically creates ""helper tasks"" (like breaking down into simpler sub-problems) to guide the learning with no expert input needed. Imagine teaching someone to identify all ingredients in a smoothie by first practicing with different fruit pairs (strawberry-banana, then mango-pineapple-strawberry), before tackling the full blend.$\mathcal{S}$-LDL works seamlessly with existing methods and even adapts to more related tasks. Experiments show it’s both effective and efficient. This is the first work to tackle such problems using generated subtasks."
Poster,Diving into Self-Evolving Training for Multimodal Reasoning,https://ICML.cc//virtual/2025/poster/44984,"Wei Liu, Junlong Li, Xiwen Zhang, Fan Zhou, Yu Cheng, Junxian He","Self-evolving training—where models iteratively learn from their own outputs—has emerged as a key approach for complex reasoning tasks, addressing the scarcity of high-quality chain-of-thought data. However, its effectiveness in multimodal reasoning, a domain more intricate than text-only reasoning, remains underexplored, and the understanding of critical factors in this training paradigm remains limited. Furthermore, a central challenge for this training method is performance saturation, which impedes further improvements and scalability. Inspired by reinforcement learning (RL), in this paper, we reframe self-evolving training for multimodal reasoning through the lens of RL, identifying three pivotal factors: $\textit{Training Method}$, $\textit{Reward Model}$, and $\textit{Prompt Variation}$. Through systematic analysis, we establish relatively optimal design principles that significantly enhance multimodal reasoning capabilities. Moreover, delving deeper into training dynamics, we uncover the roots of saturation and propose a new automatic balancing mechanism to mitigate this limitation. Building on these insights, we propose M-STaR (**M**ultimodal **S**elf-evolving **T**r**a**ining for **R**easoning), a framework that achieves consistent performance gains across models of varying sizes and diverse benchmarks. All resources will be made publicly available.","When training AI to solve complex problems, one promising method is having models learn from their own previous answers, refining their reasoning over time without constant human guidance. However, this self-teaching approach, though successful in language tasks, hasn't been widely explored for tasks that involve multiple types of data, such as images combined with text (multimodal reasoning). In this work, we investigate how to effectively apply this method to multimodal tasks, highlighting crucial factors such as how the model learns, how it evaluates its success, and how variations in instructions affect learning. Additionally, we identify why these methods sometimes hit performance ceilings, preventing further improvement. To overcome this, we introduce a new, automated way of balancing the learning process. Our proposed approach, called M-STaR, consistently improves multimodal reasoning performance across various tasks and model sizes. All our methods and tools will be publicly shared for wider use."
Poster,DLP: Dynamic Layerwise Pruning in Large Language Models,https://ICML.cc//virtual/2025/poster/46657,"Yuli Chen, Bo Cheng, Jiale Han, Yingying Zhang, Yingting Li, Shuhao Zhang","Pruning has recently been widely adopted to reduce the parameter scale and improve the inference efficiency of Large Language Models (LLMs). Mainstream pruning techniques often rely on uniform layerwise pruning strategies, which can lead to severe performance degradation at high sparsity levels. Recognizing the varying contributions of different layers in LLMs, recent studies have shifted their focus toward non-uniform layerwise pruning. However, these approaches often rely on pre-defined values, which can result in suboptimal performance. To overcome these limitations, we propose a novel method called Dynamic Layerwise Pruning (DLP). This approach adaptively determines the relative importance of each layer by integrating model weights with input activation information, assigning pruning rates accordingly. Experimental results show that DLP effectively preserves model performance at high sparsity levels across multiple LLMs. Specifically, at   70% sparsity, DLP reduces the perplexity of LLaMA2-7B by 7.79 and improves the average accuracy by 2.7% compared to state-of-the-art methods. Moreover, DLP is compatible with various existing LLM compression techniques and can be seamlessly integrated into Parameter-Efficient Fine-Tuning (PEFT). We release the code\footnote{The code is available at: \url{https://github.com/ironartisan/DLP}.} to facilitate future research.","Although large language models are powerful, they run slowly and incur high costs. Traditional pruning methods remove the same proportion of parameters in each layer, and when most weights are removed, they impair accuracy. We wonder whether we can do better by pruning more from less important layers and preserving more important layers without manually tuning thresholds. Our Dynamic Layerwise Pruning (DLP) method retains critical features and applies lower sparsity rates to important layers and higher sparsity rates to less important layers. Notably, at high sparsity levels, our method outperforms previous approaches and seamlessly integrates with other compression and fine‑tuning techniques. Our work facilitates the deployment of LLMs on resource‑constrained devices and contributes to the sustainability of LLM technology."
Poster,DMM: Distributed Matrix Mechanism for Differentially-Private Federated Learning Based on Constant-Overhead Linear Secret Resharing,https://ICML.cc//virtual/2025/poster/45476,"Alexander Bienstock, Ujjwal Kumar, Antigoni Polychroniadou","Federated Learning (FL) solutions with central Differential Privacy (DP) have seen large improvements in their utility in recent years arising from the matrix mechanism, while FL solutions with distributed (more private) DP have lagged behind. In this work, we introduce the distributed matrix mechanism to achieve the best-of-both-worlds; better privacy of distributed DP and better utility from the matrix mechanism. We accomplish this using a novel cryptographic protocol that securely transfers sensitive values across client committeesof different training iterations with constant communication overhead. This protocol accommodates the dynamic participation of users required by FL, including those that may drop out from the computation. We provide experiments which show that our mechanism indeed significantly improves the utility of FL models compared to previous distributed DP mechanisms, with little added overhead.","In Federated Learning (FL), a machine learning model is trained using data from several end-users. Since such data can often be sensitive, a key challenge in FL is maintaining utility of the trained models, while preserving privacy of users. The main privacy metric for FL is differential privacy (DP). Roughly speaking, DP guarantees that with high probability, one cannot tell whether a user’s data was used for training a model. In $\textit{central}$ DP, privacy holds with respect to other users in the system, but not the central service provider training the model. In $\textit{distributed}$ DP, privacy holds with respect to the service provider as well.FL with central DP uses the $\textit{matrix mechanism}$ to achieve excellent privacy-utility trade-offs. Previously, this mechanism could not be applied to distributed DP and, so, the utility of distributed DP paled in comparison to that of central DP.In this work, we propose a solution to achieve the ""best-of-both-worlds"" of the central and distributed DP settings, called the $\textit{Distributed Matrix Mechanism}$ (DMM).We achieve privacy against the service provider, i.e., distributed DP, while using the matrix mechanism to obtain the same utility as the central DP setting."
Poster,DMOSpeech: Direct Metric Optimization via Distilled Diffusion Model in Zero-Shot Speech Synthesis,https://ICML.cc//virtual/2025/poster/44048,"Yinghao Li, Rithesh Kumar, Zeyu Jin","Diffusion models have demonstrated significant potential in speech synthesis tasks, including text-to-speech (TTS) and voice cloning. However, their iterative denoising processes are computationally intensive, and previous distillation attempts have shown consistent quality degradation. Moreover, existing TTS approaches are limited by non-differentiable components or iterative sampling that prevent true end-to-end optimization with perceptual metrics. We introduce DMOSpeech, a distilled diffusion-based TTS model that uniquely achieves both faster inference and superior performance compared to its teacher model. By enabling direct gradient pathways to all model components, we demonstrate the first successful end-to-end optimization of differentiable metrics in TTS, incorporating Connectionist Temporal Classification (CTC) loss and Speaker Verification (SV) loss. Our comprehensive experiments, validated through extensive human evaluation, show significant improvements in naturalness, intelligibility, and speaker similarity while reducing inference time by orders of magnitude. This work establishes a new framework for aligning speech synthesis with human auditory preferences through direct metric optimization. The audio samples are available at https://dmospeech.github.io/demo","Our research addresses key limitations in advanced artificial speech generation, particularly with systems based on 'diffusion models.' While these models excel at producing natural-sounding voices, they are often slow—requiring many steps to generate speech—and difficult to precisely control for specific qualities like clarity or speaker resemblance. This means current methods struggle to efficiently create voices that are both high-fidelity and truly match a target speaker.DMOSpeech introduces a novel approach to overcome these challenges. We developed a technique called 'distillation' to train a much smaller, faster model from a large, complex diffusion model, drastically reducing the time it takes to generate speech. Crucially, instead of simply imitating the larger model, our method directly optimizes for measurable improvements in speech quality. We guide the model to enhance aspects like how understandable the words are and how closely the voice sounds like a specific person.The impact of DMOSpeech is significant: it allows for the rapid creation of artificial voices that are not only incredibly clear but also achieve unprecedented accuracy in matching a target speaker. Our system produces voices that, in many cases, are perceived as more similar to the original speaker than the original recordings themselves. This breakthrough paves the way for more efficient and customizable voice synthesis applications, from more natural-sounding virtual assistants to personalized audio content."
Poster,Do Bayesian Neural Networks Actually Behave Like Bayesian Models?,https://ICML.cc//virtual/2025/poster/43593,"Gábor Pituk, Vik Shirvaikar, Tom Rainforth","We empirically investigate how well popular approximate inference algorithms for Bayesian Neural Networks (BNNs) respect the theoretical properties of Bayesian belief updating. We find strong evidence on synthetic regression and real-world image classification tasks that common BNN algorithms such as variational inference, Laplace approximation, SWAG, and SGLD fail to update in a consistent manner, forget about old data under sequential updates, and violate the predictive coherence properties that would be expected of Bayesian methods. These observed behaviors imply that care should be taken when treating BNNs as true Bayesian models, particularly when using them beyond static prediction settings, such as for active, continual, or transfer learning.","Bayesian Neural Networks (BNNs) are used to help machine learning models express uncertainty. This is useful in tasks like decision making, where knowing what the model is unsure about can matter as much as the prediction itself.We test whether BNNs behave in ways that are intuitively important: remembering past data, updating sensibly when new data arrives, and not changing predictions without new information. Across a range of experiments, we find that widely used BNN methods often violate these basic expectations. They can forget earlier data, produce inconsistent updates, and behave as if they've seen new data when they haven't.These behaviors raise concerns about using BNNs in real-world situations where learning over time or from limited data is critical. While BNNs can perform well in static tasks, our findings suggest the need for caution, and for further research into improving how these models handle uncertainty and learning."
Poster,DocKS-RAG: Optimizing Document-Level Relation Extraction through LLM-Enhanced Hybrid Prompt Tuning,https://ICML.cc//virtual/2025/poster/45220,"Xiaolong Xu, Yibo Zhou, Haolong Xiang, Xiaoyong Li, Xuyun Zhang, Lianyong Qi, Wanchun Dou","Document-level relation extraction (RE) aims to extract comprehensive correlations between entities and relations from documents. Most of existing works conduct transfer learning on pre-trained language models (PLMs), which allows for richer contextual representation to improve the performance. However, such PLMs-based methods suffer from incorporating structural knowledge, such as entity-entity interactions. Moreover, current works struggle to infer the implicit relations between entities across different sentences, which results in poor prediction. To deal with the above issues, we  propose a novel and effective framework, named DocKS-RAG, which introduces extra structural knowledge and semantic information to further enhance the performance of document-level RE. Specifically, we construct a Document-level Knowledge Graph from the observable documentation data to better capture the structural information between entities and relations. Then, a Sentence-level Semantic Retrieval-Augmented Generation mechanism is designed to consider the similarity in different sentences by retrieving the relevant contextual semantic information. Furthermore, we present a hybrid-prompt tuning method on large language models (LLMs) for specific document-level RE tasks. Finally, extensive experiments conducted on two benchmark datasets demonstrate that our proposed framework enhances all the metrics compared with state-of-the-art methods.","Our work proposes DocKS-RAG, a framework for document-level relation extraction that enhances structural and semantic understanding by integrating a Document-level Knowledge Graph and a Sentence-level Semantic Retrieval-Augmented Generation mechanism. Additionally, we design a hybrid-prompt tuning method on large language models. Experiments on benchmark datasets show significant improvements over existing methods."
Poster,DocVXQA: Context-Aware Visual Explanations for Document Question Answering,https://ICML.cc//virtual/2025/poster/43613,"Mohamed Ali Souibgui, Changkyu Choi, Andrey Barsky, Kangsoo Jung, Ernest Valveny, Dimosthenis Karatzas","We propose **DocVXQA**, a novel framework for visually self-explainable document question answering, where the goal is not only to produce accurate answers to questions but also to learn visual heatmaps that highlight critical regions, offering interpretable justifications for the model decision. To integrate explanations into the learning process, we quantitatively formulate explainability principles as explicit learning criteria.Unlike conventional relevance map methods that solely emphasize regions relevant to the answer, our context-aware DocVXQA delivers explanations that are contextually sufficient yet representation-efficient. This fosters user trust while achieving a balance between predictive performance and interpretability in document visual question answering applications. Extensive experiments, including human evaluation, provide strong evidence supporting the effectiveness of our method.","When people use document visual question answering (DocVQA) systems to ask questions about their documents — like forms, invoices, or reports — the AI often returns answers without any explanation. This lack of transparency makes it hard to trust the results, especially in sensitive scenarios like business or legal documents, where understanding *why* an answer was given is crucial.We created **DocVXQA**, an AI system that doesn’t just answer questions about documents, but also shows why it gave that answer.  It highlights the most important parts of the document, known as *relevant regions*. Thus,  users can understand the reasoning behind the answers.What makes our approach stand is that we trained the AI to value explanations as part of its learning process. Instead of just focusing on the answer, it learns to find the smallest and most meaningful parts of the document that justify the response. We tested our system thoroughly, including with real people, and found that it not only performs well but is also easier to trust and understand."
Poster,Does Data Scaling Lead to Visual Compositional Generalization?,https://ICML.cc//virtual/2025/poster/45559,"Arnas Uselis, Andrea Dittadi, Seong Joon Oh","Compositional understanding is crucial for human intelligence, yet it remains unclear whether contemporary vision models exhibit it. The dominant machine learning paradigm is built on the premise that scaling data and model sizes will improve out-of-distribution performance, including compositional generalization. We test this premise through controlled experiments that systematically vary data scale, concept diversity, and combination coverage. We find that compositional generalization is driven by data diversity, not mere data scale. Increased combinatorial coverage forces models to discover a linearly factored representational structure, where concepts decompose into additive components. We prove this structure is key to efficiency, enabling perfect generalization from few observed combinations. Evaluating pretrained models (DINO, CLIP), we find above-random yet imperfect performance, suggesting partial presence of this structure. Our work motivates stronger emphasis on constructing diverse datasets for compositional generalization, and considering the importance of representational structure that enables efficient compositional learning.","Humans easily recognize new combinations of known concepts, like identifying a “green triangle” after seeing only “green squares” and “blue triangles.” We study whether simply increasing the amount of visual data helps AI achieve similar compositional generalization. Our results show that data quantity alone isn’t enough - data diversity is crucial. Only diverse training examples encourage models to form structured internal representations, enabling effective learning of new concept combinations. However, existing pretrained vision models still struggle with compositional generalization, highlighting the importance of structured representations"
