type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,CurvGAD: Leveraging Curvature for Enhanced Graph Anomaly Detection,https://ICML.cc//virtual/2025/poster/45460,"Karish Grover, Geoff Gordon, Christos Faloutsos","Does the intrinsic curvature of complex networks hold the key to unveiling graph anomalies that conventional approaches overlook? Reconstruction-based graph anomaly detection (GAD) methods overlook such geometric outliers, focusing only on structural and attribute-level anomalies. To this end, we propose CurvGAD - a mixed-curvature graph autoencoder that introduces the notion of curvature-based geometric anomalies. CurvGAD introduces two parallel pipelines for enhanced anomaly interpretability: (1) Curvature-equivariant geometry reconstruction, which focuses exclusively on reconstructing the edge curvatures using a mixed-curvature, Riemannian encoder and Gaussian kernel-based decoder; and (2) Curvature-invariant structure and attribute reconstruction, which decouples structural and attribute anomalies from geometric irregularities by regularizing graph curvature under discrete Ollivier-Ricci flow, thereby isolating the non-geometric anomalies. By leveraging curvature, CurvGAD refines the existing anomaly classifications and identifies new curvature-driven anomalies. Extensive experimentation over 10 real-world datasets (both homophilic and heterophilic) demonstrates an improvement of up to 6.5% over state-of-the-art GAD methods. The code is available at: https://github.com/karish-grover/curvgad.","In today's interconnected world, networks—be it social media platforms, financial systems, or biological interactions—play a pivotal role. Identifying anomalies within these networks is crucial, as they can signify fraudulent activities, misinformation spread, or critical system failures. Traditional detection methods primarily focus on direct connections and node attributes, often overlooking the underlying geometric structure of the network.Our research introduces CurvGAD, a novel approach that incorporates the concept of curvature from geometry to enhance anomaly detection in graphs. Curvature provides insights into the ""shape"" or ""bending"" of the network, revealing areas where the structure deviates from the norm.CurvGAD operates through two complementary mechanisms: (a) Curvature-Aware Analysis: This component examines the geometric properties of the network, identifying anomalies based on unusual curvature patterns. (b) Structure and Attribute Examination: This part focuses on the traditional aspects—connections and node attributes—ensuring that anomalies not related to geometry are also detected.By combining these perspectives, CurvGAD not only uncovers anomalies missed by conventional methods but also provides a more interpretable understanding of why certain nodes or connections are deemed anomalous. In evaluations across ten diverse real-world datasets, CurvGAD consistently outperformed existing techniques, highlighting the value of integrating geometric insights into network analysis."
Poster,Customizing the Inductive Biases of Softmax Attention using Structured Matrices,https://ICML.cc//virtual/2025/poster/45261,"Yilun Kuang, Noah Amsel, Sanae Lotfi, Shikai Qiu, Andres Potapczynski, Andrew Wilson","The core component of attention is the scoring function, which transforms the inputs into low-dimensional queries and keys and takes the dot product of each pair. While the low-dimensional projection improves efficiency, it causes information loss for certain tasks that have intrinsically high-dimensional inputs. Additionally, attention uses the same scoring function for all input pairs, without imposing a distance-dependent compute bias for neighboring tokens in the sequence. In this work, we address these shortcomings by proposing new scoring functions based on computationally efficient structured matrices with high ranks, including Block Tensor-Train (BTT) and Multi-Level Low Rank (MLR) matrices. On in-context regression tasks with high-dimensional inputs, our proposed scoring functions outperform standard attention for any fixed compute budget. On language modeling, a task that exhibits locality patterns, our MLR-based attention method achieves improved scaling laws compared to both standard attention and variants of sliding window attention.Additionally, we show that both BTT and MLR fall under a broader family of efficient structured matrices capable of encoding either full-rank or distance-dependent compute biases, thereby addressing significant shortcomings of standard attention.","Modern AI models rely heavily on a technique called attention, which helps them focus on the most relevant parts of the input. This paper points out that the current way attention works can be inefficient and sometimes not expressive enough to handle complex data. To improve this, we introduce smarter attention methods using mathematical tools called Block Tensor-Train (BTT) and Multi-Level Low Rank (MLR) matrices. We show that these new methods work better on tasks like predicting numbers from data (linear regression) and understanding language."
Poster,Cut out and Replay: A Simple yet Versatile Strategy for Multi-Label Online Continual Learning,https://ICML.cc//virtual/2025/poster/46225,"Xinrui Wang, Shao-Yuan Li, Jiaqiang Zhang, Songcan Chen","Multi-Label Online Continual Learning (MOCL) requires models to learn continuously from endless multi-label data streams, facing complex challenges including persistent catastrophic forgetting, potential missing labels, and uncontrollable imbalanced class distributions. While existing MOCL methods attempt to address these challenges through various techniques, \textit{they all overlook label-specific region identifying and feature learning} - a fundamental solution rooted in multi-label learning but challenging to achieve in the online setting with incremental and partial supervision. To this end, we first leverage the inherent structural information of input data to evaluate and verify the innate localization capability of different pre-trained models. Then, we propose CUTER (CUT-out-and-Experience-Replay), a simple yet versatile strategy that provides fine-grained supervision signals by further identifying, strengthening and cutting out label-specific regions for efficient experience replay. It not only enables models to simultaneously address catastrophic forgetting, missing labels, and class imbalance challenges, but also serves as an orthogonal solution that seamlessly integrates with existing approaches. Extensive experiments on multiple multi-label image benchmarks demonstrate the superiority of our proposed method. The code is available at \href{https://github.com/wxr99/Cut-Replay}{https://github.com/wxr99/Cut-Replay}","Multi-Label Online Continual Learning (MOCL) requires models to learn continuously from endless multi-label data streams. While existing methods have addressed this challenge through various techniques, they all overlook label-specific region identifying and feature learning - a fundamental solution rooted in multi-label learning but challenging to achieve in the online setting with incremental and partial supervision. To this end, we propose CUTER (CUT-out-and-Experience-Replay), a simple yet versatile strategy that provides fine-grained supervision signals by further identifying, strengthening and cutting out label-specific regions for efficient experience replay. It not only enables models to simultaneously address catastrophic forgetting, missing labels, and class imbalance challenges, but also serves as an orthogonal solution that seamlessly integrates with existing approaches. Extensive experiments on multiple multi-label image benchmarks demonstrate the superiority of our proposed method. The code is available at \href{https://github.com/wxr99/Cut-Replay}{https://github.com/wxr99/Cut-Replay}"
Poster,CVE-Bench: A Benchmark for AI Agents’ Ability to Exploit Real-World Web Application Vulnerabilities,https://ICML.cc//virtual/2025/poster/46522,"Yuxuan Zhu, Antony Kellermann, Dylan Bowman, Philip Li, Akul Gupta, Adarsh Danda, Richard Fang, Conner Jensen, Eric Ihli, Jason Benn, Jet Geronimo, Avi Dhir, Sudhit Rao, Kaicheng Yu, Twm Stone, Daniel Kang","Large language model (LLM) agents are increasingly capable of autonomously conducting cyberattacks, posing significant threats to existing applications. This growing risk highlights the urgent need for a real-world benchmark to evaluate the ability of LLM agents to exploit web application vulnerabilities. However, existing benchmarks fall short as they are limited to abstracted Capture-the-Flag competitions or lack comprehensive coverage. Building a benchmark for real-world vulnerabilities involves both specialized exper-tise to reproduce exploits and a systematic approach to evaluating unpredictable attacks. To address this challenge, we introduce CVE-Bench, a real-world cybersecurity benchmark based on critical-severity Common Vulnerabilities and Exposures. In CVE-Bench, we design a sandbox framework that enables LLM agents to exploit vulnerable web applications in scenarios that mimic real-world conditions, while also providing effective evaluation of their exploits. Our experiments show that the state-of-the-art agent framework can exploit up to 13% of the vulnerabilities.","Modern artificial intelligence systems (e.g., ChatGPT) are increasingly able to write code and even hack computer programs on their own. As a result, security researchers need a reliable way to see how dangerous these AI-powered hackers really are. Unfortunately, current benchmarks usually rely on toy games or cover only a limited number of cybersecurity vulnerabilities. They do not reflect the complexity and diversity of real-world web applications.We introduce CVE-Bench, a benchmark built from real-world web applications. Each application contains a critical-security vulnerability that actually happened. We developed a secure sandbox framework for these applications to simulate real-world scenarios and evaluate AI systems automatically.In our experiments, we find that state-of-the-art AI systems succeeded 13% of the time. This means current AI systems are capable of hacking some real vulnerabilities, but they still miss most of them. CVE-Bench now gives researchers a realistic, repeatable way to track that risk and to improve defenses before AI hackers grow more effective."
Poster,DA-KD: Difficulty-Aware Knowledge Distillation for Efficient Large Language Models,https://ICML.cc//virtual/2025/poster/45516,"Changyi He, Yifu Ding, Jinyang Guo, Ruihao Gong, Haotong Qin, Xianglong Liu","Although knowledge distillation (KD) is an effective approach to improve the performance of a smaller LLM (i.e., the student model) by transferring knowledge from a large LLM (i.e., the teacher model), it still suffers from high training cost. Existing LLM distillation methods ignore the difficulty difference among different samples, making the distillation of easy samples unnecessary. This leads to high distillation cost. In this paper, we propose difficulty-aware knowledge distillation (DA-KD) framework for efficient knowledge distillation, in which we dynamically adjust the distillation dataset based on the difficulty of samples. We further observe existing KD loss cannot perform well when most of samples are difficult in the distillation dataset because of unstable optimization and the neglect of hard samples. Therefore, we also propose a new KD loss called bidirectional discrepancy loss (BDL) for effective KD. Extensive experiments demonstrate that our DA-KD framework is effective and efficient. Without bells and whistles, DA-KD can outperform existing state-of-the-art KD methods by 2\% with half training cost and even surpass the teacher model with 4.7$\times$ compression.","Large language models are powerful but slow and expensive to train. One way to make them faster is to teach smaller models to copy the behavior of large ones—a process called distillation. But most methods waste time on examples that are already easy for the small model to learn.We propose a smarter method that focuses only on the hard examples the small model struggles with. It also uses a better way to guide the learning process, so the model trains more smoothly and effectively.Our approach builds smaller models that are just as good—or even better—than the large ones, while using much less time and computing power. This makes it easier to use advanced language models in everyday applications."
Poster,DAMA: Data- and Model-aware Alignment of Multi-modal LLMs,https://ICML.cc//virtual/2025/poster/43449,"Jinda Lu, Junkang Wu, Jinghan Li, Xiaojun Jia, Shuo Wang, Yi-Fan Zhang, Junfeng Fang, Xiang Wang, Xiangnan He","Direct Preference Optimization (DPO) has shown effectiveness in aligning multi-modal large language models (MLLM) with human preferences. However, existing methods exhibit an imbalanced responsiveness to the data of varying hardness, tending to overfit on the easy-to-distinguish data while underfitting on the hard-to-distinguish data. In this paper, we propose Data- and Model-aware DPO (DAMA) to dynamically adjust the optimization process from two key aspects: (1) a data-aware strategy that incorporates data hardness, and (2) a model-aware strategy that integrates real-time model responses. By combining the two strategies, DAMA enables the model to effectively adapt to data with varying levels of hardness.Extensive experiments on five benchmarks demonstrate that DAMA not only significantly enhances the trustworthiness, but also improves the effectiveness over general tasks. For instance, on the Object HalBench, our DAMA-7B reduces response-level and mentioned-level hallucination by 90.0% and 95.3%, respectively, surpassing the performance of GPT-4V.","Current DPO algorithms for multi-modal LLMs exhibit imbalanced responsiveness to data with various hardness. We propose a data- and model-aware strategy to tackle this, this will help the MLLMs effectively utilize the preference data."
Poster,DANCE: Dual Unbiased Expansion with Group-acquired Alignment for Out-of-distribution Graph Fairness Learning,https://ICML.cc//virtual/2025/poster/45227,"Yifan Wang, Hourun Li, Ling Yue, Zhiping Xiao, Jia Yang, Changling Zhou, Wei Ju, Ming Zhang, Xiao Luo","Graph neural networks (GNNs) have shown strong performance in graph fairness learning, which aims to ensure that predictions are unbiased with respect to sensitive attributes. However, existing approaches usually assume that training and test data share the same distribution, which rarely holds in the real world. To tackle this challenge, we propose a novel approach named Dual Unbiased Expansion with Group-acquired Alignment (DANCE) for graph fairness learning under distribution shifts. The core idea of our DANCE is to synthesize challenging yet unbiased virtual graph data in both graph and hidden spaces, simulating distribution shifts from a data-centric view. Specifically, we introduce the unbiased Mixup in the hidden space, prioritizing minor groups to address the potential imbalance of sensitive attributes. Simultaneously, we conduct fairness-aware adversarial learning in the graph space to focus on challenging samples and improve model robustness. To further bridge the domain gap, we propose a group-acquired alignment objective that prioritizes negative pair groups with identical sensitive labels. Additionally, a representation disentanglement objective is adopted to decorrelate sensitive attributes and target representations for enhanced fairness. Extensive experiments demonstrate the superior effectiveness of the proposed DANCE.","AI systems that learn from networked data, such as social networks or financial platforms, are increasingly used to make important decisions. However, these systems can sometimes treat people unfairly, especially when the distribution of test data differs from the training data in the real world. This often happens when data comes from different communities or changes over time. Our research introduces a new method called DANCE to help AI systems stay fair even when the distribution shifts. DANCE creates realistic training scenarios that simulate such changes, pushing the AI to learn fairer and more balanced patterns. It also teaches the system to focus on meaningful traits instead of sensitive ones like gender or race, and ensures that people from different groups are treated consistently. With DANCE, we take a step toward AI systems that are not only smarter but also fairer and more reliable in the real world."
Poster,DataDecide: How to Predict Best Pretraining Data with Small Experiments,https://ICML.cc//virtual/2025/poster/44022,"Ian Magnusson, Tai Nguyen, Ben Bogin, David Heineman, Jena Hwang, Luca Soldaini, Akshita Bhagia, Jiacheng Liu, Dirk Groeneveld, Oyvind Tafjord, Noah Smith, Pang Wei Koh, Jesse Dodge","Because large language models are expensive to pretrain on different datasets, using smaller-scale experiments to decide on data is crucial for reducing costs. Which benchmarks and methods of making decisions from observed performance at small scale most accurately predict the datasets that yield the best large models? To empower open exploration of this question, we release models, data, and evaluations in DataDecide—the most extensive open suite of models over differences in data and scale. We conduct controlled pretraining experiments across 25 corpora with differing sources, deduplication, and filtering up to 100B tokens, model sizes up to 1B parameters, and 3 random seeds. We find that the ranking of models at a single, small size (e.g., 150M parameters) is a strong baseline for predicting best models at our larger target scale (1B) (∼ 80% of comparisons correct). No scaling law methods among 8 baselines exceed the compute-decision frontier of single-scale predictions, but DataDecide can measure improvement in future scaling laws. We also identify that using continuous likelihood metrics as proxies in small experiments makes benchmarks including MMLU, ARC, HellaSwag, MBPP, and HumanEval > 80% predictable at the target 1B scale with just 0.01% of the compute.","Because large language models are expensive to pretrain on different datasets of text, experiments with smaller-scale models are used to decide what data to use in the large final model. But how do we know when small experiments help us make the right decisions or not? To help answer this, we release models, data, and evaluations in the DataDecide suite. This is the most extensive open suite of models over differences in data and scale. We find that which models do best at a single, small size is a good prediction for which are best at our larger target scale. Fitting a line to multiple small experiments doesn't do any better. DataDecide can be used to test improvements in future ways to make decisions with small experiments that we don't know about yet. For instance we already find that using different metrics for the small experiments can make commonly used benchmarks much easier to predict with much smaller experiments."
Poster,Data-driven Design of Randomized Control Trials with Guaranteed Treatment Effects,https://ICML.cc//virtual/2025/poster/44063,"Santiago Cortes-Gomez, Naveen Raman, Aarti Singh, Bryan Wilder","Randomized controlled trials (RCTs) generate guarantees for treatment effects. However, RCTs often spend unnecessary resources exploring sub-optimal treatments, which can reduce the power of treatment guarantees. To address this, we propose a two-stage RCT design. In the first stage, a data-driven screening procedure prunes low-impact treatments, while the second stage focuses on developing high-probability lower bounds for the best-performing treatment effect. Unlike existing adaptive RCT frameworks, our method is simple enough to be implemented in scenarios with limited adaptivity.We derive optimal designs for two-stage RCTs and demonstrate how such designs can be implemented through sample splitting.Empirically, we demonstrate that two-stage designs improve upon single-stage approaches, especially for scenarios where domain knowledge is available through a prior. Our work is thus, a simple yet effective design for RCTs, optimizing for the ability to certify with high probability the largest possible treatment effect for at least one of the arms studied.","Randomized controlled trials (RCTs) are used to figure out which treatments or interventions actually work. But often, these trials waste time and resources testing options that turn out to be ineffective — which makes it harder to confidently prove when something does work.In this paper, we introduce a new, simple two-step approach to improve RCTs. First, we run a screening step that filters out the least promising treatments using the data we’ve gathered so far. Then, we focus all remaining resources on carefully testing the most promising treatments, aiming to confidently guarantee at least one strong result.What makes our approach special is that, unlike many existing methods, it’s practical to use even in settings where only limited adjustments can be made as the trial unfolds. We also provide mathematical tools to help design these kinds of trials in the best possible way.When we tested our approach, we found it consistently outperformed traditional one-stage trials, especially when experts’ prior knowledge about the treatments was available. In short, our method offers a practical and powerful way to run RCTs that makes the best use of limited data and resources."
Poster,"Data-Driven Selection of Instrumental Variables for Additive Nonlinear, Constant Effects Models",https://ICML.cc//virtual/2025/poster/44429,"Xichen Guo, Feng Xie, Yan Zeng, Hao Zhang, zhi geng","We consider the problem of selecting instrumental variables from observational data, a fundamental challenge in causal inference.  Existing methods mostly focus on additive linear, constant effects models, limiting their applicability in complex real-world scenarios.In this paper, we tackle a more general and challenging setting: the additive non-linear, constant effects model. We first propose a novel testable condition, termed the Cross Auxiliary-based independent Test (CAT) condition, for selecting the valid IV set. We show that this condition is both necessary and sufficient for identifying valid instrumental variable sets within such a model under milder assumptions. Building on this condition, we develop a practical algorithm for selecting the set of valid instrumental variables. Extensive experiments on both synthetic and two real-world datasets demonstrate the effectiveness and robustness of our proposed approach, highlighting its potential for broader applications in causal analysis.","We consider the problem of selecting instrumental variables from observational data, a fundamental challenge in causal inference.  Existing methods mostly focus on additive linear, constant effects models, limiting their applicability in complex real-world scenarios.In this paper, we tackle a more general and challenging setting: the additive non-linear, constant effects model. We first propose a novel testable condition, termed the Cross Auxiliary-based independent Test (CAT) condition, for selecting the valid IV set. We show that this condition is both necessary and sufficient for identifying valid instrumental variable sets within such a model under milder assumptions. Building on this condition, we develop a practical algorithm for selecting the set of valid instrumental variables. Extensive experiments on both synthetic and two real-world datasets demonstrate the effectiveness and robustness of our proposed approach, highlighting its potential for broader applications in causal analysis."
