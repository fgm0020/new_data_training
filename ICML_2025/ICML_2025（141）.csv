type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Implicit Regularization for Tubal Tensor Factorizations via Gradient Descent,https://ICML.cc//virtual/2025/poster/46592,"Santhosh Karnik, Anna Veselovska, Mark Iwen, Felix Krahmer","We provide a rigorous analysis of implicit regularization in an overparametrized tensor factorization problem beyond the lazy training regime. For matrix factorization problems, this phenomenon has been studied in a number of works. A particular challenge has been to design universal initialization strategies which provably lead to implicit regularization in gradient-descent methods. At the same time, it has been argued by Cohen et. al. 2016 that more general classes of neural networks can be captured by considering tensor factorizations. However, in the tensor case, implicit regularization has only been rigorously established for gradient flow or in the lazy training regime. In this paper, we prove the first tensor result of its kind for gradient descent rather than gradient flow. We focus on the tubal tensor product and the associated notion of low tubal rank, encouraged by the relevance of this model for image data.  We establish that gradient descent in an overparametrized tensor factorization model with a small random initialization exhibits an implicit bias towards solutions of low tubal rank.  Our theoretical findings are illustrated in an extensive set of numerical simulations show-casing the dynamics predicted by our theory as well as the crucial role of using a small random initialization.","Many machine learning models (including neural networks) often work well, even when they use far more parameters than data points. One mystery is why these models don’t overfit the training data but instead find simple solutions that fit unseen data points. A line of research known as implicit regularization shows that gradient descent (a common algorithm for training these models) naturally nudges the models towards simpler solutions, even without being explicitly told to avoid complicated solutions.We take a step towards the broader goal of understanding this paradigm by establishing this phenomenon for the problem of recovering a tensor (a multidimensional array of numbers) from limited observations. Like neural network training, our tensor recovery problem has many more parameters than necessary, and thus, many solutions exist. Yet, we show that gradient descent finds a “simple” low-rank tensor which fits the observations instead of one of the many “complicated” high-rank tensors which also fit. Hence, implicit regularization can be used to recover low-rank tensors, which naturally arise in a wide range of applications, including video processing and recommender systems.We expect that studying implicit regularization in a controlled setting, will pave the way towards theoretical insights into training neural networks and designing better training algorithms in the future."
Poster,Implicit Riemannian Optimism with Applications to Min-Max Problems,https://ICML.cc//virtual/2025/poster/45525,"Christophe Roux, David Martinez-Rubio, Sebastian Pokutta","We introduce a Riemannian optimistic online learning algorithm for Hadamard manifolds based on inexact implicit updates. Unlike prior work, our method can handle in-manifold constraints, and matches the best known regret bounds in the Euclidean setting with no dependence on geometric constants, like the minimum curvature. Building on this, we develop algorithms for g-convex, g-concave smooth min-max problems on Hadamard manifolds. Notably, one method nearly matches the gradient oracle complexity of the lower bound for Euclidean problems, for the first time.","Many problems, like training advanced machine learning models or analyzing complex data, require making decisions in spaces that aren't like our own. Imagine for instance a smooth surface shaped like a Pringle chip, stretching out endlessly in all directions (and maybe in a million dimensions).  These problems may require to take decisions within a specific region, like being limited to a marked area on the chip. Our research introduces new algorithms for learning and making decisions efficiently on these curved spaces, even when they have to follow extra rules about where they can go. Our approach overcomes challenges caused by these restrictions and are as fast as the fastest methods for spaces that are not curved. This progress allows machine learning systems to handle a wider variety of real-world challenges, especially those where new information keeps arriving over time, or where it's unclear what future situations might look like."
Poster,Implicit Subgraph Neural Network,https://ICML.cc//virtual/2025/poster/45327,"Yongjian Zhong, Liao Zhu, Hieu Vu, Bijaya Adhikari","Subgraph neural networks have recently gained prominence for various subgraph-level predictive tasks. However, existing methods either \emph{1)} apply simple standard pooling over graph convolutional networks, failing to capture essential subgraph properties, or \emph{2)} rely on rigid subgraph definitions, leading to suboptimal performance. Moreover, these approaches fail to model long-range dependencies both between and within subgraphs—a critical limitation, as many real-world networks contain subgraphs of varying sizes and connectivity patterns.  In this paper, we propose a novel implicit subgraph neural network, the first of its kind, designed to capture dependencies across subgraphs. Our approach also integrates label-aware subgraph-level information. We formulate implicit subgraph learning as a bilevel optimization problem and develop a provably convergent algorithm that requires fewer gradient estimations than standard bilevel optimization methods.  We evaluate our approach on real-world networks against state-of-the-art baselines, demonstrating its effectiveness and superiority.","Researchers have been using subgraph neural networks—a kind of artificial intelligence model—to make predictions based on smaller parts (subgraphs) of larger networks, like sections of social networks or protein interaction maps. However, current methods either oversimplify the data or depend too heavily on rigid definitions of what a subgraph is, which limits how well they perform—especially when it comes to understanding how distant parts of the network relate to each other.This study introduces a new kind of neural network that overcomes these problems. It can capture relationships both within subgraphs and between different subgraphs, even when they're far apart or vary in size and structure. The model also takes into account the labels or categories associated with subgraphs to improve prediction accuracy.To train the model efficiently, the researchers used a smart mathematical strategy called bilevel optimization and improved it so that it works faster and more reliably than traditional methods. Tests on real-world data show that this new method outperforms existing techniques."
Poster,Importance Corrected Neural JKO Sampling,https://ICML.cc//virtual/2025/poster/43535,"Johannes Hertrich, Robert Gruhlke","In order to sample from an unnormalized probability density function, we propose to combine continuous normalizing flows (CNFs) with rejection-resampling steps based on importance weights. We relate the iterative training of CNFs with regularized velocity fields to a JKO scheme and prove convergence of the involved velocity fields to the velocity field of the Wasserstein gradient flow (WGF). The alternation of local flow steps and non-local rejection-resampling steps allows to overcome local minima or slow convergence of the WGF for multimodal distributions. Since the proposal of the rejection step is generated by the model itself, they do not suffer from common drawbacks of classical rejection schemes. The arising model can be trained iteratively, reduces the reverse Kullback-Leibler (KL) loss function in each step, allows to generate iid samples and moreover allows for evaluations of the generated underlying density. Numerical examples show that our method yields accurate results on various test distributions including high-dimensional multimodal targets and outperforms the state of the art in almost all cases significantly.","We consider the problem of sampling from a probability distribution given a density function which is known up to a multiplicative constant. To this end, we propose the combination of two different steps. The first step is based on regularized continuous normalizing flows, which locally adjusts the position of the samples. In the second step, we propose a rejection-resampling scheme based on importance weights to globally move samples from over-represented modes to under-represented ones. Both steps are designed such that they allow for the evaluation of intermediate densities, a crucial part of the proposed algorithm. From a theoretical side, we link the regularized continuous normalizing flows to gradient flows in the Wasserstein space and provide some convergence analysis. Moreover, we prove that both kinds of steps reduce the Kullback-Leibler divergence to the target distribution. Finally, our paper provides numerical examples and comparisons to Markov chain Monte Carlo methods and recent neural samplers. Here, we observe that our model outperforms the comparisons significantly."
Poster,Importance Sampling for Nonlinear Models,https://ICML.cc//virtual/2025/poster/44518,"Prakash Palanivelu Rajmohan, Fred Roosta","While norm-based and leverage-score-based methods have been extensively studied for identifying ""important"" data points in linear models, analogous tools for nonlinear models remain significantly underdeveloped. By introducing the concept of the adjoint operator of a nonlinear map, we address this gap and generalize norm-based and leverage-score-based importance sampling to nonlinear settings. We demonstrate that sampling based on these generalized notions of norm and leverage scores provides approximation guarantees for the underlying nonlinear mapping, similar to linear subspace embeddings. As direct applications, these nonlinear scores not only reduce the computational complexity of training nonlinear models by enabling efficient sampling over large datasets but also offer a novel mechanism for model explainability and outlier detection. Our contributions are supported by both theoretical analyses and experimental results across a variety of supervised learning scenarios.","Modern AI systems often rely on enormous datasets, which can dramatically increase computational demands—leading to higher costs, more energy use, and technical challenges. One way to tackle this is by shrinking these datasets: keeping only the most ""important"" data points to reduce cost and speed up training. The problem? Existing methods for finding these key samples only work well for simple models—not for the complex, nonlinear models like neural networks that power today’s AI in areas like image recognition, language processing, and healthcare.We’ve developed a new mathematical framework that brings these sampling ideas to nonlinear models, and backs them up with strong theoretical guarantees. Think of it like summarizing a long book by keeping only the chapters that carry the core message—our method does this with data, even for models that learn complicated patterns. By examining how each data point influences the model’s learning, we can identify the ones that matter most, even in challenging scenarios like rare disease detection or high-resolution image analysis.This advancement means AI systems can train faster and more cheaply while still performing at top levels. It can help cut the cost of data labeling, lower energy usage, and even improve how we understand model decisions—making AI systems more transparent and trustworthy. By focusing on data quality over quantity, this work takes a major step toward making AI more accessible, efficient, and sustainable."
Poster,Impossible Videos,https://ICML.cc//virtual/2025/poster/45548,"Zechen Bai, Hai Ci, Mike Zheng Shou","Synthetic videos nowadays is widely used to complement data scarcity and diversity of real-world videos.Current synthetic datasets primarily replicate real-world scenarios, leaving impossible, counterfactual and anti-reality video concepts underexplored. This work aims to answer two questions: 1) Can today's video generation models effectively follow prompts to create impossible video content? 2) Are today's video understanding models good enough for understanding impossible videos?To this end, we introduce *IPV-Bench*, a novel benchmark designed to evaluate and foster progress in video understanding and generation. *IPV-Bench* is underpinned by a comprehensive taxonomy, encompassing 4 domains, 14 categories.It features diverse scenes that defy physical, biological, geographical, or social laws. Based on the taxonomy, a prompt suite is constructed to evaluate video generation models, challenging their prompt following and creativity capabilities. In addition, a video benchmark is curated to assess Video-LLMs on their ability of understanding impossible videos, which particularly requires reasoning on temporal dynamics and world knowledge. Comprehensive evaluations reveal limitations and insights for future directions of video models, paving the way for next-generation video models.","We introduce a benchmark of ""Impossible Videos"" that defy physical or commonsense laws—like snow in the tropics or objects moving on their own. Current AI models struggle with these cases. Our work reveals their limitations and encourages the development of video models with stronger reasoning and world knowledge."
Poster,Improved Algorithm for Deep Active Learning under Imbalance via Optimal Separation,https://ICML.cc//virtual/2025/poster/43870,"Shyam Nuggehalli, Jifan Zhang, Lalit Jain, Robert Nowak","Class imbalance severely impacts machine learning performance on minority classes in real-world applications. While various solutions exist, active learning offers a fundamental fix by strategically collecting balanced, informative labeled examples from abundant unlabeled data. We introduce DIRECT, an algorithm that identifies class separation boundaries and selects the most uncertain nearby examples for annotation. By reducing the problem to one-dimensional active learning, DIRECT leverages established theory to handle batch labeling and label noise -- another common challenge in data annotation that particularly affects active learning methods.Our work presents the first comprehensive study of active learning under both class imbalance and label noise. Extensive experiments on imbalanced datasets show DIRECT reduces annotation costs by over 60\% compared to state-of-the-art active learning methods and over 80\% versus random sampling, while maintaining robustness to label noise.","Machine learning models learn by being shown labeled examples, but real-world data is rarely perfect. Some classes, like tumors in medical scans or endangered species in wildlife photos, appear far less frequently than others, and human-provided labels can be wrong due to fatigue or ambiguity. These issues—class imbalance and label noise—make it difficult and expensive to train accurate models.We introduce DIRECT, a new method that helps models learn more effectively from imperfect data. Instead of labeling examples randomly, DIRECT finds the borderline cases the model is most unsure about and focuses labeling efforts there—where new information is most helpful. To do this reliably, even with noisy labels, it breaks the overall problem into simpler, one-dimensional tasks that are easier to solve.DIRECT also supports practical workflows where multiple annotators label data in parallel, unlike many previous methods that assume labels come one at a time. In experiments across diverse datasets, it reduces labeling costs by over 60% compared to state-of-the-art methods, without sacrificing performance. This makes machine learning more efficient and accessible—especially in domains where clean, balanced data is hard to collect."
Poster,Improved and Oracle-Efficient Online $\ell_1$-Multicalibration,https://ICML.cc//virtual/2025/poster/45314,"Rohan Ghuge, Vidya Muthukumar, Sahil Singla","We study *online multicalibration*, a framework for ensuring calibrated predictions across multiple groups in adversarial settings, across $T$ rounds. Although online calibration is typically studied in the $\ell_1$ norm, prior approaches to online multicalibration have taken the indirect approach of obtaining rates in other norms (such as $\ell_2$ and $\ell_{\infty}$) and then transferred these guarantees to $\ell_1$  at additional loss. In contrast, we propose a direct method that achieves improved  and oracle-efficient rates of $\widetilde{\mathcal{O}}(T^{-1/3})$ and $\widetilde{\mathcal{O}}(T^{-1/4})$ respectively, for online $\ell_1$-multicalibration. Our key insight is a novel reduction of online $\ell_1$-multicalibration to an online learning problem with product-based rewards, which we refer to as *online linear-product optimization* ($\mathtt{OLPO}$). To obtain the improved rate of $\widetilde{\mathcal{O}}(T^{-1/3})$, we introduce a linearization of $\mathtt{OLPO}$ and design a no-regret algorithm for this linearized problem. Although this method guarantees the desired sublinear rate (nearly matching the best rate for online calibration), it is computationally expensive when the group family $\mathcal{H}$ is large or infinite, since it enumerates all possible groups. To address scalability, we propose a second approach to $\mathtt{OLPO}$  that makes only a polynomial number of calls to an offline optimization (*multicalibration evaluation*) oracle, resulting in *oracle-efficient* online $\ell_1$-multicalibration with a corresponding rate of $\widetilde{\mathcal{O}}(T^{-1/4})$. Our framework also extends to certain infinite families of groups (e.g., all linear functions on the context space) by exploiting a $1$-Lipschitz property of the $\ell_1$-multicalibration error with respect to $\mathcal{H}$.","In many real-world applications—like loan approval, medical diagnosis, or hiring—machine learning algorithms make predictions that impact different groups of people. A key metric used to evaluate the performance of such probability forecasters is *calibration*, which requires that, for any predicted probability $p \in [0,1]$, the actual frequency of the event should converge to $p$. However, a major limitation of standard calibration is that it may still yield systematically biased predictions for specific subpopulations defined by features like gender, race, or age. Our work addresses this limitation through a stronger fairness notion called *multicalibration*, which ensures that predictions are accurate not just on average, but across all relevant subgroups. We study this problem in an online setting, where predictions must be made sequentially, without access to future data—a scenario that captures the constraints of many real-time decision-making systems.We develop new algorithms that are both fast and theoretically sound, ensuring fair predictions even when feedback is limited and data arrives in a stream. Our approach introduces a novel way to reframe the problem—making it easier to solve and analyze using tools from online optimization. As a result, we obtain improved guarantees on how quickly fairness can be achieved, and we ensure that our algorithms remain efficient enough for practical deployment."
Poster,Improved Approximations for Hard Graph Problems using Predictions,https://ICML.cc//virtual/2025/poster/46430,"Anders Aamand, Justin Chen, Siddharth Gollapudi, Sandeep Silwal, Hao WU","We design improved approximation algorithms for NP-hard graph problems by incorporating predictions (e.g., learned from past data). Our prediction model builds upon and extends the $\varepsilon$-prediction framework by Cohen-Addad, d'Orsi, Gupta, Lee, and Panigrahi (NeurIPS 2024).  We consider an edge-based version of this model, where each edge provides two bits of information, corresponding to predictions about whether each of its endpoints belong to an optimal solution. Even with weak predictions where each bit is only $\varepsilon$-correlated with the true solution, this information allows us to break approximation barriers in the standard setting. We develop algorithms with improved approximation ratios for MaxCut, Vertex Cover, Set Cover, and Maximum Independent Set problems (among others). Across these problems, our algorithms share a unifying theme, where we separately satisfy constraints related to high degree vertices (using predictions) and low-degree vertices (without using predictions) and carefully combine the answers.","We design improved approximation algorithms for NP-hard graph problems by incorporating predictions (e.g., learned from past data). Our prediction model builds upon and extends the $\varepsilon$-prediction framework by Cohen-Addad, d'Orsi, Gupta, Lee, and Panigrahi (NeurIPS 2024).  We consider an edge-based version of this model, where each edge provides two bits of information, corresponding to predictions about whether each of its endpoints belong to an optimal solution. Even with weak predictions where each bit is only $\varepsilon$-correlated with the true solution, this information allows us to break approximation barriers in the standard setting. We develop algorithms with improved approximation ratios for MaxCut, Vertex Cover, Set Cover, and Maximum Independent Set problems (among others). Across these problems, our algorithms share a unifying theme, where we separately satisfy constraints related to high degree vertices (using predictions) and low-degree vertices (without using predictions) and carefully combine the answers."
Poster,Improved Coresets for Vertical Federated Learning: Regularized Linear and Logistic Regressions,https://ICML.cc//virtual/2025/poster/43903,"Supratim Shit, Gurmehak chadha, Surendra kumar, Bapi Chatterjee","Coreset, as a summary of training data, offers an efficient approach for reducing data processing and storage complexity during training. In the emerging vertical federated learning (VFL) setting, where scattered clients store different data features, it directly reduces communication complexity. In this work, we introduce coresets construction for regularized logistic regression both in centralized and VFL settings. Additionally, we improve the coreset size for regularized linear regression in the VFL setting. We also eliminate the dependency of the coreset size on a property of the data due to the VFL setting. The improvement in the coreset sizes is due to our novel coreset construction algorithms that capture the reduced model complexity due to the added regularization and its subsequent analysis. In experiments, we provide extensive empirical evaluation that backs our theoretical claims. We also report the performance of our coresets by comparing the models trained on the complete data and on the coreset.","A theoretically proven better approach for training the regularized versions of the logistic regression and linear regression methods in a data-efficient way when implemented in a setting that allows the partitioning of the feature space of the training data. In this setting, the parties to which the feature space of data is partitioned are able to maintain data privacy. Such a setting is an excellent fit for a consortium of organizations working in domains such as finance, healthcare, etc., where they have to maintain information privacy about their customers. The data efficiency comes via an approach where only the important samples out of the entire training sample set are selected. The regularization of the methods ensures that the trained models will not be suitable only for the samples on which they are trained, but also for previously unseen samples. Such an approach is the first in its class of methods to the best of the knowledge of the co-authors."
