type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Generalization Performance of Ensemble Clustering: From Theory to Algorithm,https://ICML.cc//virtual/2025/poster/46061,"Xu Zhang, Haoye Qiu, Weixuan Liang, Hui LIU, Junhui Hou, Yuheng Jia","Ensemble clustering has demonstrated great success in practice; however, its theoretical foundations remain underexplored. This paper examines the generalization performance of ensemble clustering, focusing on generalization error, excess risk and consistency. We derive a convergence rate of generalization error bound and excess risk bound both of $\mathcal{O}(\sqrt{\frac{\log n}{m}}+\frac{1}{\sqrt{n}})$, with $n$ and $m$ being the numbers of samples and base clusterings. Based on this, we prove that when $m$ and $n$ approach infinity and $m$ is significantly larger than log $n$, i.e., $m,n\to \infty, m\gg \log n$, ensemble clustering is consistent. Furthermore, recognizing that $n$ and $m$ are finite in practice, the generalization error cannot be reduced to zero. Thus, by assigning varying weights to finite clusterings, we minimize the error between the empirical average clusterings and their expectation. From this, we theoretically demonstrate that to achieve better clustering performance, we should minimize the deviation (bias) of base clustering from its expectation and maximize the differences (diversity) among various base clusterings. Additionally, we derive that maximizing diversity is nearly equivalent to a robust (min-max) optimization model. Finally, we instantiate our theory to develop a new ensemble clustering algorithm. Compared with SOTA methods, our approach achieves average improvements of 6.1\%, 7.3\%, and 6.0\% on 10 datasets w.r.t. NMI, ARI, and Purity. The code is available at https://github.com/xuz2019/GPEC.","Ensemble clustering is a widely used technique that combines multiple clustering results to achieve higher robustness and accuracy. It has found applications in fields such as image analysis, customer segmentation, and bioinformatics. Despite its empirical success, its theoretical underpinnings remain largely unexplored. This work provides a rigorous analysis of the generalization performance of ensemble clustering. We derive bounds for the generalization error and excess risk, and characterize the asymptotic consistency of ensemble clustering. Our results demonstrate that increasing the number of samples alone is insufficient to guarantee performance gains; rather, the number and diversity of base clusterings are critical factors. Building upon this theoretical framework, we propose a novel weighted ensemble clustering algorithm that jointly minimizes bias and maximizes diversity across the base clusterings. Extensive experiments on real-world datasets confirm that our method consistently outperforms state-of-the-art techniques, with average improvements exceeding 6\%. This study not only advances the theoretical understanding of ensemble clustering but also offers practical insights into the design of more effective and principled clustering algorithms."
Poster,Generalization Principles for Inference over Text-Attributed Graphs  with Large Language Models,https://ICML.cc//virtual/2025/poster/44628,"Haoyu Wang, Shikun Liu, Rongzhe Wei, Pan Li","Large language models (LLMs) have recently been introduced to graph learning, aiming to extend their zero-shot generalization success to tasks where labeled graph data is scarce. Among these applications, inference over text-attributed graphs (TAGs) presents unique challenges: existing methods struggle with LLMs' limited context length for processing large node neighborhoods and the misalignment between node embeddings and the LLM token space. To address these issues, we establish two key principles for ensuring generalization and derive the framework LLM-BP accordingly: (1) **Unifying the attribute space with task-adaptive embeddings**, where we leverage LLM-based encoders and task-aware prompting to enhance generalization of the text attribute embeddings; (2) **Developing a generalizable graph information aggregation mechanism**, for which we adopt belief propagation with LLM-estimated parameters that adapt across graphs. Evaluations on 11 real-world TAG benchmarks demonstrate that LLM-BP significantly outperforms existing approaches, achieving 8.10\% improvement with task-conditional embeddings and an additional 1.71\% gain from adaptive aggregation. The code and task-adaptive embeddings are publicly available.","Large language models (LLMs), powerful AI systems known for their ability to understand text, have recently been applied to learning from graph data, particularly graphs whose nodes carry textual information. However, current methods face challenges: LLMs have limited memory for handling large networks of information. To address the issue, we introduced LLM-BP, an approach built around two key ideas. First, we designed specialized embeddings—ways of translating text into numbers—that adapt specifically to the tasks we want the model to perform. Second, we created a flexible method inspired by belief propagation, a common technique used to spread information efficiently across graphs, where the LLM itself decides how best to combine data from different nodes. When tested across multiple real-world datasets, LLM-BP showed substantial improvements over existing methods, making it much better at handling graphs with text-based data. This research could enhance applications like knowledge discovery, recommendation systems, and information retrieval, where efficiently interpreting large-scale text-rich data is essential."
Poster,Generalized additive models via direct optimization of regularized decision stump forests,https://ICML.cc//virtual/2025/poster/46531,"Magzhan Gabidolla, Miguel Carreira-Perpinan","We explore ensembles of axis-aligned decision stumps, which can be viewed as a generalized additive model (GAM). In this model, stumps utilizing the same feature are grouped to form a shape function for that feature. Instead of relying on boosting or bagging, we employ alternating optimization to learn a fixed-size stump forest. We optimize the parameters of each stump exactly through enumeration, given the other stumps are fixed. For fixed stump splits, the leaf values are optimized jointly by solving a convex problem. To address the overfitting issue inherent in naive optimization of stump forests, we propose effective regularization techniques. Our regularized stump forests achieve accuracy comparable to state-of-the-art GAM methods while using fewer parameters. This work is the first to successfully learn stump forests without employing traditional ensembling techniques like bagging or boosting.","Many AI models, such as deep neural networks, are considered ""black boxes"" because it is difficult, or even impossible, to understand how they make decisions. This lack of transparency poses a challenge when using AI in high-stake areas like healthcare or finance, where decisions must be trusted and explained. In contrast, interpretable models are simpler and can be more easily understood by humans, making them better suited for such domains. This paper focuses on one type of interpretable model: generalized additive models (GAMs). These models make predictions by adding up individual contributions from each input feature, which makes them easier to visualize and explain. The paper introduces a new optimization-based algorithm that can train GAMs more accurately and efficiently."
Poster,Generalized Category Discovery via Reciprocal Learning and Class-Wise Distribution Regularization,https://ICML.cc//virtual/2025/poster/43993,"Duo Liu, Zhiquan Tan, Linglan Zhao, Zhongqiang Zhang, Xiangzhong Fang, Weiran Huang","Generalized Category Discovery (GCD) aims to identify unlabeled samples by leveraging the base knowledge from labeled ones, where the unlabeled set consists of both base and novel classes. Since clustering methods are time-consuming at inference, parametric-based approaches have become more popular. However, recent parametric-based methods suffer from inferior base discrimination due to unreliable self-supervision. To address this issue, we propose a Reciprocal Learning Framework (RLF) that introduces an auxiliary branch devoted to base classification. During training, the main branch filters the pseudo-base samples to the auxiliary branch. In response, the auxiliary branch provides more reliable soft labels for the main branch, leading to a virtuous cycle. Furthermore, we introduce Class-wise Distribution Regularization (CDR) to mitigate the learning bias towards base classes. CDR  essentially increases the prediction confidence of the unlabeled data and boosts the novel class performance. Combined with both components, our proposed method, RLCD, achieves superior performance in all classes with negligible extra computation. Comprehensive experiments across seven GCD datasets validate its superiority.Our codes are available at https://github.com/APORduo/RLCD.","This paper addresses the challenge of classifying unlabeled images by leveraging information from partially labeled data. We observe that recent methods often show a decreased ability to distinguish known categories. To mitigate this issue, we propose a reciprocal framework that introduces an auxiliary branch to offer more reliable supervision and preserve knowledge of known categories.  Additionally, we develop a novel regularization technique, called Class-wise Distribution Regularization (CDR), to promote balanced learning across all categories. Consequently, our method achieves significantly improved performance."
Poster,Generalized Interpolating Discrete Diffusion,https://ICML.cc//virtual/2025/poster/43859,"Dimitri von Rütte, Janis Fluri, Yuhui Ding, Antonio Orvieto, Bernhard Schölkopf, Thomas Hofmann","While state-of-the-art language models achieve impressive results through next-token prediction, they have inherent limitations such as the inability to revise already generated tokens. This has prompted exploration of alternative approaches such as discrete diffusion. However, masked diffusion, which has emerged as a popular choice due to its simplicity and effectiveness, reintroduces this inability to revise words. To overcome this, we generalize masked diffusion, deriving a new family of general interpolating discrete diffusion (GIDD) which offers greater flexibility in the design of the noising processes. Leveraging a novel diffusion ELBO, we achieve compute-matched state-of-the-art performance in diffusion language modeling. Exploiting GIDD's flexibility, we explore a hybrid approach combining masking and uniform noise, leading to improved sample quality and unlocking the ability for the model to correct its own mistakes, an area where autoregressive models notoriously have struggled.Code: https://github.com/dvruette/gidd/","Modern language models, like those powering chatbots and writing assistants, typically generate text one word (or token) at a time, predicting the next word based on what came before. This method works well but has a key limitation: once a word is written, the model can't go back to fix it, even if it realizes later that it made a mistake.One promising direction of research to address this is called discrete diffusion, where the model generates text by starting at pure noise and gradually removing the noise, e.g. by filling in missing words, over the course of multiple steps until a complete sentence has emerged. However, the most popular diffusion method, called masked diffusion, still can’t revise earlier word choices effectively.In this work, we introduce a more flexible version of diffusion called General Interpolating Discrete Diffusion (GIDD). GIDD allows the model to better control how it refines text, making it possible to fix earlier errors. We also develop a new technique for training these models that helps them perform as well as leading discrete diffusion models.By combining different types of noise, we show that GIDD not only generates higher-quality text, but also learns how to revise and improve its outputs, something today’s models often struggle with. This brings us a step closer to AI systems that can think and write more like humans: drafting, revising, and improving as they go."
Poster,Generalized Random Forests Using Fixed-Point Trees,https://ICML.cc//virtual/2025/poster/46613,"David Fleischer, David A Stephens, Archer Yang","We propose a computationally efficient alternative to generalized random forests (GRFs) for estimating heterogeneous effects in large dimensions. While GRFs rely on a gradient-based splitting criterion, which in large dimensions is computationally expensive and unstable, our method introduces a fixed-point approximation that eliminates the need for Jacobian estimation. This gradient-free approach preserves GRF’s theoretical guarantees of consistency and asymptotic normality while significantly improving computational efficiency. We demonstrate that our method achieves a speedup of multiple times over standard GRFs without compromising statistical accuracy. Experiments on both simulated and real-world data validate our approach. Our findings suggest that the proposed method is a scalable alternative for localized effect estimation in machine learning and causal inference applications.","In many fields, like medicine or public policy, it’s crucial to know not just whether something works, but who it works best for. Do patients have unique responses to a new drug? Do economic policies affect different communities in distinct ways? The method of Generalized Random Forests (GRFs) is a powerful method specifically tailored to measure these types of group-specific effects. However, GRFs can become bogged down in complex and time-consuming calculations when trying to estimate many effects at the same time. Our idea is to replace the source of these expensive calculations with a much faster, streamlined approximation that sidesteps this problem altogether. Our ""fixed-point tree"" (FPT) approach is not only faster--often multiple times faster--but we show that its relative speed over GRF increases when applied to a larger number of effects. The key result is that both the original GRF approach and our faster GRF-FPT approach are about as accurate as one another, meaning that the speed that we offer doesn't come at the cost of accuracy. This makes the already powerful method of GRFs even more attractive for large-scale problems."
Poster,Generalized Smooth Bilevel Optimization with Nonconvex Lower-Level,https://ICML.cc//virtual/2025/poster/45586,"Siqi Zhang, Xing Huang, Feihu Huang","Bilevel optimization is widely applied in many machine learning tasks such as hyper-parameter learning and meta learning. Recently, many algorithms have been proposed to solve these bilevel optimization problems, which rely on the smoothness condition of  objective functions of the bilevel optimization. In fact, some machine learning tasks such as learning language model do not satisfy the smoothness condition of objective functions. More recently,  some methods have begun to study generalized smooth bilevel optimization. However, these proposed methods for generalized smooth bilevel optimization only focus on the (strongly) convex lower objective function. Meanwhile, these methods only consider the generalized-smooth upper-level objective, but still require the standard smooth lower-level objective in the bilevel optimization. To fill this gap, in the paper, thus we study the generalized-smooth bilevel optimization with the nonconvex lower-level objective function, where both upper-level and lower-level objectives are generalized-smooth. We propose an efficient single-loop Hessian/Jacobian-free penalty normalized gradient (i.e., PNGBiO) method. Moreover, we prove that our PNGBiO obtains a fast convergence rate of $O(\frac{1}{T^{1/4}})$ for finding a stationary solution, where $T$ denotes the iteration number. Meanwhile, we also propose a stochastic version of our PNGBiO (i.e., S-PNGBiO) method to solve stochastic bilevel problems, and prove that our S-PNGBiO has a fast convergence rate of $O(\frac{1}{T^{1/6}})$.  Some experimental results on hyper-parameter learning and meta learning demonstrate efficiency of our proposed methods.","Bilevel optimization is widely applied in many machine learning tasks such as hyper-parameter learning and meta learning. Recently, many algorithms have been proposed to solve these bilevel optimization problems, which rely on the smoothness condition of  objective functions of the bilevel optimization. In fact, some machine learning tasks such as learning language model do not satisfy the smoothness condition of objective functions. More recently,  some methods have begun to study generalized smooth bilevel optimization. However, these proposed methods for generalized smooth bilevel optimization only focus on the (strongly) convex lower objective function. Meanwhile, these methods only consider the generalized-smooth upper-level objective, but still require the standard smooth lower-level objective in the bilevel optimization. To fill this gap, in the paper, thus we study the generalized-smooth bilevel optimization with the nonconvex lower-level objective function, where both upper-level and lower-level objectives are generalized-smooth. We propose an efficient single-loop Hessian/Jacobian-free penalty normalized gradient (i.e., PNGBiO) method. Moreover, we prove that our PNGBiO obtains a fast convergence rate for finding a stationary solution. Meanwhile, we propose a stochastic version of our PNGBiO (i.e., S-PNGBiO) method to solve stochastic bilevel problems, and prove that our S-PNGBiO also has a fast convergence rate.  Some experimental results on hyper-parameter learning and meta learning demonstrate efficiency of our proposed methods."
Poster,Generalized Venn and Venn-Abers Calibration with Applications in Conformal Prediction,https://ICML.cc//virtual/2025/poster/44237,"Lars van der Laan, Ahmed Alaa","Ensuring model calibration is critical for reliable prediction, yet popular distribution-free methods such as histogram binning and isotonic regression offer only asymptotic guarantees. We introduce a unified framework for Venn and Venn-Abers calibration that extends Vovk's approach beyond binary classification to a broad class of prediction tasks defined by generic loss functions. Our method transforms any perfectly in-sample calibrated predictor into a set-valued predictor that, in finite samples, outputs at least one marginally calibrated point prediction. These set predictions shrink asymptotically and converge to a conditionally calibrated prediction, capturing epistemic uncertainty. We further propose Venn multicalibration, a new approach for achieving finite-sample calibration across subpopulations. For quantile loss, our framework recovers group-conditional and multicalibrated conformal prediction as special cases and yields novel prediction intervals with quantile-conditional coverage.","To be trustworthy, machine learning models must be well-calibrated—that is, when a model predicts an 80\% chance of an event, that event should occur about 80\% of the time. Traditional calibration methods, such as histogram binning and isotonic regression, adjust model outputs to align with observed outcomes, but they only guarantee reliable performance when applied to large datasets. We introduce a new approach that generalizes Vovk’s method—originally developed for binary classification—to a broad class of prediction problems. Specifically, our framework extends calibration to any elicitable property defined via the minimization of a loss function, including but not limited to probabilities and quantiles. Instead of producing a single point prediction, our method outputs a set of possible predictions for each input. This set is guaranteed to contain at least one prediction that is well-calibrated, even in small-sample settings. As more data becomes available, the prediction sets shrink, eventually converging to a single, conditionally calibrated prediction. Moreover, we extend this approach to ensure calibration holds across different subpopulations, ensuring fairness and reliability. Overall, our method provides a unified and practical solution for capturing and communicating uncertainty in model predictions, especially when data is limited or decisions are high-stakes."
Poster,Generalizing Causal Effects from Randomized Controlled Trials to Target Populations across Diverse Environments,https://ICML.cc//virtual/2025/poster/44751,"Baohong Li, Yingrong Wang, Anpeng Wu, ma ming, Ruoxuan Xiong, Kun Kuang","Generalizing causal effects from Randomized Controlled Trials (RCTs) to target populations across diverse environments is of significant practical importance, as RCTs are often costly and logistically complex to conduct. A key challenge is environmental shift, defined as changes in the distribution and availability of covariates between source and target environments. A common approach addressing this challenge is to identify a separating set--covariates that govern both treatment effect heterogeneity and environmental differences--and combine RCT samples with target populations matched on this set. However, this approach assumes that the separating set is fully observed and shared across datasets, an assumption often violated in practice. We propose a novel Two-Stage Doubly Robust (2SDR) method that relaxes this assumption by allowing the separating set to be observed in only one of the two datasets. 2SDR leverages shadow variables to impute missing components of the separating set and generalize treatment effects across environments in a two-stage procedure. We show the identification of causal effects in target environments under 2SDR and demonstrate its effectiveness through extensive experiments on both synthetic and real-world datasets.","Generalizing causal effects from Randomized Controlled Trials (RCTs) across diverse environments is challenging due to environmental shifts. A common solution to this challenge is combining and matching RCT data with observational data from the target population using a separating set. The problem with the common solution is that it relies on the assumption that the covariates shared by both groups contain the separating set, which is difficult to satisfy in real-world scenarios under experimental shifts.Our solution, Two-Stage Doubly Robust (2SDR), relaxes the assumption made in the common solution. It only assumes that variables from the separating set are present in at least one of the two data groups—either the RCT data or the observational data from the target population. 2SDR leverages automatically selected shadow variables to impute the missing covariates for generalizing treatment effects from RCTs across environments in a two-stage way. Both identifiability theory and extensive experimental evidence on synthetic and real-world datasets support the correctness and effectiveness of our solution."
Poster,Generalizing from SIMPLE to HARD Visual Reasoning: Can We Mitigate Modality Imbalance in VLMs?,https://ICML.cc//virtual/2025/poster/43878,"Simon Park, Abhishek Panigrahi, Yun Cheng, Dingli Yu, Anirudh Goyal, Sanjeev Arora","Vision Language Models (VLMs) are impressive at visual question answering and image captioning. But they underperform on multi-step visual reasoning---even compared to LLMs on the same tasks presented in text form---giving rise to perceptions of *modality imbalance* or *brittleness*. Towards a systematic study of such issues, we introduce a synthetic framework for assessing the ability of VLMs to perform algorithmic visual reasoning, comprising three tasks: Table Readout, Grid Navigation, and Visual Analogy. Each has two levels of difficulty, SIMPLE and HARD, and even the SIMPLE versions are difficult for frontier VLMs. We propose strategies for training on the SIMPLE version of tasks that improve performance on the corresponding HARD task, i.e., simple-to-hard (S2H) generalization. This controlled setup, where each task also has an equivalent text-only version, allows a quantification of the modality imbalance and how it is impacted by training strategy. We show that 1) explicit image-to-text conversion is important in promoting S2H generalization on images, by transferring reasoning from text; 2) conversion can be internalized at test time. We also report results of mechanistic study of this phenomenon. We identify measures of gradient alignment that can identify training strategies that promote better S2H generalization. Ablations highlight the importance of chain-of-thought.","A family of models called Vision Language Models (VLMs) have been developed towards solving tasks on both text and image inputs. However, recent studies show signs of *modality imbalance*, where the trained models reason better if the same task is presented as text instead of image.We design a framework to quantify and mitigate the *modality imbalance*. We propose three algorithmic reasoning tasks, where each task 1) has two levels of diffuclty (SIMPLE and HARD); and 2) has an equivalent pair of text-only and image-only versions. We propose different strategies for training on the SIMPLE version of task and evaluate them on the corresponding HARD version. By comparing the simple-to-hard (S2H) generalization---i.e., the accuracy on the HARD version---we can quantify modality imbalance and assess how it is impacted by the training strategy. We first show that training on image-only version of the task shows poorer reasoning capability than training on text-only version, showcasing a concrete sign of *modality imbalance*. Next, we show that we can promote the model's reasoning capability on image by training the model to explicitly convert a provided image to its equivalent text representation before solving the task---here, the model is transferring its text reasoning towards image input. Furthermore, this conversion step can later be internalized, meaning once the training is complete, the model can skip the conversion and directly solve the task.We also report results of mechanistic study of this phenomenon. We identify measures of gradient alignment that can identify training strategies that promote better S2H generalization. Our ablation studies highlight the importance of chain-of-thought in the process of transfer of reasoning capabilities across modalities."
