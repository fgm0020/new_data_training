type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Learning State-Based Node Representations from a Class Hierarchy for Fine-Grained Open-Set Detection,https://ICML.cc//virtual/2025/poster/45501,"Spandan Pyakurel, Qi Yu","Fine-Grained Openset Detection (FGOD) poses a fundamental challenge due to the similarity between the openset classes and those closed-set ones. Since real-world objects/entities tend to form a hierarchical structure, the fine-grained relationship among the closed-set classes as captured by the hierarchy could potentially improve the FGOD performance. Intuitively, the hierarchical dependency among different classes allows the model to recognize their subtle differences, which in turn makes it better at differentiating similar open-set classes even they may share the same parent. However, simply performing openset detection in a top-down fashion by building a local detector for each node may result in a poor detection performance. Our theoretical analysis also reveals that maximizing the probability of the path leading to the ground-truth leaf node also results in a sub-optimal training process. To systematically address this issue, we propose to formulate a novel state-based node representation, which constructs a state space based upon the entire hierarchical structure. We prove that the state-based representation guarantees to maximize the probability on the path leading to the ground-truth leaf node. Extensive experiments on multiple real-world hierarchical datasets clearly demonstrate the superior performance of the proposed method.","We develop AI models capable of recognizing previously unseen image categories that differ from those present in the training data. Our approach leverages the hierarchical structure of known categories to identify instances of unknown but related categories. For example, given a training hierarchy such as Bird → Sparrow → Fox Sparrow, our goal is to correctly flag an unseen class like Le Conte’s Sparrow as an unknown subcategory of Sparrow. Prior methods typically address this challenge by classifying images at each node of the training hierarchy independently. However, we find that this approach yields limited performance. To address this, we propose a new methodology that fully exploits the hierarchical relationships among all nodes in the training taxonomy, including parent-child, ancestor-descendant, and sibling-sibling relationships. We encode these relationships through a tailored state formulation and train our model to learn from the global structure of the hierarchy, leading to significantly improved performance in recognizing novel categories."
Poster,Learning Strategic Language Agents in the Werewolf Game with Iterative Latent Space Policy Optimization,https://ICML.cc//virtual/2025/poster/45520,"Zelai Xu, Wanjun Gu, Chao Yu, Yi Wu, Yu Wang","Large language model (LLM) agents have recently demonstrated impressive capabilities in various domains like open-ended conversation and multi-step decision-making. However, it remains challenging for these agents to solve strategic language games, such as Werewolf, which demand both strategic decision-making and free-form language interactions. Existing LLM agents often suffer from intrinsic bias in their action distributions and limited exploration of the unbounded text action space, resulting in suboptimal performance. To address these challenges, we propose Latent Space Policy Optimization (LSPO), an iterative framework that combines game-theoretic methods with LLM fine-tuning to build strategic language agents. LSPO leverages the observation that while the language space is combinatorially large, the underlying strategy space is relatively compact. We first map free-form utterances into a finite latent strategy space, yielding an abstracted extensive-form game. Then we apply game-theoretic methods like Counterfactual Regret Minimization (CFR) to optimize the policy in the latent space. Finally, we fine-tune the LLM via Direct Preference Optimization (DPO) to align with the learned policy. By iteratively alternating between these steps, our LSPO agents progressively enhance both strategic reasoning and language communication. Experiment on the Werewolf game shows that our agents iteratively expand the strategy space with improving performance and outperform existing Werewolf agents, underscoring their effectiveness in free-form language games with strategic interactions.","Many social deduction games, like Werewolf, hinge on strategic conversation: players must bluff, persuade, and out-reason each other. Current LLM agents struggle in these settings because they show predictable habits (e.g., a ""werewolf"" agent tends to ""kill player 0"") and rarely explore bold new strategies, making them easy to outsmart. We address these challenges by introducing a latent strategy space and combining game-theoretic methods with LLM fine-tuning. We first abstract the language game to a structured tree-form game. Then we use game-theoretic methods to optimize policy in the abstracted game. Finally, we align the LLM to the learned policy and expand the strategy space. By iterating between the three steps, our agents explore and learn strong strategies.Our method leads to an agent that bluffs, adapts, and beats existing Werewolf agents. This approach could help build better AI for negotiation, diplomacy, and other language-based strategic interactions."
Poster,Learning Survival Distributions with the Asymmetric Laplace Distribution,https://ICML.cc//virtual/2025/poster/44758,"Deming Sheng, Ricardo Henao","Probabilistic survival analysis models seek to estimate the distribution of the future occurrence (time) of an event given a set of covariates.In recent years, these models have preferred nonparametric specifications that avoid directly estimating survival distributions via discretization.Specifically, they estimate the probability of an individual event at fixed times or the time of an event at fixed probabilities (quantiles), using supervised learning.Borrowing ideas from the quantile regression literature, we propose a parametric survival analysis method based on the Asymmetric Laplace Distribution (ALD).This distribution allows for closed-form calculation of popular event summaries such as mean, median, mode, variation, and quantiles.The model is optimized by maximum likelihood to learn, at the individual level, the parameters (location, scale, and asymmetry) of the ALD distribution.Extensive results on synthetic and real-world data demonstrate that the proposed method outperforms parametric and nonparametric approaches in terms of accuracy, discrimination and calibration.","Predicting how long it will take for something to happen, such as the failure of a machine part or the progression of a disease, is important in many fields including healthcare and engineering. This type of prediction is known as survival analysis. However, making accurate predictions can be challenging, especially when complete information is not available for every case. For example, a patient may not yet have experienced the event being studied by the time data collection ends.In this work, we introduce a new method based on a statistical distribution called the Asymmetric Laplace Distribution. This distribution provides a flexible way to describe the range and likelihood of possible outcomes for each individual. Unlike many existing approaches that rely on simplifying assumptions or discretizing time, our method models the entire probability distribution directly. As a result, it allows us to compute meaningful summaries, such as the expected time of an event or the uncertainty associated with that prediction.We evaluated our method on a wide range of simulated and real-world datasets, including several from healthcare applications. Across different settings, it consistently outperformed traditional and modern survival models in terms of accuracy and reliability. Our approach is especially effective when dealing with incomplete data or rare events, making it a valuable tool for personalized risk prediction and decision-making."
Poster,Learning the Electronic Hamiltonian of Large Atomic Structures,https://ICML.cc//virtual/2025/poster/45027,"Chen Hao Xia, Manasa Kaniselvan, Alexandros Nikolaos Ziogas, Marko Mladenovic, Rayen Mahjoub, Alexander Maeder, Mathieu Luisier","Graph neural networks (GNNs) have shown promise in learning the ground-state electronic properties of materials, subverting *ab initio* density functional theory (DFT) calculations when the underlying lattices can be represented as small and/or repeatable unit cells (i.e., molecules and periodic crystals). Realistic systems are, however, non-ideal and generally characterized by higher structural complexity. As such, they require large (10+ Å) unit cells and thousands of atoms to be accurately described. At these scales, DFT becomes computationally prohibitive, making GNNs especially attractive. In this work, we present a strictly local equivariant GNN capable of learning the electronic Hamiltonian (**H**) of realistically extended materials. It incorporates an *augmented partitioning* approach that enables training on arbitrarily large structures while preserving local atomic environments beyond boundaries. We demonstrate its capabilities by predicting the electronic Hamiltonian of various systems with up to 3,000 nodes (atoms), 500,000+ edges, ~ 28 million orbital interactions (nonzero entries of **H**), and $\leq$0.53\% error in the eigenvalue spectra. Our work expands the applicability of current electronic property prediction methods to some of the most challenging cases encountered in computational materials science, namely systems with disorder, interfaces, and defects.","Our work focuses on the machine learning of Hamiltonian matrices for large systems of atoms. The Hamiltonian matrix is an operator that allows key information about a material to be extracted, including how well it conducts electricity. It is therefore an integral part of material/device research and is normally computed from the ground up using physics approaches.Previous work on this topic is largely restricted to either small, isolated groups of atoms (molecules) or atomic structures with repeating patterns (e.g. crystals). In real life, however, materials are rarely perfect, often containing defects, disorder, and interfaces. To capture these details, the Hamiltonian of large numbers of atoms (1000+) in various arrangements needs to be computed, making previous ground-up computational methods unfeasible. In this work, we aim to overcome this open problem by proposing a local graph network combined with an approach that breaks down large atomic graphs into small, independent slices. Besides overcoming memory limitations of hardware, it also allows for flexible, efficient parallel training while maintaining the correct atomic neighborhoods. In short, our work bridges the gap between ML methods and real-life large scale materials applications."
Poster,Learning the RoPEs: Better 2D and 3D Position Encodings with STRING,https://ICML.cc//virtual/2025/poster/44956,"Connor Schenck, Isaac Reid, Mithun Jacob, Alex Bewley, Joshua Ainslie, David Rendleman, Deepali Jain, Mohit Sharma, Kumar Avinava Dubey, Ayzaan Wahid, Sumeet Singh, René Wagner, Tianli Ding, Chuyuan Fu, Arunkumar Byravan, Jacob J Varley, Alexey Gritsenko, Matthias Minderer, Dmitry Kalashnikov, Jonathan Tompson, Vikas Sindhwani, Krzysztof Choromanski","We introduce $\textbf{STRING}$: Separable Translationally Invariant Position Encodings. STRING extends Rotary Position Encodings, a recently proposed and widely used algorithm in large language models, via a unifying theoretical framework. Importantly, STRING still provides $\textbf{exact}$ translation invariance, including token coordinates of arbitrary dimensionality, whilst maintaining a low computational footprint. These properties are especially important in robotics, where efficient 3D token representation is key. We integrate STRING into Vision Transformers with RGB(-D) inputs (color plus optional depth), showing substantial gains, e.g. in open-vocabulary object detection and for robotics controllers.We complement our experiments with a rigorous mathematical analysis, proving the universality of our methods. Videos of STRING-based robotics controllers can be found here: https://sites.google.com/view/string-robotics.","This paper introduces STRING, a new and improved method for AI to understand the position of items, especially in 2D images and 3D scenes. Current AI models (Transformers) grasp content but struggle with order or location. STRING builds upon a popular method called RoPE but is more general and better suited for multi-dimensional data. It retains RoPE's key benefits—encoding each item's position independently (""separability"") and focusing on relative distances (""translational invariance"")—while being more powerful. The paper proves STRING is theoretically the most comprehensive approach of its kind under certain conditions. Crucially, it delivers significant performance gains in practical applications like object detection and robotics control, where efficiently representing 2D/3D information is vital. In short, STRING helps AI ""see"" and understand spatial arrangements more effectively."
Poster,Learning Time-Aware Causal Representation for Model Generalization in Evolving Domains,https://ICML.cc//virtual/2025/poster/45628,"Zhuo He, Shuang Li, Wenze Song, Longhui Yuan, Jian Liang, Han Li, Kun Gai","Endowing deep models with the ability to generalize in dynamic scenarios is of vital significance for real-world deployment, given the continuous and complex changes in data distribution. Recently, evolving domain generalization (EDG) has emerged to address distribution shifts over time, aiming to capture evolving patterns for improved model generalization. However, existing EDG methods may suffer from spurious correlations by modeling only the dependence between data and targets across domains, creating a shortcut between task-irrelevant factors and the target, which hinders generalization. To this end, we design a time-aware structural causal model (SCM) that incorporates dynamic causal factors and the causal mechanism drifts, and propose **S**tatic-D**YN**amic **C**ausal Representation Learning (**SYNC**), an approach that effectively learns time-aware causal representations.  Specifically, it integrates specially designed information-theoretic objectives into a sequential VAE framework which captures evolving patterns, and produces the desired representations by preserving intra-class compactness of causal factors both across and within domains. Moreover, we theoretically show that our method can yield the optimal causal predictor for each time domain. Results on both synthetic and real-world datasets exhibit that SYNC can achieve superior temporal generalization performance.","Machine learning models often fail in the real world because the data distribution they rely on keeps changing, for example due to shifting environments or behaviors. This problem is known as evolving domain generalization (EDG). We find that many existing EDG methods fall into the trap of learning shortcuts—misleading patterns that seem useful but break under changing conditions, leading to poor generalization in dynamic environments.To fix this, we introduce a new causal model that describes how data distribution evolves over time in dynamic situations. On this basis, we develop a static-dynamic causal representation learning method that teaches models to recognize both stable and changing causes, allowing the model to learn to focus on what really causes outcomes, not just what appears correlated.By filtering out misleading patterns and highlighting what really matters, our method significantly improves a model’s ability to generalize across time. This research brings us closer to building AI systems that remain reliable and effective even as the world around them changes."
Poster,Learning Time-Varying Multi-Region Brain Communications  via Scalable Markovian Gaussian Processes,https://ICML.cc//virtual/2025/poster/44011,"Weihan Li, Yule Wang, Chengrui Li, Anqi Wu","Understanding and constructing brain communications that capture dynamic communications across multiple regions is fundamental to modern system neuroscience, yet current methods struggle to find time-varying region-level communications or scale to large neural datasets with long recording durations. We present a novel framework using Markovian Gaussian Processes to learn brain communications with time-varying temporal delays from multi-region neural recordings, named Adaptive Delay Model (ADM). Our method combines Gaussian Processes with State Space Models and employs parallel scan inference algorithms, enabling efficient scaling to large datasets while identifying concurrent  communication patterns that evolve over time. This time-varying approach captures how brain region interactions shift dynamically during cognitive processes. Validated on synthetic and multi-region neural recordings datasets, our approach discovers both the directionality and temporal dynamics of neural communication. This work advances our understanding of distributed neural computation and provides a scalable tool for analyzing dynamic brain networks. Code is available at https://github.com/BRAINML-GT/Adaptive-Delay-Model.","Our brains are made up of many regions that constantly exchange information. But this communication isn’t static because it shifts over time, especially during tasks like seeing or thinking. Existing tools often miss these subtle timing changes or are too slow for analyzing large brain datasets.To solve this, we developed a new method called the Adaptive Delay Model (ADM). ADM uses a combination of Gaussian Processes and State Space Models to detect not just who is talking to whom in the brain, but also when they’re doing it, with precise timing that changes over time. It’s also designed to be fast, so it can handle modern, large-scale brain recordings.We applied ADM to both simulated data and real recordings from mice and monkeys and found that it revealed dynamic patterns of brain communication that match known brain hierarchies. This opens the door to deeper understanding of how brain regions coordinate during perception, thought, or even disease, and could eventually help improve brain-computer interfaces or treatments for neurological conditions."
Poster,Learning to Generate Projections for Reducing Dimensionality of Heterogeneous Linear Programming Problems,https://ICML.cc//virtual/2025/poster/45568,"Tomoharu Iwata, Shinsaku Sakaue","We propose a data-driven method for reducing the dimensionality of linear programming problems (LPs) by generating instance-specific projection matrices using a neural network-based model. Once the model is trained using multiple LPs by maximizing the expected objective value, we can efficiently find high-quality feasible solutions of newly given LPs. Our method can shorten the computational time of any LP solvers due to its solver-agnostic nature, it can provide feasible solutions by relying on projection that reduces the number of variables, and it can handle LPs of different sizes using neural networks with permutation equivariance and invariance. We also provide a theoretical analysis of the generalization bound for learning a neural network to generate projection matrices that reduce the size of LPs. Our experimental results demonstrate that our method can obtain solutions with higher quality than the existing methods, while its computational time is significantly shorter than solving the original LPs.","We propose a method for more efficiently solving a class of optimization problems, specifically linear programming problems. Our approach uses a neural network to learn how to simplify these problems. Once trained, the model can quickly give good solutions to new problems without solving them from scratch."
Poster,Learning to Incentivize in Repeated Principal-Agent Problems with Adversarial Agent Arrivals,https://ICML.cc//virtual/2025/poster/46490,"Junyan Liu, ARNAB MAITI, Artin Tajdini, Kevin Jamieson, Lillian Ratliff","We initiate the study of a repeated principal-agent problem over a finite horizon $T$, where a principal sequentially interacts with $K\geq 2$ types of agents arriving in an *adversarial* order. At each round, the principal strategically chooses one of the $N$ arms to incentivize for an arriving agent of *unknown type*.  The agent then chooses an arm based on its own utility and the provided incentive, and the principal receives a corresponding reward. The objective is to minimize regret against the best incentive in hindsight. Without prior knowledge of agent behavior, we show that the problem becomes intractable, leading to linear regret. We analyze two key settings where sublinear regret is achievable. In the first setting, the principal knows the arm each agent type would select greedily for any given incentive. Under this setting, we propose an algorithm that achieves a regret bound of $\mathcal{O}(\min(\sqrt{KT\log N},K\sqrt{T}))$ and provide a matching lower bound up to a $\log K$ factor. In the second setting, an agent's response varies smoothly with the incentive and is governed by a Lipschitz constant $L$. Under this setting, we show that there is an algorithm with a regret bound of $\tilde{\mathcal{O}}((LN)^{1/3}T^{2/3})$ and establish a matching lower bound up to logarithmic factors. Finally, we extend our algorithmic results for both settings by allowing the principal to incentivize multiple arms simultaneously in each round.","Imagine you're a seller trying to convince a stream of customers—each with different preferences—to buy one of several products. You don’t know their exact preferences, and they’re arriving in an unpredictable order. In each interaction, you can offer incentives (like discounts) to influence their choice, but you only get to see what they pick and how well it worked. How should you adapt your strategy over time to get the best overall outcome? In our work, we study this problem through the lens of machine learning and economics, modeling it as a repeated principal-agent problem. We show that if you have no information about how customers respond to incentives, the problem is too hard to solve well. But with a little structure—like knowing how different customer types behave in general, or assuming their behavior changes smoothly with incentives—we design algorithms that learn how to offer better incentives over time, with performance guarantees that get better as more interactions happen. Our results also extend to situations where multiple products can be incentivized at once."
Poster,Learning to Keep a Promise: Scaling Language Model Decoding Parallelism with Learned Asynchronous Decoding,https://ICML.cc//virtual/2025/poster/44837,"Tian Jin, Ellie Cheng, Zachary Ankner, Nikunj Saunshi, Blake Elias, Amir Yazdanbakhsh, Jonathan Ragan-Kelley, Suvinay Subramanian, Michael Carbin","Decoding with autoregressive language models traditionally occurs sequentially, generating one token after another. Recent attempts to introduce parallelism require a pre-determined structure in the generated content to implement parallel generation, such as by pattern-matching on bullet points. In this work, we present a new technique to automate parallel generation by dynamically exploiting the semantic independence of generation outputs to implement asynchronous decoding. We introduce an annotation language Pasta-Lang for language models to initiate asynchronous decoding at inference time. We also develop an accompanying Pasta-Lang interpreter that performs on-the-fly asynchronous decoding, effectively implementing parallel generation and speeding up inference. We present an instruction-finetuning dataset with Pasta-Lang-annotated responses for teaching LLMs to annotate semantic independence with Pasta-Lang as well as the methodology for creating the dataset. Our evaluation shows using the interpreter with a Pasta-Lang-equipped model achieves significant speedup while maintaining the same generation quality.","Most language models write left-to-right, even when different parts of the reply do not depend on each other. PASTA trains the model to tag those independent spans while it is composing. A lightweight interpreter reads the tags, fires off several decoding threads in parallel, and then stitches the finished chunks back into place. This parallel decoding technique largely preserves answer quality while delivering 1.2 ×–1.9 × faster responses. Crucially, the model itself—not hand-written rules—decides what can run in parallel. The approach opens a simple route to faster text generation."
