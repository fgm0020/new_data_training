type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Quadratic Upper Bound for Boosting Robustness,https://ICML.cc//virtual/2025/poster/44505,"Euijin You, Hyang-Won Lee","Fast adversarial training (FAT) aims to enhance the robustness of models against adversarial attacks with reduced training time, however, FAT often suffers from compromised robustness due to insufficient exploration of adversarial space. In this paper, we develop a loss function to mitigate the problem of degraded robustness under FAT. Specifically, we derive a quadratic upper bound (QUB) on the adversarial training (AT) loss function and propose to utilize the bound with existing FAT methods. Our experimental results show that applying QUB loss to the existing methods yields significant improvement of robustness. Furthermore, using various metrics, we demonstrate that this improvement is likely to result from the smoothened loss landscape of the resulting model.","Modern AI systems can recognize images with high accuracy, but they can be easily fooled by tiny, almost invisible changes to the image — a trick known as an *adversarial attack*. This poses serious safety concerns for real-world applications.To defend against such attacks, a common approach is *adversarial training*, where the model learns from both clean and slightly altered images. However, faster training methods often use weaker attacks that don’t fully prepare the model for stronger, more dangerous ones.Our research proposes a new mathematical method that makes models more robust, even against attacks they haven't seen before. We adjust the way the model learns from difficult examples by focusing on worst-case situations. This leads to better protection against strong attacks.Importantly, our method maintains the time efficiency of fast training approaches while significantly enhancing robustness. It can also be applied to many existing systems, offering a practical way to improve the safety of AI without significant training delays."
Poster,Quadruple Attention in Many-body Systems for Accurate Molecular Property Predictions,https://ICML.cc//virtual/2025/poster/44950,"Jiahua Rao, Dahao Xu, Wentao Wei, Yicong Chen, Mingjun Yang, Yuedong Yang","While Graph Neural Networks and Transformers have shown promise in predicting molecular properties, they struggle with directly modeling complex many-body interactions. Current methods often approximate interactions like three- and four-body terms in message passing, while attention-based models, despite enabling direct atom communication, are typically limited to triplets, making higher-order interactions computationally demanding. To address the limitations, we introduce MABNet, a geometric attention framework designed to model four-body interactions by facilitating direct communication among atomic quartets. This approach bypasses the computational bottlenecks associated with traditional triplet-based attention mechanisms, allowing for the efficient handling of higher-order interactions. MABNet achieves state-of-the-art performance on benchmarks like MD22 and SPICE. These improvements underscore its capability to accurately capture intricate many-body interactions in large molecules. By unifying rigorous many-body physics with computational efficiency, MABNet advances molecular simulations for applications in drug design and materials discovery, while its extensible framework paves the way for modeling higher-order quantum effects.","Predicting molecular properties is crucial for advancements in drug discovery and materials science. However, current computational methods face challenges in accurately capturing complex interactions between multiple atoms, especially when these interactions involve more than three atoms. To overcome this, we developed MABNet, a novel framework that introduces a new way for atoms to communicate directly in groups of four. This innovation allows our model to better understand and simulate intricate molecular behaviors without the usual computational hurdles. By achieving state-of-the-art results on key benchmarks, MABNet demonstrates its potential to enhance molecular simulations and accelerate discoveries in chemistry and biology."
Poster,Quamba2: A Robust and Scalable Post-training Quantization Framework for Selective State Space Models,https://ICML.cc//virtual/2025/poster/44833,"Hung-Yueh Chiang, Chi-Chih Chang, Natalia Frumkin, Kai-Chiang Wu, Mohamed Abdelfattah, Diana Marculescu","State Space Models (SSMs) are gaining attention as an efficient alternative to Transformers due to their constant memory complexity and comparable performance. Yet, deploying large-scale SSMs on cloud-based services or resource-constrained devices faces challenges. To address this, quantizing SSMs using low bit-width data types is proposed to reduce model size and leverage hardware acceleration. Given that SSMs are sensitive to quantization errors, recent advancements focus on quantizing a specific model or bit-width to improve their efficiency while maintaining performance. However, different bit-width configurations, such as W4A8 for cloud service throughput and W4A16 for improving question-answering on personal devices, are necessary for specific scenarios.To this end, we present Quamba2, compatible with \textbf{W8A8}, \textbf{W4A8}, and \textbf{W4A16} for both \textbf{Mamba} and \textbf{Mamba2}, addressing the rising demand for SSM deployment across various platforms. We propose an offline approach to quantize inputs of a linear recurrence in 8-bit by sorting and clustering for $x$, combined with a per-state-group quantization for $B$ and $C$. To ensure compute-invariance in the SSM output, we offline rearrange weights according to the clustering sequence. The experiments show Quamba2-8B outperforms several state-of-the-art SSMs quantization methods and delivers 1.3$\times$ and 3$\times$ speedup in the pre-filling and generation stages and 4$\times$ memory reduction with only a $1.6$% accuracy drop on average. The code and quantized models will be released at:","Large AI models are powerful but often too big and slow to run efficiently on everyday devices or even in the cloud. State Space Models (SSMs) are a newer type of AI model that use memory more efficiently than the popular Transformer models, making them a promising option. However, running these models quickly and on different hardware remains a challenge.Our work introduces Quamba2, a method that makes these models smaller and faster by converting their numbers into simpler, lower-precision formats. This helps the models run better on everything from cloud servers to personal laptops, depending on the task. Quamba2 supports several precision levels, so it can balance speed and accuracy depending on where it’s used.We tested Quamba2 on large models and found it could cut memory use by up to 4× and speed up responses significantly, with only a small drop in performance. This brings us closer to making powerful AI models work smoothly across a wide range of platforms. Our code and models will be shared with the community."
Poster,QuanONet: Quantum Neural Operator with Application to Differential Equation,https://ICML.cc//virtual/2025/poster/44463,"Ruocheng Wang, Zhuo Xia, Ge Yan, Junchi Yan","Differential equations are essential and popular in science and engineering. Learning-based methods including neural operators, have emerged as a promising paradigm. We explore its quantum counterpart, and propose QuanONet -- a quantum neural operator which has not been well studied in literature compared with their counterparts in other machine learning areas. We design a novel architecture as a hardware-efficient ansatz, in the era of noisy intermediate-scale quantum (NISQ). Its circuit is pure quantum. By lying its ground on the operator approximation theorem for its quantum counterpart, QuanONet in theory can fit various differential equation operators. We also propose its modified version TF-QuanONet with ability to adaptively fit the dominant frequency of the problem. The real-device empirical results on problems including anti-derivative operators, Diffusion-reaction Systems demonstrate that QuanONet outperforms peer quantum methods when their model sizes are set akin to QuanONet.","Differential equations are like mathematical recipes that describe how things change over time or space — from the weather and fluid flow to biological processes and engineering systems. Traditionally, solving these equations can be slow and complicated, especially for complex problems.Recently, new learning methods inspired by artificial intelligence have shown promise in speeding up and improving these solutions. Our work takes this idea a step further by exploring how quantum computers — powerful machines that use the strange rules of quantum physics — can help solve these equations even more efficiently.We introduce QuanONet, a new kind of quantum-based learning model designed specifically for this task. It’s built to work well with today’s early quantum devices, which are still limited but rapidly improving. Our approach allows QuanONet to learn and predict solutions to a wide variety of differential equations. We also developed an improved version called TF-QuanONet, which can automatically focus on the most important features of the problem for better accuracy.Testing our models showed that QuanONet outperforms other similar quantum approaches, demonstrating a promising step toward practical quantum-enhanced scientific computing."
Poster,Quantifying Memory Utilization with Effective State-Size,https://ICML.cc//virtual/2025/poster/44915,"Rom N. Parnichkun, Neehal Tumma, Armin Thomas, Alessandro Moro, Qi An, Taiji Suzuki, Atsushi Yamashita, Michael Poli, Stefano Massaroli","As the space of causal sequence modeling architectures continues to grow, the need to develop a general framework for their analysis becomes increasingly important. With this aim, we draw insights from classical signal processing and control theory, to develop a quantitative measure of *memory utilization*: the internal mechanisms through which a model stores past information to produce future outputs. This metric, which we call ***effective state-size*** (ESS), is tailored to the fundamental class of systems with *input-invariant* and *input-varying linear operators*, encompassing a variety of computational units such as variants of attention, convolutions, and recurrences. Unlike prior work on memory utilization, which either relies on raw operator visualizations (e.g. attention maps), or simply the total *memory capacity* (i.e. cache size) of a model, our metrics provide highly interpretable and actionable measurements. In particular, we show how ESS can be leveraged to improve initialization strategies, inform novel regularizers and advance the performance-efficiency frontier through model distillation. Furthermore, we demonstrate that the effect of context delimiters (such as end-of-speech tokens) on ESS highlights cross-architectural differences in how large language models utilize their available memory to recall information. Overall, we find that ESS provides valuable insights into the dynamics that dictate memory utilization, enabling the design of more efficient and effective sequence models.","As models that process sequences (like text or speech) become more complex, it’s increasingly important to understand how they “remember” and ""utilize"" past information to generate accurate future outputs. This research introduces a tool derived from signal processing and control theory called ***Effective State-Size*** (ESS) that measures how efficiently a model uses its internal memory.Unlike older methods that just look at visual patterns or how much memory a model has, ESS offers a more theoretically grounded way to analyze memory use. We show that ESS can help in several ways: designing better model starting points (initializations), creating new training techniques (regularizers), and making models faster and more efficient through distillation. We also find that ESS reveals how different models respond to context cues (like end-of-sentence tokens), giving insight into their memory utilization patterns."
Poster,Quantifying Prediction Consistency Under Fine-tuning Multiplicity in Tabular LLMs,https://ICML.cc//virtual/2025/poster/46165,"Faisal Hamman, Sachindra P Dissanayake, Saumitra Mishra, Freddy Lecue, Sanghamitra Dutta","Fine-tuning LLMs on tabular classification tasks can lead to the phenomenon of *fine-tuning multiplicity* where equally well-performing models make conflicting predictions on the same input. Fine-tuning multiplicity can arise due to variations in the training process, e.g., seed, weight initialization, minor changes to training data, etc., raising concerns about the reliability of Tabular LLMs in high-stakes applications such as finance, hiring, education, healthcare. Our work formalizes this unique challenge of fine-tuning multiplicity in Tabular LLMs and proposes a novel measure to quantify the consistency of individual predictions without expensive model retraining. Our measure quantifies a prediction's consistency by analyzing (sampling) the model's local behavior around that input in the embedding space. Interestingly, we show that sampling in the local neighborhood can be leveraged to provide probabilistic guarantees on prediction consistency under a broad class of fine-tuned models, i.e., inputs with sufficiently high local stability (as defined by our measure) also remain consistent across several fine-tuned models with high probability. We perform experiments on multiple real-world datasets to show that our local stability measure preemptively captures consistency under actual multiplicity across several fine-tuned models, outperforming competing measures.","Tabular large language models (TabLLMs) are increasingly used in high-stakes areas like finance, education, and healthcare, where we expect predictions to be reliable. But surprisingly, even small changes during training, like using a different random seed, weight initialization, or minor changes to training data, can lead to different results for the same input. This is a big problem when important decisions are at stake.Our research shows that this unpredictability - what we call fine-tuning multiplicity - is common in TabLLMs. We introduce a novel method to measure how consistent a model’s prediction is under fine-tuning multiplicity without needing to retrain our model multiple times. We leverage the the model behavior in the “neighborhood” around an input, using our local stability measure, to estimate how likely a prediction is to stay consistent.Our approach can help identify which predictions are trustworthy and which might change if the model were retrained. It’s a step toward more reliable AI in high-stakes settings."
Poster,Quantifying Treatment Effects: Estimating Risk Ratios via Observational Studies,https://ICML.cc//virtual/2025/poster/45747,"Ahmed Boughdiri, julie Josse, Erwan Scornet","The Risk Difference (RD), an absolute measure of effect, is widely used and well-studied in both randomized controlled trials (RCTs) and observational studies. Complementary to the RD, the Risk Ratio (RR), as a relative measure, is critical for a comprehensive understanding of intervention effects: RD can downplay small absolute changes, while RR can highlight them. Despite its significance, the theoretical study of RR has received less attention, particularly in observational settings. This paper addresses this gap by tackling the estimation of RR in observational data. We propose several RR estimators and establish their theoretical properties, including asymptotic normality and confidence intervals. Through analyses on simulated and real-world datasets, we evaluate the performance of these estimators in terms of bias, efficiency, and robustness to generative data models. We also examine the coverage and length of the associated confidence intervals. Due to the non-linear nature of RR, influence function theory yields two distinct efficient estimators with different convergence assumptions. Based on theoretical and empirical insights, we recommend, among all estimators, one of the two doubly-robust estimators, which, intriguingly, challenges conventional expectations.","Causal inference is a field of research that helps scientists and doctors figure out whether a treatment or intervention actually causes a change in people’s health, rather than just being linked to it by coincidence. One commonly used way to measure the effect of a treatment is the Risk Ratio, which compares how likely an outcome (e.g., getting sick) is between two groups such as those who received a treatment and those who did not. We examine methods for estimating the Risk Ratio when using data from real-world settings, where treatments are not randomly assigned to people. We also look closely at what happens to these estimates as the number of people in the study gets very large."
Poster,QuantSpec: Self-Speculative Decoding with Hierarchical Quantized KV Cache,https://ICML.cc//virtual/2025/poster/46326,"Rishabh Tiwari, Haocheng Xi, Aditya Tomar, Coleman Hooper, Sehoon Kim, Maxwell Horton, Mahyar Najibi, Michael Mahoney, Kurt Keutzer, Amir Gholaminejad","Large Language Models (LLMs) are increasingly being deployed on edge devices for long-context settings, creating a growing need for fast and efficient long-context inference. In these scenarios, the Key-Value (KV) cache is the primary bottleneck in terms of both GPU memory and latency, as the full KV cache must be loaded for each decoding step. While speculative decoding is a widely accepted technique to accelerate autoregressive decoding, existing methods often struggle to achieve significant speedups due to inefficient KV cache optimization strategies and result in low acceptance rates. To address these challenges, we propose a novel self-speculative decoding framework, QuantSpec, where the draft model shares the architecture of the target model but employs a hierarchical 4-bit quantized KV cache and 4-bit quantized weights for acceleration. QuantSpec maintains high acceptance rates ($>$90\%) and reliably provides consistent end-to-end speedups upto $\sim2.5\times$, outperforming other self-speculative decoding methods that use sparse KV cache for long-context LLM inference. QuantSpec also reduces the memory requirements by $\sim 1.3\times$ compared to these alternatives.","Running large language models (LLMs) on devices like phones or laptops is becoming more common, especially for tasks that involve long conversations or documents. However, this is slow and memory-intensive, mainly because the model needs to repeatedly access a large memory cache at each step. We introduce QuantSpec, a new method that speeds up this process by using a smaller, compressed version of the model’s memory, without sacrificing quality. By using a lightweight version of the model to make fast guesses and then checking them with the full model, QuantSpec achieves up to 2.5× faster performance and reduces memory use by 1.3×, while still getting accurate results most of the time."
Poster,Quantum Algorithms for Finite-horizon Markov Decision Processes,https://ICML.cc//virtual/2025/poster/43760,"Bin Luo, Yuwen Huang, Jonathan Allcock, Xiaojun Lin, Shengyu Zhang, John C. S. Lui","In this work, we design quantum algorithms that are more efficient than classical algorithms to solve time-dependent and finite-horizon Markov Decision Processes (MDPs) in two distinct settings: (1) In the exact dynamics setting, where the agent has full knowledge of the environment's dynamics (i.e., transition probabilities), we prove that our **Quantum Value Iteration (QVI)** algorithm **QVI-1** achieves a quadratic speedup in the size of the action space $(A)$ compared with the classical value iteration algorithm for computing the optimal policy ($\pi^{\ast}$) and the optimal V-value function ($V_{0}^{\ast}$). Furthermore, our algorithm **QVI-2** provides an additional speedup in the size of the state space $(S)$ when obtaining near-optimal policies and V-value functions. Both **QVI-1** and **QVI-2** achieve quantum query complexities that provably improve upon classical lower bounds, particularly in their dependences on $S$ and $A$. (2) In the generative model setting, where samples from the environment are accessible in quantum superposition, we prove that our algorithms **QVI-3** and **QVI-4** achieve improvements in sample complexity over the state-of-the-art (SOTA) classical algorithm in terms of $A$, estimation error $(\epsilon)$, and time horizon $(H)$. More importantly, we prove quantum lower bounds to show that **QVI-3** and **QVI-4** are asymptotically optimal, up to logarithmic factors, assuming a constant time horizon.","Markov Decision Processes (MDPs) help model how agents make decisions over time in uncertain environments—from robots navigating rooms to systems managing resources. However, solving these problems becomes increasingly hard as the number of choices (actions) or situations (states) grows. Our work uses quantum computing to tackle this challenge more efficiently than classical methods. We design four quantum algorithms that solve MDPs faster in two important scenarios: when the agent knows exactly how the world works (exact dynamics model) and when it only learns by interacting with it (generative model). These quantum algorithms offer provable speedups in key parameters, including the number of actions, states, total time horizon, and the desired solution accuracy. Our theoretical analysis shows that our quantum speedups are near the best possible, and that exponential quantum speedups are impossible. Our results provide a step toward practical quantum speedups for reinforcement learning and stochastic control problems."
Poster,Quantum Optimization via Gradient-Based Hamiltonian Descent,https://ICML.cc//virtual/2025/poster/43703,"Jiaqi Leng, Bin Shi","With rapid advancements in machine learning, first-order algorithms have emerged as the backbone of modern optimization techniques, owing to their computational efficiency and low memory requirements. Recently, the connection between accelerated gradient methods and damped heavy-ball motion, particularly within the framework of Hamiltonian dynamics, has inspired the development of innovative quantum algorithms for continuous optimization. One such algorithm, Quantum Hamiltonian Descent (QHD), leverages quantum tunneling to escape saddle points and local minima, facilitating the discovery of global solutions in complex optimization landscapes. However, QHD faces several challenges, including slower convergence rates compared to classical gradient methods and limited robustness in highly non-convex problems due to the non-local nature of quantum states. Furthermore, the original QHD formulation primarily relies on function value information, which limits its effectiveness. Inspired by insights from high-resolution differential equations that have elucidated the acceleration mechanisms in classical methods, we propose an enhancement to QHD by incorporating gradient information, leading to what we call gradient-based QHD. This gradient-based QHD achieves faster convergence and significantly increases the likelihood of identifying global solutions. Numerical simulations on challenging problem instances demonstrate that this gradient-based QHD outperforms existing quantum and classical methods by at least an order of magnitude.","In machine learning, we often need to find the lowest point of a complex function, a bit like finding the bottom of a tricky valley. This is called continuous optimization. Traditional methods are good at this, but they can sometimes get stuck in ""local minima""—spots that seem like the lowest point but aren't the absolute deepest. With quantum computing emerging as a powerful new tool, we wanted to see if these futuristic machines could help us find those true lowest points more effectively.Our paper shares an exciting discovery: by adding ""gradient information"" (which tells us the steepest way down the valley) to existing quantum methods, these algorithms can perform much better on tough optimization problems. Our new approach, called gradient-based Quantum Hamiltonian Descent, finds the actual lowest point much faster and more reliably.These findings open up new possibilities for designing quantum optimization algorithms. They also suggest that quantum computers could play a big role in speeding up how we train machine learning models in the future."
