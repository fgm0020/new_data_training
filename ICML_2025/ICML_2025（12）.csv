type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,A Forget-and-Grow Strategy for Deep Reinforcement Learning Scaling in Continuous Control,https://ICML.cc//virtual/2025/poster/45054,"Zilin Kang, Chenyuan Hu, Yu Luo, Zhecheng Yuan, Ruijie Zheng, Huazhe Xu","Deep reinforcement learning for continuous control has recently achieved impressive progress. However, existing methods often suffer from primacy bias—a tendency to overfit early experiences stored in the replay buffer—which limits an RL agent’s sample efficiency and generalizability. A common existing approach to mitigate this issue is periodically resetting the agent during training. Yet, even after multiple resets, RL agents could still be impacted by early experiences. In contrast, humans are less susceptible to such bias, partly due to *infantile amnesia*, where the formation of new neurons disrupts early memory traces, leading to the forgetting of initial experiences. Inspired by this dual processes of forgetting and growing in neuroscience, in this paper, we propose *Forget and Grow* (**FoG**), a new deep RL algorithm with two mechanisms introduced. First, *Experience Replay Decay (ER Decay)*—""forgetting early experience''—which balances memory by gradually reducing the influence of early experiences. Second, *Network Expansion*—""growing neural capacity''—which enhances agents' capability to exploit the patterns of existing data by dynamically adding new parameters during training. Empirical results on four major continuous control benchmarks with more than 40 tasks demonstrate the superior performance of **FoG** against SoTA existing deep RL algorithms, including BRO, SimBa and TD-MPC2.","AI systems learning to control robots, like those for movement or grasping objects, often get stuck on their initial experiences. These early ""memories"" are replayed so much they can prevent the AI from fully using newer lessons, trapping it in old habits.To tackle this, we developed ""Forget and Grow"" (FoG), a method inspired by human learning. FoG has two key features: first, it gradually lessens the influence of early experiences, much like humans forget their infant memories, preventing them from becoming overly dominant. Second, it dynamically increases the AI's learning capacity – its ""brain"" makes new connections during training, enabling it to better handle new tasks.Our tests on various robotic control tasks show that FoG significantly improves learning efficiency and adaptability, helping AIs learn better and faster."
Poster,AGAV-Rater: Adapting Large Multimodal Model for AI-Generated Audio-Visual Quality Assessment,https://ICML.cc//virtual/2025/poster/43704,"Yuqin Cao, Xiongkuo Min, Yixuan Gao, Wei Sun, Guangtao Zhai","Many video-to-audio (VTA) methods have been proposed for dubbing silent AI-generated videos. An efficient quality assessment method for AI-generated audio-visual content (AGAV) is crucial for ensuring audio-visual quality. Existing audio-visual quality assessment methods struggle with unique distortions in AGAVs, such as unrealistic and inconsistent elements. To address this, we introduce **AGAVQA-3k**, the first large-scale AGAV quality assessment dataset, comprising $3,382$ AGAVs from $16$ VTA methods. AGAVQA-3k includes two subsets: AGAVQA-MOS, which provides multi-dimensional scores for audio quality, content consistency, and overall quality, and AGAVQA-Pair, designed for optimal AGAV pair selection. We further propose **AGAV-Rater**, a LMM-based model that can score AGAVs, as well as audio and music generated from text, across multiple dimensions, and selects the best AGAV generated by VTA methods to present to the user. AGAV-Rater achieves state-of-the-art performance on AGAVQA-3k, Text-to-Audio, and Text-to-Music datasets. Subjective tests also confirm that AGAV-Rater enhances VTA performance and user experience. The dataset and code is available at https://github.com/charlotte9524/AGAV-Rater.","Can LMMs be utilized to evaluate the quality of audio-visual content (AGAV) generated by video-to-audio (VTA) methods? Our goal is to adapt LMMs to score AGAVs like humans.We introduce AGAVQA-3k, the first large-scale AGAV quality assessment dataset, comprising 3,382 AGAVs from 16 VTA methods. We further propose AGAV-Rater, an LMM-based model that can score AGAVs, as well as audio and music generated from text, across multiple dimensions. Remarkably, AGAV-Rater achieves state-of-the-art performance and can help VTA methods select the highest-quality AGAVs to present to users.Our research contributes to the study of AGAVs' perceptual quality and demonstrates its potential for supervising and controlling the quality of AGAVs."
Poster,A General Framework for Inference-time Scaling and Steering of Diffusion Models,https://ICML.cc//virtual/2025/poster/45673,"Raghav Singhal, Zachary Horvitz, Ryan Teehan, Mengye Ren, Zhou Yu, Kathleen McKeown, Rajesh Ranganath","Diffusion models have demonstrated remarkable performance in generative modeling, but generating samples with specific desiderata remains challenging. Existing solutions --- such as fine-tuning,  best-of-n sampling, and gradient-based guidance --- are expensive, inefficient, or limited in applicability. In this work, we propose FK steering, a framework for inference-time steering diffusion models with reward functions. In this work, we introduce FK steering, which applies Feynman-Kac interacting particle systems to the inference-time steering of diffusion models with arbitrary reward functions. FK steering works by generating multiple trajectories, called particles, and resampling particles at intermediate steps based on scores computed using functions called potentials. Potentials are defined using rewards for intermediate states and are chosen such that a high score indicates the particle will yield a high-reward sample. We explore various choices of potentials, rewards, and samplers. Steering text-to-image models with a human preference reward, we find that FK steering outperforms fine-tuned models with just 2 particles. Moreover, FK steering a 0.8B parameter model outperforms a 2.6B model, achieving state-of-the-art performance on prompt fidelity. We also steer text diffusion models with rewards for text quality and rare attributes such as toxicity, and find that FK steering generates lower perplexity text and enables gradient-free control.  Overall, inference-time scaling and steering of diffusion models, even training-free, provides significant quality and controllability benefits. Code available [here](https://github.com/zacharyhorvitz/FK-Diffusion-Steering).","Recently, AI systems have become increasingly effective at generating text, images, videos, and even new potential treatments for disease. Diffusion models have been a highly successful approach for these settings. However, getting diffusion models to produce exactly what a particular user wants can be challenging. One way to do this is to retrain a model, but this is slow, requires training resources, and may not work in many cases. This paper introduces Feynman-Kac (FK) steering, an approach that guides the model while it's generating outputs, using a scoring system to keep only the most promising candidates. It doesn’t require any additional training and works by generating multiple candidates in parallel and favoring the ones more likely to meet the desired goal. The method performs surprisingly well. We show that FK steering improves models for image and text generation. Notably, small models using FK steering can outperform larger models using fewer resources. In sum, FK steering offers an efficient and flexible way to control AI-generated content."
Poster,A General Graph Spectral Wavelet Convolution via Chebyshev Order Decomposition,https://ICML.cc//virtual/2025/poster/45116,"Nian Liu, Xiaoxin He, Thomas Laurent, Francesco Di Giovanni, Michael Bronstein, Xavier Bresson","Spectral graph convolution, an important tool of data filtering on graphs, relies on two essential decisions: selecting spectral bases for signal transformation and parameterizing the kernel for frequency analysis. While recent techniques mainly focus on standard Fourier transform and vector-valued spectral functions, they fall short in flexibility to model signal distributions over large spatial ranges, and capacity of spectral function. In this paper, we present a novel wavelet-based graph convolution network, namely WaveGC, which integrates multi-resolution spectral bases and a matrix-valued filter kernel. Theoretically, we establish that WaveGC can effectively capture and decouple short-range and long-range information, providing superior filtering flexibility, surpassing existing graph wavelet neural networks. To instantiate WaveGC, we introduce a novel technique for learning general graph wavelets by separately combining odd and even terms of Chebyshev polynomials. This approach strictly satisfies wavelet  admissibility criteria. Our numerical experiments showcase the consistent improvements in both short-range and long-range tasks. This underscores the effectiveness of the proposed model in handling different scenarios.","Graphs are a powerful way to represent complex systems — from molecules and transportation networks to social interactions. A key challenge in machine learning is teaching models to recognize patterns on these graphs, especially across both local and global structures.In this work, we introduce WaveGC, a new method for learning on graphs using wavelets — mathematical tools that can capture information at multiple scales. Traditional graph learning methods often rely on fixed mathematical bases and limited filters. WaveGC instead learns flexible, multi-resolution wavelet bases tailored to the structure of each graph, enabling it to more effectively process both short-range and long-range interactions.We achieve this by decomposing the mathematical building blocks (Chebyshev polynomials) into two components that separately handle broad background patterns and detailed variations. This design satisfies key mathematical criteria for wavelets and allows for efficient learning.WaveGC consistently outperforms existing techniques across diverse graph learning tasks, from classifying scientific datasets to analyzing large-scale networks. Our work improves the ability of machine learning systems to make sense of structured, interconnected data."
Poster,A Generalizable Physics-Enhanced State Space Model for Long-Term Dynamics Forecasting in Complex Environments,https://ICML.cc//virtual/2025/poster/46230,"Yuchen Wang, Hongjue Zhao, Haohong Lin, Enze Xu, Lifang He, Huajie Shao","This work aims to address the problem of long-term dynamic forecasting in complex environments where data are noisy and irregularly sampled. While recent studies have introduced some methods to improve prediction performance, these approaches still face a significant challenge in handling long-term extrapolation tasks under such complex scenarios. To overcome this challenge, we propose Phy-SSM, a general-purpose framework that integrates partial physics knowledge into state space models (SSMs) for long-term dynamics forecasting in complex environments. Our motivation is that SSMs can effectively capture long-range dependencies in sequential data and model continuous dynamical systems, while the incorporation of physics knowledge improves generalization ability. The key challenge lies in how to seamlessly incorporate partially known physics into SSMs. To achieve this, we decompose partially known system dynamics into known and unknown state matrices, which are integrated into a Phy-SSM unit. To further enhance long-term prediction performance, we introduce a physics state regularization term to make the estimated latent states align with system dynamics. Besides, we theoretically analyze the uniqueness of the solutions for our method. Extensive experiments on three real-world applications, including vehicle motion prediction, drone state prediction, and COVID-19 epidemiology forecasting, demonstrate the superior performance of Phy-SSM over the baselines in both long-term interpolation and extrapolation tasks. The source code will be publicly available upon publication.","Predicting how systems evolve over time — such as the motion of cars and drones, or the spread of disease — is challenging in real-world settings, especially when data is noisy and our understanding of the underlying physics is incomplete. We wondered: can we still make accurate predictions using only partial knowledge of the physical system?To tackle this, we developed Phy-SSM — a method that seamlessly combines partially known physics with a deep state space model, a type of AI that excels at learning from time series data. Our key innovation is to explicitly separate the known and unknown parts of the physical system, then merge them in a unified framework that helps the model learn the true system dynamics. Surprisingly, we found that even incomplete physics knowledge can significantly improve the model’s ability to generalize for long-term predictions on unseen data.Phy-SSM allows users to easily incorporate partial physics knowledge into different systems to make more accurate forecasts. Our research highlights the potential of combining traditional physics with modern AI to tackle real-world prediction challenges."
Poster,A Generalization Result for Convergence in Learning-to-Optimize,https://ICML.cc//virtual/2025/poster/45367,"Michael Sucker, Peter Ochs","Learning-to-optimize leverages machine learning to accelerate optimization algorithms. While empirical results show tremendous improvements compared to classical optimization algorithms, theoretical guarantees are mostly lacking, such that the outcome cannot be reliably assured. Especially, convergence is hardly studied in learning-to-optimize, because conventional convergence guarantees in optimization are based on geometric arguments, which cannot be applied easily to learned algorithms. Thus, we develop a probabilistic framework that resembles classical optimization and allows for transferring geometric arguments into learning-to-optimize. Based on our new proof-strategy, our main theorem is a generalization result for parametric classes of potentially non-smooth, non-convex loss functions and establishes the convergence of learned optimization algorithms to critical points with high probability. This effectively generalizes the results of a worst-case analysis into a probabilistic framework, and frees the design of the learned algorithm from using safeguards.","Traditional optimization algorithms can be slow, so we aim to accelerate them by using machine learning. However, learned algorithms can make mistakes, while traditional ones provably work in the intended way. To “work in the intended way” means that if we run the algorithm for a long enough time, its final output gets closer and closer to a point that can serve as a solution to the optimization problem - technically called “convergence”. This type of behavior is hard to prove for learned algorithms, because they are trained on a data set and might over-adapt to it. Additionally, known results from the optimization literature do not apply to this setting. Thus, we tackle this problem from a new, statistical perspective and show that it is highly likely that, if the algorithm does work in the intended way during training, it will also do so on unseen problems - technically called “generalization”. Even more so, while our paper exemplifies the underlying idea for the problem of convergence in learning-to-optimize, our new proof-strategy applies more generally to algorithms that obey a certain structural property and allows for showing that their overall behavior generalizes from training to test data."
Poster,A Generalization Theory for Zero-Shot Prediction,https://ICML.cc//virtual/2025/poster/44260,"Ronak Mehta, Zaid Harchaoui","A modern paradigm for generalization in machine learning and AI consists of pre-training a task-agnostic foundation model, generally obtained using self-supervised and multimodal contrastive learning. The resulting representations can be used for prediction on a downstream task for which no labeled data is available. We present a theoretical framework to better understand this approach, called zero-shot prediction. We identify the target quantities that zero-shot prediction aims to learn, or learns in passing, and the key conditional independence relationships that enable its generalization ability.","Traditional machine learning approaches rely on creating models that adhere to a set of input-output examples. For data-scarce applications such as classifying medical images, there may not be enough such examples to produce a performant classifier. Zero-shot prediction is a method in which models that were trained for complex tasks can be combined and reused to create classifiers for certain applications, without the need for any additional labeled training examples. This modern, remarkable technique does not have the same level of mathematical understanding that the classical approach outlined above. We aim to address this gap by providing a theoretical model for zero-shot prediction in which the qualities of the data and task that make this method succeed and fail can be expressed and analyzed mathematically."
Poster,A General Representation-Based Approach to Multi-Source Domain Adaptation,https://ICML.cc//virtual/2025/poster/46089,"Ignavier Ng, Yan Li, Zijian Li, Yujia Zheng, Guangyi Chen, Kun Zhang","A central problem in unsupervised domain adaptation is determining what to transfer from labeled source domains to an unlabeled target domain. To handle high-dimensional observations (e.g., images), a line of approaches use deep learning to learn latent representations of the observations, which facilitate knowledge transfer in the latent space. However, existing approaches often rely on restrictive assumptions to establish identifiability of the joint distribution in the target domain, such as independent latent variables or invariant label distributions, limiting their real-world applicability. In this work, we propose a general domain adaptation framework that learns compact latent representations to capture distribution shifts relative to the prediction task and address the fundamental question of what representations should be learned and transferred. Notably, we first demonstrate that learning representations based on all the predictive information, i.e., the label's Markov blanket in terms of the learned representations, is often underspecified in general settings. Instead, we show that, interestingly, general domain adaptation can be achieved by partitioning the representations of Markov blanket into those of the label's parents, children, and spouses. Moreover, its identifiability guarantee can be established. Building on these theoretical insights, we develop a practical, nonparametric approach for domain adaptation in a general setting, which can handle different types of distribution shifts.","A major challenge in machine learning is adapting models trained on multiple labeled sources to make predictions in a new, unlabeled domain. We address this by developing a new framework that learns compact, meaningful representations of data that capture how the underlying distributions change across domains. This helps answer the fundamental question of what information should be transferred, leading to more reliable adaptation in diverse, real-world scenarios."
Poster,"A Generic Family of Graphical Models: Diversity, Efficiency, and Heterogeneity",https://ICML.cc//virtual/2025/poster/44227,"Yufei Huang, Changhu Wang, Junjie Tang, Weichi Wu, Ruibin Xi","Traditional network inference methods, such as Gaussian Graphical Models, which are built on continuity and homogeneity, face challenges when modeling discrete data and heterogeneous frameworks. Furthermore, under high-dimensionality, the parameter estimation of such models can be hindered by the notorious intractability of high-dimensional integrals. In this paper, we introduce a new and flexible device for graphical models, which accommodates diverse data types, including Gaussian, Poisson log-normal, and latent Gaussian copula models. The new device is driven by a new marginally recoverable parametric family, which can be effectively estimated without evaluating the high-dimensional integration in high-dimensional settings thanks to the marginal recoverability. We further introduce a mixture of marginally recoverable models to capture ubiquitous heterogeneous structures. We show the validity of the desirable properties of the models and the effective estimation methods, and demonstrate their advantages over the state-of-the-art network inference methods via extensive simulation studies and a gene regulatory network analysis of real single-cell RNA sequencing data.","To understand how variables interact in complex systems —like how genes influence each other during biological processes — scientists often build networks that map out these relationships. Traditional methods for building these networks assume the data are continuous and come from a single population. But in reality, especially in modern biological studies like single-cell RNA sequencing, the data are often discrete and collected from multiple groups, such as different cell types. Moreover, when the number of variables is very large, traditional methods become computationally intensive and slow. Our research introduces a new statistical framework to tackle these challenges. We designed a model that can handle different kinds of data — including discrete data and mixtures from different populations. To make these models efficient to use, we developed a novel estimation method that avoids the heavy computations typically required in high-dimensional analysis. We show that our method works reliably across many tests and outperforms current state-of-the-art tools."
Poster,Agent-as-a-Judge: Evaluate Agents with Agents,https://ICML.cc//virtual/2025/poster/45485,"Mingchen Zhuge, Changsheng Zhao, Dylan Ashley, Wenyi Wang, Dmitrii Khizbullin, Yunyang Xiong, Zechun Liu, Ernie Chang, Raghuraman Krishnamoorthi, Yuandong Tian, Yangyang Shi, Vikas Chandra, Jürgen Schmidhuber","Contemporary evaluation techniques are inadequate for agentic systems. These approaches either focus exclusively on final outcomes---ignoring the step-by-step nature of the thinking done by agentic systems---or require excessive manual labour. To address this, we introduce the **Agent-as-a-Judge** framework, wherein agentic systems are used to evaluate agentic systems. This is a natural extension of the LLM-as-a-Judge framework, incorporating agentic features that enable intermediate feedback for the entire task-solving processes for more precise evaluations. We apply the Agent-as-a-Judge framework to the task of code generation. To overcome issues with existing benchmarks and provide a proof-of-concept testbed for Agent-as-a-Judge, we present **DevAI**, a new benchmark of 55 realistic AI code generation tasks. DevAI includes rich manual annotations, like a total of 365 hierarchical solution requirements, which make it particularly suitable for an agentic evaluator. We benchmark three of the top code-generating agentic systems using Agent-as-a-Judge and find that our framework dramatically outperforms LLM-as-a-Judge and is as reliable as our human evaluation baseline. Altogether, we believe that this work represents a concrete step towards enabling vastly more sophisticated agentic systems. To help that, our dataset and the full implementation of Agent-as-a-Judge will be publically available at https://github.com/metauto-ai/agent-as-a-judge","Existing evaluation methods either focus solely on final outcomes—overlooking the agent’s reasoning—or depend on costly human review, making them impractical for large-scale systems .We introduce the “Agent-as-a-Judge” framework, in which one autonomous agent observes and provides step-by-step, fine-grained assessments of another agent’s task execution .To validate our approach, we created DevAI, a new benchmark comprising 55 real-world AI development tasks and 365 hierarchical requirements .In code-generation experiments, Agent-as-a-Judge agreed with human expert evaluations about 90% of the time—substantially outperforming the 70% agreement rate of previous LLM-as-a-Judge methods.Moreover, our framework cuts evaluation time and cost by roughly 97%, reducing effort from 86 hours and  1,297 USD to approximately 2 hours and 31 USD.By delivering human-level reliability at a fraction of the cost, Agent-as-a-Judge paves the way for rapid, trustworthy analysis of complex multi-agent systems"
