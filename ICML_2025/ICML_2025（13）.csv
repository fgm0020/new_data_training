type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Agent-Centric Actor-Critic for Asynchronous Multi-Agent Reinforcement Learning,https://ICML.cc//virtual/2025/poster/46556,"Whiyoung Jung, Sunghoon Hong, Deunsol Yoon, Kanghoon Lee, Woohyung Lim","Multi-Agent Reinforcement Learning (MARL) struggles with coordination in sparse reward environments. Macro-actions —sequences of actions executed as single decisions— facilitate long-term planning but introduce asynchrony, complicating Centralized Training with Decentralized Execution (CTDE). Existing CTDE methods use padding to handle asynchrony, risking misaligned asynchronous experiences and spurious correlations. We propose the Agent-Centric Actor-Critic (ACAC) algorithm to manage asynchrony without padding. ACAC uses agent-centric encoders for independent trajectory processing, with an attention-based aggregation module integrating these histories into a centralized critic for improved temporal abstractions. The proposed structure is trained via a PPO-based algorithm with a modified Generalized Advantage Estimation for asynchronous environments. Experiments show ACAC accelerates convergence and enhances performance over baselines in complex MARL tasks.","In many real-world tasks, multiple intelligent agents need to work together to achieve a shared goal—like preparing a meal in a game such as Overcooked. These agents only receive occasional signals about how well they’re doing, which makes it difficult to learn effective teamwork.  To speed up learning, they can use “macro-actions”—longer, high-level plans like “go to the tomato”—instead of taking one small step at a time. But since different agents take different amounts of time to complete these actions, they can fall out of sync, making coordination and learning much harder. Existing methods try to handle this by filling in missing information when an agent is busy. However, this can create confusing or misleading training data. Our method, called Agent-Centric Actor-Critic (ACAC), avoids this problem. Each agent records its own actions and timing independently. During training, a central module integrates these timelines in a coordinated way—without needing any artificial filler—while each agent still learns to act independently. Experiments show that ACAC leads to faster learning and better coordination—especially when rewards are rare and teamwork is essential."
Poster,Agent Reviewers: Domain-specific Multimodal Agents with Shared Memory for Paper Review,https://ICML.cc//virtual/2025/poster/43850,"Kai Lu, Shixiong Xu, Jinqiu Li, Kun Ding, Gaofeng Meng","Feedback from peer review is essential to improve the quality of scientific articles. However, at present, many manuscripts do not receive sufficient external feedback for refinement before or during submission. Therefore, a system capable of providing detailed and professional feedback is crucial for enhancing research efficiency. In this paper, we have compiled the largest dataset of paper reviews to date by collecting historical open-access papers and their corresponding review comments and standardizing them using LLM. We then developed a multi-agent system that mimics real human review processes, based on LLMs. This system, named Agent Reviewers, includes the innovative introduction of multimodal reviewers to provide feedback on the visual elements of papers. Additionally, a shared memory pool that stores historical papers' metadata is preserved, which supplies reviewer agents with background knowledge from different fields. Our system is evaluated using ICLR 2024 papers and achieves superior performance compared to existing AI-based review systems. Comprehensive ablation studies further demonstrate the effectiveness of each module and agent in this system.","Peer review is the process where experts give feedback on scientific papers before they are published. This feedback helps authors improve their work and ensures the quality of research. However, many researchers—especially early-career ones—struggle to get useful feedback due to the increasing number of papers and limited time from human reviewers.To help solve this, we created a system called Agent Reviewers that uses artificial intelligence to simulate how real reviewers work. Our system includes multiple AI “agents” that specialize in different topics, and even one that can evaluate images and charts in a paper—something most AI tools can’t do. These agents read a paper, discuss with each other, and produce thoughtful comments and suggestions.To support this system, we also gathered and standardized the largest public dataset of scientific reviews. We tested our tool on hundreds of real research papers and found that it provides more helpful and diverse feedback than existing AI systems. We hope Agent Reviewers can help researchers improve their papers and make the peer review process more accessible and effective for everyone."
Poster,Agent Workflow Memory,https://ICML.cc//virtual/2025/poster/45496,"Zhiruo Wang, Jiayuan Mao, Daniel Fried, Graham Neubig","Despite the potential of language model-based agents to solve real-world tasks such as web navigation, current methods still struggle with long-horizon tasks with complex action trajectories. In contrast, humans can flexibly solve complex tasks by learning reusable task workflows from past experiences and using them to guide future actions. To build agents that can similarly benefit from this process, we introduce Agent Workflow Memory (AWM), a method for inducing commonly reused routines, i.e., workflows, and selectively providing workflows to the agent to guide subsequent generations. AWM flexibly applies to both offline and online scenarios, where agents induce workflows from training examples beforehand or from test queries on the fly. We experiment on two major web navigation benchmarks — Mind2Web and WebArena — that collectively cover 1000+ tasks from 200+ domains across travel, shopping, and social media, among others. AWM substantially improves the baseline results by 24.6% and 51.1% relative success rate on Mind2Web and WebArena while reducing the number of steps taken to solve WebArena tasks successfully. Furthermore, online AWM robustly generalizes in cross-task, website, and domain evaluations, surpassing baselines from 8.9 to 14.0 absolute points as train-test task distribution gaps widen.","Language models are increasingly used as digital assistants to help users complete tasks on the web — like booking flights or shopping online. However, these AI agents often struggle when tasks are long or complex. Humans, by contrast, tend to learn from experience: once we figure out how to do something, we remember the steps and reuse them when a similar situation comes up.Our research introduces a new technique called Agent Workflow Memory (AWM) that helps AI agents do the same. AWM allows agents to learn useful ""task recipes"" — or workflows — from previous examples and reuse them when solving new problems.We tested AWM on two large collections of real-world web tasks covering over 1,000 examples from sites like shopping and social platforms. AWM significantly improved success rates and made agents more efficient. Even when the agent encountered new tasks or websites it hadn't seen before, AWM helped it generalize and perform better than existing methods."
Poster,A Geometric Approach to Personalized Recommendation with Set-Theoretic Constraints Using Box Embeddings,https://ICML.cc//virtual/2025/poster/46603,"Shib S Dasgupta, Michael Boratko, Andrew McCallum","Personalized item recommendation typically suffers from data sparsity, which is most often addressed by learning vector representations of users and items via low-rank matrix factorization. While this effectively densifies the matrix by assuming users and movies can be represented by linearly dependent latent features, it does not capture more complicated interactions. For example, vector representations struggle with set-theoretic relationships, such as negation and intersection, e.g. recommending a movie that is “comedy and action, but not romance”. In this work, we formulate the problem of personalized item recommendation as matrix completion where rows are set-theoretically dependent. To capture this set-theoretic dependence we represent each user and attribute by a hyperrectangle or box (i.e. a Cartesian product of intervals). Box embeddings can intuitively be understood as trainable Venn diagrams, and thus not only inherently represent similarity (via the Jaccard index), but also naturally and faithfully support arbitrary set-theoretic relationships. Queries involving set-theoretic constraints can be efficiently computed directly on the embedding space by performing geometric operations on the representations. We empirically demonstrate the superiority of box embeddings over vector-based neural methods on both simple and complex item recommendation queries by up to 30% overall.","Online platforms like Netflix and Amazon recommend items—such as movies, products, or travel destinations—by learning from user preferences. Often, users also want to filter results using specific conditions, such as “funny action movies without clowns.” Traditional recommendation systems struggle with these kinds of structured queries, especially when combining multiple preferences or exclusions.Our research introduces a new geometric approach to recommendation that supports such complex user queries. We represent users and item attributes (like “comedy” or “children’s”) as multi-dimensional boxes. These box-shaped regions make it easier to perform logical operations—like intersections and differences—on preferences. This means the system can handle queries that combine conditions (e.g., action ∧ comedy ∧ ¬romance) more naturally than existing methods.We also design efficient ways to compute these combinations and show that our method outperforms standard vector-based approaches in accuracy. While we train our system using only simple interactions (such as user–item or attribute–item pairs), it generalizes well to more complex combinations at test time. Our work bridges the gap between personalized recommendations and structured user intent, enabling more flexible and interpretable recommendation systems."
Poster,Aggregation Buffer: Revisiting DropEdge with a New Parameter Block,https://ICML.cc//virtual/2025/poster/43832,"Dooho Lee, Myeong Kong, Sagad Hamid, Cheonwoo Lee, Jaemin Yoo","We revisit DropEdge, a data augmentation technique for GNNs which randomly removes edges to expose diverse graph structures during training. While being a promising approach to effectively reduce overfitting on specific connections in the graph, we observe that its potential performance gain in supervised learning tasks is significantly limited. To understand why, we provide a theoretical analysis showing that the limited performance of DropEdge comes from the fundamental limitation that exists in many GNN architectures.Based on this analysis, we propose **Aggregation Buffer**, a parameter block specifically designed to improve the robustness of GNNs by addressing the limitation of DropEdge. Our method is compatible with any GNN model, and shows consistent performance improvements on multiple datasets. Moreover, our method effectively addresses well-known problems such as degree bias or structural disparity as a unifying solution. Code and datasets are available at https://github.com/dooho00/agg-buffer.","Randomly removing parts of the input is a common way to help machine learning models handle data variation. In graph-structured data—like social networks, where items are linked by edges—a technique called “DropEdge” removes some connections during training to improve reliability.However, we observe that its effectiveness is significantly limited in practice. Our analysis reveals that the issue lies in how graph models aggregate information from connected nodes. To address this, we introduce a post-training component called the “Aggregation Buffer.” We attach it to a trained model to improve its ability to handle varying connection patterns. In tests on 12 datasets, it consistently and significantly improves performance.Our work highlights the importance of edge-robustness—an often-overlooked issue—and offers a simple yet effective way to enhance graph models after training."
Poster,Aggregation of Dependent Expert Distributions in Multimodal Variational Autoencoders,https://ICML.cc//virtual/2025/poster/44298,"Rogelio A. Mancisidor, Robert Jenssen, Shujian Yu, Michael Kampffmeyer","Multimodal learning with variational autoencoders (VAEs) requires estimating joint distributions to evaluate the evidence lower bound (ELBO). Current methods, the product and mixture of experts, aggregate single-modality distributions assuming independence for simplicity, which is an overoptimistic assumption. This research introduces a novel methodology for aggregating single-modality distributions by exploiting the principle of *consensus of dependent experts* (CoDE), which circumvents the aforementioned assumption. Utilizing the CoDE method, we propose a novel ELBO that approximates the joint likelihood of the multimodal data by learning the contribution of each subset of modalities. The resulting CoDE-VAE model demonstrates better performance in terms of balancing the trade-off between generative coherence and generative quality, as well as generating more precise log-likelihood estimations. CoDE-VAE further minimizes the generative quality gap as the number of modalities increases. In certain cases, it reaches a generative quality similar to that of unimodal VAEs, which is a desirable property that is lacking in most current methods. Finally, the classification accuracy achieved by CoDE-VAE is comparable to that of state-of-the-art multimodal VAE models.","In today’s world, we often deal with information coming from many different sources at once, like images, text, and sound. Teaching computers to understand and combine this kind of mixed information to generate realistic and consistent data is called multimodal learning. A popular tool for this purpose is a type of artificial intelligence model known as multimodal variational autoencoder (VAE). However, current methods for combining different types of data in multimodal VAEs often make a simplifying assumption: that each type of data is independent from the others. This assumption makes the math easier, but it doesn’t reflect how things work in the real world where, for example, a picture and its caption are clearly related.This research introduces a smarter way to combine different types of data by using a new method called CoDE (Consensus of Dependent Experts). Rather than assuming independence, CoDE models the interdependency between each type of data. This leads to a new and improved version of a multimodal VAE, called CoDE-VAE. The results show that CoDE-VAE does a better job at generating realistic and consistent data, especially when more types of data are involved. It also matches the accuracy of the best existing models when it comes to classifying information."
Poster,Aguvis: Unified Pure Vision Agents for Autonomous GUI Interaction,https://ICML.cc//virtual/2025/poster/45371,"Yiheng Xu, Zekun Wang, Junli Wang, Dunjie Lu, Tianbao Xie, Amrita Saha, Doyen Sahoo, Tao Yu, Caiming Xiong","Automating GUI tasks remains challenging due to reliance on textual representations, platform-specific action spaces, and limited reasoning capabilities. We introduce Aguvis, a unified vision-based framework for autonomous GUI agents that directly operates on screen images, standardizes cross-platform interactions and incorporates structured reasoning via inner monologue. To enable this, we construct Aguvis data collection, a large-scale dataset with multimodal grounding and reasoning annotations, and develop a two-stage training pipeline that separates GUI grounding from planning and reasoning. Experiments show that Aguvis achieves state-of-the-art performance across offline and real-world online benchmarks, marking the first fully autonomous vision-based GUI agent that operates without closed-source models. We open-source all datasets, models, and training recipes at https://aguvis-project.github.io to advance future research.","Most computer users interact with software through graphical interfaces. Creating AI agents that can automate these tasks could dramatically improve productivity, but current approaches face major limitations. Existing methods typically read the underlying code of interfaces (like HTML/AXTree) rather than seeing them visually, require different programming for each platform, and struggle with complex reasoning.We developed AGUVIS, an AI agent that interacts with computer interfaces the same way humans do—by looking at the screen and understanding what it sees. Instead of reading code, our agent processes screenshots directly and uses a unified approach to control any device, whether it's a website, mobile app, or desktop program. Crucially, we taught the agent to ""think out loud"" through inner monologue, allowing it to plan multi-step tasks and adapt to new situations rather than just reacting automatically.Our approach achieves the best performance on standard benchmarks while being significantly more efficient than previous methods. This represents the first fully autonomous visual interface agent that works without depending on proprietary AI systems. By making our datasets, models, and training methods publicly available, we're providing a foundation that could accelerate the development of AI assistants capable of automating routine computer tasks across any platform."
Poster,A Hitchhiker's Guide to Scaling Law Estimation,https://ICML.cc//virtual/2025/poster/45620,"Leshem Choshen, Yang Zhang, Jacob Andreas","Scaling laws predict the loss of a target machine learning model by extrapolatingfrom easier-to-train models with fewer parameters or smaller training sets. Thisprovides an efficient way for practitioners and researchers alike to compare pre-training decisions involving optimizers, datasets, and model architectures. Despitethe widespread use of scaling laws to model the dynamics of language modeltraining, there has been little work on understanding how to best estimate andinterpret them. We collect (and release) a large-scale dataset containing losses anddownstream evaluations for 485 previously published pretrained models. We usethese to estimate more than 1000 scaling laws, then derive a set of best practicesfor estimating scaling laws in new model families. We find that fitting scaling lawsto intermediate checkpoints of training runs (and not just their final losses) substan-tially improves accuracy, and that—all else equal—estimates of performance aregenerally most accurate when derived from other models of similar sizes. However,because there is a significant degree of variability across model seeds, trainingmultiple small models is sometimes more useful than training a single large one.Moreover, while different model families differ in scaling behavior, they are oftensimilar enough that a target model’s behavior can be predicted from a single modelwith the same architecture, along with scaling parameter estimates derived fromother model families.","Training large language models is expensive and time-consuming, so researchers often try to predict how a model will perform before fully training it. One common technique is using ""scaling laws,"" which are mathematical formulas that estimate how a model’s performance changes as you increase the size of the model or the training data. These predictions help guide decisions like which architecture to use or how much data to collect.In this paper, we take a closer look at how to make these predictions more accurate and useful. We gather a large dataset of nearly 500 language models and analyze how well different scaling law methods work. We discover that using not just the final results of model training but also data from earlier training steps leads to better predictions. We also find that comparing models of similar sizes gives more reliable results, and that training a few small models can sometimes give you more insight than training one big one. Even though different types of models scale differently, we show that it’s often possible to predict how a new model will behave based on similar models and a few smart estimates. Our work offers practical tips for researchers trying to design and train better models more efficiently."
Poster,"AI for Global Climate Cooperation: Modeling Global Climate Negotiations, Agreements, and Long-Term Cooperation in RICE-N",https://ICML.cc//virtual/2025/poster/45380,"Tianyu Zhang, Andrew Williams, Phillip Wozny, Kai-Hendrik Cohrs, Koen Ponse, Marco Jiralerspong, Soham Phade, Sunil Srinivasa, Lu Li, Yang Zhang, Prateek Gupta, Erman Acar, Irina Rish, Yoshua Bengio, Stephan Zheng","Global cooperation on climate change mitigation is essential to limit temperature increases while supporting long-term, equitable economic growth and sustainable development. Achieving such cooperation among diverse regions, each with different incentives, in a dynamic environment shaped by complex geopolitical and economic factors, without a central authority, is a profoundly challenging game-theoretic problem. This article introduces RICE-N, a multi-region integrated assessment model that simulates the global climate, economy, and climate negotiations and agreements. RICE-N uses multi-agent reinforcement learning (MARL) to encourage agents to develop strategic behaviors based on the environmental dynamics and the actions of the others. We present two negotiation protocols: (1) Bilateral Negotiation, an exemplary protocol and (2) Basic Club, inspired from Climate Clubs and the carbon border adjustment mechanism (Nordhaus, 2015; Comissions, 2022). We compare their impact against a no-negotiation baseline with various mitigation strategies, showing that both protocols significantly reduce temperature growth at the cost of a minor drop in production while ensuring a more equitable distribution of the emission reduction costs.","Getting countries to agree on tackling climate change is incredibly difficult. Nations often have conflicting priorities, and there's no global authority to enforce agreements, making it hard to ensure fair and effective action. Many current climate predictions also assume countries will simply follow prescribed plans, without fully exploring if that’s realistic given their individual self-interest.To address this, we developed a sophisticated computer simulation called RICE-N. In this virtual world, AI-driven ""regions"" learn to make strategic decisions about their economies and climate policies, mimicking real-world complexities. We then introduced and tested different ways for these regions to negotiate climate agreements, including a novel ""Basic Club"" approach inspired by real-world proposals.Our simulation shows that these structured negotiation methods can lead to significant cuts in global warming with only a minor impact on the global economy. Importantly, they also help ensure the costs of fighting climate change are shared more fairly between regions. This research provides a more realistic way to explore how different international negotiation strategies could help us achieve effective and equitable global climate solutions."
Poster,AKORN: Adaptive Knots generated Online for RegressioN splines,https://ICML.cc//virtual/2025/poster/43661,"Sunil Madhow, Dheeraj Baby, Yu-Xiang Wang","In order to attain optimal rates, state-of-the-art algorithms for non-parametric regression require that a hyperparameter be tuned according to the smoothness of the ground truth (Tibshirani, 2014). This amounts to an assumption of oracle access to certain features of the data-generating process. We present a parameter-free algorithm for offline non-parametric regression over $TV_1$-bounded functions. By feeding offline data into an optimal online denoising algorithm styled after (Baby et al., 2021), we are able to use change-points to adaptively select knots that respect the geometry of the underlying ground truth. We call this procedure AKORN (Adaptive Knots gener- ated Online for RegressioN splines). By combining forward and backward passes over the data, we obtain an estimator whose empirical performance is close to Trend Filtering (Kim et al., 2009; Tibshirani, 2014), even when we provide the latter with oracle knowledge of the ground truth’s smoothness.","This paper introduces AKORN, a method for drawing smooth curves through noisy data—like temperature trends or stock prices—without needing to guess how complex the pattern is. Unlike traditional tools that require manual tuning, AKORN learns where to adjust its fit by first selectively hiding parts of the data from itself. It places curve “bends” only where needed, adapting automatically to the data’s structure. Despite being fully automatic, it performs nearly as well as methods that rely on expert tuning."
