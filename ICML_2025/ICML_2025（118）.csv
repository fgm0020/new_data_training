type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Function-Space Learning Rates,https://ICML.cc//virtual/2025/poster/44586,"Edward Milsom, Ben Anson, Laurence Aitchison","We consider layerwise function-space learning rates, which measure the magnitude of the change in a neural network's output function in response to an update to a parameter tensor. This contrasts with traditional learning rates, which describe the magnitude of changes in parameter space. We develop efficient methods to measure and set function-space learning rates in arbitrary neural networks, requiring only minimal computational overhead through a few additional backward passes that can be performed at the start of, or periodically during, training. We demonstrate two key applications: (1) analysing the dynamics of standard neural network optimisers in function space, rather than parameter space, and (2) introducing FLeRM (Function-space Learning Rate Matching), a novel approach to hyperparameter transfer across model scales. FLeRM records function-space learning rates while training a small, cheap base model, then automatically adjusts parameter-space layerwise learning rates when training larger models to maintain consistent function-space updates. FLeRM gives hyperparameter transfer across model width, depth, initialisation scale, and LoRA rank in various architectures including MLPs with residual connections and transformers with different layer normalisation schemes.","We propose a way to estimate how changes to individual parts of an AI system affect its operation as a whole. This will help AI researchers better understand why current AI systems work well and how to improve them in the future. For example, in our paper we utilise our method to tune very large AI systems by tuning a small, cheap model and then copying the settings to the large model (which would be very computationally expensive to tune by itself). This is not usually possible, because the optimal settings change between small and large AI systems, but with our method, we can predict and therefore correct these changes."
Poster,Function-to-Style Guidance of LLMs for Code Translation,https://ICML.cc//virtual/2025/poster/44745,"Longhui Zhang, Bin Wang, Jiahao Wang, Xiaofeng Zhao, Min Zhang, Hao yang, Meishan Zhang, YU LI, Jing Li, Jun Yu, Min Zhang","Large language models (LLMs) have made significant strides in code translation tasks. However, ensuring both the correctness and readability of translated code remains a challenge, limiting their effective adoption in real-world software development. In this work, we propose F2STrans,  a function-to-style guiding paradigm designed to progressively improve the performance of LLMs in code translation. Our approach comprises two key stages: (1) Functional learning, which optimizes translation correctness using high-quality source-target code pairs mined from online programming platforms, and (2) Style learning, which improves translation readability by incorporating both positive and negative style examples. Additionally, we introduce a novel code translation benchmark that includes up-to-date source code, extensive test cases, and manually annotated ground-truth translations, enabling comprehensive functional and stylistic evaluations. Experiments on both our new benchmark and existing datasets demonstrate that our approach significantly improves code translation performance. Notably, our approach enables Qwen-1.5B to outperform prompt-enhanced Qwen-32B and GPT-4 on average across 20 diverse code translation scenarios.","Modern AI tools can already rewrite computer code from one language to another, yet the output usually forces developers to choose between “works correctly” or “easy to read”.We created F2STrans, a two‑step training recipe that teaches an AI model to deliver both at once.First, the model studies thousands of real programs and their trusted translations so it never changes what the code does.Next, it sees examples of clean versus messy style, nudging it to write code that looks like something a seasoned programmer would proudly share.By making automatic code translation reliable and pleasant to read, our work could speed up software maintenance, help companies modernize legacy projects, and let developers collaborate across programming languages more easily."
Poster,Fundamental Bias in Inverting Random Sampling Matrices with Application to Sub-sampled Newton,https://ICML.cc//virtual/2025/poster/45565,"Chengmei Niu, Zhenyu Liao, Zenan Ling, Michael Mahoney","A substantial body of work in machine learning (ML) and randomized numerical linear algebra (RandNLA) has exploited various sorts of random sketching methodologies, including random sampling and random projection, with much of the analysis using Johnson--Lindenstrauss and subspace embedding techniques.  Recent studies have identified the issue of *inversion bias* -- the phenomenon that inverses of random sketches are *not* unbiased, despite the unbiasedness of the sketches themselves. This bias presents challenges for the use of random sketches in various ML pipelines, such as fast stochastic optimization, scalable statistical estimators, and distributed optimization. In the context of random projection, the inversion bias can be easily corrected for dense Gaussian projections (which are, however, too expensive for many applications). Recent work has shown how the inversion bias can be corrected for sparse sub-gaussian projections. In this paper, we show how the inversion bias can be corrected for random sampling methods, both uniform and non-uniform leverage-based, as well as for structured random projections, including those based on the Hadamard transform. Using these results, we establish problem-independent local convergence rates for sub-sampled Newton methods.","Modern machine learning often relies on randomized techniques to accelerate large-scale computations, such as approximating large matrices through random sampling or projection. However, recent studies have uncovered a subtle yet systematic error, known as inversion bias, which arises when these approximations are inverted within machine learning pipelines like stochastic optimization. This bias can degrade the reliability and performance of widely used algorithms. While previous work has addressed inversion bias for dense Gaussian and sparse sub-Gaussian projections, no general correction has been available for random sampling, which remains one of the most practical and computationally efficient sketching techniques. Our research introduces a unified correction framework that mitigates inversion bias for both uniform and leverage-based random sampling, as well as for structured projections such as those based on the Hadamard transform. We apply this framework to sub-sampled Newton methods and establish improved, problem-independent local convergence rates. By bridging theoretical insights with practical algorithm design, our work enhances the accuracy and robustness of randomized methods in large-scale machine learning and optimization tasks."
Poster,Fundamental limits of learning in sequence multi-index models and deep attention networks: high-dimensional asymptotics and sharp thresholds,https://ICML.cc//virtual/2025/poster/45453,"Emanuele Troiani, Hugo Cui, Yatin Dandi, FLORENT KRZAKALA, Lenka Zdeborová","In this manuscript, we study the  learning of deep attention neural networks, defined as the composition of multiple self-attention layers, with tied and low-rank weights. We first establish a mapping of such models to sequence multi-index models, a generalization of the widely studied multi-index model to sequential covariates, for which we establish a number of general results.  In the context of Bayes-optimal learning, in the limit of large dimension $D$ and proportionally large number of samples $N$, we derive a sharp asymptotic characterization of the optimal performance as well as the performance of the best-known polynomial-time algorithm for this setting --namely approximate message-passing--, and characterize sharp thresholds on the minimal sample complexity required for better-than-random prediction performance. Our analysis uncovers, in particular, how the different layers are learned sequentially.  Finally, we discuss how this sequential learning can also be observed in a realistic setup.","Modern AI systems often rely on attention networks — models that look at relationships between different parts of the input. These are central to breakthroughs like large language models. But how do such complex networks actually learn, and how much data do they need to start making accurate predictions?We studied deep attention networks in a simplified, low-rank setting, allowing us to derive exact results on the fundamental limits of learning from data. Our analysis provides a comprehensive mathematical framework to understand when learning is possible and how well these models can perform.One of our most surprising findings is that the network doesn’t learn all at once: instead, its layers are learned sequentially. This means the model gradually builds up complexity, layer by layer — a behavior we also observe in some realistic scenarios."
Poster,Fundamental Limits of Visual Autoregressive Transformers: Universal Approximation Abilities,https://ICML.cc//virtual/2025/poster/44146,"Yifang Chen, Xiaoyu Li, Yingyu Liang, Zhenmei Shi, Zhao Song","We investigate the fundamental limits of transformer-based foundation models, extending our analysis to include Visual Autoregressive (VAR) transformers. VAR represents a big step toward generating images using a novel, scalable, coarse-to-fine ``next-scale prediction'' framework. These models set a new quality bar, outperforming all previous methods, including Diffusion Transformers, while having state-of-the-art performance for image synthesis tasks. Our primary contributions establish that, for single-head VAR transformers with a single self-attention layer and single interpolation layer, the VAR Transformer is universal. From the statistical perspective, we prove that such simple VAR transformers are universal approximators for any word-to-image Lipschitz functions. Furthermore, we demonstrate that flow-based autoregressive transformers inherit similar approximation capabilities. Our results provide important design principles for effective and computationally efficient VAR Transformer strategies that can be used to extend their utility to more sophisticated VAR models in image generation and other related areas.","A new model called Visual Autoregressive (VAR) Transformer – winner of a NeurIPS 2024 Best Paper award—generates images by starting with a rough sketch and then repeatedly “fills in” finer details. Our study asks a simple question: How powerful is VAR at its core? We prove that a VAR Transformer can, in theory, generate any reasonable mapping from words to pictures. In other words, it is a universal image builder. Demonstrating universality for such a lightweight architecture suggests that we can design smaller, faster image generators without sacrificing expressive power. This opens the door to more efficient creative tools on everyday devices and provides a solid theoretical foundation for the next wave of visual AI."
Poster,FuseUNet: A Multi-Scale Feature Fusion Method for U-like Networks,https://ICML.cc//virtual/2025/poster/45634,"Quansong He, Xiangde Min, Kaishen Wang, Tao He","Medical image segmentation is a critical task in computer vision, with UNet serving as a milestone architecture. The typical component of UNet family is the skip connection, however, their skip connections face two significant limitations: (1) they lack effective interaction between features at different scales, and (2) they rely on simple concatenation or addition operations, which constrain efficient information integration. While recent improvements to UNet have focused on enhancing encoder and decoder capabilities, these limitations remain overlooked. To overcome these challenges, we propose a novel multi-scale feature fusion method that reimagines the UNet decoding process as solving an initial value problem (IVP), treating skip connections as discrete nodes. By leveraging principles from the linear multistep method, we propose an adaptive ordinary differential equation method to enable effective multi-scale feature fusion. Our approach is independent of the encoder and decoder architectures, making it adaptable to various U-Net-like networks. Experiments on ACDC, KiTS2023, MSD brain tumor, and ISIC2017/2018 skin lesion segmentation datasets demonstrate improved feature utilization, reduced network parameters, and maintained high performance. The code is available athttps://github.com/nayutayuki/FuseUNet.","Medical imaging helps doctors detect diseases by analyzing scans. A popular AI model for this task is called UNet. However, UNet often struggles to combine image details from different scales, which limits its accuracy.We propose a new method that treats this combination process like solving a mathematical problem step by step. This allows the model to better integrate information from different parts of the image, improving its understanding.Our solution works with many types of existing models, improves results across several datasets, and requires fewer computing resources — potentially making medical AI tools more efficient and accurate."
Poster,Fusing Reward and Dueling Feedback in Stochastic Bandits,https://ICML.cc//virtual/2025/poster/44138,"Xuchuang Wang, Qirun Zeng, Jinhang Zuo, Xutong Liu, Mohammad Hajiesmaili, John C. S. Lui, Adam Wierman","This paper investigates the fusion of absolute (reward) and relative (dueling) feedback in stochastic bandits,    where both feedback types are gathered in each decision round.    We derive a regret lower bound, demonstrating that an efficient algorithm may incur only the smaller among the reward and dueling-based regret for each individual arm.    We propose two fusion approaches:    (1) a simple elimination fusion algorithm that leverages both feedback types to explore all arms and unifies collected information by sharing a common candidate arm set,    and (2) a decomposition fusion algorithm that selects the more effective feedback to explore the corresponding arms    and    randomly assigns one feedback type for exploration and the other for exploitation in each round.    The elimination fusion experiences a suboptimal multiplicative term of the number of arms in regret due to the intrinsic suboptimality of dueling elimination.    In contrast, the decomposition fusion achieves regret matching the lower bound up to a constant under a common assumption.    Extensive experiments confirm the efficacy of our algorithms and theoretical results.","Online recommendation platforms—think movie ratings on IMDb or hotel reviews on TripAdvisor—gather two kinds of user feedback: **absolute feedback**, where you assign a score to a single item (“I give this movie 4 stars”), and **relative feedback**, where you compare two items (“I prefer Movie A over Movie B”). Rather than treating these two feedback channels separately, our work asks: *Can we combine them to make better future recommendations?* This question is also highly relevant when training large language models, where multiple signal types can guide learning.We propose two simple yet powerful ways to fuse absolute and relative feedback:1. **ElimFusion** removes any recommendation that receives a negative judgment in either feedback mode. If a movie scores poorly or loses a head‑to‑head comparison, it’s eliminated from consideration—letting us focus only on items with consistently positive signals.2. **DecoFusion** splits potential recommendations into two groups: one optimized for absolute scores and another for pairwise comparisons. By tailoring how we process each group, we capture the strengths of both feedback types without forcing them into a single metric.Across a range of experiments, both ElimFusion and DecoFusion outperform methods that rely on just one kind of feedback. Our results show that collecting and intelligently combining absolute and relative preferences can significantly boost recommendation quality. Beyond recommendation systems, these fusion strategies open up new opportunities for any machine‑learning task that benefits from multiple forms of human or automated feedback."
Poster,G-Adaptivity: optimised graph-based mesh relocation for finite element methods,https://ICML.cc//virtual/2025/poster/43974,"James Rowbottom, Georg Maierhofer, Teo Deveney, Eike Müller, Alberto Paganini, Katharina Schratz, Pietro Lió, Carola-Bibiane Schönlieb, Chris Budd","We present a novel, and effective, approach to achieve optimal mesh relocation in finite element methods (FEMs). The cost and accuracy of FEMs is critically dependent on the choice of mesh points. Mesh relocation (r-adaptivity) seeks to optimise the mesh geometry to obtain the best solution accuracy at given computational budget. Classical r-adaptivity relies on the solution of a separate nonlinear ``meshing'' PDE to determine mesh point locations. This incurs significant cost at remeshing, and relies on estimates that relate interpolation- and FEM-error. Recent machine learning approaches have focused on the construction of fast surrogates for such classical methods. Instead, our new approach trains a graph neural network (GNN) to determine mesh point locations by directly minimising the FE solution error from the PDE system Firedrake to achieve higher solution accuracy. Our GNN architecture closely aligns the mesh solution space to that of classical meshing methodologies, thus replacing classical estimates for optimality with a learnable strategy. This allows for rapid and robust training and results in an extremely efficient and effective GNN approach to online r-adaptivity. Our method outperforms both classical, and prior ML, approaches to r-adaptive meshing. In particular, it achieves lower FE solution error, whilst retaining the significant speed-up over classical methods observed in prior ML work.","When engineers and scientists simulate physical systems - like airflow over an aircraft wing or stress on a bridge - they often use a technique called the Finite Element Method (FEM). This method breaks down complex structures into smaller, manageable pieces called ""meshes."" The accuracy of these simulations heavily depends on how these meshes are arranged. Traditionally, mesh adaptation requires solving extra nonlinear equations - a time-consuming and costly step.We introduce a novel approach that teaches Graph Neural Networks (GNN) to adjust these meshes for fast and optimal mesh placement. By training the GNN to minimize errors in the simulation results directly, the method generates meshes with more accurate finite element solutions and at significantly faster speeds than traditional techniques.Our key insight is that our end-to-end optimisation beats both classical approaches and earlier machine learning surrogates to this adaptive meshing problem. These findings provide insights on how we can effectively benefit from the power of AI in scientific computing without sacrificing the robustness of existing FEM solvers that are currently widely used in scientific computing in areas from engineering and climate modelling, to medical imaging."
Poster,Galileo: Learning Global & Local Features of Many Remote Sensing Modalities,https://ICML.cc//virtual/2025/poster/44450,"Gabriel Tseng, Anthony Fuller, Marlena Reil, Henry Herzog, Patrick Beukema, Favyen Bastani, James Green, Evan Shelhamer, Hannah Kerner, David Rolnick","We introduce a highly multimodal transformer to represent many remote sensing modalities - multispectral optical, synthetic aperture radar, elevation, weather, pseudo-labels, and more - across space and time. These inputs are useful for diverse remote sensing tasks, such as crop mapping and flood detection. However, learning shared representations of remote sensing data is challenging, given the diversity of relevant data modalities, and because objects of interest vary massively in scale, from small boats (1-2 pixels and fast) to glaciers (thousands of pixels and slow). We present a novel self-supervised learning algorithm that extracts multi-scale features across a flexible set of input modalities through masked modeling. Our dual global and local contrastive losses differ in their targets (deep representations vs. shallow input projections) and masking strategies (structured vs. not). Our Galileo is a single generalist model that outperforms SoTA specialist models for satellite images and pixel time series across eleven benchmarks and multiple tasks.","We capture a lot of information about our planet from “remote sensing data” (satellite observations, topographic maps, and more) but we know less than you might think. Analyzing remote sensing data with machine learning  can help us better understand our changing planet.We present a machine learning model — which we call Galileo — that can help summarize remote sensing data. This means that with minimal further processing, its summaries can help make predictions and maps, like of floods or agricultural fields. We achieve this by giving Galileo an incomplete set of data for a time and place, and having it reconstruct what we removed. By being careful about exactly what we ask Galileo to reconstruct, we can make sure Galileo’s summaries take into account big and slow things (like glaciers) as well as small and fast things (like fishing boats).Galileo is uniquely relevant to remote sensing in practice by its modeling of data across space, time, and a variety of data types (e.g. optical data from satellites, topographic maps, weather data and more). We test Galileo on 15 diverse tasks against 11 other methods: Galileo performs best with a single general model. This makes it immediately useful in many existing applications."
Poster,Gamma Distribution PCA-Enhanced Feature Learning for Angle-Robust SAR Target Recognition,https://ICML.cc//virtual/2025/poster/43819,"Chong Zhang, Peng Zhang, Mengke Li","Scattering characteristics of synthetic aperture radar (SAR) targets are typically related to observed azimuth and depression angles. However, in practice, it is difficult to obtain adequate training samples at all observation angles, which probably leads to poor robustness of deep networks. In this paper, we first propose a Gamma-Distribution Principal Component Analysis ($\Gamma$PCA) model that fully accounts for the statistical characteristics of SAR data. The $\Gamma$PCA derives consistent convolution kernels to effectively capture the angle-invariant features of the same target at various attitude angles, thus alleviating deep models' sensitivity to angle changes in SAR target recognition task. We validate $\Gamma$PCA model based on two commonly used backbones, ResNet and ViT, and conduct multiple robustness experiments on the MSTAR benchmark dataset. The experimental results demonstrate that $\Gamma$PCA effectively enables the model to withstand substantial distributional discrepancy caused by angle changes. Additionally, $\Gamma$PCA convolution kernel is designed to require no parameter updates, introducing no extra computational burden to the network. The source code is available at \href{https://github.com/ChGrey/GammaPCA}{https://github.com/ChGrey/GammaPCA}.","In the context of radar target recognition, target structures are typically related to observing angles of radar towards target. Consequently, if there are not adequate training samples at all observation angles, the recognition performance of deep networks is generally unsatisfying. To tackle this problem, we propose a Gamma-PCA model to extract intrinsic features of radar target, thereby alleviating the sensitivity of deep networks to variations in imaging angles. Think of it like recognizing a friend whether they're facing you or turned sideways — our method enables the deep networks this capability in the recognition of radar targets. The proposed Gamma-PCA can be integrated with commonly used backbones, including ResNet and ViT. Experiments on a standard radar dataset demonstrate that our method significantly improves recognition reliability, even under large variations in viewing angles. Moreover, Gamma-PCA introduces no additional training overhead, ensuring computational efficiency. The source code is available at https://github.com/ChGrey/GammaPCA."
