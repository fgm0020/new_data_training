type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,NestQuant: nested lattice quantization for matrix products and LLMs,https://ICML.cc//virtual/2025/poster/46487,"Semyon Savkin, Eitan Porat, Or Ordentlich, Yury Polyanskiy","Post-training quantization (PTQ) has emerged as a critical technique for efficient deployment of large language models (LLMs). This work proposes NestQuant, a novel PTQ scheme for  weights and activations that is based on self-similar nested lattices. Recent works have mathematically shown such quantizers to be information-theoretically optimal for low-precision matrix multiplication. We implement a practical low-complexity version of NestQuant based on Gosset lattice, making it a drop-in quantizer for any matrix multiplication step (e.g., in self-attention, MLP etc).  For example, NestQuant quantizes weights, KV-cache, and activations of Llama-3-8B to 4 bits, achieving perplexity of 6.6 on wikitext2. This represents more than 55\% reduction in perplexity gap with respect to unquantized model (perplexity of 6.14) compared to state-of-the-art Meta's SpinQuant (perplexity 7.3), OstQuant (7.3) and QuaRot (8.2). Comparisons on bigger models (up to 70B) and on various LLM evaluation benchmarks confirm uniform superiority of NestQuant.","Large language models (LLMs) like ChatGPT are powerful but require a lot of memory and energy to run, making them expensive and difficult to deploy on everyday hardware. One way to make them more efficient is by compressing their internal data using fewer bits, similar to how JPEG reduces a a multi-MB high-resolution photo to a few hundred KB without losing too much detail.In this work, we propose a new lossy compression method called NestQuant for LLMs. Most existing methods use a simple rounding-to-nearest (RTN) integer method, whereas NestQuant is built on top of a mathematical idea of nested lattices. The improvement of NestQuant is similar to how one prefers stacking oranges in a pyramid instead of in a cubic grid. In our case, the tighter packing of points corresponds to  less information being lost during compression.In the end, our method significantly improves the state-of-the-art in LLM quantization. For example, when tested on a popular LLM (Llama-3 with sizes ranging from 8B to 70B) and at target quantization of 4 bits, NestQuant universally outperformed (sometimes by a factor of 2 or 3) all contemporary algorithms. Better quantization enables much more efficient (in energy spent, cost of hardware etc) deployment of advanced AI, thus broadening access to it."
Poster,NETS: A Non-equilibrium Transport Sampler,https://ICML.cc//virtual/2025/poster/45320,"Michael Albergo, Eric Vanden-Eijnden","We introduce the Non-Equilibrium Transport Sampler (NETS), an algorithm for sampling from unnormalized probability distributions. NETS builds on non-equilibrium sampling strategies that transport a simple base distribution into the target distribution in finite time, as pioneered in Neal's annealed importance sampling (AIS). In the continuous-time setting, this transport is accomplished by evolving walkers using Langevin dynamics with a time-dependent potential, while simultaneously evolving importance weights to debias their solutions following Jarzynski's equality. The key innovation of NETS is to add to the dynamics a learned drift term that offsets the need for these corrective weights by minimizing their variance through an objective that can be estimated without backpropagation and provably bounds the Kullback-Leibler divergence between the estimated and target distributions. NETS provides unbiased samples and features a tunable diffusion coefficient that can be adjusted after training to maximize the effective sample size. In experiments on standard benchmarks, high-dimensional Gaussian mixtures, and statistical lattice field theory models, NETS shows compelling performances.","This paper introduces a way to learn how to sample from a distribution with density $\rho_t$ in a statistically unbiased way, given access only to the potential $U_t$. It does so by learning a neural network that augments standard powerful Monte Carlo algorithms in a principled way that has intrinsic connections to the equations governing non-equilibrium thermodynamics. The method is contextualized and numerically compared to other recent approaches in the literature."
Poster,Network Sparsity Unlocks the Scaling Potential of Deep Reinforcement Learning,https://ICML.cc//virtual/2025/poster/44160,"Guozheng Ma, Lu Li, Zilin Wang, Li Shen, Pierre-Luc Bacon, Dacheng Tao","Effectively scaling up deep reinforcement learning models has proven notoriously difficult due to network pathologies during training,  motivating various targeted interventions such as periodic reset and architectural advances such as layer normalization. Instead of pursuing more complex modifications, we show that introducing static network sparsity alone can unlock further scaling potential beyond their dense counterparts with state-of-the-art architectures. This is achieved through simple one-shot random pruning, where a predetermined percentage of network weights are randomly removed once before training. Our analysis reveals that, in contrast to naively scaling up dense DRL networks, such sparse networks achieve both higher parameter efficiency for network expressivity and stronger resistance to optimization challenges like plasticity loss and gradient interference. We further extend our evaluation to visual and streaming RL scenarios, demonstrating the consistent benefits of network sparsity.","When we use large networks for deep reinforcement learning, training often breaks down: the models crash, forget early skills, or get stuck. Researchers usually fight these problems with complex fixes such as special layers and frequent ""resets"". We offer a simpler idea: before training, randomly cut network's connections and never add them back. This one-shot random pruning makes a static sparse network that, even with fewer weights, learns faster and scores higher than the dense model. We also demonstrate that the static sparse network prevents common failures, such as plasticity loss and gradient interference."
Poster,NeuralCohort: Cohort-aware Neural Representation Learning for Healthcare Analytics,https://ICML.cc//virtual/2025/poster/44716,"Changshuo Liu, Lingze Zeng, Kaiping Zheng, Shaofeng Cai, Beng Chin Ooi, James Yip","Electronic health records (EHR) aggregate extensive data critical for advancing patient care and refining intervention strategies. EHR data is essential for epidemiological study, more commonly referred to as cohort study, where patients with shared characteristics or similar diseases are analyzed over time. Unfortunately, existing studies on cohort modeling are limited, struggling to derive fine-grained cohorts or effectively utilize cohort information, which hinders their ability to uncover intrinsic relationships between cohorts. To this end, we propose NeuralCohort, a cohort-aware neural representation learning method that precisely segments patients into finer-grained cohorts via an innovative cohort contextualization mechanism and captures both intra- and inter-cohort information using a Biscale Cohort Learning Module. Designed as a plug-in, NeuralCohort integrates seamlessly with existing backbone models, enhancing their cohort analysis capabilities by infusing deep cohort insights into the representation learning processes. The effectiveness and generalizability of NeuralCohort are validated across extensive real-world EHR datasets. Experimental results demonstrate that NeuralCohort consistently improves the performance of various backbone models, achieving up to an 8.1% increase in AUROC.","Electronic health records (EHRs) store large amounts of patient data that can help doctors improve patient care and identify patterns in diseases. One way researchers use this data is through cohort studies, where they analyze groups of patients who share similar traits or conditions over time. However, existing methods often struggle to group patients precisely and make full use of this cohort information, which limits their ability to reveal meaningful insights.To address this, we developed **NeuralCohort**, a new AI-based method that can better group patients into more detailed categories and learn from both the differences and similarities across these groups. NeuralCohort works alongside existing models and helps them understand patient data more deeply.Our experiments can help researchers and healthcare providers make more accurate predictions and better decisions based on EHR data."
Poster,"Neural Collapse Beyond the Unconstrained Features Model:  Landscape, Dynamics, and Generalization in the Mean-Field Regime",https://ICML.cc//virtual/2025/poster/44830,"Diyuan Wu, Marco Mondelli","Neural Collapse is a phenomenon where the last-layer representations of a well-trained neural network converge to a highly structured geometry. In this paper, we focus on its first (and most basic) property, known as NC1: the within-class variability vanishes. While prior theoretical studies establish the occurrence of NC1 via the data-agnostic unconstrained features model, our work adopts a data-specific perspective, analyzing NC1 in a three-layer neural network, with the first two layers operating in the mean-field regime and followed by a linear layer. In particular, we establish a fundamental connection between NC1 and the loss landscape: we prove that points with small empirical loss and gradient norm (thus, close to being stationary) approximately satisfy NC1, and the closeness to NC1 is controlled by the residual loss and gradient norm. We then show that (i) gradient flow on the mean squared error converges to NC1 solutions with small empirical loss, and (ii) for well-separated data distributions, both NC1 and vanishing test loss are achieved simultaneously. This aligns with the empirical observation that NC1 emerges during training while models attain near-zero test error.  Overall, our results demonstrate that NC1 arises from gradient training due to the properties of the loss landscape, and they show the co-occurrence of NC1 and small test error for certain data distributions.","Neural collapse is the empirical phenomenon in which the last-layer representations of a well-trained neural network converge to a highly structured geometry. The previous theoretical understanding of this phenomenon is limited to models that do not consider the impact of data, or models that are partially in the NTK regime (which means no feature learning) during training. In this work, we prove the occurrence of the within-class variability collapse (also referred to as NC1) for a three-layer neural network in the mean-field regime (which has feature learning). We also prove the co-occurrence of NC1 and vanishing test loss on well-separated data, which aligns with the empirical observation that NC1 emerges during training while models attain near-zero test error."
Poster,Neural Discovery in Mathematics: Do Machines Dream of Colored Planes?,https://ICML.cc//virtual/2025/poster/46323,"Konrad Mundinger, Max Zimmer, Aldo Kiem, Christoph Spiegel, Sebastian Pokutta","We demonstrate how neural networks can drive mathematical discovery through a case study of the Hadwiger-Nelson problem, a long-standing open problem at the intersection of discrete geometry and extremal combinatorics that is concerned with coloring the plane while avoiding monochromatic unit-distance pairs. Using neural networks as approximators, we reformulate this mixed discrete-continuous geometric coloring problem with hard constraints as an optimization task with a probabilistic, differentiable loss function. This enables gradient-based exploration of admissible configurations that most significantly led to the discovery of two novel six-colorings, providing the first improvement in thirty years to the off-diagonal variant of the original problem (Mundinger et al., 2024a). Here, we establish the underlying machine learning approach used to obtain these results and demonstrate its broader applicability through additional numerical insights.","How many colors are needed to color the plane so that if you drop a matchstick both ends always land on different colors? This might sound like a puzzle, but it’s actually a famous unsolved math problem called the Hadwiger-Nelson problem.We used neural networks, the same kind of technology behind modern artificial intelligence systems, to explore possible solutions to this problem in a new way. By turning the challenge into something a computer can learn and optimize, we were able to search through countless coloring patterns and avoid the usual trial-and-error approach.This led to the discovery of two new coloring configurations that improve upon previous results for a variation of the problem. It's the first progress in over 30 years. Our approach shows how machine learning can help solve deep, abstract problems in mathematics and could inspire similar breakthroughs in other hard-to-crack areas."
Poster,Neural Encoding and Decoding at Scale,https://ICML.cc//virtual/2025/poster/43679,"Yizi Zhang, Yanchen Wang, Mehdi Azabou, Alexandre Andre, Zixuan Wang, Hanrui Lyu, International Brain Laboratory, Eva Dyer, Department of Statistics Liam Paninski, Cole Hurwitz","Recent work has demonstrated that large-scale, multi-animal models are powerful tools for characterizing the relationship between neural activity and behavior. Current large-scale approaches, however, focus exclusively on either predicting neural activity from behavior (encoding) or predicting behavior from neural activity (decoding), limiting their ability to capture the bidirectional relationship between neural activity and behavior. To bridge this gap, we introduce a multimodal, multi-task model that enables simultaneous Neural Encoding and Decoding at Scale (NEDS). Central to our approach is a novel multi-task-masking strategy, which alternates between neural, behavioral, within-modality, and cross-modality masking. We pretrain our method on the International Brain Laboratory (IBL) repeated site dataset, which includes recordings from 83 animals performing the visual decision-making task. In comparison to other large-scale modeling approaches, we demonstrate that NEDS achieves state-of-the-art performance for both encoding and decoding when pretrained on multi-animal data and then fine-tuned on new animals. Surprisingly, NEDS's learned embeddings exhibit emergent properties: even without explicit training, they are highly predictive of the brain regions in each recording. Altogether, our approach is a step towards a foundation model of the brain that enables seamless translation between neural activity and behavior.","Understanding how neural activity and behavior influence each other is a central goal in neuroscience. Most current approaches address only one direction, either predicting neural activity from behavior or behavior from neural activity. We present a new model that performs both tasks simultaneously, using data from many animals engaged in a visual decision-making task. Our model not only outperforms existing methods but also uncovers meaningful anatomical patterns in the brain without explicit human supervision. This work marks a major step toward a unified model that links neural activity and behavior."
Poster,Neural Event-Triggered Control with Optimal Scheduling,https://ICML.cc//virtual/2025/poster/44623,"Luan Yang, Jingdong Zhang, Qunxi Zhu, Wei Lin","Learning-enabled controllers with stability certificate functions have demonstrated impressive empirical performance in addressing control problems in recent years. Nevertheless, directly deploying the neural controllers onto actual digital platforms requires impractically excessive communication resources due to a continuously updating demand from the closed-loop feedback controller. We introduce a framework aimed at learning the event-triggered controller (ETC) with optimal scheduling, i.e., minimal triggering times, to address this challenge in resource-constrained scenarios. Our proposed framework, denoted by Neural ETC, includes two practical algorithms: the path integral algorithm based on directly simulating the event-triggered dynamics, and the Monte Carlo algorithm derived from new theoretical results regarding lower bound of inter-event time. Furthermore, we propose a projection operation with an analytical expression that ensures theoretical stability and schedule optimality for Neural ETC. Compared to the conventional neural controllers, our empirical results show that the Neural ETC significantly reduces the required communication resources while enhancing the control performance in constrained communication resources scenarios.","Modern controllers powered by machine learning can make smart decisions in complex systems—like self-driving cars or robotic arms—but they often demand constant updates and heavy data communication to stay stable and effective. This makes them hard to use in real-world devices where communication is limited, like drones or satellites. We tackled this by designing a controller that only sends updates when absolutely necessary, without sacrificing safety or performance. Our new method, called Neural ETC, learns when to act and when to stay silent, reducing the number of communications needed. The result: smarter, quieter controllers that work better in the real world. This brings us one step closer to deploying intelligent systems in places where every bit of data—and every second of response time—counts."
Poster,Neural Genetic Search in Discrete Spaces,https://ICML.cc//virtual/2025/poster/43742,"Hyeonah Kim, Sanghyeok Choi, Jiwoo Son, Jinkyoo Park, Changhyun Kwon","Effective search methods are crucial for improving the performance of deep generative models at test time. In this paper, we introduce a novel test-time search method, Neural Genetic Search (NGS), which incorporates the evolutionary mechanism of genetic algorithms into the generation procedure of deep models. The core idea behind NGS is its crossover, which is defined as parent-conditioned generation using trained generative models. This approach offers a versatile and easy-to-implement search algorithm for deep generative models. We demonstrate the effectiveness and flexibility of NGS through experiments across three distinct domains: routing problems, adversarial prompt generation for language models, and molecular design.","Many real-world problems in various domains, ranging from planning delivery routes to designing new molecules or generating text, involve searching and optimizing over complex, discrete spaces. Deep generative models, especially those that build solutions step-by-step (sequentially), have made real progress in these areas. But in practice, these models often settle for “good enough” answers, generating solutions in a single pass without further refinement.In this work, we propose Neural Genetic Search (NGS), a method that brings the evolutionary ideas of genetic algorithms into the test-time generation process of deep models. NGS builds and evolves a population of solutions by combining good candidates using two key operations:  crossover, where the model generates new sequences using only the tokens seen in selected parents, and mutation, which allows variation beyond the parent tokens. These operations are applied directly through the model’s generation process, enabling structured and model-aware exploration of the solution space.NGS is simple, model-agnostic, and easy to integrate with generative models that generate discrete sequences. It effectively turns a generator into a more powerful search tool capable of iterative refinement, and holds promise for a wide range of applications, particularly in light of the growing popularity of autoregressive generative models."
Poster,Neural Graph Matching Improves Retrieval Augmented Generation in Molecular Machine Learning,https://ICML.cc//virtual/2025/poster/44092,"Runzhong Wang, Rui-Xi Wang, Mrunali Manjrekar, Connor Coley","Molecular machine learning has gained popularity with the advancements of geometric deep learning. In parallel, retrieval-augmented generation has become a principled approach commonly used with language models. However, the optimal integration of retrieval augmentation into molecular machine learning remains unclear. Graph neural networks stand to benefit from clever matching to understand the structural alignment of retrieved molecules to a query molecule. Neural graph matching offers a compelling solution by explicitly modeling node and edge affinities between two structural graphs while employing a noise-robust, end-to-end neural network to learn affinity metrics. We apply this approach to mass spectrum simulation and introduce MARASON, a novel model that incorporates neural graph matching to enhance a fragmentation-based neural network. Experimental results highlight the effectiveness of our design, with MARASON achieving 27% top-1 accuracy, a substantial improvement over the non-retrieval state-of-the-art accuracy of 19%. Moreover, MARASON outperforms both naive retrieval-augmented generation methods and traditional graph matching approaches. Code is publicly available at https://github.com/coleygroup/ms-pred.","Retrieval-augmented generation (RAG) enhances the accuracy of text generation, particularly in large language models (LLMs), although its potential in molecular machine learning remains to be understood. In this paper, we identify that the structural alignment between reference and target molecules is an important factor in RAG-aided tasks, whereas a naive retrieval-augmented generation method was found to have a negative impact. Instead, neural graph matching offers a noise-robust, end-to-end solution. By focusing on mass spectrum simulation, we present MARASON, a mass spectrum prediction network that integrates reference intensity information through graph matching of the reference and target structures.We highlight the effectiveness of our design, with MARASON achieving 27% top-1 accuracy in structural identification, a substantial improvement over the non-retrieval state-of-the-art accuracy of 19%. MARASON also outperforms traditional graph matching approaches."
