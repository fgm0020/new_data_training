type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Differentiable Quadratic Optimization For the Maximum Independent Set Problem,https://ICML.cc//virtual/2025/poster/44801,"Ismail Alkhouri, Cedric Le Denmat, Yingjie Li, CUNXI YU, Jia (Kevin) Liu, Rongrong Wang, Alvaro Velasquez","Combinatorial Optimization (CO) addresses many important problems, including the challenging Maximum Independent Set (MIS) problem. Alongside exact and heuristic solvers, differentiable approaches have emerged, often using continuous relaxations of quadratic objectives. Noting that an MIS in a graph is a Maximum Clique (MC) in its complement, we propose a new quadratic formulation for MIS by incorporating an MC term, improving convergence and exploration. We show that every maximal independent set corresponds to a local minimizer, derive conditions with respect to the MIS size, and characterize stationary points. To tackle the non-convexity of the objective, we propose optimizing several initializations in parallel using momentum-based gradient descent, complemented by an efficient MIS checking criterion derived from our theory. We dub our method as **p**arallelized **C**lique-Informed **Q**uadratic **O**ptimization for MIS (pCQO-MIS). Our experimental results demonstrate the effectiveness of the proposed method compared to exact, heuristic, sampling, and data-centric approaches. Notably, our method avoids the out-of-distribution tuning and reliance on (un)labeled data required by data-centric methods, while achieving superior MIS sizes and competitive run-time relative to their inference time. Additionally, a key advantage of pCQO-MIS is that, unlike exact and heuristic solvers, the run-time scales only with the number of nodes in the graph, not the number of edges. Our code is available at the GitHub repository: https://github.com/ledenmat/pCQO-mis-benchmark/tree/refactor.","Many important real-world problems, such as scheduling, managing resources, or designing networks, can be framed as combinatorial optimization problems. One such problem is the Maximum Independent Set (MIS) problem, which involves finding the largest group of non-connected nodes in a graph. This task is especially difficult as the size of the graph increases.Traditional methods for solving MIS include exact algorithms and heuristics, but they can be slow or require expert tuning. Recently, new approaches have emerged that use smooth mathematical functions and gradient descent to search for solutions. In our work, we propose a new way to design such a function that makes it easier and more reliable to find large independent sets.Our method, called parallelized Clique-inspired Quadratic Optimization (pCQO-MIS), runs multiple searches in parallel and uses mathematical insights to check whether each candidate solution is valid. pCQO-MIS doesn’t rely on any training data, making it more broadly applicable than many data-driven methods. We show that our approach outperforms many existing techniques in terms of both solution quality and speed—especially on large and dense graphs—while being more efficient in how it scales."
Poster,Differentiable Solver Search for Fast Diffusion Sampling,https://ICML.cc//virtual/2025/poster/44059,"shuai wang, Zexian Li, Qipeng zhang, Tianhui Song, Xubin Li, Tiezheng Ge, Bo Zheng, Limin Wang","Diffusion models have demonstrated remarkable generation quality but at the cost of numerous function evaluations. Recently, advanced ODE-based solvers have been developed to mitigate the substantial computational demands of reverse-diffusion solving under limited sampling steps. However, these solvers, heavily inspired by Adams-like multistep methods, rely solely on t-related Lagrange interpolation. We show that t-related Lagrange interpolation is suboptimal for diffusion model and reveal a compact search space comprised of time steps and solver coefficients. Building on our analysis, we propose a novel differentiable solver search algorithm to identify more optimal solver. Equipped with the searched solver, rectified-flow models, e.g., SiT-XL/2 and FlowDCN-XL/2, achieve FID scores of 2.40 and 2.35, respectively, on ImageNet-$256\times256$ with only 10 steps. Meanwhile, DDPM model, DiT-XL/2, reaches a FID score of 2.33 with only 10 steps. Notably, our searched solver outperforms traditional solvers by a significant margin. Moreover, our searched solver demonstrates generality across various model architectures, resolutions, and model sizes.","Diffusion models have demonstrated remarkable generation quality but at the cost of numerous function evaluations. Recently, advanced ODE-based solvers have been developed to mitigate the substantial computational demands of reverse-diffusion solving under limited sampling steps. However, these solvers, heavily inspired by Adams-like multistep methods, rely solely on t-related Lagrange interpolation. We show that t-related Lagrange interpolation is suboptimal for diffusion model and reveal a compact search space comprised of time steps and solver coefficients. Building on our analysis, we propose a novel differentiable solver search algorithm to identify more optimal solver. Equipped with the searched solver, rectified-flow models, e.g., SiT-XL/2 and FlowDCN-XL/2, achieve FID scores of 2.40 and 2.35, respectively, on ImageNet-$256\times256$ with only 10 steps. Meanwhile, DDPM model, DiT-XL/2, reaches a FID score of 2.33 with only 10 steps. Notably, our searched solver outperforms traditional solvers by a significant margin. Moreover, our searched solver demonstrates generality across various model architectures, resolutions, and model sizes."
Poster,Differentiable Structure Learning with Ancestral Constraints,https://ICML.cc//virtual/2025/poster/44494,"Taiyu Ban, Changxin Rong, Xiangyu Wang, Lyuzhou Chen, Xin Wang, Derui Lyu, Qinrui Zhu, Huanhuan Chen","Differentiable structure learning of causal directed acyclic graphs (DAGs) is an emerging field in causal discovery, leveraging powerful neural learners. However, the incorporation of ancestral constraints, essential for representing abstract prior causal knowledge, remains an open research challenge. This paper addresses this gap by introducing a generalized framework for integrating ancestral constraints. Specifically, we identify two key issues: the non-equivalence of relaxed characterizations for representing path existence and order violations among paths during optimization. In response, we propose a binary-masked characterization method and an order-guided optimization strategy, tailored to address these challenges. We provide theoretical justification for the correctness of our approach, complemented by experimental evaluations on both synthetic and real-world datasets.","Understanding cause-and-effect relationships from data, known as causal discovery, is an important goal in many scientific fields. Recent machine learning methods can uncover complex causal patterns but struggle to incorporate the kind of general, high-level knowledge that researchers often have, such as knowing that one variable affects another indirectly.We address this limitation by introducing a new framework that allows such broad, qualitative knowledge to guide the learning process. By integrating information about whether a causal connection (even indirect) should exist or not, our approach makes machine learning-based causal discovery more accurate and aligned with expert understanding."
Poster,Differential Coding for Training-Free ANN-to-SNN Conversion,https://ICML.cc//virtual/2025/poster/45408,"Zihan Huang, Wei Fang, Tong Bu, Peng Xue, Zecheng Hao, Wenxuan Liu, Yuanhong Tang, Zhaofei Yu, Tiejun Huang","Spiking Neural Networks (SNNs) exhibit significant potential due to their low energy consumption. Converting Artificial Neural Networks (ANNs) to SNNs is an efficient way to achieve high-performance SNNs. However, many conversion methods are based on rate coding, which requires numerous spikes and longer time-steps compared to directly trained SNNs, leading to increased energy consumption and latency. This article introduces differential coding for ANN-to-SNN conversion, a novel coding scheme that reduces spike counts and energy consumption by transmitting changes in rate information rather than rates directly, and explores its application across various layers. Additionally, the threshold iteration method is proposed to optimize thresholds based on activation distribution when converting Rectified Linear Units (ReLUs) to spiking neurons. Experimental results on various Convolutional Neural Networks (CNNs) and Transformers demonstrate that the proposed differential coding significantly improves accuracy while reducing energy consumption, particularly when combined with the threshold iteration method, achieving state-of-the-art performance. The source codes of the proposed method are available at https://github.com/h-z-h-cell/ANN-to-SNN-DCGS.","We noticed that when converting traditional Artificial Neural Networks (ANNs) into energy-efficient Spiking Neural Networks (SNNs), most methods rely on rate coding—which requires many spikes and long time steps, leading to increased energy consumption and latency.To address this, we introduced differential coding, which transmits changes in information rather than direct rates to reduce spike counts and energy use. We also introduced a threshold iteration technique to better adapt ReLUs to spiking neurons based on their activation patterns.Our experiments demonstrated that combining these methods not only improves accuracy but also significantly reduces energy consumption, achieving state-of-the-art performance. This research paves the way for developing efficient, low-energy AI systems, showcasing potential for various applications and advancing more sustainable computing technologies."
Poster,"Differentially Private Analysis for Binary Response Models: Optimality, Estimation, and Inference",https://ICML.cc//virtual/2025/poster/46409,"Ce Zhang, Yixin Han, Yafei Wang, Xiaodong Yan, Linglong Kong, Ting Li, Bei Jiang","Randomized response (RR) mechanisms constitute a fundamental and effective technique for ensuring label differential privacy (LabelDP). However, existing RR methods primarily focus on the response labels while overlooking the influence of covariates and often do not fully address optimality. To address these challenges, this paper explores optimal LabelDP procedures using RR mechanisms, focusing on achieving optimal estimation and inference in binary response models. We first analyze the asymptotic behaviors of RR binary response models and then optimize the procedure by maximizing the trace of the Fisher Information Matrix within the $\varepsilon$- and $(\varepsilon,\delta)$-LabelDP constraints. Our theoretical results indicate that the proposed methods achieve optimal LabelDP guarantees while maintaining statistical accuracy in binary response models under mild conditions. Furthermore, we develop private confidence intervals with nominal coverage for statistical inference. Extensive simulation studies and real-world applications confirm that our methods outperform existing approaches in terms of precise estimation, privacy protection, and reliable inference.","In today's data-driven world, it’s essential to protect people’s sensitive information, like personal survey answers, while still allowing scientists to make useful conclusions. One common way to do this is through “randomized response,” a technique that introduces intentional noise to protect individual answers. But the challenge is: how do we still make accurate conclusions from such noisy data? Our paper presents a new method that balances privacy and accuracy more effectively. We design an improved system that works especially well when the responses are “yes or no” (binary), and we show that it performs better than older methods, especially in real-world tasks like detecting plagiarism in student surveys. We also create a way to give researchers confidence intervals — a key tool in statistics — even when the data is privatized. This work helps ensure privacy doesn't come at the cost of scientific reliability, making it valuable for fields like health, education, and social science."
Poster,Differentially Private Boxplots,https://ICML.cc//virtual/2025/poster/44585,"Kelly Ramsay, Jairo Diaz-Rodriguez","Despite the potential of differentially private data visualization to harmonize data analysis and privacy, research in this area remains  underdeveloped. Boxplots are a widely popular visualization used for summarizing a dataset and for comparison of multiple datasets. Consequentially, we introduce a differentially private boxplot. We evaluate its effectiveness for displaying location, scale, skewness and tails of a given empirical distribution. In our theoretical exposition, we show that the location and scale of the boxplot are estimated with optimal sample complexity, and the skewness and tails are estimated consistently, which is not always the case for a boxplot naively constructed from a single existing differentially private quantile algorithm. As a byproduct of this exposition, we introduce several new results concerning private quantile estimation. In simulations, we show that this boxplot performs similarly to a non-private boxplot, and it outperforms the naive boxplot. Additionally, we conduct a real data analysis of Airbnb listings, which shows that comparable analysis can be achieved through differentially private boxplot visualization.","Boxplots are a cornerstone of data exploration, but standard versions show statistics extracted directly from raw data—posing privacy risks in sensitive domains. We present a “differentially private boxplot” that injects minimal, controlled noise to protect individual records while still displaying the core characteristics of a dataset: its median, variability, asymmetry, and outliers.Built on private quantile‐estimation techniques, our method achieve optimal median and interquartile range and consistently reflects skewness and tail behavior. In both simulations and a real‐world Airbnb price study, our private boxplots are visually indistinguishable from the traditional plots and notably superior to naive approaches, making it easy to share insightful visual summaries without compromising confidentiality."
Poster,Differentially Private Federated $k$-Means Clustering with Server-Side Data,https://ICML.cc//virtual/2025/poster/45962,"Jonathan Scott, Christoph Lampert, David Saulpic","Clustering is a cornerstone of data analysis that is particularly suited to identifying coherent subgroups or substructures in unlabeled data, as are generated continuously in large amounts these days. However, in many cases traditional clustering methods are not applicable, because data are increasingly being produced and stored in a distributed way, e.g. on edge devices, and privacy concerns prevent it from being transferred to a central server. To address this challenge, we present FedDP-KMeans, a new algorithm for $k$-means clustering that is fully-federated as well as differentially private. Our approach leverages (potentially small and out-of-distribution) server-side data to overcome the primary challenge of differentially private clustering methods: the need for a good initialization. Combining our initialization with a simple federated DP-Lloyds algorithm we obtain an algorithm that achieves excellent results on synthetic and real-world benchmark tasks. We also provide a theoretical analysis of our method that provides bounds on the convergence speed and cluster identification success.","Clustering is a technique used to group similar items in large, unlabeled datasets. Traditional clustering methods assume that all the data is stored in one central location. However, in today's world, data is often generated and stored across many separate devices, like smartphones, and privacy concerns often prevent this data from being shared.To address this challenge, we introduce a new method that allows devices to collaborate on clustering without sharing their raw data. This approach protects user privacy using a technique called differential privacy, which ensures that nothing specific about any individual device can be inferred from the final clustering results. A key part of our method is using a small amount of publicly available or server-side data to help kick-start the clustering process, which is then refined collaboratively.We support our method with both a theoretical analysis of its performance and an experimental evaluation that demonstrates its practical usefulness."
Poster,Differentially Private Space-Efficient Algorithms for Counting Distinct Elements in the Turnstile Model,https://ICML.cc//virtual/2025/poster/45462,"Rachel Cummings, Alessandro Epasto, Jieming Mao, Tamalika Mukherjee, Tingting Ou, Peilin Zhong","The *turnstile* continual release model of differential privacy captures scenarios where a privacy-preserving real-time analysis is sought for a dataset evolving  through additions and deletions.  In typical applications of real-time data analysis, both the length of the stream $T$ and the size of the universe $|\mathcal{U}|$ from which data come can be extremely large.  This motivates the study of private algorithms in the turnstile setting using space sublinear in both $T$ and $|\mathcal{U}|$.  In this paper, we give the first sublinear space differentially private algorithms for the fundamental problems of counting distinct elements in the turnstile streaming model. Our algorithm achieves, on arbitrary streams, $O_{\eta}(T^{1/3})$ space and additive error, and a $(1+\eta)$-relative approximation for all $\eta \in (0,1)$. Our result significantly improves upon the space requirements of the state-of-the-art algorithms for this problem, which is linear, approaching the known $\Omega(T^{1/4})$ additive error lower bound for arbitrary streams. Moreover, when a bound $W$ on the number of times an item appears in the stream is known, our algorithm provides $O_{\eta}(\sqrt{W})$ additive error, using $O_{\eta}(\sqrt{W})$ space. This additive error asymptotically matches that of prior work which required instead linear space.  Our results address an open question posed by Jain et al. about designing low-memory mechanisms for this problem. We complement this results with a space lower bound for this problem, which shows that any algorithm that uses similar techniques must use space $\Omega(T^{1/3})$.","In our modern era of big data, there is a growing need to analyze fast-changing data streams -- such as social media activity, online transactions, or sensor feeds -- while protecting individual privacy. This becomes particularly challenging when the dataset is extremely large and constantly evolving, with items being both added and removed continuously. Existing privacy-preserving methods typically require memory that scales with the total size of the data, making them impractical for large-scale, real-time analysis.Our research introduces the first algorithm that can accurately and differentially privately count the number of distinct items in such evolving data streams of length $T$ while using sublinear $O(T^{1/3})$ space. Our algorithm provides strong privacy and accuracy guarantees on the count that it produces. By addressing a key open question from prior work, our results pave the way for more space-efficient, privacy-aware data analysis where real-time insights are crucial."
Poster,Differential Privacy Guarantees of Markov Chain Monte Carlo Algorithms,https://ICML.cc//virtual/2025/poster/44204,"Andrea Bertazzi, Tim Johnston, Gareth Roberts, Alain Oliviero Durmus","This paper aims to provide differential privacy (DP) guarantees for Markov chain Monte Carlo (MCMC) algorithms. In a first part, we establish DP guarantees on samples output by MCMC algorithms as well as Monte Carlo estimators associated with these methods under assumptions on the convergence properties of the underlying Markov chain. In particular, our results highlight the critical condition of ensuring the target distribution is differentially private itself. In a second part, we specialise our analysis to the unadjusted Langevin algorithm and stochastic gradient Langevin dynamics and establish guarantees on their (Rényi) DP. To this end, we develop a novel methodology based on Girsanov's theorem combined with a perturbation trick to obtain bounds for an unbounded domain and in a non-convex setting. We establish: (i) uniform in $n$ privacy guarantees when the state of the chain after $n$ iterations is released, (ii) bounds on the privacy of the entire chain trajectory. These findings provide concrete guidelines for privacy-preserving MCMC.","Differential privacy is a framework which verifies that a statistical procedure is not too sensitive to individual components of the data. Specifically, it considers statistics that are randomised in such a way that changing a given entry in the data set only changes the (random) statistic a suitably small amount. This means one can prove mathematically that the (random) statistic does not give too much information about any one data point.In this paper we investigate the differential privacy of a class of widely used algorithms in statistics and optimisation. The class of algorithms we consider are often used for deriving additional information given a certain amount of prior information (sampling from Bayesian posteriors). We show firstly that the idealised theoretical privacy (the true posterior) and the implementable approximation (MCMC method) must broadly agree in their differential privacy if the numerical approximation is accurate. In the next part we show that certain implementable approximations (MCMC methods) can be differentially private under weaker (non-convex) technical assumptions than previously considered in the literature."
Poster,Differential Privacy Under Class Imbalance: Methods and Empirical Insights,https://ICML.cc//virtual/2025/poster/45213,"Lucas Rosenblatt, Yuliia Lut, Ethan Turok, Marco Medina, Rachel Cummings","Imbalanced learning occurs in classification settings where the distribution of class-labels is highly skewed in the training data, such as when predicting rare diseases or in fraud detection. This class imbalance presents a significant algorithmic challenge, which can be further exacerbated when privacy-preserving techniques such as differential privacy are applied to protect sensitive training data. Our work formalizes these challenges and provides a number of algorithmic solutions. We consider DP variants of pre-processing methods that privately augment the original dataset to reduce the class imbalance, alongside DP variants of in-processing techniques, which adjust the learning algorithm to account for the imbalance. For each method, we either adapt an existing imbalanced learning technique to the private setting or demonstrate its incompatibility with differential privacy. Finally, we empirically evaluate these privacy-preserving imbalanced learning methods under various data and distributional settings. We find that private synthetic data methods perform well as a data pre-processing step, while class-weighted ERMs are an alternative in higher-dimensional settings where private synthetic data suffers from the curse of dimensionality.","Data with rare (but potentially important) events — fraudulent transactions or uncommon diseases — are hard for machine learning models to accurately classify, especially when we add privacy restrictions that protect people’s data. We found that popular quick fixes for this “class imbalance,” like copying rare examples, can actually shatter the strong privacy standard, known as differential privacy, to which we try to adhere. We investigated some ways to address this limitation: (i) a way to create realistic, differentially private synthetic data that boosts the rare class without exposing anyone’s records, and (ii) a training approach that lets the model pay extra attention to scarce cases while still respecting privacy limits. We then evaluated across eight real-world, class-imbalanced datasets, and discussed what worked well and what didn’t."
