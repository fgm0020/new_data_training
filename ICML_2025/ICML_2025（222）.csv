type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Piloting Structure-Based Drug Design via Modality-Specific Optimal Schedule,https://ICML.cc//virtual/2025/poster/44761,"Keyue Qiu, Yuxuan Song, Zhehuan Fan, Peidong Liu, Zhe Zhang, Mingyue Zheng, Hao Zhou, Wei-Ying Ma","Structure-Based Drug Design (SBDD) is crucial for identifying bioactive molecules. Recent deep generative models are faced with challenges in geometric structure modeling. A major bottleneck lies in the twisted probability path of multi-modalities—continuous 3D positions and discrete 2D topologies—which jointly determine molecular geometries. By establishing the fact that noise schedules decide the Variational Lower Bound (VLB) for the twisted probability path, we propose VLB-Optimal Scheduling (VOS) strategy in this under-explored area, which optimizes VLB as a path integral for SBDD. Our model effectively enhances molecular geometries and interaction modeling, achieving state-of-the-art PoseBusters passing rate of 95.9\% on CrossDock, more than 10\% improvement upon strong baselines, while maintaining high affinities and robust intramolecular validity evaluated on held-out test set. Code is available at https://github.com/AlgoMole/MolCRAFT.","**Problem**: Developing new drugs requires creating molecules that can precisely fit into target proteins, similar to finding the right key for a lock. Current methods struggle to design these molecules accurately because they must handle two different aspects simultaneously like solving a 2D/3D jigsaw puzzle: the 3D arrangement of atoms *(the shape of the key)* and the 2D connections between different types of atoms *(the material of the key)*. This often results in unrealistic molecular designs that either don’t fit well or are chemically unstable.**Solution**: We developed VOS, a strategy that acts like a “smart roadmap” during the generative process, ensuring both the 3D geometry and 2D structure evolve harmoniously in an analytical way. Think of it as teaching the generative model to refine how it builds molecules, not just what it builds. **Impact**: Integrated with advanced framework, our MolPilot significantly improves the physical plausibility of AI-generated drug candidates, with 95.9% PoseBusters passing rate (10%+ higher than previous SOTA). These molecules also maintain strong binding to target proteins, potentially accelerating drug discovery by providing scientists with more reliable starting points for development."
Poster,PINNsAgent: Automated PDE Surrogation with Large Language Models,https://ICML.cc//virtual/2025/poster/45282,"Qingpo Wuwu, Chonghan Gao, Tianyu Chen, Yihang Huang, Yuekai Zhang, Jianing Wang, Jianxin Li, Haoyi Zhou, Shanghang Zhang","Solving partial differential equations (PDEs) using neural methods has been a long-standing scientific and engineering research pursuit. Physics-Informed Neural Networks (PINNs) have emerged as a promising alternative to traditional numerical methods for solving PDEs. However, the gap between domain-specific knowledge and deep learning expertise often limits the practical application of PINNs. Previous works typically involve manually conducting extensive PINNs experiments and summarizing heuristic rules for hyperparameter tuning. In this work, we introduce PINNsAgent, a novel surrogation framework that leverages large language models (LLMs) to bridge the gap between domain-specific knowledge and deep learning. PINNsAgent integrates Physics-Guided Knowledge Replay (PGKR) for efficient knowledge transfer from solved PDEs to similar problems, and Memory Tree Reasoning for exploring the search space of optimal PINNs architectures. We evaluate PINNsAgent on 14 benchmark PDEs, demonstrating its effectiveness in automating the surrogation process and significantly improving the accuracy of PINNs-based solutions.","Solving complex physical equations is crucial in science and engineering, but modern neural methods like Physics-Informed Neural Networks (PINNs) require extensive parameter tuning to work effectively. This tuning process typically demands both physics knowledge and deep learning expertise—a rare combination that creates barriers for many researchers.Our research introduces PINNsAgent, an AI assistant that automates the parameter tuning process for solving these equations. By leveraging large language models, our system intelligently searches for optimal configurations based on the specific properties of each equation. PINNsAgent remembers which parameters worked well for similar equations in the past and systematically explores new options to find the best solution.When tested on 14 different mathematical problems, our automated approach found better configurations than conventional tuning methods, making these powerful equation-solving techniques more accessible to scientists without deep learning expertise. This research saves valuable research time by eliminating tedious manual parameter tuning, allowing scientists to focus on their core scientific questions rather than the technical details of neural networks."
Poster,PIPA: Preference Alignment as Prior-Informed Statistical Estimation,https://ICML.cc//virtual/2025/poster/44970,"Junbo Li, Zhangyang “Atlas” Wang, qiang liu","Offline preference alignment for language models such as Direct Preference Optimization (DPO) is favored for its effectiveness and simplicity, eliminating the need for costly reinforcement learning. Various offline algorithms have been developed for different data settings, yet they lack a unified understanding. In this study, we introduce Pior-Informed Preference Alignment (PIPA), a unified, RL-free probabilistic framework that formulates language model preference alignment as a Maximum Likelihood Estimation (MLE) problem with prior constraints. This method effectively accommodates both paired and unpaired data, as well as answer and step-level annotations. We illustrate that DPO and KTO are special cases with different prior constraints within our framework. By integrating different types of prior information, we developed two variations of PIPA: PIPA-M and PIPA-N. Both algorithms demonstrate a $3\sim10\%$ performance enhancement on the GSM8K and MATH benchmarks across all configurations, achieving these gains without additional training or computational costs compared to existing algorithms.","1. Fine-tuning a pre-trained LLM on high-quality data, called alignment, is crucial for enhancing specific capabilities such as reasoning. However, current offline alignment approaches inspired by offline RL (e.g., DPO and KTO) face several limitations: (1) they rely on contrastive training with positive-negative pairs, which may be unnecessary for reasoning tasks; (2) they struggle to incorporate step-wise supervision; and (3) they lack a unified theoretical framework.2. In this work, we recast the alignment problem within a probabilistic framework, formulating it as a MLE problem with constraints on some prior distributions. Within this framework, we show that existing methods like DPO and KTO emerge as special cases corresponding to different choices of prior. We introduce two new algorithms—PIPA-M and PIPA-N—which impose priors on the marginal and negative-conditioned distributions, respectively. Our formulation naturally extends to settings that include step-level supervision, maintaining a consistent framework.3. We evaluate our approach on mathematical reasoning benchmarks and find that both PIPA-M and PIPA-N outperform existing methods."
Poster,PipeOffload: Improving Scalability of Pipeline Parallelism with Memory Optimization,https://ICML.cc//virtual/2025/poster/45468,"Xinyi Wan, Penghui Qi, Guangxing Huang, Min Lin, Jialin Li","Pipeline parallelism (PP) is widely used for training large language models (LLMs), yet its scalability is often constrained by high activation memory consumption as the number of in-flight microbatches grows with the degree of PP. In this paper, we focus on addressing this challenge by leveraging the under-explored memory offload strategy in PP. With empirical study, we discover that in the majority of standard configurations, at least half, and potentially all, of the activations can be offloaded with negligible overhead. In the cases where full overload is not possible, we introduce a novel selective offload strategy that decreases peak activation memory in a better-than-linear manner. Furthermore, we integrate memory offload with other techniques to jointly consider overall throughput and memory limitation. Our experiments proves that the per-device activation memory effectively reduces with the total number of stages, making PP a stronger alternative than TP, offering up to a 19\% acceleration with even lower memory consumption.","Pipeline parallelism (PP) is a commonly used technique for training large language models (LLMs). However, its scalability is often limited by high activation memory demands. This study addresses that limitation by exploring the use of memory offloading — moving activations temporarily to lower-cost memory — within the context of PP. Through extensive experiments, the paper shows that in most typical settings, at least half, and sometimes all, of the activation data can be offloaded with minimal performance impact. In cases where full offloading is not feasible, we introduce a new selective offloading strategy that reduces peak memory usage more efficiently than previous methods. By integrating offloading with other optimization techniques, the paper demonstrates improved training speed and reduced memory consumption. Our findings suggest that as the number of pipeline stages increases, the memory required per device decreases significantly. As a result, pipeline parallelism becomes a more attractive and efficient alternative to tensor parallelism, achieving up to a 19% increase in training speed while using less memory."
Poster,PISA Experiments: Exploring Physics Post-Training for Video Diffusion Models by Watching Stuff Drop,https://ICML.cc//virtual/2025/poster/45288,"Chenyu Li, Oscar Michel, Xichen Pan, Sainan Liu, Mike Roberts, Saining Xie","Large-scale pre-trained video generation models excel in content creation but are not reliable as physically accurate world simulators out of the box. This work studies the process of post-training these models for accurate world modeling through the lens of the simple, yet fundamental, physics task of modeling object freefall. We show state-of-the-art video generation models struggle with this basic task, despite their visually impressive outputs. To remedy this problem, we find that fine-tuning on a relatively small amount of simulated videos is effective in inducing the dropping behavior in the model, and we can further improve results through a novel reward modeling procedure we introduce. Our study also reveals key limitations of post-training in generalization and distribution modeling. Additionally, we release a benchmark for this task that may serve as a useful diagnostic tool for tracking physical accuracy in large-scale video generative model development. Code is available at this repository: https://github.com/vision-x-nyu/pisa-experiments.","Artificial intelligence can now create realistic-looking videos, but it still doesn’t fully understand how the real world works. For example, if you ask a computer to generate a video of an object falling, it might make it look good—but the object might not fall the way it would in real life.In this work, we focus on teaching computers to better understand simple physical rules like gravity. We do this by giving them extra practice: first, we show them some videos that follow real physics, and then we gently correct their mistakes using a special scoring system that rewards more realistic behavior.Even with this training, we find that these programs can still make errors in new situations. To help researchers check how well these systems understand physics, we’ve also built a testing tool and made everything publicly available online."
Poster,Pivoting Factorization: A Compact Meta Low-Rank Representation of Sparsity for Efficient Inference in Large Language Models,https://ICML.cc//virtual/2025/poster/46433,"Jialin Zhao, Yingtao Zhang, Carlo Cannistraci","The rapid growth of Large Language Models has driven demand for effective model compression techniques to reduce memory and computation costs. Low-rank pruning has gained attention for its GPU compatibility across all densities. However, low-rank pruning struggles to match the performance of semi-structured pruning, often doubling perplexity at similar densities. In this paper, we propose **Pi**voting **Fa**ctorization (**PIFA**), a novel **lossless** meta low-rank representation that unsupervisedly learns a **compact** form of any low-rank representation, effectively eliminating redundant information. PIFA identifies pivot rows (linearly independent rows) and expresses non-pivot rows as linear combinations, achieving **24.2\%** additional memory savings and **24.6\%** faster inference over low-rank layers at rank = 50\% of dimension. To mitigate the performance degradation caused by low-rank pruning, we introduce a novel, retraining-free reconstruction method that **m**inimizes error accumulation (**M**). **MPIFA**, combining M and PIFA into an end-to-end framework, significantly outperforms existing low-rank pruning methods, and achieves performance comparable to semi-structured pruning, while surpassing it in GPU efficiency and compatibility. Our code is available at https://github.com/biomedical-cybernetics/pivoting-factorization.","Large language models like ChatGPT are incredibly powerful but also massive, requiring enormous memory and computation to run. Compressing these models helps make them faster and cheaper to use, but current techniques either depend on specialized hardware or lead to worse performance. Our research introduces a new compression method called MPIFA, which combines two ideas: a reconstruction method that prevents errors from piling up, and a new matrix math technique (called pivoting factorization) that removes hidden redundancies in compressed model layers—without losing information. Unlike existing methods, MPIFA works on any hardware and maintains the model’s performance while significantly improving memory and speed. We tested MPIFA on popular models like LLaMA and found that it matches the performance of specialized pruning techniques, while running faster and using less memory. This means AI models could soon become more accessible and efficient across a wide range of devices, from laptops to data centers."
Poster,Pixel2Feature Attack (P2FA): Rethinking the Perturbed Space to Enhance Adversarial Transferability,https://ICML.cc//virtual/2025/poster/44743,"Renpu Liu, Hao Wu, Jiawei Zhang, Xin Cheng, Xiangyang Luo, Bin Ma, Jinwei Wang","Adversarial examples have been shown to deceive Deep Neural Networks (DNNs), raising widespread concerns about this security threat. More seriously, as different DNN models share critical features, feature-level attacks can generate transferable adversarial examples, thereby deceiving black-box models in real-world scenarios. Nevertheless, we have theoretically discovered the principle behind the limited transferability of existing feature-level attacks: Their attack effectiveness is essentially equivalent to perturbing features in one step along the direction of feature importance in the feature space, despite performing multiple perturbations in the pixel space. This finding indicates that existing feature-level attacks are inefficient in disrupting features through multiple pixel-space perturbations. To address this problem, we propose a P2FA that efficiently perturbs features multiple times. Specifically, we directly shift the perturbed space from pixel to feature space. Then, we perturb the features multiple times rather than just once in the feature space with the guidance of feature importance to enhance the efficiency of disrupting critical shared features. Finally, we invert the perturbed features to the pixels to generate more transferable adversarial examples. Numerous experimental results strongly demonstrate the superior transferability of P2FA over State-Of-The-Art (SOTA) attacks.","Deep neural networks can be tricked by ""adversarial examples""—slightly altered inputs that cause errors. However, existing methods for creating these examples are inefficient, as they disrupt key features by modifying images at the pixel level.We propose a new method, P2FA, which directly targets and disrupts these key features multiple times within the feature space, significantly improving attack effectiveness.P2FA generates adversarial examples that more effectively deceive various AI models, surpassing the best existing methods. Our research exposes weaknesses in AI systems, helping developers create safer, more reliable models to protect AI-dependent technologies from real-world threats."
Poster,Pixel-level Certified Explanations via Randomized Smoothing,https://ICML.cc//virtual/2025/poster/45484,"Alaa Anani, Tobias Lorenz, Mario Fritz, Bernt Schiele","Post-hoc attribution methods aim to explain deep learning predictions by highlighting influential input pixels. However, these explanations are highly non-robust: small, imperceptible input perturbations can drastically alter the attribution map while maintaining the same prediction. This vulnerability undermines their trustworthiness and calls for rigorous robustness guarantees of pixel-level attribution scores. We introduce the first certification framework that guarantees pixel-level robustness for any black-box attribution method using randomized smoothing. By sparsifying and smoothing attribution maps, we reformulate the task as a segmentation problem and certify each pixel's importance against $\ell_2$-bounded perturbations. We further propose three evaluation metrics to assess certified robustness, localization, and faithfulness. An extensive evaluation of 12 attribution methods across 5 ImageNet models shows that our certified attributions are robust, interpretable, and faithful, enabling reliable use in downstream tasks. Our code is at [https://github.com/AlaaAnani/certified-attributions](https://github.com/AlaaAnani/certified-attributions).","When AI models make decisions, like identifying objects in images, we often try to understand why by looking at which parts of the image influenced the prediction. But these explanations can be unreliable: even tiny, invisible changes to the image can completely change what the AI says is important, even though its answer doesn’t change. We’ve developed a new method that makes these explanations much more stable and trustworthy. It works with any existing explanation technique and shows which parts of an image truly matter, even if the image is slightly altered. We also created new ways to measure how reliable and useful these explanations are. Our tests on many AI models show that our approach makes AI explanations clearer, more consistent, and safer to use in real applications."
Poster,Plan-and-Act: Improving Planning of Agents for Long-Horizon Tasks,https://ICML.cc//virtual/2025/poster/43522,"Lutfi Erdogan, Hiroki Furuta, Sehoon Kim, Nicholas Lee, Suhong Moon, Gopala Anumanchipalli, Kurt Keutzer, Amir Gholaminejad","Large language models (LLMs) have shown remarkable advancements in enabling language agents to tackle simple tasks. However, applying them for complex, multi-step, long-horizon tasks remains a challenge. Recent work have found success by separating high-level planning from low-level execution, which enables the model to effectively balance high-level planning objectives and low-level execution details. However, generating accurate plans remains difficult since LLMs are not inherently trained for this task. To address this, we propose Plan-and-Act, a novel framework that incorporates explicit planning into LLM-based agents and introduces a scalable method to enhance plan generation through a novel synthetic data generation method. Plan-and-Act consists of a Planner model which generates structured, high-level plans to achieve user goals, and an Executor model that translates these plans into environment-specific actions. To train the Planner effectively, we introduce a synthetic data generation method that annotates ground-truth trajectories with feasible plans, augmented with diverse and extensive examples to enhance generalization. We evaluate Plan-and-Act using web navigation as a representative long-horizon planning environment, demonstrating a state-of-the-art 57.58% success rate on the WebArena-Lite benchmark as well as a text-only state-of-the-art 81.36% success rate on WebVoyager.","Current AI systems struggle with complex tasks that require multiple steps, like booking flights or finding information across websites. This is because they try to both plan what to do and execute detailed actions simultaneously, which often leads to confusion and mistakes.We created Plan-and-Act, a system that separates the planning process from the action execution. Like how a head chef plans a meal while line cooks execute specific tasks, our system uses one component to create high-level plans and another to carry out precise actions. We also developed methods to generate training examples that teach our system to plan effectively.Our approach significantly improves AI's ability to complete multi-step online tasks, achieving state-of-the-art performance on web navigation benchmarks. This advancement could lead to more helpful digital assistants that can navigate websites, complete online forms, or find information across multiple pages without getting lost or confused. In the future, this could make digital services more accessible to everyone, especially for complex tasks that currently require significant technical knowledge or patience."
Poster,Plausible Token Amplification for Improving Accuracy of Differentially Private In-Context Learning Based on Implicit Bayesian Inference,https://ICML.cc//virtual/2025/poster/43818,"Yusuke Yamasaki, Kenta Niwa, Daiki Chijiwa, Takumi Fukami, Takayuki Miura","We propose Plausible Token Amplification (PTA) to improve the accuracy of Differentially Private In-Context Learning (DP-ICL) using DP synthetic demonstrations. While Tang et al. empirically improved the accuracy of DP-ICL by limiting vocabulary space during DP synthetic demonstration generation, its theoretical basis remains unexplored. By interpreting ICL as implicit Bayesian inference on a concept underlying demonstrations, we not only provide theoretical evidence supporting Tang et al.'s empirical method but also introduce PTA, a refined method for modifying next-token probability distribution. Through the modification, PTA highlights tokens that distinctly represent the ground-truth concept underlying the original demonstrations. As a result, generated DP synthetic demonstrations guide the Large Language Model to successfully infer the ground-truth concept, which improves the accuracy of DP-ICL. Experimental evaluations on both synthetic and real-world text-classification datasets validated the effectiveness of PTA.","Large language models (LLMs) can solve tasks by showing just a few related examples in a prompt, called in-context learning (ICL). While useful, using raw examples risks leaking sensitive information. To address this, researchers rely on Differential Privacy (DP) --- a standard that limits information leakage --- by adding noise to create synthetic examples for ICL, thereby protecting the privacy of the raw examples. This method, known as DP-ICL, mitigates leakage of individual data but often degrades accuracy. Although a practical remedy exists, its effectiveness has been theoretically unclear. We offer a theoretical explanation showing that the existing remedy is reasonable, but also reveals room for improvement. On the basis of this insight, we propose Plausible Token Amplification (PTA), the first theoretically grounded approach that improves DP-ICL by generating clearer, more informative synthetic examples while preserving privacy. This enables more accurate and private use of LLMs in sensitive tasks like medical triage, legal review, or customer profiling."
