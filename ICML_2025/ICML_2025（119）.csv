type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,Gandalf the Red: Adaptive Security for LLMs,https://ICML.cc//virtual/2025/poster/44928,"Niklas Pfister, Václav Volhejn, Manuel Knott, Santiago Arias, Julia Bazinska, Mykhailo Bichurin, Alan Commike, Janet Darling, Peter Dienes, Matthew Fiedler, David Haber, Matthias Kraft, Marco Lancini, Max Mathys, Damian Pascual-Ortiz, Jakub Podolak, Adrià Romero-López, Kyriacos Shiarlis, Andreas Signer, Zsolt Terek, Athanasios Theocharis, Daniel Timbrell, Samuel Trautwein, Samuel Watts, Yun-Han Wu, Mateo Rojas-Carulla","Current evaluations of defenses against prompt attacks in large language model (LLM) applications often overlook two critical factors: the dynamic nature of adversarial behavior and the usability penalties imposed on legitimate users by restrictive defenses. We propose D-SEC (Dynamic Security Utility Threat Model), which explicitly separates attackers from legitimate users, models multi-step interactions, and expresses the security-utility in an optimizable form. We further address the shortcomings in existing evaluations by introducing Gandalf, a crowd-sourced, gamified red-teaming platform designed to generate realistic, adaptive attack. Using Gandalf, we collect and release a dataset of 279k prompt attacks. Complemented by benign user data, our analysis reveals the interplay between security and utility, showing that defenses integrated in the LLM (e.g., system prompts) can degrade usability even without blocking requests. We demonstrate that restricted application domains, defense-in-depth, and adaptive defenses are effective strategies for building secure and useful LLM applications.","A major security flaw in today’s AI systems is their inability to tell the difference between data and instructions. This opens the door for attackers to take control of systems in unexpected ways. One of the biggest open challenges is figuring out how to evaluate an AI system’s security, and how that security affects legitimate users. After all, a system that blocks everything might be secure, but it’s not useful.We bring two core contributions. First, D-SEC, a new evaluation framework that balances how well a system defends against attackers with how it affects normal users. It also accounts for the fact that attackers adapt and learn over time.Second, we introduce Gandalf, a crowdsourced game where players try to trick AI systems. This lets us study creative, real-world attacks, and test defenses using D-SEC.We found that many application defenses unintentionally hurt the user experience. Based on our research, we identify three strategies for building secure and usable AI: limit what the system can do, layer defenses, and use adaptive protections. To support the community, we’ve released a dataset of nearly 300,000 human-generated attacks to drive future work on secure, reliable AI."
Poster,GANQ: GPU-Adaptive Non-Uniform Quantization for Large Language Models,https://ICML.cc//virtual/2025/poster/43984,"Pengxiang Zhao, Xiaoming Yuan","Large Language Models (LLMs) face significant deployment challenges due to their substantial resource requirements. While low-bit quantized weights can reduce memory usage and improve inference efficiency, current hardware lacks native support for mixed-precision General Matrix Multiplication (mpGEMM), resulting in inefficient dequantization-based implementations. Moreover, uniform quantization methods often fail to capture weight distributions adequately, leading to performance degradation. We propose GANQ (GPU-Adaptive Non-Uniform Quantization), a layer-wise post-training non-uniform quantization framework optimized for hardware-efficient lookup table-based mpGEMM. GANQ achieves superior quantization performance by utilizing a training-free, GPU-adaptive optimization algorithm to  efficiently reduce layer-wise quantization errors. Extensive experiments demonstrate GANQ's ability to reduce the perplexity gap from the FP16 baseline compared to state-of-the-art methods for both 3-bit and 4-bit quantization. Furthermore, when deployed on a single NVIDIA RTX 4090 GPU, GANQ's quantized models achieve up to 2.57$\times$ speedup over the baseline, advancing memory and inference efficiency in LLM deployment.","Large language models (LLMs) are powerful but require substantial computing resources, making them expensive to operate., This poses a significant barrier to their widespread use. A common solution is quantization which reduces the precision of model weights to save memory, but current methods face hardware inefficiencies and accuracy issues. To address these challenges, we developed GANQ, a layer-wise post-training non-uniform quantization framework optimized for lookup-table (LUT)-based inference. This method replaces complex computations with simple table lookups, allowing GANQ to determine effective low-bit representations for LUTs. Unlike existing heuristic approaches, GANQ mathematically minimizes errors layer by layer and decomposes the optimization task into independent subproblems, allowing for parallel processing on GPUs and enhancing computational efficiency. This innovative approach reduces memory usage and accelerates inference, enabling larger and faster LLMs to run on everyday hardware. By making advanced AI more practical and accessible, GANQ represents a significant advancement in the field."
Poster,Gap-Dependent Bounds for Federated $Q$-Learning,https://ICML.cc//virtual/2025/poster/46668,"Haochen Zhang, Zhong Zheng, Lingzhou Xue","We present the first gap-dependent analysis of regret and communication cost for on-policy federated $Q$-Learning in tabular episodic finite-horizon Markov decision processes (MDPs). Existing FRL methods focus on worst-case scenarios, leading to $\sqrt{T}$-type regret bounds and communication cost bounds with a $\log T$ term scaling with the number of agents $M$, states $S$, and actions $A$, where $T$ is the average total number of steps per agent. In contrast, our novel framework leverages the benign structures of MDPs, such as a strictly positive suboptimality gap, to achieve a $\log T$-type regret bound and a refined communication cost bound that disentangles exploration and exploitation. Our gap-dependent regret bound reveals a distinct multi-agent speedup pattern, and our gap-dependent communication cost bound removes the dependence on $MSA$ from the $\log T$ term. Notably, our gap-dependent communication cost bound also yields a better global switching cost when $M=1$, removing $SA$ from the $\log T$ term.","Existing theoretical analyses of federated reinforcement learning (FRL) algorithms don't fully capture their real-world effectiveness. While these methods show strong performance in practice, their mathematical guarantees remain overly conservative, especially in scenarios where some actions are clearly better than others.We present a new analysis revealing the hidden efficiency of standard FRL approaches. By accounting for natural structures in learning problems—particularly the difference between optimal and non-optimal decisions—we show these methods converge much faster and require far less coordination than previously proven. Our work provides precise mathematical characterization of how exploration and exploitation phases contribute to overall performance.This research bridges the gap between theory and practice, explaining why these algorithms work so well in real applications. Our results demonstrate these methods scale remarkably well with multiple learners, supporting their use in privacy-sensitive areas like healthcare and robotics."
Poster,GAPrompt: Geometry-Aware Point Cloud Prompt for 3D Vision Model,https://ICML.cc//virtual/2025/poster/46482,"Zixiang Ai, Zichen Liu, Yuanhang Lei, Zhenyu Cui, Xu Zou, Jiahuan Zhou","Pre-trained 3D vision models have gained significant attention for their promising performance on point cloud data. However, fully fine-tuning these models for downstream tasks is computationally expensive and storage-intensive. Existing parameter-efficient fine-tuning (PEFT) approaches, which focus primarily on input token prompting, struggle to achieve competitive performance due to their limited ability to capture the geometric information inherent in point clouds. To address this challenge, we propose a novel Geometry-Aware Point Cloud Prompt (GAPrompt) that leverages geometric cues to enhance the adaptability of 3D vision models. First, we introduce a Point Prompt that serves as an auxiliary input alongside the original point cloud, explicitly guiding the model to capture fine-grained geometric details. Additionally, we present a Point Shift Prompter designed to extract global shape information from the point cloud, enabling instance-specific geometric adjustments at the input level. Moreover, our proposed Prompt Propagation mechanism incorporates the shape information into the model's feature extraction process, further strengthening its ability to capture essential geometric characteristics. Extensive experiments demonstrate that GAPrompt significantly outperforms state-of-the-art PEFT methods and achieves competitive results compared to full fine-tuning on various benchmarks, while utilizing only 2.19\% of trainable parameters.","Pre-trained 3D vision models have gained significant attention for their promising performance on point cloud data. However, fully fine-tuning these models for downstream tasks is computationally expensive and storage-intensive. Existing parameter-efficient fine-tuning (PEFT) approaches, which focus primarily on input token prompting, struggle to achieve competitive performance due to their limited ability to capture the geometric information inherent in point clouds. To address this challenge, we propose a novel Geometry-Aware Point Cloud Prompt (GAPrompt) that leverages geometric cues to enhance the adaptability of 3D vision models. Extensive experiments demonstrate that GAPrompt significantly outperforms state-of-the-art PEFT methods and achieves competitive results compared to full fine-tuning on various benchmarks, while utilizing only 2.19\% of trainable parameters."
Poster,Gaussian Mixture Flow Matching Models,https://ICML.cc//virtual/2025/poster/46040,"Hansheng Chen, Kai Zhang, Hao Tan, Zexiang Xu, Fujun Luan, Leonidas Guibas, Gordon Wetzstein, Sai Bi","Diffusion models approximate the denoising distribution as a Gaussian and predict its mean, whereas flow matching models reparameterize the Gaussian mean as flow velocity. However, they underperform in few-step sampling due to discretization error and tend to produce over-saturated colors under classifier-free guidance (CFG). To address these limitations, we propose a novel Gaussian mixture flow matching (GMFlow) model: instead of predicting the mean, GMFlow predicts dynamic Gaussian mixture (GM) parameters to capture a multi-modal flow velocity distribution, which can be learned with a KL divergence loss. We demonstrate that GMFlow generalizes previous diffusion and flow matching models where a single Gaussian is learned with an $L_2$ denoising loss. For inference, we derive GM-SDE/ODE solvers that leverage analytic denoising distributions and velocity fields for precise few-step sampling. Furthermore, we introduce a novel probabilistic guidance scheme that mitigates the over-saturation issues of CFG and improves image generation quality. Extensive experiments demonstrate that GMFlow consistently outperforms flow matching baselines in generation quality, achieving a Precision of 0.942 with only 6 sampling steps on ImageNet 256$\times$256.","Image generation models like diffusion and flow matching have revolutionized digital content creation but still face challenges. They often need many computational steps to generate high-quality images and tend to produce overly vivid, unrealistic colors when guided to follow specific styles or prompts.To address these issues, we developed Gaussian Mixture Flow Matching (GMFlow). Unlike previous methods that predict only one possible outcome for each step of image creation, GMFlow predicts multiple possible outcomes simultaneously, capturing a richer set of variations through something called a Gaussian mixture. We then designed specialized algorithms to efficiently generate high-quality images with fewer steps and less computational effort. Additionally, we introduced a probabilistic approach to better control image styles, reducing unrealistic colors.Our method significantly improves image generation quality, producing clearer, more realistic images faster. This advancement means generating high-quality visuals becomes quicker and more reliable, benefiting applications ranging from digital art to realistic virtual environments."
Poster,GaussMark: A Practical Approach for Structural Watermarking of Language Models,https://ICML.cc//virtual/2025/poster/44921,"Adam Block, Alexander Rakhlin, Ayush Sekhari","Watermarking, the process by which Large Language Model (LLM) servers imbed an imperceptible signal at inference time in order to detect text generated by their own models, has grown in importance due to the significant improvements in natural language processing tasks by modern LLMs. Current approaches are often impractical due to generation latency, detection time, degradation in text quality, or robustness; such problems often arise due to the focus on token level watermarking, which ignores the inherent structure of text. In this work, we introduce a new scheme, GaussMark, that is simple and efficient to implement, has formal statistical guarantees, comes at no cost in generation latency, and embeds the watermark into the weights of the model itself, providing a structural watermark. Our approach is based on Gaussian independence testing and is motivated by recent empirical observations that minor additive corruptions to LLM weights can result in models of identical (or even improved) quality. We provide formal statistical bounds on the validity and power of our procedure and, through an extensive suite of experiments, demonstrate that GaussMark is reliable, efficient, relatively robust to corruption, and can be instantiated with essentially no loss in model quality.","As AI models become better at writing human-like content, it is getting harder to tell whether a piece of text was written by a human or by a language model. This creates challenges in areas like education, journalism, and law, where it can be important to know who actually created the content. This research introduces a new method called GaussMark that helps identify when a text has been written by a language model. Instead of changing the text sampling process itself (like previous approaches did), GaussMark works by slightly adjusting the weights of the language model in a way that leaves behind a hidden signal. This signal can later be detected, showing that the text came from that specific model. The method is fast, easy to use, and does not harm the quality or speed of the text generation. It is also based on sound statistical reasoning, which means it can provide strong evidence that a piece of text was created by a specific language model. In summary, GaussMark offers a reliable and efficient way to track the origin of AI-generated text, making these powerful tools more trustworthy and responsible."
Poster,GaussMarker: Robust Dual-Domain Watermark for Diffusion Models,https://ICML.cc//virtual/2025/poster/44171,"Kecen Li, Zhicong Huang, Xinwen Hou, Cheng Hong","As Diffusion Models (DM) generate increasingly realistic images, related issues such as copyright and misuse have become a growing concern. Watermarking is one of the promising solutions. Existing methods inject the watermark into the *single-domain* of initial Gaussian noise for generation, which suffers from unsatisfactory robustness. This paper presents the first *dual-domain* DM watermarking approach using a pipelined injector to consistently embed watermarks in both the spatial and frequency domains. To further boost robustness against certain image manipulations and advanced attacks, we introduce a model-independent learnable Gaussian Noise Restorer (GNR) to refine Gaussian noise extracted from manipulated images and enhance detection robustness by integrating the detection scores of both watermarks.GaussMarker efficiently achieves state-of-the-art performance under eight image distortions and four advanced attacks across three versions of Stable Diffusion with better recall and lower false positive rates, as preferred in real applications.","As AI-generated images become more realistic, concerns about their misuse and copyright issues are growing. One way to address this is by embedding invisible watermarks into the images. Most current methods only add watermarks in one part of the image generation process — the so-called “noise image” — but these watermarks can be easily removed or broken by simple image edits.In this work, we introduce GaussMarker, the first method that embeds watermarks in two domains: both in the spatial structure and frequency patterns of the noise used to generate images. We also design a tool called Gaussian Noise Restorer (GNR) that helps recover and verify watermarks even after the image has been edited.Our approach works across different versions of popular image-generating models like Stable Diffusion, offering stronger protection with high accuracy and fewer false alarms — making it well-suited for real-world use. We believe that our approach can mitigate issues such as copyright infringement and misuse associated with DM, thereby promoting the development of trustworthy generative AI."
Poster,GCAL: Adapting Graph Models to Evolving Domain Shifts,https://ICML.cc//virtual/2025/poster/43474,"Ziyue Qiao, Qianyi Cai, Hao Dong, Jiawei Gu, Pengyang Wang, Meng Xiao, Xiao Luo, Hui Xiong","This paper addresses the challenge of graph domain adaptation on evolving, multiple out-of-distribution (OOD) graphs.Conventional graph domain adaptation methods are confined to single-step adaptation, making them ineffective in handling continuous domain shifts and prone to catastrophic forgetting. This paper introduces the Graph Continual Adaptive Learning (GCAL) method, designed to enhance model sustainability and adaptability across various graph domains. GCAL employs a bilevel optimization strategy. The ""adapt"" phase uses an information maximization approach to fine-tune the model with new graph domains while re-adapting past memories to mitigate forgetting. Concurrently, the ""generate memory"" phase, guided by a theoretical lower bound derived from information bottleneck theory, involves a variational memory graph generation module to condense original graphs into memories. Extensive experimental evaluations demonstrate that GCAL substantially outperforms existing methods in terms of adaptability and knowledge retention.","Many real-world networks—like social networks or recommendation systems—keep changing over time, so models trained on past data often struggle to work well on new, different graphs and tend to forget what they learned before. We introduce GCAL, a two-phase approach that alternates between “adapt,” where the model fine-tunes itself on incoming graph domains while re-visiting past memories to avoid forgetting, and “generate memory,” where a compact memory of the new graph data is created. Think of it like teaching someone new topics while making sure they remember what they already knew. This makes GCAL a promising step toward long-lasting, flexible graph learning in dynamic environments."
Poster,G-Designer: Architecting Multi-agent Communication Topologies via Graph Neural Networks,https://ICML.cc//virtual/2025/poster/45567,"Guibin Zhang, Yanwei Yue, Xiangguo Sun, Guancheng Wan, Miao Yu, Junfeng Fang, Kun Wang, Tianlong Chen, Dawei Cheng","Recent advancements in large language model (LLM)-based agents have demonstrated that collective intelligence can significantly surpass the capabilities of individual agents, primarily due to well-crafted inter-agent communication topologies. Despite the diverse and high-performing designs available, practitioners often face confusion when selecting the most effective pipeline for their specific task: \textit{Which topology is the best choice for my task, avoiding unnecessary communication token overhead while ensuring high-quality solution?} In response to this dilemma, we introduce G-Designer, an adaptive, efficient, and robust solution for multi-agent deployment, which dynamically designs task-aware, customized communication topologies. Specifically, G-Designer models the multi-agent system as a multi-agent network, leveraging a variational graph auto-encoder to encode both the nodes (agents) and a task-specific virtual node, and decodes a task-adaptive and high-performing communication topology. Extensive experiments on six benchmarks showcase that G-Designer is: \textbf{(1) high-performing}, achieving superior results on MMLU with accuracy at $84.50\\%$ and on HumanEval with pass@1 at $89.90\\%$; \textbf{(2) task-adaptive}, architecting communication protocols tailored to task difficulty, reducing token consumption by up to $95.33\\%$ on HumanEval; and \textbf{(3) adversarially robust}, defending against agent adversarial attacks with merely $0.3\\%$ accuracy drop.",G-Designer makes the first attempt to employ graph neural networks (GNNs) for constructing query-specific and task-adaptive large language model (LLM)-based multi-agent systems.
Poster,GEFA: A General Feature Attribution Framework Using Proxy Gradient Estimation,https://ICML.cc//virtual/2025/poster/45304,"Yi Cai, Thibaud Ardoin, Gerhard Wunder","Feature attribution explains machine decisions by quantifying each feature's contribution.While numerous approaches rely on exact gradient measurements, recent work has adopted gradient estimation to derive explanatory information under query-level access, a restrictive yet more practical accessibility assumption known as the black-box setting.Following this direction, this paper introduces GEFA (Gradient-estimation-based Explanation For All), a general feature attribution framework leveraging proxy gradient estimation.Unlike the previous attempt that focused on explaining image classifiers, the proposed explainer derives feature attributions in a proxy space, making it generally applicable to arbitrary black-box models, regardless of input type.In addition to its close relationship with Integrated Gradients, our approach, a path method built upon estimated gradients, surprisingly produces unbiased estimates of Shapley Values.Compared to traditional sampling-based Shapley Value estimators, GEFA avoids potential information waste sourced from computing marginal contributions, thereby improving explanation quality, as demonstrated in quantitative evaluations across various settings.","Understanding why and how AI models make decisions is crucial, especially in critical scenarios such as healthcare or finance.This work aims to bring transparency to AI-supported systems by uncovering which parts of the input the AI is ""looking at"" when making up its mind -- a fundamental step toward the explainability of AI behavior.To achieve this, we analyze the observations of AI outcomes and summarize the patterns to determine the supporting evidence. Further endeavors are devoted to improving the explanation process for efficiency and reliability. As a result, we develop GEFA, a general-purpose tool for explaining AI decisions. The proposed solution is designed to work across various types of models and data, enhancing its generalizability. We believe that GEFA can serve as a valuable tool to support tasks such as debugging AI models, monitoring their behavior, and guiding future developments with more insights into the existing AI systems."
