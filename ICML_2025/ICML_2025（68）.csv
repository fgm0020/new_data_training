type,name,virtualsite_url,speakers/authors,abstract,lay_summary
Poster,DeepLayout: Learning Neural Representations of Circuit Placement Layout,https://ICML.cc//virtual/2025/poster/44975,"Yuxiang Zhao, zhuomin chai, Xun Jiang, Qiang Xu, Runsheng Wang, Yibo Lin","Recent advancements have integrated various deep-learning methodologies into physical design, aiming for workflows acceleration and surpasses human-devised solutions. However, prior research has primarily concentrated on developing task-specific networks, which necessitate a significant investment of time to construct large, specialized datasets, and the unintended isolation of models across different tasks. In this paper, we introduce DeepLayout, the first general representation learning framework specifically designed for backend circuit design. To address the distinct characteristics of post-placement circuits, including topological connectivity and geometric distribution, we propose a hybrid encoding architecture that integrates GNN with spatial transformers. Additionally, the framework includes a flexible decoder module that accommodates a variety of task types, supporting multiple hierarchical outputs such as nets and layouts. To mitigate the high annotation costs associated with layout data, we introduce a mask-based self-supervised learning approach designed explicitly for layout representation. This strategy involves a carefully devised masking approach tailored to layout features, precise reconstruction guidance, and most critically—two key supervised learning tasks. We conduct extensive experiments on large-scale industrial datasets, demonstrating that DeepLayout surpasses state-of-the-art (SOTA) methods specialized for individual tasks on two crucial layout quality assessment benchmarks. The experiment results underscore the framework’s robust capability to learn the intrinsic properties of circuits.","Designing computer chips involves complex backend tasks like optimizing circuit layouts for performance and manufacturability. Today, specialized AI models are built for each task—requiring huge, expensive datasets and limiting shared knowledge. We ask: Can one versatile AI framework learn the fundamentals of chip layouts to handle multiple tasks efficiently?We introduce DeepLayout, the first general AI framework for backend circuit design. It learns a unified understanding of circuits by analyzing both their connectivity (like a wiring) and physical placement using a hybrid neural network. Crucially, it avoids costly manual data labeling with a layout-oriented self-supervised training technique: we mask parts of the layout and train the framework to reconstruct them, helping it learn intrinsic circuit properties. The framework then adapts flexibly to diverse tasks.Surprisingly, DeepLayout outperformed specialized state-of-the-art tools on critical industrial benchmarks for predicting circuit quality, despite being a generalist. By learning the universal representation of layouts, it effectively predicts chip designs' performance while reducing data costs."
Poster,"Deep Linear Network Training Dynamics from Random Initialization: Data, Width, Depth, and Hyperparameter Transfer",https://ICML.cc//virtual/2025/poster/45234,"Blake Bordelon, Cengiz Pehlevan","We theoretically characterize gradient descent dynamics in deep linear networks trained at large width from random initialization and on large quantities of random data. Our theory captures the ``wider is better"" effect of mean-field/maximum-update parameterized networks as well as hyperparameter transfer effects, which can be contrasted with the neural-tangent parameterization where optimal learning rates shift with model width. We provide asymptotic descriptions of both non-residual and residual neural networks, the latter of which enables an infinite depth limit when branches are scaled as $1/\sqrt{\text{depth}}$. We also compare training with one-pass stochastic gradient descent to the dynamics when training data are repeated at each iteration. Lastly, we show that this model recovers the accelerated power law training dynamics for power law structured data in the rich regime observed in recent works.","Methods that scale up neural networks in a way that preserves certain properties of training can reduce the need for retuning hyperparameters at each model size. One popular approach to this is to increasing the width and depth of a neural network in maximum-update ($\mu$P) scaling. Prior works have empirically shown that (1) wider networks perform better in $\mu$P and (2) that optimal learning rates are approximately constant across widths & depths. However, to date no theory has been proposed that can capture this effect. In this work, we develop a minimal theory of the learning rate transfer effect in randomly initialized deep linear networks. Our theory captures both (1) arbitrarily large deviations from lazy learning and (2) the harmful finite width effects. Our theory accurately captures the failure of hyperparameter transfer in NTK scaling and the success of hyperparameter transfer across widths and depths in $\mu$P with $1/\sqrt{\text{depth}}$ residual branch scaling. Our results are based on a dynamical mean field theory approach, where the finite width effects and SGD noise effects gradually build up over training time and corrupt the dynamics of finite models compared to infinite width models."
Poster,Deep Neural Cellular Potts Models,https://ICML.cc//virtual/2025/poster/46513,"Koen Minartz, Tim d&#x27;Hondt, Leon Hillmann, Jörn Starruß, Lutz Brusch, Vlado Menkovski","The cellular Potts model (CPM) is a powerful computational method for simulating collective spatiotemporal dynamics of biological cells.To drive the dynamics, CPMs rely on physics-inspired Hamiltonians. However, as first principles remain elusive in biology, these Hamiltonians only approximate the full complexity of real multicellular systems.To address this limitation, we propose NeuralCPM, a more expressive cellular Potts model that can be trained directly on observational data.At the core of NeuralCPM lies the Neural Hamiltonian, a neural network architecture that respects universal symmetries in collective cellular dynamics.Moreover, this approach enables seamless integration of domain knowledge by combining known biological mechanisms and the expressive Neural Hamiltonian into a hybrid model.Our evaluation with synthetic and real-world multicellular systems demonstrates that NeuralCPM is able to model cellular dynamics that cannot be accounted for by traditional analytical Hamiltonians.","Researchers in the life sciences use the cellular Potts model (CPM) to simulate (parts of) a living organism, for instance to find out how biological cells interact and collectively achieve a well-proportioned and functional body plan. So far, it has been difficult to set up and gradually improve the interaction formulas, termed Hamiltonians, inside such a CPM, as thousands of different types of molecules contribute to cell-cell interactions in unexplored ways. To address this challenge, we propose NeuralCPM, a CPM with a Neural Hamiltonian as interaction formula. The Neural Hamiltonian is a neural network that can be trained directly on experimental data like microscopy videos. This approach guarantees fundamental physical and biological properties, thanks to the embedding into the CPM formalism, but now allows for realistic simulations of complex processes as we demonstrate for synthetic and real biological experiments."
Poster,Deep Principal Support Vector Machines for Nonlinear Sufficient Dimension Reduction,https://ICML.cc//virtual/2025/poster/43795,"YinFeng Chen, Jin Liu, Rui Qiu","The normal vectors obtained from the support vector machine (SVM) method offer the potential to achieve sufficient dimension reduction in both classification and regression scenarios. Motivated by it, we in this paper introduce a unified framework for nonlinear sufficient dimension reduction based on classification ensemble. Kernel principal SVM, which leverages the reproducing kernel Hilbert space, can almost be regarded as a special case of this framework, and we generalize it by using a neural network function class for more flexible deep nonlinear reduction. We theoretically prove its unbiasedness with respect to the central $\sigma$-field and provide a nonasymptotic upper bound for the estimation error. Simulations and real data analysis demonstrate the considerable competitiveness of the proposed method, especially under heavy data contamination, large sample sizes, and complex inputs.","In many real-world problems, data can be noisy, making it difficult to identify the most important information. Inspired by how support vector machines (SVMs) detect key patterns, we propose a general framework to achieve more efficient dimension reduction using multiple SVMs. This approach helps isolate the most informative structures within the data.To increase flexibility, we incorporate neural networks, which are well-known for adapting to complex problems. By combining these tools, we can learn meaningful representations that capture both linear and nonlinear relationships. Our method performs well in both theoretical analysis and practical experiments. Overall, it represents a promising step toward making complex data easier to understand and analyze efficiently."
Poster,Deep Reinforcement Learning from Hierarchical Preference Design,https://ICML.cc//virtual/2025/poster/43978,"Alexander Bukharin, Yixiao Li, Pengcheng He, Tuo Zhao","Reward design is a fundamental, yet challenging aspect of reinforcement learning (RL). Researchers typically utilize feedback signals from the environment to handcraft a reward function, but this process is not always effective due to the varying scale and intricate dependencies of the feedback signals. This paper shows by exploiting certain structures, one can ease the reward design process. Specifically, we propose a hierarchical reward design framework -- HERON for scenarios: (I) The feedback signals naturally present hierarchy; (II) The reward is sparse, but with less important surrogate feedback to help policy learning. Both scenarios allow us to design a hierarchical decision tree induced by the importance ranking of the feedback signals to compare RL trajectories. With such preference data, we can then train a reward model for policy learning. We apply HERON to several RL applications, and we find that our framework can not only train high performing agents on a variety of difficult tasks, but also provide additional benefits such as improved sample efficiency and robustness.","When training AI agents we typically need to construct a reward function, which tells the agent whether they are doing a task well or poorly. Such reward functions are usually constructed by combining several feedback signals such as correctness, cost, and safety into the final reward. However, current methods for designing reward functions are often inflexible and tedious. In order to ease the reward design process, we propose HERON, which constructs the reward with a hierarchical relationship between the different feedback signals. HERON allows us to design flexible reward functions very easily. Experimental results show HERON can be used to train high performing agents in a wide variety of tasks."
Poster,Deep Ridgelet Transform and Unified Universality Theorem for Deep and Shallow Joint-Group-Equivariant Machines,https://ICML.cc//virtual/2025/poster/45702,"Sho Sonoda, Yuka Hashimoto, Isao Ishikawa, Masahiro Ikeda","We present a constructive universal approximation theorem for learning machines equipped with joint-group-equivariant feature maps, called the joint-equivariant machines, based on the group representation theory. ``Constructive'' here indicates that the distribution of parameters is given in a closed-form expression known as the ridgelet transform. Joint-group-equivariance encompasses a broad class of feature maps that generalize classical group-equivariance. Particularly, fully-connected networks are *not* group-equivariant *but* are joint-group-equivariant. Our main theorem also unifies the universal approximation theorems for both shallow and deep networks. Until this study, the universality of deep networks has been shown in a different manner from the universality of shallow networks, but our results discuss them on common ground. Now we can understand the approximation schemes of various learning machines in a unified manner. As applications, we show the constructive universal approximation properties of four examples: depth-$n$ joint-equivariant machine, depth-$n$ fully-connected network, depth-$n$ group-convolutional network, and a new depth-$2$ network with quadratic forms whose universality has not been known.","We have obtained a new formula that is applicable to a variety of neural networks. The formula indicates how to assign the network parameters for the network to acquire an objective function. Before this study, such an assignment was either obtained by a black-box machine learning process or hand-crafted by experts case-by-case. Now not only an expert but students can code by using our formula."
Poster,Deep Streaming View Clustering,https://ICML.cc//virtual/2025/poster/45814,"Honglin Yuan, Xingfeng Li, Jian Dai, Xiaojian You, Yuan Sun, Zhenwen Ren","Existing deep multi-view clustering methods have demonstrated excellent performance, which addressing issues such as missing views and view noise. But almost all existing methods are within a static framework, which assumes that all views have already been collected. However, in practical scenarios, new views are continuously collected over time, which forms the stream of views. Additionally, there exists the data imbalance of quality and distribution between different view streams, i.e., concept drift problem. To this end, we propose a novel Deep Streaming View Clustering (DSVC) method, which mitigates the impact of concept drift on streaming view clustering. Specifically, DSVC consists of a knowledge base and three core modules. Through the knowledge aggregation learning module, DSVC extracts representative features and prototype knowledge from the new view. Subsequently, the distribution consistency learning module aligns the prototype knowledge from the current view with the historical knowledge distribution to mitigate the impact of concept drift. Then, the knowledge guidance learning module leverages the prototype knowledge to guide the data distribution and enhance the clustering structure. Finally, the prototype knowledge from the current view is updated in the knowledge base to guide the learning of subsequent views. Extensive experiments demonstrate that, even in dynamic environments, the clustering performance of DSVC outperforms 12 state-of-the-art DMVC methods under static frameworks.","Existing deep multi-view clustering methods typically assume that all view data is fully collected before training. In contrast, we aim to achieve clustering in dynamic scenarios, where multi-view data are continuously collected over time and need to be processed in a timely manner. However, due to the distributional discrepancies among different views, it is essential to address and mitigate such inter-view distribution shifts to ensure an effective multi-view cluster. We first design a historical knowledge base to store prototype knowledge extracted from the previous view. Subsequently, we introduce a knowledge extraction module that derives representative prototype knowledge from the current view to capture its underlying distribution. Finally, we align the prototype knowledge extracted from the current view with that stored in the historical knowledge base. The aligned prototypes are then employed to guide the distribution of samples in the current view. Through this process, each collected view exhibits distributional consistency, and each sample preserves intra-class commonality while maintaining inter-class diversity.Our study achieves streaming view clustering in dynamic environments. Experimental results demonstrate the effectiveness of the proposed method, which highlights its significance for advancing multi-view clustering research."
Poster,Deep Sturm–Liouville: From Sample-Based to 1D Regularization with Learnable Orthogonal Basis Functions,https://ICML.cc//virtual/2025/poster/46030,"David Vigouroux, Joseba Dalmau, Louis Béthune, Victor Boutin","Although Artificial Neural Networks (ANNs) have achieved remarkable success across various tasks, they still suffer from limited generalization. We hypothesize that this limitation arises from the traditional sample-based (0--dimensionnal) regularization used in ANNs. To overcome this, we introduce Deep Sturm-Liouville (DSL), a novel function approximator that enables continuous 1D regularization along field lines in the input space by integrating the Sturm-Liouville Theorem (SLT) into the deep learning framework. DSL defines field lines traversing the input space, along which a Sturm-Liouville problem is solved to generate orthogonal basis functions, enforcing implicit regularization thanks to the desirable properties of SLT. These basis functions are linearly combined to construct the DSL approximator. Both the vector field and basis functions are parameterized by neural networks and learned jointly. We demonstrate that the DSL formulation naturally arises when solving a Rank-1 Parabolic Eigenvalue Problem. DSL is trained efficiently using stochastic gradient descent via implicit differentiation and achieves competitive performance on diverse multivariate datasets, including high-dimensional image datasets such as MNIST and CIFAR-10.","In traditional machine learning, data is typically projected onto a predefined target representation with the goal of learning useful features. In contrast, Deep Sturm—Liouville introduces a fundamentally different perspective: inspired by fluid dynamics, we define the transformation directly within the data space itself. This novel perspective enables the design of novel regularization mechanisms. As a result, we achieve improved sample efficiency—a key indicator of better generalization."
Poster,Deep Unsupervised Hashing via External Guidance,https://ICML.cc//virtual/2025/poster/43790,"Qihong Song, XitingLiu, Hongyuan Zhu, Joey Tianyi Zhou, Xi Peng, Peng Hu","Recently, deep unsupervised hashing has gained considerable attention in image retrieval due to its advantages in cost-free data labeling, computational efficiency, and storage savings. Although existing methods achieve promising performance by leveraging inherent visual structures within the data, they primarily focus on learning discriminative features from unlabeled images through limited internal knowledge, resulting in an intrinsic upper bound on their performance. To break through this intrinsic limitation, we propose a novel method, called Deep Unsupervised Hashing with External Guidance (DUH-EG), which incorporates external textual knowledge as semantic guidance to enhance discrete representation learning. Specifically, our DUH-EG: i) selects representative semantic nouns from an external textual database by minimizing their redundancy, then matches images with them to extract more discriminative external features; and ii) presents a novel bidirectional contrastive learning mechanism to maximize agreement between hash codes in internal and external spaces, thereby capturing discrimination from both external and intrinsic structures in Hamming space. Extensive experiments on four benchmark datasets demonstrate that our DUH-EG remarkably outperforms existing state-of-the-art hashing methods.","In the digital world, quickly finding the right image from a huge collection is a big challenge. One way to do this is by using short binary codes (called “hash codes”) that help computers search faster. Many recent methods create these codes by training models directly on images without the need for human-provided labels, which saves both time and effort. However, their performance is often limited because they rely solely on the visual information within the images. To address this, we propose a novel method, called Deep Unsupervised Hashing with External Guidance (DUH-EG). Specifically, we use nouns from an external textual database to help the model better understand the content of images. By effectively compare and integrate what the model “sees” in the images with what it “knows” from nouns, it can generate more accurate and useful codes. We test our DUH-EG method on four well-known image datasets, and it clearly do better than the best methods currently available."
Poster,DEFAME: Dynamic Evidence-based FAct-checking with Multimodal Experts,https://ICML.cc//virtual/2025/poster/43719,"Tobias Braun, Mark Rothermel, Marcus Rohrbach, Anna Rohrbach","The proliferation of disinformation demands reliable and scalable fact-checking solutions. We present **D**ynamic **E**vidence-based **FA**ct-checking with **M**ultimodal **E**xperts (DEFAME), a modular, zero-shot MLLM pipeline for open-domain, text-image claim verification. DEFAME operates in a six-stage process, dynamically selecting the tools and search depth to extract and evaluate textual and visual evidence. Unlike prior approaches that are text-only, lack explainability, or rely solely on parametric knowledge, DEFAME performs end-to-end verification, accounting for images in claims *and* evidence while generating structured, multimodal reports. Evaluation on the popular benchmarks VERITE, AVeriTeC, and MOCHEG shows that DEFAME surpasses all previous methods, establishing itself as the new general state-of-the-art fact-checking system for uni- and multimodal fact-checking. Moreover, we introduce a new multimodal benchmark, ClaimReview2024+, featuring claims after the knowledge cutoff of GPT-4o, avoiding data leakage. Here, DEFAME drastically outperforms the GPT-4o baselines, showing temporal generalizability and the potential for real-time fact-checking.","Misinformation is becoming more common and harder to detect—especially when it mixes text with images. People often believe what they see, and misleading image-text combinations can quickly spread across the internet. To help address this, we built a system called DEFAME that checks whether claims found online are true or false, using both text and images.DEFAME mimics how a human fact-checker might work: it searches the web, reviews images, and cross-checks information from different sources. Unlike earlier systems that look at text alone or rely heavily on built-in memory, DEFAME uses external tools to find fresh and reliable evidence and then explains its verdict in clear, structured reports.We tested DEFAME on standard fact-checking tasks and also built a new set of recent claims, chosen to come after the time when models like GPT-4o were last updated. This is a good way to test how well a system handles fresh, real-world information. DEFAME not only beat older methods but also outperformed powerful models like GPT-4o on these newer claims. This shows that DEFAME may be better suited for keeping up with breaking news and fast-spreading misinformation."
